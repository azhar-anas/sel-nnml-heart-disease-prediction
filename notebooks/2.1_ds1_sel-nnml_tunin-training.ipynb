{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SEL-NNML Tuning - Kaggle Heart Failure Prediction Dataset**\n",
    "\n",
    "This notebook implements several tuning methods on the `Stacking Ensemble Learning with a Neural Network Meta-Learner (SEL-NNML)` model using the `Kaggle Heart Failure Prediction Dataset (KHFPD)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Global Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global configuration loaded successfully!\n",
      "Random State: 42\n",
      "Test Size: 0.2\n",
      "CV Folds: 5\n",
      "Optimization Iterations: 100\n",
      "Optimization Metric: accuracy\n",
      "Optimization Direction: maximize\n"
     ]
    }
   ],
   "source": [
    "# Random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Data splitting configuration\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Cross-validation configuration\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Hyperparameter tuning configuration\n",
    "OPTIMIZATION_ITERATIONS = 100\n",
    "OPTIMIZATION_METRIC = 'accuracy'\n",
    "OPTIMIZATION_DIRECTION='maximize'\n",
    "\n",
    "# Parallel processing configuration\n",
    "N_JOBS = -1 \n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_PATH = '../datasets/processed/ds1_kaggle_heart_clean.csv'\n",
    "TARGET_COLUMN = 'HeartDisease'\n",
    "\n",
    "print('Global configuration loaded successfully!')\n",
    "print(f'Random State: {RANDOM_STATE}')\n",
    "print(f'Test Size: {TEST_SIZE}')\n",
    "print(f'CV Folds: {CV_FOLDS}')\n",
    "print(f'Optimization Iterations: {OPTIMIZATION_ITERATIONS}')\n",
    "print(f'Optimization Metric: {OPTIMIZATION_METRIC}')\n",
    "print(f'Optimization Direction: {OPTIMIZATION_DIRECTION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src import base_model_tuning, meta_model_tuning\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 746 entries, 0 to 745\n",
      "Data columns (total 17 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              746 non-null    int64  \n",
      " 1   Sex                              746 non-null    bool   \n",
      " 2   RestingBP                        746 non-null    int64  \n",
      " 3   Cholesterol                      746 non-null    int64  \n",
      " 4   FastingBS                        746 non-null    bool   \n",
      " 5   MaxHR                            746 non-null    int64  \n",
      " 6   ExerciseAngina                   746 non-null    bool   \n",
      " 7   Oldpeak                          746 non-null    float64\n",
      " 8   HeartDisease                     746 non-null    bool   \n",
      " 9   ChestPainType_ATA                746 non-null    bool   \n",
      " 10  ChestPainType_NAP                746 non-null    bool   \n",
      " 11  RestingECG_Normal                746 non-null    bool   \n",
      " 12  ST_Slope_Flat                    746 non-null    bool   \n",
      " 13  ST_Slope_Up                      746 non-null    bool   \n",
      " 14  Male_ST_Slope_Flat               746 non-null    bool   \n",
      " 15  ChestPainType_ASY_ST_Slope_Flat  746 non-null    bool   \n",
      " 16  Male_ChestPainType_ASY           746 non-null    bool   \n",
      "dtypes: bool(12), float64(1), int64(4)\n",
      "memory usage: 38.0 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sex",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingBP",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cholesterol",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "FastingBS",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "MaxHR",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ExerciseAngina",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Oldpeak",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HeartDisease",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_ATA",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_NAP",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingECG_Normal",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ST_Slope_Flat",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ST_Slope_Up",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Male_ST_Slope_Flat",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_ASY_ST_Slope_Flat",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Male_ChestPainType_ASY",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "fc17332f-89dd-409c-874d-4f0b7194c08e",
       "rows": [
        [
         "0",
         "40",
         "True",
         "140",
         "289",
         "False",
         "172",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "1",
         "49",
         "False",
         "160",
         "180",
         "False",
         "156",
         "False",
         "1.0",
         "True",
         "False",
         "True",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "2",
         "37",
         "True",
         "130",
         "283",
         "False",
         "98",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "3",
         "48",
         "False",
         "138",
         "214",
         "False",
         "108",
         "True",
         "1.5",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "4",
         "54",
         "True",
         "150",
         "195",
         "False",
         "122",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "5",
         "39",
         "True",
         "120",
         "339",
         "False",
         "170",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "6",
         "45",
         "False",
         "130",
         "237",
         "False",
         "170",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "7",
         "54",
         "True",
         "110",
         "208",
         "False",
         "142",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "8",
         "37",
         "True",
         "140",
         "207",
         "False",
         "130",
         "True",
         "1.5",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "9",
         "48",
         "False",
         "120",
         "284",
         "False",
         "120",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "10",
         "37",
         "False",
         "130",
         "211",
         "False",
         "142",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "11",
         "58",
         "True",
         "136",
         "164",
         "False",
         "99",
         "True",
         "2.0",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "12",
         "39",
         "True",
         "120",
         "204",
         "False",
         "145",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "13",
         "49",
         "True",
         "140",
         "234",
         "False",
         "140",
         "True",
         "1.0",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "14",
         "42",
         "False",
         "115",
         "211",
         "False",
         "137",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "15",
         "54",
         "False",
         "120",
         "273",
         "False",
         "150",
         "False",
         "1.5",
         "False",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "16",
         "38",
         "True",
         "110",
         "196",
         "False",
         "166",
         "False",
         "0.0",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "17",
         "43",
         "False",
         "120",
         "201",
         "False",
         "165",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "18",
         "60",
         "True",
         "100",
         "248",
         "False",
         "125",
         "False",
         "1.0",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "19",
         "36",
         "True",
         "120",
         "267",
         "False",
         "160",
         "False",
         "3.0",
         "True",
         "True",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "20",
         "43",
         "False",
         "100",
         "223",
         "False",
         "142",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "21",
         "44",
         "True",
         "120",
         "184",
         "False",
         "142",
         "False",
         "1.0",
         "False",
         "True",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "22",
         "49",
         "False",
         "124",
         "201",
         "False",
         "164",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "23",
         "44",
         "True",
         "150",
         "288",
         "False",
         "150",
         "True",
         "3.0",
         "True",
         "True",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "24",
         "40",
         "True",
         "130",
         "215",
         "False",
         "138",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "25",
         "36",
         "True",
         "130",
         "209",
         "False",
         "178",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "26",
         "53",
         "True",
         "124",
         "260",
         "False",
         "112",
         "True",
         "3.0",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "27",
         "52",
         "True",
         "120",
         "284",
         "False",
         "118",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "28",
         "53",
         "False",
         "113",
         "468",
         "False",
         "127",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "29",
         "51",
         "True",
         "125",
         "188",
         "False",
         "145",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "30",
         "53",
         "True",
         "145",
         "518",
         "False",
         "130",
         "False",
         "0.0",
         "True",
         "False",
         "True",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "31",
         "56",
         "True",
         "130",
         "167",
         "False",
         "114",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "32",
         "54",
         "True",
         "125",
         "224",
         "False",
         "122",
         "False",
         "2.0",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "33",
         "41",
         "True",
         "130",
         "172",
         "False",
         "130",
         "False",
         "2.0",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "34",
         "43",
         "False",
         "150",
         "186",
         "False",
         "154",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "35",
         "32",
         "True",
         "125",
         "254",
         "False",
         "155",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "36",
         "65",
         "True",
         "140",
         "306",
         "True",
         "87",
         "True",
         "1.5",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "37",
         "41",
         "False",
         "110",
         "250",
         "False",
         "142",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "38",
         "48",
         "False",
         "120",
         "177",
         "True",
         "148",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "39",
         "48",
         "False",
         "150",
         "227",
         "False",
         "130",
         "True",
         "1.0",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "40",
         "54",
         "False",
         "150",
         "230",
         "False",
         "130",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "41",
         "54",
         "False",
         "130",
         "294",
         "False",
         "100",
         "True",
         "0.0",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "42",
         "35",
         "True",
         "150",
         "264",
         "False",
         "168",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "43",
         "52",
         "True",
         "140",
         "259",
         "False",
         "170",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "44",
         "43",
         "True",
         "120",
         "175",
         "False",
         "120",
         "True",
         "1.0",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True"
        ],
        [
         "45",
         "59",
         "True",
         "130",
         "318",
         "False",
         "120",
         "True",
         "1.0",
         "False",
         "False",
         "True",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "46",
         "37",
         "True",
         "120",
         "223",
         "False",
         "168",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "47",
         "50",
         "True",
         "140",
         "216",
         "False",
         "170",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "48",
         "36",
         "True",
         "112",
         "340",
         "False",
         "184",
         "False",
         "1.0",
         "False",
         "False",
         "True",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "49",
         "41",
         "True",
         "110",
         "289",
         "False",
         "170",
         "False",
         "0.0",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 746
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "      <th>Male_ST_Slope_Flat</th>\n",
       "      <th>ChestPainType_ASY_ST_Slope_Flat</th>\n",
       "      <th>Male_ChestPainType_ASY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>False</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>156</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>False</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>108</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>False</td>\n",
       "      <td>122</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>False</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>True</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "      <td>3.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>False</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>False</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age    Sex  RestingBP  Cholesterol  FastingBS  MaxHR  ExerciseAngina  \\\n",
       "0     40   True        140          289      False    172           False   \n",
       "1     49  False        160          180      False    156           False   \n",
       "2     37   True        130          283      False     98           False   \n",
       "3     48  False        138          214      False    108            True   \n",
       "4     54   True        150          195      False    122           False   \n",
       "..   ...    ...        ...          ...        ...    ...             ...   \n",
       "741   45   True        110          264      False    132           False   \n",
       "742   68   True        144          193       True    141           False   \n",
       "743   57   True        130          131      False    115            True   \n",
       "744   57  False        130          236      False    174           False   \n",
       "745   38   True        138          175      False    173           False   \n",
       "\n",
       "     Oldpeak  HeartDisease  ChestPainType_ATA  ChestPainType_NAP  \\\n",
       "0        0.0         False               True              False   \n",
       "1        1.0          True              False               True   \n",
       "2        0.0         False               True              False   \n",
       "3        1.5          True              False              False   \n",
       "4        0.0         False              False               True   \n",
       "..       ...           ...                ...                ...   \n",
       "741      1.2          True              False              False   \n",
       "742      3.4          True              False              False   \n",
       "743      1.2          True              False              False   \n",
       "744      0.0          True               True              False   \n",
       "745      0.0         False              False               True   \n",
       "\n",
       "     RestingECG_Normal  ST_Slope_Flat  ST_Slope_Up  Male_ST_Slope_Flat  \\\n",
       "0                 True          False         True               False   \n",
       "1                 True           True        False               False   \n",
       "2                False          False         True               False   \n",
       "3                 True           True        False               False   \n",
       "4                 True          False         True               False   \n",
       "..                 ...            ...          ...                 ...   \n",
       "741               True           True        False                True   \n",
       "742               True           True        False                True   \n",
       "743               True           True        False                True   \n",
       "744              False           True        False               False   \n",
       "745               True          False         True               False   \n",
       "\n",
       "     ChestPainType_ASY_ST_Slope_Flat  Male_ChestPainType_ASY  \n",
       "0                              False                   False  \n",
       "1                              False                   False  \n",
       "2                              False                   False  \n",
       "3                               True                   False  \n",
       "4                              False                   False  \n",
       "..                               ...                     ...  \n",
       "741                            False                   False  \n",
       "742                             True                    True  \n",
       "743                             True                    True  \n",
       "744                            False                   False  \n",
       "745                            False                   False  \n",
       "\n",
       "[746 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into desired training and testing\n",
    "- After that, Scaling the data using Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Min-Max Scaler function for this dataset to ../artifacts/ds1/models/min_max_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "# Separate numeric and boolean columns\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "bool_cols = X_train.select_dtypes(include=['bool', 'uint8']).columns  # includes one-hot from get_dummies\n",
    "\n",
    "# Initialize scaler and fit_transform only on numeric data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=num_cols, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=num_cols, index=X_test.index)\n",
    "\n",
    "# Concatenate back with boolean features (without modification)\n",
    "X_train = pd.concat([X_train_scaled, X_train[bool_cols]], axis=1)\n",
    "X_test = pd.concat([X_test_scaled, X_test[bool_cols]], axis=1)\n",
    "\n",
    "# Save Min-Max Scaler\n",
    "scaler_filename = '../artifacts/ds1/models/min_max_scaler.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f'Saved Min-Max Scaler function for this dataset to {scaler_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Base Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:09,767] A new study created in memory with name: Logistic Regression Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd85c648ab74bf69dfebfbf2e57cf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:12,847] Trial 0 finished with value: 0.6459803921568629 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.6459803921568629.\n",
      "[I 2025-10-06 13:13:15,210] Trial 1 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cholesky', 'C': 0.3470266988650412}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:17,459] Trial 2 finished with value: 0.7265686274509804 and parameters: {'solver': 'newton-cg', 'C': 0.0008111941985431928}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,547] Trial 3 finished with value: 0.8137394957983192 and parameters: {'solver': 'newton-cholesky', 'C': 0.0028585493941961923}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,598] Trial 4 finished with value: 0.8489775910364145 and parameters: {'solver': 'lbfgs', 'C': 0.019069966103000432}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,634] Trial 5 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00017070728830306665}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,673] Trial 6 finished with value: 0.8372268907563025 and parameters: {'solver': 'sag', 'C': 6.732248920775331}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,714] Trial 7 finished with value: 0.8489775910364145 and parameters: {'solver': 'lbfgs', 'C': 0.015876781526923997}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,751] Trial 8 finished with value: 0.7919327731092437 and parameters: {'solver': 'sag', 'C': 0.0019674328025306126}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,790] Trial 9 finished with value: 0.7248879551820728 and parameters: {'solver': 'lbfgs', 'C': 0.0008399864445957502}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,862] Trial 10 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cholesky', 'C': 1.1187356543600973}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:13:19,923] Trial 11 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.1581215145862693}. Best is trial 11 with value: 0.8540056022408965.\n",
      "[I 2025-10-06 13:13:19,985] Trial 12 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cholesky', 'C': 0.2826411346239428}. Best is trial 11 with value: 0.8540056022408965.\n",
      "[I 2025-10-06 13:13:20,024] Trial 13 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.15483130563709926}. Best is trial 11 with value: 0.8540056022408965.\n",
      "[I 2025-10-06 13:13:20,066] Trial 14 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.09972594704960076}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,105] Trial 15 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.06203312414676465}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,180] Trial 16 finished with value: 0.8523249299719889 and parameters: {'solver': 'newton-cholesky', 'C': 0.04765640964080815}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,221] Trial 17 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 1.9989182198186966}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,260] Trial 18 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.006773830006602749}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,302] Trial 19 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.057561380402283126}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,343] Trial 20 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cholesky', 'C': 0.8998683788955588}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,381] Trial 21 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cg', 'C': 0.05445563274677051}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,420] Trial 22 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cg', 'C': 0.05222777458549933}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,463] Trial 23 finished with value: 0.8472969187675069 and parameters: {'solver': 'newton-cg', 'C': 0.009629479389652446}. Best is trial 14 with value: 0.8556862745098041.\n",
      "[I 2025-10-06 13:13:20,502] Trial 24 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09767265811237319}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,543] Trial 25 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.17226820658879263}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,585] Trial 26 finished with value: 0.8523389355742296 and parameters: {'solver': 'newton-cg', 'C': 0.4366352557638398}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,623] Trial 27 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 4.762669068815654}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,662] Trial 28 finished with value: 0.8523249299719889 and parameters: {'solver': 'newton-cholesky', 'C': 0.02556427794939435}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,740] Trial 29 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cg', 'C': 0.12491521220001954}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,780] Trial 30 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.007737533766592418}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,820] Trial 31 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08935907307444503}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,862] Trial 32 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08221581184721423}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,899] Trial 33 finished with value: 0.8523389355742296 and parameters: {'solver': 'newton-cg', 'C': 0.40683251865914827}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,940] Trial 34 finished with value: 0.8472969187675069 and parameters: {'solver': 'newton-cg', 'C': 0.7321293277958111}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:20,982] Trial 35 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.10116525254141127}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,020] Trial 36 finished with value: 0.8506442577030814 and parameters: {'solver': 'newton-cg', 'C': 0.02310004675740012}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,061] Trial 37 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cg', 'C': 0.2559390944936855}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,104] Trial 38 finished with value: 0.827156862745098 and parameters: {'solver': 'newton-cg', 'C': 0.0036768838110748073}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,143] Trial 39 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 1.9872356792327053}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,183] Trial 40 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cg', 'C': 0.013473075989352282}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,226] Trial 41 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08298392271885094}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,264] Trial 42 finished with value: 0.8556862745098041 and parameters: {'solver': 'sag', 'C': 0.1002867730699071}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,335] Trial 43 finished with value: 0.8540056022408965 and parameters: {'solver': 'lbfgs', 'C': 0.03447139196461603}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,377] Trial 44 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08511984334061946}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,415] Trial 45 finished with value: 0.8506442577030813 and parameters: {'solver': 'newton-cg', 'C': 0.2466442221932091}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,456] Trial 46 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cholesky', 'C': 0.0002161881801369018}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,500] Trial 47 finished with value: 0.8472969187675069 and parameters: {'solver': 'newton-cholesky', 'C': 0.564830125760394}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,537] Trial 48 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.0321577072390126}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,594] Trial 49 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.07531984218226175}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,636] Trial 50 finished with value: 0.8540056022408965 and parameters: {'solver': 'sag', 'C': 0.17536305948558265}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,674] Trial 51 finished with value: 0.8523249299719889 and parameters: {'solver': 'newton-cholesky', 'C': 0.03707504276106241}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,713] Trial 52 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08300240837245654}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,754] Trial 53 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cholesky', 'C': 0.016133235803825426}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,792] Trial 54 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08211889353251148}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,832] Trial 55 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.19447610351695724}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,884] Trial 56 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cholesky', 'C': 0.12149605514373868}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,925] Trial 57 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cg', 'C': 0.3594110117442694}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:21,964] Trial 58 finished with value: 0.8523249299719889 and parameters: {'solver': 'newton-cholesky', 'C': 0.04774584251144689}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,004] Trial 59 finished with value: 0.8456022408963586 and parameters: {'solver': 'newton-cg', 'C': 0.004799886712481634}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,043] Trial 60 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cholesky', 'C': 0.012996395693582578}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,083] Trial 61 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.0785722654769642}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,125] Trial 62 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.0783480058755403}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,163] Trial 63 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cholesky', 'C': 0.02235182490611525}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,205] Trial 64 finished with value: 0.8506442577030814 and parameters: {'solver': 'newton-cholesky', 'C': 0.04206987175744226}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,246] Trial 65 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.1402047016163719}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,284] Trial 66 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.06852356079398723}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,325] Trial 67 finished with value: 0.850658263305322 and parameters: {'solver': 'sag', 'C': 0.29577726392713105}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,367] Trial 68 finished with value: 0.8540056022408965 and parameters: {'solver': 'lbfgs', 'C': 0.190187885477197}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,406] Trial 69 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.10283944225417667}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,446] Trial 70 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.029781110574601574}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,502] Trial 71 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.0600524927117993}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,540] Trial 72 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.06897685695535657}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,579] Trial 73 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08455448682477403}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,620] Trial 74 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cholesky', 'C': 0.12960404074541546}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,660] Trial 75 finished with value: 0.8506442577030813 and parameters: {'solver': 'newton-cg', 'C': 0.21040962256583223}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,700] Trial 76 finished with value: 0.8523249299719889 and parameters: {'solver': 'newton-cholesky', 'C': 0.04794689372482433}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,740] Trial 77 finished with value: 0.8523389355742296 and parameters: {'solver': 'newton-cg', 'C': 0.474499484355501}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,779] Trial 78 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cholesky', 'C': 0.01970052923552421}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,819] Trial 79 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09366328123192785}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,860] Trial 80 finished with value: 0.7667787114845938 and parameters: {'solver': 'newton-cholesky', 'C': 0.0013695212108777485}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,899] Trial 81 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.07481834279378459}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,938] Trial 82 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.15346769121109127}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:22,980] Trial 83 finished with value: 0.8506442577030814 and parameters: {'solver': 'newton-cholesky', 'C': 0.0391833300457993}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,019] Trial 84 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cholesky', 'C': 0.10492433438795512}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,063] Trial 85 finished with value: 0.850658263305322 and parameters: {'solver': 'sag', 'C': 0.2795235007529722}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,119] Trial 86 finished with value: 0.8540056022408965 and parameters: {'solver': 'lbfgs', 'C': 0.053003227019521496}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,158] Trial 87 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.02725069230679014}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,199] Trial 88 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cg', 'C': 0.12917815032654287}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,239] Trial 89 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.07730586648607454}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,277] Trial 90 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.059948497590128866}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,316] Trial 91 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08136093781878218}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,357] Trial 92 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08417638708889652}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,396] Trial 93 finished with value: 0.8506442577030813 and parameters: {'solver': 'newton-cholesky', 'C': 0.24247787470425983}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,436] Trial 94 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.03427850468751443}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,477] Trial 95 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.1627649803313838}. Best is trial 24 with value: 0.8573669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:23,641] A new study created in memory with name: Decision Tree Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:23,518] Trial 96 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cholesky', 'C': 0.11108880443801417}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,558] Trial 97 finished with value: 0.8506442577030814 and parameters: {'solver': 'newton-cholesky', 'C': 0.04352740739315006}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,599] Trial 98 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.05941864093493942}. Best is trial 24 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:13:23,638] Trial 99 finished with value: 0.8506442577030813 and parameters: {'solver': 'newton-cholesky', 'C': 0.21100777741857166}. Best is trial 24 with value: 0.8573669467787116.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using TPESampler: {'solver': 'newton-cg', 'C': 0.09767265811237319}\n",
      "Best accuracy: 0.8574, at trial: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d689ab96f597472e9e85f0a57d66ae02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:23,760] Trial 0 finished with value: 0.8137535014005601 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[I 2025-10-06 13:13:23,840] Trial 1 finished with value: 0.8104061624649859 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[I 2025-10-06 13:13:23,918] Trial 2 finished with value: 0.8087254901960785 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[I 2025-10-06 13:13:23,998] Trial 3 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,025] Trial 4 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,055] Trial 5 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,081] Trial 6 finished with value: 0.8171148459383752 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,111] Trial 7 finished with value: 0.7902240896358543 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,138] Trial 8 finished with value: 0.7969467787114846 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,167] Trial 9 finished with value: 0.8187815126050421 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,209] Trial 10 finished with value: 0.813767507002801 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,246] Trial 11 finished with value: 0.8104061624649861 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:13:24,282] Trial 12 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,318] Trial 13 finished with value: 0.7885994397759104 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,341] Trial 14 finished with value: 0.8204481792717087 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,374] Trial 15 finished with value: 0.8238095238095238 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,418] Trial 16 finished with value: 0.8238515406162465 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,443] Trial 17 finished with value: 0.8053081232492996 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,475] Trial 18 finished with value: 0.8238515406162465 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,511] Trial 19 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,544] Trial 20 finished with value: 0.8238095238095238 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 12 with value: 0.8288515406162464.\n",
      "[I 2025-10-06 13:13:24,577] Trial 21 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,613] Trial 22 finished with value: 0.8053501400560223 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,647] Trial 23 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,684] Trial 24 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,722] Trial 25 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,754] Trial 26 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,789] Trial 27 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,823] Trial 28 finished with value: 0.8237955182072829 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,844] Trial 29 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,880] Trial 30 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,914] Trial 31 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,949] Trial 32 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:24,981] Trial 33 finished with value: 0.830546218487395 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,015] Trial 34 finished with value: 0.8087254901960785 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,053] Trial 35 finished with value: 0.8238515406162465 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,086] Trial 36 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,120] Trial 37 finished with value: 0.8338935574229691 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,155] Trial 38 finished with value: 0.8154341736694677 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,188] Trial 39 finished with value: 0.8154341736694677 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,222] Trial 40 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,260] Trial 41 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,313] Trial 42 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,351] Trial 43 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,387] Trial 44 finished with value: 0.8187815126050418 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,421] Trial 45 finished with value: 0.8120868347338936 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,455] Trial 46 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,490] Trial 47 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,522] Trial 48 finished with value: 0.8120728291316526 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,557] Trial 49 finished with value: 0.8188095238095239 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,593] Trial 50 finished with value: 0.8221288515406162 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,625] Trial 51 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,661] Trial 52 finished with value: 0.8188095238095239 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,697] Trial 53 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,731] Trial 54 finished with value: 0.8137535014005601 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,766] Trial 55 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,804] Trial 56 finished with value: 0.8070308123249299 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,840] Trial 57 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,878] Trial 58 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,915] Trial 59 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,946] Trial 60 finished with value: 0.8070308123249299 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:25,982] Trial 61 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,018] Trial 62 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,050] Trial 63 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,083] Trial 64 finished with value: 0.830546218487395 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,119] Trial 65 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,151] Trial 66 finished with value: 0.8187815126050418 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,187] Trial 67 finished with value: 0.8271708683473389 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,224] Trial 68 finished with value: 0.8120728291316526 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,258] Trial 69 finished with value: 0.8238095238095238 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,293] Trial 70 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,330] Trial 71 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,372] Trial 72 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,413] Trial 73 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,454] Trial 74 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,488] Trial 75 finished with value: 0.8204481792717087 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,522] Trial 76 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,561] Trial 77 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,594] Trial 78 finished with value: 0.8237955182072829 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,628] Trial 79 finished with value: 0.8086974789915967 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,662] Trial 80 finished with value: 0.8120728291316526 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,685] Trial 81 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,719] Trial 82 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,754] Trial 83 finished with value: 0.8188095238095239 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,789] Trial 84 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,823] Trial 85 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,857] Trial 86 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,895] Trial 87 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,931] Trial 88 finished with value: 0.8188095238095239 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:26,968] Trial 89 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,003] Trial 90 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,037] Trial 91 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,075] Trial 92 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,116] Trial 93 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,154] Trial 94 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,193] Trial 95 finished with value: 0.8188095238095239 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,232] Trial 96 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,269] Trial 97 finished with value: 0.8120868347338936 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:13:27,304] Trial 98 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8339075630252101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:27,344] A new study created in memory with name: Random Forest Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:27,342] Trial 99 finished with value: 0.8154341736694677 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8339075630252101.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using TPESampler: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}\n",
      "Best accuracy: 0.8339, at trial: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640d6d5ce8ae4683a4b84196f54ccafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:27,495] Trial 0 finished with value: 0.8372408963585434 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8372408963585434.\n",
      "[I 2025-10-06 13:13:27,669] Trial 1 finished with value: 0.8590756302521008 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:27,822] Trial 2 finished with value: 0.8356022408963586 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:27,964] Trial 3 finished with value: 0.8456302521008402 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:28,076] Trial 4 finished with value: 0.8389355742296918 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:28,167] Trial 5 finished with value: 0.8339075630252101 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:28,266] Trial 6 finished with value: 0.8288795518207281 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 22, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:28,494] Trial 7 finished with value: 0.8439495798319326 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:28,666] Trial 8 finished with value: 0.8456582633053223 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:28,808] Trial 9 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:29,040] Trial 10 finished with value: 0.850672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 98, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:29,212] Trial 11 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:29,373] Trial 12 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:13:29,562] Trial 13 finished with value: 0.8607703081232494 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8607703081232494.\n",
      "[I 2025-10-06 13:13:29,756] Trial 14 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.8607703081232494.\n",
      "[I 2025-10-06 13:13:29,897] Trial 15 finished with value: 0.8489775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.8607703081232494.\n",
      "[I 2025-10-06 13:13:30,131] Trial 16 finished with value: 0.8540196078431371 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8607703081232494.\n",
      "[I 2025-10-06 13:13:30,302] Trial 17 finished with value: 0.8540476190476189 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.8607703081232494.\n",
      "[I 2025-10-06 13:13:30,514] Trial 18 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.8607703081232494.\n",
      "[I 2025-10-06 13:13:30,702] Trial 19 finished with value: 0.8624229691876751 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 48, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:30,885] Trial 20 finished with value: 0.8439775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:31,025] Trial 21 finished with value: 0.8573809523809522 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:31,133] Trial 22 finished with value: 0.8473249299719889 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 31, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:31,270] Trial 23 finished with value: 0.8439775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:31,418] Trial 24 finished with value: 0.8540336134453781 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:31,569] Trial 25 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:31,748] Trial 26 finished with value: 0.8490056022408965 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:31,857] Trial 27 finished with value: 0.8573809523809522 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:31,953] Trial 28 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 24, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:32,030] Trial 29 finished with value: 0.8355602240896358 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 14, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:32,170] Trial 30 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 48, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:32,308] Trial 31 finished with value: 0.8607563025210085 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.8624229691876751.\n",
      "[I 2025-10-06 13:13:32,477] Trial 32 finished with value: 0.8641036414565825 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 59, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:32,626] Trial 33 finished with value: 0.8624229691876749 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:32,778] Trial 34 finished with value: 0.8473249299719887 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 67, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:32,926] Trial 35 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:33,107] Trial 36 finished with value: 0.850658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 78, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:33,237] Trial 37 finished with value: 0.845658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 41, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:33,447] Trial 38 finished with value: 0.8573809523809522 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 85, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:33,629] Trial 39 finished with value: 0.8356162464985994 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 71, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:33,779] Trial 40 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 58, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:33,928] Trial 41 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:34,098] Trial 42 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:34,257] Trial 43 finished with value: 0.8557002801120447 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:34,388] Trial 44 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:34,544] Trial 45 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:34,674] Trial 46 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 48, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:34,843] Trial 47 finished with value: 0.85906162464986 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:35,004] Trial 48 finished with value: 0.8590896358543418 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 53, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:35,205] Trial 49 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 82, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:35,397] Trial 50 finished with value: 0.8389775910364146 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 73, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:35,535] Trial 51 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:35,721] Trial 52 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:35,893] Trial 53 finished with value: 0.8574089635854341 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:36,023] Trial 54 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 41, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:36,174] Trial 55 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:36,314] Trial 56 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:36,476] Trial 57 finished with value: 0.8557002801120447 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:36,627] Trial 58 finished with value: 0.8590616246498598 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:36,801] Trial 59 finished with value: 0.8473389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:36,930] Trial 60 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:37,080] Trial 61 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:37,243] Trial 62 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:37,403] Trial 63 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:37,492] Trial 64 finished with value: 0.8439775910364146 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:37,651] Trial 65 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:37,822] Trial 66 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:38,002] Trial 67 finished with value: 0.8372689075630252 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:38,109] Trial 68 finished with value: 0.8439775910364146 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 35, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:38,237] Trial 69 finished with value: 0.8506862745098038 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:38,402] Trial 70 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:38,552] Trial 71 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:38,700] Trial 72 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:38,840] Trial 73 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:38,978] Trial 74 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:39,119] Trial 75 finished with value: 0.8607422969187674 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:39,268] Trial 76 finished with value: 0.8506862745098038 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 45, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:39,470] Trial 77 finished with value: 0.85906162464986 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 71, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:39,644] Trial 78 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:39,848] Trial 79 finished with value: 0.8624369747899159 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:40,106] Trial 80 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 91, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:40,309] Trial 81 finished with value: 0.8624369747899159 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 77, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:40,502] Trial 82 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 74, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:40,705] Trial 83 finished with value: 0.8439635854341738 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 78, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:40,931] Trial 84 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 82, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:41,125] Trial 85 finished with value: 0.8439775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:41,285] Trial 86 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:41,485] Trial 87 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 85, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:41,635] Trial 88 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8641036414565825.\n",
      "[I 2025-10-06 13:13:41,795] Trial 89 finished with value: 0.865798319327731 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 89 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:13:42,030] Trial 90 finished with value: 0.8439775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 89 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:13:42,225] Trial 91 finished with value: 0.8674649859943976 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:13:42,396] Trial 92 finished with value: 0.86578431372549 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:13:42,589] Trial 93 finished with value: 0.86578431372549 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:13:42,770] Trial 94 finished with value: 0.8674649859943976 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:13:42,953] Trial 95 finished with value: 0.8674649859943976 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:13:43,139] Trial 96 finished with value: 0.8573809523809522 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 91 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:13:43,320] Trial 97 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 74, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:13:43,503] Trial 98 finished with value: 0.8590896358543418 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 79, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:13:43,695] Trial 99 finished with value: 0.8574089635854343 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.8674649859943976.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:43,695] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Random Forest Using TPESampler: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
      "Best accuracy: 0.8675, at trial: 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5794bdeaa84a558f0a5408f9b3c80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:43,785] Trial 0 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:13:43,944] Trial 1 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:13:43,995] Trial 2 finished with value: 0.8472969187675069 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:13:44,156] Trial 3 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:13:44,216] Trial 4 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:13:44,262] Trial 5 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:13:44,312] Trial 6 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 6 with value: 0.8590196078431372.\n",
      "[I 2025-10-06 13:13:44,359] Trial 7 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 6 with value: 0.8590196078431372.\n",
      "[I 2025-10-06 13:13:44,406] Trial 8 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 8 with value: 0.8607002801120448.\n",
      "[I 2025-10-06 13:13:44,459] Trial 9 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 8 with value: 0.8607002801120448.\n",
      "[I 2025-10-06 13:13:44,508] Trial 10 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 8 with value: 0.8607002801120448.\n",
      "[I 2025-10-06 13:13:44,558] Trial 11 finished with value: 0.8556582633053221 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 8 with value: 0.8607002801120448.\n",
      "[I 2025-10-06 13:13:44,631] Trial 12 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:44,682] Trial 13 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:44,809] Trial 14 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:44,862] Trial 15 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:44,914] Trial 16 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:44,964] Trial 17 finished with value: 0.8472689075630251 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,016] Trial 18 finished with value: 0.8238095238095238 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 4, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,152] Trial 19 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,201] Trial 20 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,349] Trial 21 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,473] Trial 22 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,507] Trial 23 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,537] Trial 24 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,611] Trial 25 finished with value: 0.8506442577030813 and parameters: {'algorithm': 'brute', 'n_neighbors': 26, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,664] Trial 26 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,694] Trial 27 finished with value: 0.8556582633053221 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,746] Trial 28 finished with value: 0.8539915966386555 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,799] Trial 29 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,851] Trial 30 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,904] Trial 31 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:45,955] Trial 32 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,010] Trial 33 finished with value: 0.8523249299719889 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 27, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,060] Trial 34 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,094] Trial 35 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,143] Trial 36 finished with value: 0.8556862745098041 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,195] Trial 37 finished with value: 0.850658263305322 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,273] Trial 38 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 1}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,323] Trial 39 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,355] Trial 40 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 29, 'p': 1}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,385] Trial 41 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,417] Trial 42 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,448] Trial 43 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,482] Trial 44 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,532] Trial 45 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 30, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,584] Trial 46 finished with value: 0.8573389355742297 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,618] Trial 47 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'brute', 'n_neighbors': 48, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,669] Trial 48 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 17, 'p': 1}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,722] Trial 49 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,774] Trial 50 finished with value: 0.8490196078431372 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 7, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,825] Trial 51 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,879] Trial 52 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,934] Trial 53 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:46,999] Trial 54 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,053] Trial 55 finished with value: 0.8590056022408963 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,106] Trial 56 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,156] Trial 57 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,208] Trial 58 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,259] Trial 59 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,309] Trial 60 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,363] Trial 61 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,414] Trial 62 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,467] Trial 63 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,519] Trial 64 finished with value: 0.8573389355742297 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,572] Trial 65 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,621] Trial 66 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,673] Trial 67 finished with value: 0.8556862745098041 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,724] Trial 68 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,776] Trial 69 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,827] Trial 70 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,900] Trial 71 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:47,950] Trial 72 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,003] Trial 73 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,053] Trial 74 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,106] Trial 75 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,156] Trial 76 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,210] Trial 77 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,261] Trial 78 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,313] Trial 79 finished with value: 0.855686274509804 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,364] Trial 80 finished with value: 0.8539915966386555 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,418] Trial 81 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,467] Trial 82 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,521] Trial 83 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,572] Trial 84 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,637] Trial 85 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,689] Trial 86 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,743] Trial 87 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,793] Trial 88 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,847] Trial 89 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,899] Trial 90 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:48,954] Trial 91 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:49,005] Trial 92 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:49,058] Trial 93 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:49,113] Trial 94 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:49,166] Trial 95 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:49,218] Trial 96 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:49,270] Trial 97 finished with value: 0.8540056022408964 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 24, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:13:49,321] Trial 98 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:49,378] A new study created in memory with name: Support Vector Machine Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:49,376] Trial 99 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8624089635854343.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using TPESampler: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}\n",
      "Best accuracy: 0.8624, at trial: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ea642409ed4d5eb91df6b20fb7ce0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:49,462] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-10-06 13:13:49,499] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.005399484409787433}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-10-06 13:13:49,528] Trial 2 finished with value: 0.5453221288515406 and parameters: {'kernel': 'sigmoid', 'C': 0.008706020878304856}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:13:49,555] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023270677083837802}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:13:49,584] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0003823475224675188}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:13:49,621] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005404103854647331}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:13:49,650] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010677482709481358}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:13:49,677] Trial 7 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00021930485556643703, 'degree': 2}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:13:49,704] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004066563313514797}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:13:49,731] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00017541893487450815}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:13:49,779] Trial 10 finished with value: 0.8187254901960783 and parameters: {'kernel': 'poly', 'C': 0.007335514278058898, 'degree': 5}. Best is trial 10 with value: 0.8187254901960783.\n",
      "[I 2025-10-06 13:13:49,811] Trial 11 finished with value: 0.8321708683473389 and parameters: {'kernel': 'poly', 'C': 0.009580123613205892, 'degree': 5}. Best is trial 11 with value: 0.8321708683473389.\n",
      "[I 2025-10-06 13:13:49,842] Trial 12 finished with value: 0.7735014005602242 and parameters: {'kernel': 'poly', 'C': 0.0036177149553450723, 'degree': 5}. Best is trial 11 with value: 0.8321708683473389.\n",
      "[I 2025-10-06 13:13:49,873] Trial 13 finished with value: 0.7718207282913166 and parameters: {'kernel': 'poly', 'C': 0.002733762389478879, 'degree': 5}. Best is trial 11 with value: 0.8321708683473389.\n",
      "[I 2025-10-06 13:13:49,907] Trial 14 finished with value: 0.8338375350140057 and parameters: {'kernel': 'poly', 'C': 0.009634955722383544, 'degree': 5}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:49,938] Trial 15 finished with value: 0.7718207282913164 and parameters: {'kernel': 'poly', 'C': 0.0023976227274240727, 'degree': 4}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:49,968] Trial 16 finished with value: 0.7718067226890757 and parameters: {'kernel': 'poly', 'C': 0.004812370668209514, 'degree': 4}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:49,998] Trial 17 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.009870099073530512, 'degree': 3}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:50,031] Trial 18 finished with value: 0.7718207282913164 and parameters: {'kernel': 'poly', 'C': 0.0017215476725043046, 'degree': 5}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:50,060] Trial 19 finished with value: 0.7718067226890757 and parameters: {'kernel': 'poly', 'C': 0.004943018624063396, 'degree': 4}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:50,100] Trial 20 finished with value: 0.753375350140056 and parameters: {'kernel': 'poly', 'C': 0.0010139544648010092, 'degree': 3}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:50,132] Trial 21 finished with value: 0.8170448179271708 and parameters: {'kernel': 'poly', 'C': 0.006732534117889717, 'degree': 5}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:50,165] Trial 22 finished with value: 0.8338375350140057 and parameters: {'kernel': 'poly', 'C': 0.009624188197704678, 'degree': 5}. Best is trial 14 with value: 0.8338375350140057.\n",
      "[I 2025-10-06 13:13:50,194] Trial 23 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009980295032795012, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,247] Trial 24 finished with value: 0.7718207282913166 and parameters: {'kernel': 'poly', 'C': 0.003669882086077255, 'degree': 4}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,289] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.006234586431169063}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,321] Trial 26 finished with value: 0.6459803921568626 and parameters: {'kernel': 'poly', 'C': 0.0001051909502813386, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,353] Trial 27 finished with value: 0.7735014005602242 and parameters: {'kernel': 'poly', 'C': 0.003035072575984439, 'degree': 4}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,385] Trial 28 finished with value: 0.7835574229691877 and parameters: {'kernel': 'poly', 'C': 0.004301744354985008, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,415] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0017864705023163873}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,448] Trial 30 finished with value: 0.7969327731092436 and parameters: {'kernel': 'poly', 'C': 0.0077321657153169195, 'degree': 4}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,480] Trial 31 finished with value: 0.8304901960784313 and parameters: {'kernel': 'poly', 'C': 0.009132710552994805, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,510] Trial 32 finished with value: 0.8019887955182072 and parameters: {'kernel': 'poly', 'C': 0.005626797022644088, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,541] Trial 33 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009971823842758182, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,576] Trial 34 finished with value: 0.8170448179271708 and parameters: {'kernel': 'poly', 'C': 0.007049771734998944, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,615] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.005878281059090514}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,656] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004010560076493871}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,689] Trial 37 finished with value: 0.8321708683473389 and parameters: {'kernel': 'poly', 'C': 0.009479242056499701, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,732] Trial 38 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007497331768054277}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,772] Trial 39 finished with value: 0.7600840336134453 and parameters: {'kernel': 'poly', 'C': 0.002221740896347902, 'degree': 2}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,813] Trial 40 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0055514865500898005}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,878] Trial 41 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.0099805689709412, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,909] Trial 42 finished with value: 0.8271288515406162 and parameters: {'kernel': 'poly', 'C': 0.007578496818532207, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,939] Trial 43 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009974792629370526, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:50,972] Trial 44 finished with value: 0.8220868347338935 and parameters: {'kernel': 'poly', 'C': 0.007503312895323563, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,000] Trial 45 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.00802847723228509, 'degree': 4}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,041] Trial 46 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.006246176636798124}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,074] Trial 47 finished with value: 0.7885994397759104 and parameters: {'kernel': 'poly', 'C': 0.004608092134443632, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,103] Trial 48 finished with value: 0.7818627450980392 and parameters: {'kernel': 'poly', 'C': 0.008149161255005297, 'degree': 2}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,135] Trial 49 finished with value: 0.7684733893557423 and parameters: {'kernel': 'poly', 'C': 0.0012136203216594832, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,175] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003597913676494745}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,210] Trial 51 finished with value: 0.8304901960784313 and parameters: {'kernel': 'poly', 'C': 0.009238509692402273, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,239] Trial 52 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009891191967621933, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,270] Trial 53 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009968521103497665, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,301] Trial 54 finished with value: 0.8170448179271708 and parameters: {'kernel': 'poly', 'C': 0.006815045015335766, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,353] Trial 55 finished with value: 0.7718207282913166 and parameters: {'kernel': 'poly', 'C': 0.0032748802836417216, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,384] Trial 56 finished with value: 0.7986414565826331 and parameters: {'kernel': 'poly', 'C': 0.005102201701641412, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,422] Trial 57 finished with value: 0.5436274509803921 and parameters: {'kernel': 'sigmoid', 'C': 0.008337484302885962}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,454] Trial 58 finished with value: 0.8136974789915966 and parameters: {'kernel': 'poly', 'C': 0.0062826671989180734, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,488] Trial 59 finished with value: 0.8304901960784313 and parameters: {'kernel': 'poly', 'C': 0.008290074240689185, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,518] Trial 60 finished with value: 0.8086694677871147 and parameters: {'kernel': 'poly', 'C': 0.009698635795572308, 'degree': 4}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,550] Trial 61 finished with value: 0.8338375350140057 and parameters: {'kernel': 'poly', 'C': 0.00966341629527166, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,582] Trial 62 finished with value: 0.8170448179271708 and parameters: {'kernel': 'poly', 'C': 0.006851577986899474, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,613] Trial 63 finished with value: 0.7986414565826331 and parameters: {'kernel': 'poly', 'C': 0.005241212905567969, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,645] Trial 64 finished with value: 0.8288095238095238 and parameters: {'kernel': 'poly', 'C': 0.008012761766988397, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,677] Trial 65 finished with value: 0.7852380952380953 and parameters: {'kernel': 'poly', 'C': 0.007077842151027592, 'degree': 3}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,710] Trial 66 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009906018364593084, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,741] Trial 67 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.00982856440692612, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,772] Trial 68 finished with value: 0.7835574229691877 and parameters: {'kernel': 'poly', 'C': 0.0042557687834475985, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,827] Trial 69 finished with value: 0.8137114845938374 and parameters: {'kernel': 'poly', 'C': 0.00601221688308442, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,874] Trial 70 finished with value: 0.6996778711484595 and parameters: {'kernel': 'rbf', 'C': 0.008614834785933142}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,905] Trial 71 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.00985925983783744, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,936] Trial 72 finished with value: 0.8304901960784313 and parameters: {'kernel': 'poly', 'C': 0.008264203165714504, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:51,970] Trial 73 finished with value: 0.8187254901960783 and parameters: {'kernel': 'poly', 'C': 0.007291516223650338, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,001] Trial 74 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.00995776088043942, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,033] Trial 75 finished with value: 0.8153781512605042 and parameters: {'kernel': 'poly', 'C': 0.0064319406159326215, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,064] Trial 76 finished with value: 0.800280112044818 and parameters: {'kernel': 'poly', 'C': 0.008459139817421937, 'degree': 4}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,106] Trial 77 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005275386816463847}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,136] Trial 78 finished with value: 0.7533893557422969 and parameters: {'kernel': 'poly', 'C': 0.0006648490563091663, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,169] Trial 79 finished with value: 0.6879131652661066 and parameters: {'kernel': 'poly', 'C': 0.0001239764148354952, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,203] Trial 80 finished with value: 0.8187254901960783 and parameters: {'kernel': 'poly', 'C': 0.007307776112653602, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,233] Trial 81 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.00992668496512985, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,265] Trial 82 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009997388391681322, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,296] Trial 83 finished with value: 0.8288095238095238 and parameters: {'kernel': 'poly', 'C': 0.008755767618565037, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,354] Trial 84 finished with value: 0.8304901960784313 and parameters: {'kernel': 'poly', 'C': 0.008911934773044482, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,387] Trial 85 finished with value: 0.8220868347338935 and parameters: {'kernel': 'poly', 'C': 0.007472617298760821, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,427] Trial 86 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.006120776243379244}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,460] Trial 87 finished with value: 0.7315686274509804 and parameters: {'kernel': 'poly', 'C': 0.0002708109739198311, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,491] Trial 88 finished with value: 0.7885714285714286 and parameters: {'kernel': 'poly', 'C': 0.00876555981964115, 'degree': 3}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,523] Trial 89 finished with value: 0.8170448179271708 and parameters: {'kernel': 'poly', 'C': 0.006813124712437635, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,554] Trial 90 finished with value: 0.7969327731092436 and parameters: {'kernel': 'poly', 'C': 0.007858904510969086, 'degree': 4}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,588] Trial 91 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009887341512796775, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,620] Trial 92 finished with value: 0.8304901960784313 and parameters: {'kernel': 'poly', 'C': 0.008977464588122605, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,652] Trial 93 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.009932427177301181, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,692] Trial 94 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00559092157879868}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,726] Trial 95 finished with value: 0.8288095238095238 and parameters: {'kernel': 'poly', 'C': 0.007671026663867703, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,755] Trial 96 finished with value: 0.8304901960784313 and parameters: {'kernel': 'poly', 'C': 0.008879678679423063, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,808] Trial 97 finished with value: 0.8153781512605042 and parameters: {'kernel': 'poly', 'C': 0.006573146447491561, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:52,877] A new study created in memory with name: AdaBoost Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:52,843] Trial 98 finished with value: 0.7701400560224089 and parameters: {'kernel': 'poly', 'C': 0.0013158769024905054, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:13:52,872] Trial 99 finished with value: 0.8288095238095238 and parameters: {'kernel': 'poly', 'C': 0.00765510812912413, 'degree': 5}. Best is trial 23 with value: 0.8355182072829133.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using TPESampler: {'kernel': 'poly', 'C': 0.009980295032795012, 'degree': 5}\n",
      "Best accuracy: 0.8355, at trial: 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71f49d8b76f40cf9a2029c21dd5fba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:13:52,994] Trial 0 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:13:53,145] Trial 1 finished with value: 0.84390756302521 and parameters: {'n_estimators': 76, 'learning_rate': 0.06251373574521749}. Best is trial 1 with value: 0.84390756302521.\n",
      "[I 2025-10-06 13:13:53,214] Trial 2 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029375384576328283}. Best is trial 1 with value: 0.84390756302521.\n",
      "[I 2025-10-06 13:13:53,295] Trial 3 finished with value: 0.8388795518207284 and parameters: {'n_estimators': 15, 'learning_rate': 0.39676050770529875}. Best is trial 1 with value: 0.84390756302521.\n",
      "[I 2025-10-06 13:13:53,428] Trial 4 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:13:53,476] Trial 5 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 11, 'learning_rate': 0.8123245085588685}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:13:53,640] Trial 6 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 85, 'learning_rate': 0.004335281794951566}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:13:53,707] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.0035498788321965025}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:13:53,799] Trial 8 finished with value: 0.8305882352941175 and parameters: {'n_estimators': 37, 'learning_rate': 0.03752055855124281}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:13:53,918] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 49, 'learning_rate': 0.007476312062252299}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:13:54,076] Trial 10 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 67, 'learning_rate': 0.14171731252095018}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:54,225] Trial 11 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 63, 'learning_rate': 0.14519765494874043}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:54,378] Trial 12 finished with value: 0.8472829131652662 and parameters: {'n_estimators': 65, 'learning_rate': 0.158341601515545}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:54,587] Trial 13 finished with value: 0.8238655462184873 and parameters: {'n_estimators': 96, 'learning_rate': 0.01504383897839578}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:54,762] Trial 14 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 74, 'learning_rate': 0.0010952927106776854}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:54,909] Trial 15 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 58, 'learning_rate': 0.12523250179185427}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:55,042] Trial 16 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 52, 'learning_rate': 0.27549296838305987}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:55,290] Trial 17 finished with value: 0.84390756302521 and parameters: {'n_estimators': 99, 'learning_rate': 0.055354118270137316}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:55,466] Trial 18 finished with value: 0.8338375350140057 and parameters: {'n_estimators': 78, 'learning_rate': 0.024259951521645146}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:55,561] Trial 19 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 36, 'learning_rate': 0.08661025596666062}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:55,692] Trial 20 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 57, 'learning_rate': 0.31089751060469933}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:55,850] Trial 21 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 65, 'learning_rate': 0.1451460636666487}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:55,994] Trial 22 finished with value: 0.8489355742296919 and parameters: {'n_estimators': 59, 'learning_rate': 0.08385569132042653}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:56,150] Trial 23 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 69, 'learning_rate': 0.1876323498026873}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:56,336] Trial 24 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 87, 'learning_rate': 0.42201102880979324}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:56,503] Trial 25 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 71, 'learning_rate': 0.2166473013715805}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:56,680] Trial 26 finished with value: 0.8338375350140057 and parameters: {'n_estimators': 84, 'learning_rate': 0.022085156115870287}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:56,807] Trial 27 finished with value: 0.8338655462184873 and parameters: {'n_estimators': 45, 'learning_rate': 0.04887855508310364}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:56,963] Trial 28 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 72, 'learning_rate': 0.08384575666726464}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:57,089] Trial 29 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 56, 'learning_rate': 0.47115971245591615}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:57,193] Trial 30 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 40, 'learning_rate': 0.6980850553500259}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:57,377] Trial 31 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 67, 'learning_rate': 0.12139233032030246}. Best is trial 10 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:13:57,531] Trial 32 finished with value: 0.8523249299719889 and parameters: {'n_estimators': 80, 'learning_rate': 0.18822220249563218}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:57,697] Trial 33 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 81, 'learning_rate': 0.22730489995915337}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:57,855] Trial 34 finished with value: 0.8372268907563024 and parameters: {'n_estimators': 71, 'learning_rate': 0.5513706192309124}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:58,051] Trial 35 finished with value: 0.843921568627451 and parameters: {'n_estimators': 93, 'learning_rate': 0.21469299408899872}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:58,248] Trial 36 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 91, 'learning_rate': 0.10180715303682082}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:58,395] Trial 37 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 59, 'learning_rate': 0.05967441289993888}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:58,559] Trial 38 finished with value: 0.8372408963585434 and parameters: {'n_estimators': 77, 'learning_rate': 0.8757865517937496}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:58,736] Trial 39 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 81, 'learning_rate': 0.03532530465853952}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:58,850] Trial 40 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 47, 'learning_rate': 0.332897839309282}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:59,028] Trial 41 finished with value: 0.8523249299719888 and parameters: {'n_estimators': 80, 'learning_rate': 0.23049035590405006}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:59,184] Trial 42 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 69, 'learning_rate': 0.18518134924994317}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:59,397] Trial 43 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 87, 'learning_rate': 0.2908181628458759}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:59,529] Trial 44 finished with value: 0.8523109243697478 and parameters: {'n_estimators': 61, 'learning_rate': 0.10935715690370966}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:59,632] Trial 45 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 52, 'learning_rate': 0.11960160215998632}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:59,787] Trial 46 finished with value: 0.84390756302521 and parameters: {'n_estimators': 62, 'learning_rate': 0.07402465030976878}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:13:59,951] Trial 47 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 75, 'learning_rate': 0.04491260801603925}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:14:00,077] Trial 48 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 53, 'learning_rate': 0.011150950860431828}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:14:00,235] Trial 49 finished with value: 0.8523109243697478 and parameters: {'n_estimators': 80, 'learning_rate': 0.10887939606611055}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:14:00,404] Trial 50 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 81, 'learning_rate': 0.5832813316804556}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:14:00,550] Trial 51 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 62, 'learning_rate': 0.10899408974298203}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:14:00,757] Trial 52 finished with value: 0.843921568627451 and parameters: {'n_estimators': 91, 'learning_rate': 0.1604818834802999}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:14:00,934] Trial 53 finished with value: 0.84390756302521 and parameters: {'n_estimators': 78, 'learning_rate': 0.06889386547707586}. Best is trial 32 with value: 0.8523249299719889.\n",
      "[I 2025-10-06 13:14:01,127] Trial 54 finished with value: 0.8523389355742296 and parameters: {'n_estimators': 84, 'learning_rate': 0.2511295868890071}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:01,316] Trial 55 finished with value: 0.8523249299719889 and parameters: {'n_estimators': 83, 'learning_rate': 0.24978360789846746}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:01,544] Trial 56 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 100, 'learning_rate': 0.33218793811323966}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:01,728] Trial 57 finished with value: 0.8506442577030814 and parameters: {'n_estimators': 84, 'learning_rate': 0.256576859745782}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:01,838] Trial 58 finished with value: 0.843921568627451 and parameters: {'n_estimators': 22, 'learning_rate': 0.4163200102419329}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:02,016] Trial 59 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 96, 'learning_rate': 0.0021850156068446702}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:02,203] Trial 60 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 89, 'learning_rate': 0.1769825135547641}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:02,390] Trial 61 finished with value: 0.8523249299719889 and parameters: {'n_estimators': 83, 'learning_rate': 0.2590614846315296}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:02,568] Trial 62 finished with value: 0.8506442577030814 and parameters: {'n_estimators': 80, 'learning_rate': 0.25791431237157747}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:02,759] Trial 63 finished with value: 0.84390756302521 and parameters: {'n_estimators': 85, 'learning_rate': 0.09833374525727315}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:02,925] Trial 64 finished with value: 0.8372128851540616 and parameters: {'n_estimators': 73, 'learning_rate': 0.5156745972282418}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:03,134] Trial 65 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 94, 'learning_rate': 0.3449237329105007}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:03,313] Trial 66 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 76, 'learning_rate': 0.14774341062273263}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:03,500] Trial 67 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 83, 'learning_rate': 0.38478389117136425}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:03,690] Trial 68 finished with value: 0.8355462184873949 and parameters: {'n_estimators': 87, 'learning_rate': 0.7405735461260583}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:03,884] Trial 69 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 89, 'learning_rate': 0.21284939794691313}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:04,041] Trial 70 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 79, 'learning_rate': 0.13237053853279945}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:04,227] Trial 71 finished with value: 0.843921568627451 and parameters: {'n_estimators': 83, 'learning_rate': 0.22815663254099208}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:04,385] Trial 72 finished with value: 0.8456022408963586 and parameters: {'n_estimators': 84, 'learning_rate': 0.2666748857266239}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:04,533] Trial 73 finished with value: 0.830532212885154 and parameters: {'n_estimators': 75, 'learning_rate': 0.9939144972329228}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:04,721] Trial 74 finished with value: 0.8422408963585435 and parameters: {'n_estimators': 97, 'learning_rate': 0.19458225931002537}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:04,876] Trial 75 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 89, 'learning_rate': 0.2626395175211273}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:05,065] Trial 76 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 86, 'learning_rate': 0.16389130881003608}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:05,265] Trial 77 finished with value: 0.8338515406162464 and parameters: {'n_estimators': 92, 'learning_rate': 0.4375847164200441}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:05,441] Trial 78 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 82, 'learning_rate': 0.6581308473530172}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:05,618] Trial 79 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 78, 'learning_rate': 0.3556528498133171}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:05,787] Trial 80 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 70, 'learning_rate': 0.09613896167631207}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:05,954] Trial 81 finished with value: 0.8506442577030814 and parameters: {'n_estimators': 74, 'learning_rate': 0.24397482581717764}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:06,144] Trial 82 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 85, 'learning_rate': 0.2870668253887125}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:06,330] Trial 83 finished with value: 0.843921568627451 and parameters: {'n_estimators': 80, 'learning_rate': 0.19580065608214317}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:06,491] Trial 84 finished with value: 0.8338375350140057 and parameters: {'n_estimators': 67, 'learning_rate': 0.02647431578949125}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:06,575] Trial 85 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 30, 'learning_rate': 0.13111515693373704}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:06,751] Trial 86 finished with value: 0.8506442577030814 and parameters: {'n_estimators': 80, 'learning_rate': 0.245175752892289}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:06,931] Trial 87 finished with value: 0.843921568627451 and parameters: {'n_estimators': 76, 'learning_rate': 0.1558883386303147}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:07,110] Trial 88 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 89, 'learning_rate': 0.3013430797343605}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:07,266] Trial 89 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 72, 'learning_rate': 0.4574760711005565}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:07,443] Trial 90 finished with value: 0.84390756302521 and parameters: {'n_estimators': 78, 'learning_rate': 0.07521716625497114}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:07,670] Trial 91 finished with value: 0.8472829131652662 and parameters: {'n_estimators': 74, 'learning_rate': 0.22280956334074964}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:07,847] Trial 92 finished with value: 0.8456022408963586 and parameters: {'n_estimators': 82, 'learning_rate': 0.2666861450324896}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:08,046] Trial 93 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 87, 'learning_rate': 0.17900312563940743}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:08,234] Trial 94 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 80, 'learning_rate': 0.117587790718329}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:08,422] Trial 95 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 84, 'learning_rate': 0.34915112590641684}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:08,599] Trial 96 finished with value: 0.8506442577030813 and parameters: {'n_estimators': 77, 'learning_rate': 0.2371314120908609}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:08,797] Trial 97 finished with value: 0.8472829131652662 and parameters: {'n_estimators': 83, 'learning_rate': 0.1452611296320169}. Best is trial 54 with value: 0.8523389355742296.\n",
      "[I 2025-10-06 13:14:08,963] Trial 98 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 73, 'learning_rate': 0.5082655228397287}. Best is trial 54 with value: 0.8523389355742296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:14:09,123] A new study created in memory with name: Gradient Boosting Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:14:09,121] Trial 99 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 64, 'learning_rate': 0.2991832346748574}. Best is trial 54 with value: 0.8523389355742296.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using TPESampler: {'n_estimators': 84, 'learning_rate': 0.2511295868890071}\n",
      "Best accuracy: 0.8523, at trial: 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b899b3aa1ab490fb8048eab462059e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:14:09,283] Trial 0 finished with value: 0.7985994397759104 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.7985994397759104.\n",
      "[I 2025-10-06 13:14:09,449] Trial 1 finished with value: 0.83890756302521 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.0026587543983272706, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.762378215816119}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:14:09,508] Trial 2 finished with value: 0.7028991596638656 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.00383962929980417, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.5998368910791798}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:14:09,607] Trial 3 finished with value: 0.8019607843137255 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.002193048555664369, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9041986740582306}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:14:09,748] Trial 4 finished with value: 0.7129551820728292 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.0017541893487450805, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6293899908000085}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:14:09,932] Trial 5 finished with value: 0.8086834733893558 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.0023426581058204046, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.9474136752138245}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:14:10,031] Trial 6 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.0012315571723666018, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9143687545759647}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:14:10,090] Trial 7 finished with value: 0.8456162464985993 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.040215545266902894, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.5993578407670862}. Best is trial 7 with value: 0.8456162464985993.\n",
      "[I 2025-10-06 13:14:10,214] Trial 8 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.034877126245459314, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9315517129377968}. Best is trial 8 with value: 0.8590616246498598.\n",
      "[I 2025-10-06 13:14:10,345] Trial 9 finished with value: 0.8204481792717087 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.004470608546778492, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7361074625809747}. Best is trial 8 with value: 0.8590616246498598.\n",
      "[I 2025-10-06 13:14:10,912] Trial 10 finished with value: 0.8389355742296918 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.08691089486124963, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1, 'subsample': 0.9861142660861426}. Best is trial 8 with value: 0.8590616246498598.\n",
      "[I 2025-10-06 13:14:10,962] Trial 11 finished with value: 0.8473109243697478 and parameters: {'max_features': None, 'n_estimators': 13, 'learning_rate': 0.03567555788805259, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.5331802480191359}. Best is trial 8 with value: 0.8590616246498598.\n",
      "[I 2025-10-06 13:14:11,111] Trial 12 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 78, 'learning_rate': 0.02244381186443635, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6869867069023236}. Best is trial 8 with value: 0.8590616246498598.\n",
      "[I 2025-10-06 13:14:11,386] Trial 13 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 79, 'learning_rate': 0.013987888918434402, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.836932074470251}. Best is trial 13 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:14:11,849] Trial 14 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 99, 'learning_rate': 0.010312819636259005, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.8441147559750997}. Best is trial 13 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:14:12,253] Trial 15 finished with value: 0.8574229691876752 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.01422823261046283, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.8535872238782521}. Best is trial 13 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:14:12,573] Trial 16 finished with value: 0.8540196078431371 and parameters: {'max_features': 'log2', 'n_estimators': 73, 'learning_rate': 0.0645873556358564, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8497493399247723}. Best is trial 13 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:14:12,808] Trial 17 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.00694737861712601, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.9731371520855301}. Best is trial 13 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:14:13,062] Trial 18 finished with value: 0.8657703081232494 and parameters: {'max_features': 'sqrt', 'n_estimators': 87, 'learning_rate': 0.018140837457893834, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.8962208780251872}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:13,308] Trial 19 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 89, 'learning_rate': 0.017811094548039016, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.7881623884982839}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:13,667] Trial 20 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.007123498417990446, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.8808744229893546}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:14,045] Trial 21 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.00843981655856991, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.8893895834719348}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:14,404] Trial 22 finished with value: 0.8640896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.007486082476729294, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.8916528559962942}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:14,743] Trial 23 finished with value: 0.8657703081232494 and parameters: {'max_features': 'sqrt', 'n_estimators': 94, 'learning_rate': 0.007520369224197892, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.8947741754825929}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:15,070] Trial 24 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 90, 'learning_rate': 0.005194647799703174, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.9893626205081512}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:15,440] Trial 25 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.026070508291559234, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8084615508191668}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:15,805] Trial 26 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 93, 'learning_rate': 0.010608496336350704, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.9447782097330527}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:16,012] Trial 27 finished with value: 0.8489775910364145 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.00371825659038047, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.7110146669737579}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:16,249] Trial 28 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.005957899740687674, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.869858241137637}. Best is trial 18 with value: 0.8657703081232494.\n",
      "[I 2025-10-06 13:14:16,496] Trial 29 finished with value: 0.8674649859943976 and parameters: {'max_features': 'sqrt', 'n_estimators': 94, 'learning_rate': 0.011699215593661917, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8095352747657649}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:16,674] Trial 30 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 61, 'learning_rate': 0.01543330611269642, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.8037705523078187}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:16,836] Trial 31 finished with value: 0.8590476190476191 and parameters: {'max_features': 'sqrt', 'n_estimators': 95, 'learning_rate': 0.010063920541720285, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.8151081216802245}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:17,080] Trial 32 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.02108834160574158, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.7698278171236397}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:17,253] Trial 33 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 95, 'learning_rate': 0.0030775943197354255, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.9064859008632475}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:17,532] Trial 34 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 87, 'learning_rate': 0.008117422658482705, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.955547343969871}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:17,747] Trial 35 finished with value: 0.8624089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 96, 'learning_rate': 0.01286971962528933, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.921209503438401}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:18,073] Trial 36 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.005902041427586271, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8747000603053369}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:18,303] Trial 37 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.028977614163466683, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9, 'subsample': 0.7487476564839493}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:18,515] Trial 38 finished with value: 0.7264005602240896 and parameters: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.0017564300329827728, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.9098765183172247}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:18,687] Trial 39 finished with value: 0.8540616246498599 and parameters: {'max_features': None, 'n_estimators': 67, 'learning_rate': 0.04827877939282762, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.8277010975508363}. Best is trial 29 with value: 0.8674649859943976.\n",
      "[I 2025-10-06 13:14:18,988] Trial 40 finished with value: 0.8674649859943978 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.01844240199125311, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.9575434585153517}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:19,236] Trial 41 finished with value: 0.8624089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.018665670354256658, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.9357782417068946}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:19,489] Trial 42 finished with value: 0.8657703081232494 and parameters: {'max_features': 'sqrt', 'n_estimators': 72, 'learning_rate': 0.012352516112092269, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.9611369249735305}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:19,713] Trial 43 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 72, 'learning_rate': 0.011581245317271513, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 10, 'subsample': 0.9675302023513306}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:19,987] Trial 44 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.016761175796243942, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 9, 'subsample': 0.99410698052101}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:20,215] Trial 45 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 63, 'learning_rate': 0.026427956257768427, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.9541416554168999}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:20,469] Trial 46 finished with value: 0.8523669467787116 and parameters: {'max_features': None, 'n_estimators': 73, 'learning_rate': 0.01263855131651544, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.9140739125338675}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:20,611] Trial 47 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 41, 'learning_rate': 0.0211700422653304, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9, 'subsample': 0.9385251129099397}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:20,886] Trial 48 finished with value: 0.8523669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 88, 'learning_rate': 0.030324263856347972, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.6661558861577318}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:21,091] Trial 49 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 56, 'learning_rate': 0.0011305785446349397, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.8609140692143167}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:21,274] Trial 50 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.008989145059613277, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5074003153212657}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:21,575] Trial 51 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 95, 'learning_rate': 0.008004640086342229, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.9005390559829404}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:21,926] Trial 52 finished with value: 0.8540196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 97, 'learning_rate': 0.004277687914200089, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.8919220808379923}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:22,260] Trial 53 finished with value: 0.8624089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 92, 'learning_rate': 0.01463167466692896, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.9276625699986322}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:22,654] Trial 54 finished with value: 0.8657843137254903 and parameters: {'max_features': 'sqrt', 'n_estimators': 99, 'learning_rate': 0.007045546024919646, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.9707367050742606}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:23,038] Trial 55 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 88, 'learning_rate': 0.011989302821964608, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.9632614820201802}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:23,383] Trial 56 finished with value: 0.8641036414565827 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.006373400870829545, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.9996156069094597}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:23,454] Trial 57 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 10, 'learning_rate': 0.004891520510817533, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.9772699110994327}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:23,784] Trial 58 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 93, 'learning_rate': 0.0417239872052281, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.9781612687092404}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:24,134] Trial 59 finished with value: 0.8473249299719889 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.009899127390633481, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7842967385281132}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:24,492] Trial 60 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 90, 'learning_rate': 0.01882652709618291, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.9480450770644244}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:24,781] Trial 61 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.006056238408818077, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.9943257192012234}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:25,079] Trial 62 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.006824672697021263, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.9980027958774508}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:25,274] Trial 63 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.015810400551409788, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.9679034453692555}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:25,684] Trial 64 finished with value: 0.850672268907563 and parameters: {'max_features': 'sqrt', 'n_estimators': 98, 'learning_rate': 0.0031873583587712544, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.9301345148095259}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:26,013] Trial 65 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.009277037064347298, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.9807535148935773}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:26,292] Trial 66 finished with value: 0.8540056022408964 and parameters: {'max_features': 'log2', 'n_estimators': 86, 'learning_rate': 0.011130096681094073, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.8394253533263303}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:26,640] Trial 67 finished with value: 0.8641316526610645 and parameters: {'max_features': 'sqrt', 'n_estimators': 93, 'learning_rate': 0.024123098410950138, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.9584889970205093}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:26,953] Trial 68 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 92, 'learning_rate': 0.023350251665559433, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.8627444699968392}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:27,159] Trial 69 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 99, 'learning_rate': 0.01461652702387124, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.8817422991076665}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:27,497] Trial 70 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 96, 'learning_rate': 0.023377062236187917, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.9532156741502498}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:27,805] Trial 71 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.005908380962278316, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.9421899698580941}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:28,123] Trial 72 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 89, 'learning_rate': 0.006907641370693342, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.9200706393126008}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:28,381] Trial 73 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.018408719826640205, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.5713912696929879}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:28,679] Trial 74 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 94, 'learning_rate': 0.013050026837910665, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.999859883140652}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:29,016] Trial 75 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.008334346203752079, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.9647041663837435}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:29,357] Trial 76 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 90, 'learning_rate': 0.005144987758702971, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.7251951364720743}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:29,703] Trial 77 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.032060587469477445, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.9849986009252122}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:29,866] Trial 78 finished with value: 0.8473389355742297 and parameters: {'max_features': 'sqrt', 'n_estimators': 26, 'learning_rate': 0.03774856803920524, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.9030169539284174}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:30,155] Trial 79 finished with value: 0.8322128851540616 and parameters: {'max_features': None, 'n_estimators': 69, 'learning_rate': 0.09421024060519738, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.8211874234265901}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:30,465] Trial 80 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.010535376985891, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.9559445563022897}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:30,765] Trial 81 finished with value: 0.8674649859943976 and parameters: {'max_features': 'sqrt', 'n_estimators': 97, 'learning_rate': 0.006973716451152555, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.8955244826097358}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:31,062] Trial 82 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 97, 'learning_rate': 0.004147884977188954, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.9385899736100547}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:31,412] Trial 83 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 93, 'learning_rate': 0.007523782223304368, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.9240009998605431}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:31,734] Trial 84 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 87, 'learning_rate': 0.00622856726914456, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.8885579548540843}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:32,052] Trial 85 finished with value: 0.8624089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.009201658742725863, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.9709797855186505}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:32,370] Trial 86 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 97, 'learning_rate': 0.02641634911192855, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.8688027461320789}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:32,503] Trial 87 finished with value: 0.8641036414565827 and parameters: {'max_features': 'sqrt', 'n_estimators': 45, 'learning_rate': 0.020385683794663823, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.9072420084957692}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:32,760] Trial 88 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.013312346766011368, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 9, 'subsample': 0.8483853820301105}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:33,007] Trial 89 finished with value: 0.8641036414565827 and parameters: {'max_features': 'sqrt', 'n_estimators': 94, 'learning_rate': 0.005464604010990776, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7976360223037499}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:33,356] Trial 90 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 88, 'learning_rate': 0.016032275206508836, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.9823247011378108}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:33,588] Trial 91 finished with value: 0.8641036414565825 and parameters: {'max_features': 'sqrt', 'n_estimators': 98, 'learning_rate': 0.021529917419337775, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.8982185130437489}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:33,699] Trial 92 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 43, 'learning_rate': 0.019952703392229557, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.91201013145399}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:33,933] Trial 93 finished with value: 0.8607422969187676 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.011518770738141988, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.8797967414430847}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:34,076] Trial 94 finished with value: 0.8607282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 47, 'learning_rate': 0.007780656019169967, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.9302143888630349}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:34,305] Trial 95 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 56, 'learning_rate': 0.02393399383012656, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.9464786894633835}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:34,416] Trial 96 finished with value: 0.8456302521008403 and parameters: {'max_features': None, 'n_estimators': 47, 'learning_rate': 0.0176608289929441, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.9140455577469125}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:34,511] Trial 97 finished with value: 0.8237955182072829 and parameters: {'max_features': 'log2', 'n_estimators': 38, 'learning_rate': 0.00457005563872474, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.955482825913371}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:34,779] Trial 98 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 60, 'learning_rate': 0.00643382621914568, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.968734021593445}. Best is trial 40 with value: 0.8674649859943978.\n",
      "[I 2025-10-06 13:14:34,954] Trial 99 finished with value: 0.8691456582633054 and parameters: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.014113282033022877, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.8334644059485119}. Best is trial 99 with value: 0.8691456582633054.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using TPESampler: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.014113282033022877, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.8334644059485119}\n",
      "Best accuracy: 0.8691, at trial: 99\n",
      "TPE Base Models Training Time: 85.58 seconds\n"
     ]
    }
   ],
   "source": [
    "tpe_base_models_training_start = time.time()\n",
    "\n",
    "# TPE Hyperparameter Tuning with Cross Validation\n",
    "tpe_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "tpe_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "tpe_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "tpe_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "tpe_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "tpe_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "tpe_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "# Model Fitting with best parameters\n",
    "tpe_logistic_regression.fit(X_train, y_train)\n",
    "tpe_decision_tree.fit(X_train, y_train)\n",
    "tpe_random_forest.fit(X_train, y_train)\n",
    "tpe_knn.fit(X_train, y_train)\n",
    "tpe_svc.fit(X_train, y_train)\n",
    "tpe_adaboost.fit(X_train, y_train)\n",
    "tpe_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "tpe_base_models_training_end = time.time()\n",
    "\n",
    "# Time taken for TPE base models training\n",
    "tpe_base_models_training_time = tpe_base_models_training_end - tpe_base_models_training_start\n",
    "print(f'TPE Base Models Training Time: {tpe_base_models_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:15:52,555] A new study created in memory with name: Logistic Regression Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13b2c883e6b4432a8ea2a5dd09eb438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:15:58,373] Trial 0 finished with value: 0.6459803921568629 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.6459803921568629.\n",
      "[I 2025-10-06 13:16:03,188] Trial 1 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cholesky', 'C': 0.3470266988650412}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:08,455] Trial 2 finished with value: 0.7265686274509804 and parameters: {'solver': 'newton-cg', 'C': 0.0008111941985431928}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:13,265] Trial 3 finished with value: 0.8137394957983192 and parameters: {'solver': 'newton-cholesky', 'C': 0.0028585493941961923}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:13,313] Trial 4 finished with value: 0.8489775910364145 and parameters: {'solver': 'lbfgs', 'C': 0.019069966103000432}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:13,360] Trial 5 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00017070728830306665}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:13,408] Trial 6 finished with value: 0.8372268907563025 and parameters: {'solver': 'sag', 'C': 6.732248920775331}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:13,446] Trial 7 finished with value: 0.8489775910364145 and parameters: {'solver': 'lbfgs', 'C': 0.015876781526923997}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:13,482] Trial 8 finished with value: 0.7919327731092437 and parameters: {'solver': 'sag', 'C': 0.0019674328025306126}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:13,519] Trial 9 finished with value: 0.7248879551820728 and parameters: {'solver': 'lbfgs', 'C': 0.0008399864445957502}. Best is trial 1 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:16:13,670] Trial 10 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08257791600771174}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:13,850] Trial 11 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cg', 'C': 1.0843297009977777}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:14,020] Trial 12 finished with value: 0.8540196078431371 and parameters: {'solver': 'sag', 'C': 0.11847167862050627}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:14,194] Trial 13 finished with value: 0.8506442577030814 and parameters: {'solver': 'newton-cholesky', 'C': 0.041750675605016385}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:14,402] Trial 14 finished with value: 0.8540056022408965 and parameters: {'solver': 'lbfgs', 'C': 0.18367733796117808}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:14,594] Trial 15 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cg', 'C': 0.013775182844460148}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:14,760] Trial 16 finished with value: 0.8523249299719888 and parameters: {'solver': 'newton-cg', 'C': 0.19833812327707598}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:15,124] Trial 17 finished with value: 0.8489775910364145 and parameters: {'solver': 'sag', 'C': 0.5610992000959879}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:15,296] Trial 18 finished with value: 0.8523249299719889 and parameters: {'solver': 'sag', 'C': 0.03658994091749913}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:15,494] Trial 19 finished with value: 0.8388935574229691 and parameters: {'solver': 'lbfgs', 'C': 2.0497509364991497}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:15,715] Trial 20 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.07451637787656343}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:15,885] Trial 21 finished with value: 0.835546218487395 and parameters: {'solver': 'newton-cholesky', 'C': 9.999999999999993}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:16,053] Trial 22 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cg', 'C': 0.055137612542946884}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:16,252] Trial 23 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cholesky', 'C': 0.11423895635122465}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:16,492] Trial 24 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08572103469293736}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:16,664] Trial 25 finished with value: 0.8556862745098041 and parameters: {'solver': 'sag', 'C': 0.10297854345148713}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:16,850] Trial 26 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09820175008594942}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:17,046] Trial 27 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.07363053906273681}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:17,234] Trial 28 finished with value: 0.850658263305322 and parameters: {'solver': 'lbfgs', 'C': 0.35988375702363457}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:17,452] Trial 29 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08659104733773268}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:17,682] Trial 30 finished with value: 0.8506442577030814 and parameters: {'solver': 'newton-cg', 'C': 0.04219120687452405}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:17,884] Trial 31 finished with value: 0.8540196078431371 and parameters: {'solver': 'lbfgs', 'C': 0.1133592106622583}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:18,111] Trial 32 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cholesky', 'C': 0.01613721579383934}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:18,313] Trial 33 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cholesky', 'C': 3.7280567881524824}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:18,527] Trial 34 finished with value: 0.8489775910364145 and parameters: {'solver': 'sag', 'C': 0.2638820278900169}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:18,749] Trial 35 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.8217374869079608}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:18,930] Trial 36 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.007056927085255724}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:19,105] Trial 37 finished with value: 0.8489775910364145 and parameters: {'solver': 'sag', 'C': 0.010741426045633806}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:19,318] Trial 38 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.0795606230481783}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:19,498] Trial 39 finished with value: 0.8556862745098041 and parameters: {'solver': 'sag', 'C': 0.07362577959427866}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:19,653] Trial 40 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cg', 'C': 0.5299529992980625}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:19,826] Trial 41 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.008977786515334181}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:19,990] Trial 42 finished with value: 0.850658263305322 and parameters: {'solver': 'sag', 'C': 0.020468470100667612}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:20,160] Trial 43 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08659763188818892}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:20,314] Trial 44 finished with value: 0.8489775910364145 and parameters: {'solver': 'lbfgs', 'C': 0.6821371652013049}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:20,470] Trial 45 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09091954437741163}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:20,668] Trial 46 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cg', 'C': 6.120932582901892}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:20,903] Trial 47 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08319388476573131}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:21,088] Trial 48 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08911755242336548}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:21,325] Trial 49 finished with value: 0.8338655462184873 and parameters: {'solver': 'lbfgs', 'C': 9.999999999999993}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:21,790] Trial 50 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09198210607612128}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:22,107] Trial 51 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.0830450510826653}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:22,368] Trial 52 finished with value: 0.8405742296918767 and parameters: {'solver': 'sag', 'C': 1.6050527468413753}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:22,737] Trial 53 finished with value: 0.8506442577030813 and parameters: {'solver': 'newton-cholesky', 'C': 0.20698813118750758}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:23,070] Trial 54 finished with value: 0.8489635854341737 and parameters: {'solver': 'lbfgs', 'C': 0.006420880593913556}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:23,347] Trial 55 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08815399026445789}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:23,665] Trial 56 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08313771672491152}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:23,936] Trial 57 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.06811222439407065}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:24,199] Trial 58 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09425773085624893}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:24,508] Trial 59 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08312997159145084}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:24,761] Trial 60 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.02714842095935069}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:25,002] Trial 61 finished with value: 0.8472969187675069 and parameters: {'solver': 'lbfgs', 'C': 0.009434023018285491}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:25,247] Trial 62 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.07495737495523959}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:25,539] Trial 63 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08755979377317219}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:25,806] Trial 64 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cg', 'C': 0.14213137004703003}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:26,203] Trial 65 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08723479435775351}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:26,488] Trial 66 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.030184405886904863}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:26,799] Trial 67 finished with value: 0.8540056022408965 and parameters: {'solver': 'lbfgs', 'C': 0.050907486413669586}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:27,078] Trial 68 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cg', 'C': 0.0271933235827535}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:27,348] Trial 69 finished with value: 0.8456022408963586 and parameters: {'solver': 'sag', 'C': 0.005270477839594299}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:27,665] Trial 70 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.0865540634251169}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:28,027] Trial 71 finished with value: 0.8523389355742296 and parameters: {'solver': 'newton-cholesky', 'C': 0.4976100856967228}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:28,364] Trial 72 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08589578385708323}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:28,619] Trial 73 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08292185986723687}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:29,102] Trial 74 finished with value: 0.8556862745098041 and parameters: {'solver': 'sag', 'C': 0.02789971860129961}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:29,477] Trial 75 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08581053319683825}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:29,766] Trial 76 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08587363143315392}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:30,231] Trial 77 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08737419439927453}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:30,670] Trial 78 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08274122164562353}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:31,272] Trial 79 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08584785618917298}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:31,569] Trial 80 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09540580744874881}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:31,925] Trial 81 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.0855071335014037}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:32,327] Trial 82 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08743331842874895}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:32,685] Trial 83 finished with value: 0.8540056022408965 and parameters: {'solver': 'sag', 'C': 0.17385557526727524}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:33,132] Trial 84 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08277454608738403}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:33,856] Trial 85 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08571390173778881}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:34,481] Trial 86 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.0874953075374899}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:35,021] Trial 87 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09525771180776721}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:35,583] Trial 88 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08577365020970641}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:36,063] Trial 89 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08269540216214549}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:36,603] Trial 90 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08658932934741859}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:37,160] Trial 91 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08573305400602257}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:37,935] Trial 92 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08754004966795108}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:38,422] Trial 93 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08563863564577799}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:39,000] Trial 94 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08265646339805834}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:39,583] Trial 95 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09531584222234728}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:40,079] Trial 96 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08508289518696946}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:40,599] Trial 97 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08276208279474598}. Best is trial 10 with value: 0.8573669467787116.\n",
      "[I 2025-10-06 13:16:41,196] Trial 98 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08572026879219513}. Best is trial 10 with value: 0.8573669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:16:41,668] A new study created in memory with name: Decision Tree Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:16:41,664] Trial 99 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09532430928985468}. Best is trial 10 with value: 0.8573669467787116.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using GPSampler: {'solver': 'newton-cg', 'C': 0.08257791600771174}\n",
      "Best accuracy: 0.8574, at trial: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d332bef8c4c4c83b3f3df63c30e3657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:16:41,813] Trial 0 finished with value: 0.8137535014005601 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[I 2025-10-06 13:16:41,916] Trial 1 finished with value: 0.8104061624649859 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[I 2025-10-06 13:16:42,027] Trial 2 finished with value: 0.8087254901960785 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[I 2025-10-06 13:16:42,109] Trial 3 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,139] Trial 4 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,172] Trial 5 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,198] Trial 6 finished with value: 0.8171148459383752 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,228] Trial 7 finished with value: 0.7902240896358543 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,259] Trial 8 finished with value: 0.7969467787114846 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,291] Trial 9 finished with value: 0.8187815126050421 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,417] Trial 10 finished with value: 0.8271708683473389 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,566] Trial 11 finished with value: 0.8271708683473389 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,699] Trial 12 finished with value: 0.8254901960784313 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,844] Trial 13 finished with value: 0.8086834733893558 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:42,987] Trial 14 finished with value: 0.8254901960784313 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:43,124] Trial 15 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:43,255] Trial 16 finished with value: 0.8271708683473389 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:43,391] Trial 17 finished with value: 0.7953221288515406 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:43,529] Trial 18 finished with value: 0.8271708683473389 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:43,654] Trial 19 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:43,786] Trial 20 finished with value: 0.8104061624649859 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8271848739495798.\n",
      "[I 2025-10-06 13:16:43,932] Trial 21 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:44,096] Trial 22 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:44,272] Trial 23 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:44,421] Trial 24 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:44,568] Trial 25 finished with value: 0.8187815126050421 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:44,718] Trial 26 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:44,862] Trial 27 finished with value: 0.8255462184873948 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:45,007] Trial 28 finished with value: 0.8322128851540616 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:45,152] Trial 29 finished with value: 0.8271708683473389 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:45,283] Trial 30 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:45,426] Trial 31 finished with value: 0.8070448179271708 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:45,554] Trial 32 finished with value: 0.8271708683473389 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:45,749] Trial 33 finished with value: 0.8070588235294117 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:45,886] Trial 34 finished with value: 0.8271708683473389 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:46,020] Trial 35 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:46,143] Trial 36 finished with value: 0.8322128851540616 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:46,250] Trial 37 finished with value: 0.8271708683473389 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:46,354] Trial 38 finished with value: 0.8070448179271708 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:46,506] Trial 39 finished with value: 0.8120868347338936 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:46,657] Trial 40 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:46,809] Trial 41 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:47,006] Trial 42 finished with value: 0.8255462184873948 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:47,162] Trial 43 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:47,324] Trial 44 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:47,474] Trial 45 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:47,632] Trial 46 finished with value: 0.8255462184873948 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:47,775] Trial 47 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:47,932] Trial 48 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:48,103] Trial 49 finished with value: 0.8154341736694677 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:48,253] Trial 50 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:48,416] Trial 51 finished with value: 0.8322128851540616 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:48,575] Trial 52 finished with value: 0.8322128851540616 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:48,727] Trial 53 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:48,912] Trial 54 finished with value: 0.8255042016806723 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:49,081] Trial 55 finished with value: 0.8271708683473389 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:49,235] Trial 56 finished with value: 0.8271708683473389 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:49,389] Trial 57 finished with value: 0.8171148459383752 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:49,542] Trial 58 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:49,688] Trial 59 finished with value: 0.8255042016806723 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:49,834] Trial 60 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:49,970] Trial 61 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:50,116] Trial 62 finished with value: 0.8322128851540616 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:50,267] Trial 63 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:50,432] Trial 64 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:50,574] Trial 65 finished with value: 0.8321988795518207 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:50,770] Trial 66 finished with value: 0.8187815126050418 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:50,961] Trial 67 finished with value: 0.823781512605042 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:51,112] Trial 68 finished with value: 0.8338935574229691 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:51,263] Trial 69 finished with value: 0.8238375350140055 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:51,455] Trial 70 finished with value: 0.8271708683473389 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:51,612] Trial 71 finished with value: 0.8338935574229691 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:51,765] Trial 72 finished with value: 0.8338935574229691 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:51,975] Trial 73 finished with value: 0.8322268907563025 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:52,139] Trial 74 finished with value: 0.8338935574229691 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:52,299] Trial 75 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:52,501] Trial 76 finished with value: 0.8238095238095238 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:52,671] Trial 77 finished with value: 0.830546218487395 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:52,831] Trial 78 finished with value: 0.8053781512605042 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:53,041] Trial 79 finished with value: 0.8238375350140055 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:53,212] Trial 80 finished with value: 0.8322268907563025 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:53,379] Trial 81 finished with value: 0.830546218487395 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:53,587] Trial 82 finished with value: 0.8238375350140055 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:53,766] Trial 83 finished with value: 0.8255742296918769 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:53,950] Trial 84 finished with value: 0.8255742296918769 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:54,150] Trial 85 finished with value: 0.8187815126050421 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:54,313] Trial 86 finished with value: 0.8271708683473389 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8338935574229691.\n",
      "[I 2025-10-06 13:16:54,502] Trial 87 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:54,729] Trial 88 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:54,874] Trial 89 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:55,029] Trial 90 finished with value: 0.8322128851540616 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:55,230] Trial 91 finished with value: 0.8204481792717087 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:55,384] Trial 92 finished with value: 0.825518207282913 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:55,530] Trial 93 finished with value: 0.8271988795518206 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:55,735] Trial 94 finished with value: 0.8187955182072828 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:55,880] Trial 95 finished with value: 0.8339075630252101 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:56,053] Trial 96 finished with value: 0.8339075630252101 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:56,267] Trial 97 finished with value: 0.8154341736694677 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 87 with value: 0.8339075630252101.\n",
      "[I 2025-10-06 13:16:56,449] Trial 98 finished with value: 0.8120728291316526 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 87 with value: 0.8339075630252101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:16:56,609] A new study created in memory with name: Random Forest Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:16:56,605] Trial 99 finished with value: 0.8339075630252101 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 87 with value: 0.8339075630252101.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using GPSampler: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}\n",
      "Best accuracy: 0.8339, at trial: 87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e595e52326df45fc9d1cc3dc77fe2072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:16:56,787] Trial 0 finished with value: 0.8372408963585434 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8372408963585434.\n",
      "[I 2025-10-06 13:16:57,006] Trial 1 finished with value: 0.8590756302521008 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:57,203] Trial 2 finished with value: 0.8356022408963586 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:57,409] Trial 3 finished with value: 0.8456302521008402 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:57,575] Trial 4 finished with value: 0.8389355742296918 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:57,688] Trial 5 finished with value: 0.8339075630252101 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:57,813] Trial 6 finished with value: 0.8288795518207281 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 22, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:58,072] Trial 7 finished with value: 0.8439495798319326 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:58,330] Trial 8 finished with value: 0.8456582633053223 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:58,537] Trial 9 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:59,027] Trial 10 finished with value: 0.8523529411764704 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 32, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:16:59,622] Trial 11 finished with value: 0.8523389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:00,066] Trial 12 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 25, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:00,780] Trial 13 finished with value: 0.845658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:01,465] Trial 14 finished with value: 0.8557002801120447 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:01,944] Trial 15 finished with value: 0.8523389355742296 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 39, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:02,479] Trial 16 finished with value: 0.8557282913165265 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:02,858] Trial 17 finished with value: 0.845672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:03,366] Trial 18 finished with value: 0.8490196078431372 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:03,831] Trial 19 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:04,358] Trial 20 finished with value: 0.8473249299719889 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:04,783] Trial 21 finished with value: 0.8473249299719887 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 11, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:05,238] Trial 22 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 23, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:05,639] Trial 23 finished with value: 0.8372549019607843 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:06,254] Trial 24 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:06,643] Trial 25 finished with value: 0.8355742296918767 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8590756302521008.\n",
      "[I 2025-10-06 13:17:07,241] Trial 26 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 26 with value: 0.8607563025210083.\n",
      "[I 2025-10-06 13:17:07,676] Trial 27 finished with value: 0.8624369747899159 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:08,114] Trial 28 finished with value: 0.8523669467787114 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:08,516] Trial 29 finished with value: 0.8523669467787114 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 28, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:08,965] Trial 30 finished with value: 0.8490336134453781 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 45, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:09,606] Trial 31 finished with value: 0.8624369747899159 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 78, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:10,215] Trial 32 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 82, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:10,822] Trial 33 finished with value: 0.8607422969187674 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 94, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:11,513] Trial 34 finished with value: 0.8557282913165265 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:12,119] Trial 35 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 91, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:12,705] Trial 36 finished with value: 0.8490056022408965 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:13,236] Trial 37 finished with value: 0.8590616246498598 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:13,774] Trial 38 finished with value: 0.8372829131652659 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:14,365] Trial 39 finished with value: 0.8607703081232494 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:14,867] Trial 40 finished with value: 0.8473529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:15,387] Trial 41 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:15,938] Trial 42 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:16,407] Trial 43 finished with value: 0.8624229691876749 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:16,910] Trial 44 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.8624369747899159.\n",
      "[I 2025-10-06 13:17:17,386] Trial 45 finished with value: 0.8641176470588234 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 52, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:17,864] Trial 46 finished with value: 0.8557422969187677 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 52, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:18,421] Trial 47 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:19,018] Trial 48 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:19,482] Trial 49 finished with value: 0.8439775910364145 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:19,983] Trial 50 finished with value: 0.8624229691876749 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:20,535] Trial 51 finished with value: 0.8490056022408963 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:21,181] Trial 52 finished with value: 0.850658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:21,789] Trial 53 finished with value: 0.850658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:22,205] Trial 54 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 48, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:22,783] Trial 55 finished with value: 0.8540476190476189 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:23,288] Trial 56 finished with value: 0.8557282913165265 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:23,991] Trial 57 finished with value: 0.8339075630252101 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:24,539] Trial 58 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:25,092] Trial 59 finished with value: 0.850658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:25,647] Trial 60 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:26,119] Trial 61 finished with value: 0.8490056022408963 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 62, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:26,767] Trial 62 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:27,330] Trial 63 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:27,937] Trial 64 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:28,420] Trial 65 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:28,974] Trial 66 finished with value: 0.8607563025210083 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:29,600] Trial 67 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:30,160] Trial 68 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:30,474] Trial 69 finished with value: 0.8405882352941175 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:30,999] Trial 70 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:31,596] Trial 71 finished with value: 0.8523669467787114 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:32,120] Trial 72 finished with value: 0.8456442577030812 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:32,722] Trial 73 finished with value: 0.8523669467787114 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:33,217] Trial 74 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:33,765] Trial 75 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:34,305] Trial 76 finished with value: 0.8523389355742296 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:34,854] Trial 77 finished with value: 0.8557142857142856 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:35,401] Trial 78 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:35,741] Trial 79 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:36,283] Trial 80 finished with value: 0.850672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:36,818] Trial 81 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:37,276] Trial 82 finished with value: 0.8590616246498598 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:37,742] Trial 83 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.8641176470588234.\n",
      "[I 2025-10-06 13:17:38,283] Trial 84 finished with value: 0.865798319327731 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 75, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:38,804] Trial 85 finished with value: 0.865798319327731 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 76, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:39,323] Trial 86 finished with value: 0.865798319327731 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 75, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:39,813] Trial 87 finished with value: 0.865798319327731 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 75, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:40,305] Trial 88 finished with value: 0.8641176470588234 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:40,819] Trial 89 finished with value: 0.8641176470588234 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:41,277] Trial 90 finished with value: 0.8641176470588234 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:41,767] Trial 91 finished with value: 0.8607563025210083 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:42,255] Trial 92 finished with value: 0.8641176470588234 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:42,763] Trial 93 finished with value: 0.8607563025210083 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:43,173] Trial 94 finished with value: 0.845658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:43,683] Trial 95 finished with value: 0.8607563025210083 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:44,233] Trial 96 finished with value: 0.837296918767507 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:44,746] Trial 97 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 90, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n",
      "[I 2025-10-06 13:17:45,307] Trial 98 finished with value: 0.8472969187675069 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 84 with value: 0.865798319327731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:17:45,896] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:17:45,891] Trial 99 finished with value: 0.8473109243697479 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 84 with value: 0.865798319327731.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using GPSampler: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 75, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "Best accuracy: 0.8658, at trial: 84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a319114a9e4c4f8fba85fb72b63d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:17:45,979] Trial 0 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:17:46,237] Trial 1 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:17:46,310] Trial 2 finished with value: 0.8472969187675069 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:17:46,544] Trial 3 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:17:46,606] Trial 4 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:17:46,665] Trial 5 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[I 2025-10-06 13:17:46,728] Trial 6 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 6 with value: 0.8590196078431372.\n",
      "[I 2025-10-06 13:17:46,787] Trial 7 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 6 with value: 0.8590196078431372.\n",
      "[I 2025-10-06 13:17:46,861] Trial 8 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 8 with value: 0.8607002801120448.\n",
      "[I 2025-10-06 13:17:46,921] Trial 9 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 8 with value: 0.8607002801120448.\n",
      "[I 2025-10-06 13:17:47,135] Trial 10 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 1}. Best is trial 8 with value: 0.8607002801120448.\n",
      "[I 2025-10-06 13:17:47,322] Trial 11 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:47,501] Trial 12 finished with value: 0.8556582633053221 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:47,673] Trial 13 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:48,016] Trial 14 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:48,211] Trial 15 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:48,404] Trial 16 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:48,560] Trial 17 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:48,729] Trial 18 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:49,079] Trial 19 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:49,244] Trial 20 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:49,431] Trial 21 finished with value: 0.8321568627450981 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:49,800] Trial 22 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 1}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:49,976] Trial 23 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:50,314] Trial 24 finished with value: 0.8556582633053221 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:50,493] Trial 25 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:50,663] Trial 26 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:50,837] Trial 27 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:51,191] Trial 28 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:51,401] Trial 29 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:51,602] Trial 30 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:51,791] Trial 31 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:51,962] Trial 32 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:52,149] Trial 33 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:52,327] Trial 34 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 11 with value: 0.8623809523809524.\n",
      "[I 2025-10-06 13:17:52,528] Trial 35 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:52,711] Trial 36 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:52,901] Trial 37 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 1}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:53,091] Trial 38 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:53,288] Trial 39 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:53,513] Trial 40 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:53,712] Trial 41 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:53,936] Trial 42 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:54,118] Trial 43 finished with value: 0.850658263305322 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 23, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:54,308] Trial 44 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:54,490] Trial 45 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:54,641] Trial 46 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:54,800] Trial 47 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 1}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:54,954] Trial 48 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:55,130] Trial 49 finished with value: 0.8573389355742297 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:55,312] Trial 50 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:55,493] Trial 51 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:55,668] Trial 52 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:55,841] Trial 53 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:56,032] Trial 54 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:56,238] Trial 55 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:56,442] Trial 56 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:56,624] Trial 57 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:56,806] Trial 58 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:56,988] Trial 59 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:57,172] Trial 60 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:57,355] Trial 61 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:57,547] Trial 62 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:57,739] Trial 63 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:57,929] Trial 64 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:58,132] Trial 65 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:58,322] Trial 66 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:58,514] Trial 67 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:58,711] Trial 68 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:58,909] Trial 69 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:59,107] Trial 70 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:59,303] Trial 71 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:59,506] Trial 72 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:59,709] Trial 73 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:17:59,909] Trial 74 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:00,119] Trial 75 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:00,343] Trial 76 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:00,537] Trial 77 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:00,730] Trial 78 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:00,937] Trial 79 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:01,133] Trial 80 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:01,341] Trial 81 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:01,553] Trial 82 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:01,762] Trial 83 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:01,960] Trial 84 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:02,176] Trial 85 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:02,372] Trial 86 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:02,582] Trial 87 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:02,779] Trial 88 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:02,980] Trial 89 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:03,176] Trial 90 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:03,489] Trial 91 finished with value: 0.8439635854341736 and parameters: {'algorithm': 'brute', 'n_neighbors': 9, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:03,784] Trial 92 finished with value: 0.8506442577030813 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:04,057] Trial 93 finished with value: 0.8573669467787115 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:04,307] Trial 94 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 16, 'p': 1}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:04,573] Trial 95 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:04,851] Trial 96 finished with value: 0.8506442577030813 and parameters: {'algorithm': 'brute', 'n_neighbors': 18, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:05,111] Trial 97 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 35 with value: 0.8624089635854343.\n",
      "[I 2025-10-06 13:18:05,480] Trial 98 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 1}. Best is trial 35 with value: 0.8624089635854343.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:18:05,732] A new study created in memory with name: Support Vector Machine Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:18:05,729] Trial 99 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 1}. Best is trial 35 with value: 0.8624089635854343.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using GPSampler: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}\n",
      "Best accuracy: 0.8624, at trial: 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544d7b3efcf14a92b989098c97cd963b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:18:05,794] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-10-06 13:18:05,843] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.005399484409787433}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-10-06 13:18:05,894] Trial 2 finished with value: 0.5453221288515406 and parameters: {'kernel': 'sigmoid', 'C': 0.008706020878304856}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:18:05,945] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023270677083837802}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:18:05,999] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0003823475224675188}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:18:06,050] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005404103854647331}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:18:06,102] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010677482709481358}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:18:06,141] Trial 7 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00021930485556643703, 'degree': 2}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:18:06,193] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004066563313514797}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:18:06,246] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00017541893487450815}. Best is trial 2 with value: 0.5453221288515406.\n",
      "[I 2025-10-06 13:18:06,386] Trial 10 finished with value: 0.6241596638655462 and parameters: {'kernel': 'sigmoid', 'C': 0.01}. Best is trial 10 with value: 0.6241596638655462.\n",
      "[W 2025-10-06 13:18:06,521] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:06,548] Trial 11 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 11 with value: 0.7986134453781512.\n",
      "[W 2025-10-06 13:18:06,625] The parameter `degree` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:06,665] Trial 12 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 11 with value: 0.7986134453781512.\n",
      "[W 2025-10-06 13:18:06,737] The parameter `degree` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:06,765] Trial 13 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:06,856] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:06,884] Trial 14 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:07,014] The parameter `degree` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:07,050] Trial 15 finished with value: 0.7751680672268908 and parameters: {'kernel': 'poly', 'C': 0.004291983016449906, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:07,136] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:07,175] Trial 16 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:07,275] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:07,314] Trial 17 finished with value: 0.812016806722689 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:07,396] The parameter `degree` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:07,436] Trial 18 finished with value: 0.812016806722689 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:07,529] The parameter `degree` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:07,567] Trial 19 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:07,707] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:07,746] Trial 20 finished with value: 0.7785294117647059 and parameters: {'kernel': 'poly', 'C': 0.004045469789682353, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:07,825] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:07,862] Trial 21 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:07,933] The parameter `degree` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:07,973] Trial 22 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:08,043] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:08,081] Trial 23 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:08,163] The parameter `degree` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:08,203] Trial 24 finished with value: 0.812016806722689 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:08,291] The parameter `degree` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:08,329] Trial 25 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:08,397] The parameter `degree` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:08,435] Trial 26 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:08,517] The parameter `degree` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:08,553] Trial 27 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:08,656] The parameter `degree` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:08,694] Trial 28 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:08,817] The parameter `degree` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:08,856] Trial 29 finished with value: 0.7751820728291318 and parameters: {'kernel': 'poly', 'C': 0.004446813366608732, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:08,939] The parameter `degree` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:08,978] Trial 30 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:09,064] The parameter `degree` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:09,102] Trial 31 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:09,187] The parameter `degree` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:09,225] Trial 32 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:09,334] The parameter `degree` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:09,370] Trial 33 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:09,463] The parameter `degree` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:09,501] Trial 34 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:09,659] The parameter `degree` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:09,700] Trial 35 finished with value: 0.7751680672268908 and parameters: {'kernel': 'poly', 'C': 0.004242996692012329, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:09,806] The parameter `degree` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:09,857] Trial 36 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:09,974] The parameter `degree` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:10,012] Trial 37 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:10,122] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:10,159] Trial 38 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:10,261] The parameter `degree` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:10,300] Trial 39 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:10,401] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:10,440] Trial 40 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:10,525] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:10,563] Trial 41 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:10,688] The parameter `degree` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:10,725] Trial 42 finished with value: 0.7768347338935575 and parameters: {'kernel': 'poly', 'C': 0.004369233103600172, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:10,820] The parameter `degree` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:10,858] Trial 43 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:10,953] The parameter `degree` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:10,993] Trial 44 finished with value: 0.812016806722689 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:11,105] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:11,143] Trial 45 finished with value: 0.812016806722689 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:11,290] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:11,330] Trial 46 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:11,431] The parameter `degree` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:11,469] Trial 47 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:11,573] The parameter `degree` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:11,611] Trial 48 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:11,723] The parameter `degree` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:11,760] Trial 49 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:11,911] The parameter `degree` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:11,948] Trial 50 finished with value: 0.7751820728291318 and parameters: {'kernel': 'poly', 'C': 0.002449699729029757, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:12,089] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:12,128] Trial 51 finished with value: 0.7751680672268908 and parameters: {'kernel': 'poly', 'C': 0.0055090163038709625, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:12,242] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:12,280] Trial 52 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:12,415] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:12,453] Trial 53 finished with value: 0.7500140056022409 and parameters: {'kernel': 'poly', 'C': 0.0018142197629092062, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:12,591] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:12,629] Trial 54 finished with value: 0.7734873949579832 and parameters: {'kernel': 'poly', 'C': 0.005792091803286313, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:12,778] Trial 55 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00010065354576858747}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:12,867] The parameter `degree` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:12,906] Trial 56 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:13,011] The parameter `degree` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:13,049] Trial 57 finished with value: 0.812016806722689 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:13,198] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:13,236] Trial 58 finished with value: 0.7751680672268908 and parameters: {'kernel': 'poly', 'C': 0.0056972425218090525, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:13,339] The parameter `degree` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:13,377] Trial 59 finished with value: 0.8355182072829133 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:13,496] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:13,534] Trial 60 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:13,622] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:13,660] Trial 61 finished with value: 0.7885854341736694 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:13,798] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:13,837] Trial 62 finished with value: 0.7584033613445378 and parameters: {'kernel': 'poly', 'C': 0.0014218599405868846, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:13,984] The parameter `degree` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:14,023] Trial 63 finished with value: 0.7617647058823529 and parameters: {'kernel': 'poly', 'C': 0.0010077243162062348, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:14,229] Trial 64 finished with value: 0.7466526610644257 and parameters: {'kernel': 'rbf', 'C': 0.01}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:14,367] The parameter `degree` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:14,404] Trial 65 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.0006486591183060499, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:14,502] The parameter `degree` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:14,550] Trial 66 finished with value: 0.6359243697478991 and parameters: {'kernel': 'poly', 'C': 0.00010000000000000009, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:14,743] Trial 67 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0001002261219855309}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:14,898] The parameter `degree` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:14,935] Trial 68 finished with value: 0.7835574229691877 and parameters: {'kernel': 'poly', 'C': 0.007715204970395831, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:15,145] Trial 69 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0015366747184220849}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:15,293] The parameter `degree` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:15,331] Trial 70 finished with value: 0.7751820728291318 and parameters: {'kernel': 'poly', 'C': 0.0028531990786904975, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:15,488] The parameter `degree` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:15,527] Trial 71 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.0009061522670267387, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:15,699] The parameter `degree` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:15,737] Trial 72 finished with value: 0.7801820728291317 and parameters: {'kernel': 'poly', 'C': 0.0077423719040888754, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:15,934] Trial 73 finished with value: 0.7466526610644257 and parameters: {'kernel': 'rbf', 'C': 0.01}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:16,096] The parameter `degree` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:16,146] Trial 74 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0005194156183978488, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:16,361] Trial 75 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0035733336042769195}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:16,531] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:16,569] Trial 76 finished with value: 0.7735014005602242 and parameters: {'kernel': 'poly', 'C': 0.0030739191819927404, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:16,716] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:16,753] Trial 77 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.007994152506883383, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:16,914] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:16,953] Trial 78 finished with value: 0.7550560224089635 and parameters: {'kernel': 'poly', 'C': 0.0011952646154409874, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:17,149] The parameter `degree` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:17,187] Trial 79 finished with value: 0.7986134453781512 and parameters: {'kernel': 'poly', 'C': 0.008076335166653485, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:17,330] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:17,369] Trial 80 finished with value: 0.7751820728291318 and parameters: {'kernel': 'poly', 'C': 0.002218703986104767, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:17,535] The parameter `degree` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:17,572] Trial 81 finished with value: 0.7768487394957984 and parameters: {'kernel': 'poly', 'C': 0.003214104906607192, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:17,746] The parameter `degree` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:17,786] Trial 82 finished with value: 0.7835434173669468 and parameters: {'kernel': 'poly', 'C': 0.008211660201480812, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:17,970] Trial 83 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.002787547217853163}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:18,124] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:18,161] Trial 84 finished with value: 0.7550560224089635 and parameters: {'kernel': 'poly', 'C': 0.0008626130188506369, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:18,344] The parameter `degree` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:18,382] Trial 85 finished with value: 0.7818627450980392 and parameters: {'kernel': 'poly', 'C': 0.008175434594040869, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:18,551] The parameter `degree` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:18,597] Trial 86 finished with value: 0.7567226890756302 and parameters: {'kernel': 'poly', 'C': 0.002029556365602928, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:18,803] The parameter `degree` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:18,842] Trial 87 finished with value: 0.7701400560224089 and parameters: {'kernel': 'poly', 'C': 0.0032775614032725473, 'degree': 3}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:19,056] Trial 88 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0008990612751346547}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:19,220] The parameter `degree` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:19,257] Trial 89 finished with value: 0.7785154061624651 and parameters: {'kernel': 'poly', 'C': 0.006759313009505826, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:19,419] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:19,457] Trial 90 finished with value: 0.7701400560224089 and parameters: {'kernel': 'poly', 'C': 0.001374574638590524, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[I 2025-10-06 13:18:19,686] Trial 91 finished with value: 0.7466526610644257 and parameters: {'kernel': 'rbf', 'C': 0.01}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:19,849] The parameter `degree` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:19,887] Trial 92 finished with value: 0.7718207282913166 and parameters: {'kernel': 'poly', 'C': 0.002633297919323557, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:20,071] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:20,110] Trial 93 finished with value: 0.800280112044818 and parameters: {'kernel': 'poly', 'C': 0.00840294636189438, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:20,284] The parameter `degree` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:20,323] Trial 94 finished with value: 0.7634313725490196 and parameters: {'kernel': 'poly', 'C': 0.0010778749509518996, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:20,502] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:20,540] Trial 95 finished with value: 0.8304901960784313 and parameters: {'kernel': 'poly', 'C': 0.008463307555227697, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:20,757] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:20,796] Trial 96 finished with value: 0.7818627450980392 and parameters: {'kernel': 'poly', 'C': 0.008326210217842543, 'degree': 2}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:20,955] The parameter `degree` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:20,992] Trial 97 finished with value: 0.8136974789915966 and parameters: {'kernel': 'poly', 'C': 0.006331466064618758, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:21,174] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:21,212] Trial 98 finished with value: 0.781890756302521 and parameters: {'kernel': 'poly', 'C': 0.006394191249138339, 'degree': 4}. Best is trial 13 with value: 0.8355182072829133.\n",
      "[W 2025-10-06 13:18:21,388] The parameter `degree` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:18:21,425] Trial 99 finished with value: 0.7718207282913164 and parameters: {'kernel': 'poly', 'C': 0.0016711422016171776, 'degree': 5}. Best is trial 13 with value: 0.8355182072829133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:18:21,429] A new study created in memory with name: AdaBoost Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Support Vector Machine Using GPSampler: {'kernel': 'poly', 'C': 0.01, 'degree': 5}\n",
      "Best accuracy: 0.8355, at trial: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0208547364d406e95601f1355cadf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:18:21,610] Trial 0 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:18:21,836] Trial 1 finished with value: 0.84390756302521 and parameters: {'n_estimators': 76, 'learning_rate': 0.06251373574521749}. Best is trial 1 with value: 0.84390756302521.\n",
      "[I 2025-10-06 13:18:21,916] Trial 2 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029375384576328283}. Best is trial 1 with value: 0.84390756302521.\n",
      "[I 2025-10-06 13:18:21,974] Trial 3 finished with value: 0.8388795518207284 and parameters: {'n_estimators': 15, 'learning_rate': 0.39676050770529875}. Best is trial 1 with value: 0.84390756302521.\n",
      "[I 2025-10-06 13:18:22,150] Trial 4 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:22,209] Trial 5 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 11, 'learning_rate': 0.8123245085588685}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:22,431] Trial 6 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 85, 'learning_rate': 0.004335281794951566}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:22,523] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.0035498788321965025}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:22,643] Trial 8 finished with value: 0.8305882352941175 and parameters: {'n_estimators': 37, 'learning_rate': 0.03752055855124281}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:22,809] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 49, 'learning_rate': 0.007476312062252299}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:23,464] Trial 10 finished with value: 0.8472829131652662 and parameters: {'n_estimators': 100, 'learning_rate': 0.20055395036977625}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:23,984] Trial 11 finished with value: 0.8456022408963586 and parameters: {'n_estimators': 77, 'learning_rate': 0.15549057059439053}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:24,589] Trial 12 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 100, 'learning_rate': 0.11311041132020137}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:25,048] Trial 13 finished with value: 0.8372408963585434 and parameters: {'n_estimators': 100, 'learning_rate': 1.0}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:25,543] Trial 14 finished with value: 0.8422408963585435 and parameters: {'n_estimators': 76, 'learning_rate': 0.1930655361702922}. Best is trial 4 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:18:26,126] Trial 15 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.10663414295863138}. Best is trial 15 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:18:26,688] Trial 16 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 100, 'learning_rate': 0.09696468478395336}. Best is trial 15 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:18:27,037] Trial 17 finished with value: 0.8272268907563024 and parameters: {'n_estimators': 10, 'learning_rate': 0.12569570411489334}. Best is trial 15 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:18:27,570] Trial 18 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.05711431423811406}. Best is trial 15 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:18:28,160] Trial 19 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 100, 'learning_rate': 0.06123713714000869}. Best is trial 15 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:18:28,477] Trial 20 finished with value: 0.8321848739495797 and parameters: {'n_estimators': 10, 'learning_rate': 1.0}. Best is trial 15 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:18:29,056] Trial 21 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.1150034209015256}. Best is trial 15 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:18:29,668] Trial 22 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.0981251861874955}. Best is trial 15 with value: 0.8506302521008402.\n",
      "[I 2025-10-06 13:18:30,254] Trial 23 finished with value: 0.8506442577030813 and parameters: {'n_estimators': 100, 'learning_rate': 0.16526806233749494}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:30,859] Trial 24 finished with value: 0.8506442577030813 and parameters: {'n_estimators': 100, 'learning_rate': 0.16199768421876495}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:31,490] Trial 25 finished with value: 0.8456022408963586 and parameters: {'n_estimators': 100, 'learning_rate': 0.1596723429508411}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:32,089] Trial 26 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.09080686803399793}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:32,685] Trial 27 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.09029448800502834}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:33,361] Trial 28 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.0899059775618316}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:34,050] Trial 29 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.08963430597831262}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:34,730] Trial 30 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.08864951429733414}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:35,437] Trial 31 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.08616653627108026}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:36,220] Trial 32 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.06818213633151823}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:37,045] Trial 33 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.1082241008371174}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:37,819] Trial 34 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.05856075644520236}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:38,387] Trial 35 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.057302297988503365}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:38,897] Trial 36 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.08012130649293839}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:39,351] Trial 37 finished with value: 0.8472549019607843 and parameters: {'n_estimators': 100, 'learning_rate': 0.04968636633772432}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:39,869] Trial 38 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.09122785811823661}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:40,360] Trial 39 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.09088090993314965}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:40,893] Trial 40 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.0905075154348405}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:41,314] Trial 41 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.0901258413058173}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:41,753] Trial 42 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.08951918916664905}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:42,198] Trial 43 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.08838582479088063}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:42,601] Trial 44 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 100, 'learning_rate': 0.0873862052017713}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:43,106] Trial 45 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.08316601187295533}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:43,603] Trial 46 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.08084681189517899}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:44,045] Trial 47 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 100, 'learning_rate': 0.07918430107728758}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:44,492] Trial 48 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 100, 'learning_rate': 0.2799640463731915}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:44,973] Trial 49 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 88, 'learning_rate': 0.09347855650106737}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:45,439] Trial 50 finished with value: 0.8455742296918768 and parameters: {'n_estimators': 100, 'learning_rate': 0.0473530267027675}. Best is trial 23 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:18:45,865] Trial 51 finished with value: 0.8523109243697478 and parameters: {'n_estimators': 100, 'learning_rate': 0.10652192145694565}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:46,249] Trial 52 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 100, 'learning_rate': 0.0010000000000000002}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:46,710] Trial 53 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 59, 'learning_rate': 0.3483268580560805}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:47,149] Trial 54 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 48, 'learning_rate': 0.22980542712524685}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:47,461] Trial 55 finished with value: 0.830532212885154 and parameters: {'n_estimators': 62, 'learning_rate': 0.9999999999999991}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:47,963] Trial 56 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 52, 'learning_rate': 0.14681010192660493}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:48,406] Trial 57 finished with value: 0.8506442577030813 and parameters: {'n_estimators': 39, 'learning_rate': 0.2968819391864659}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:48,902] Trial 58 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 39, 'learning_rate': 0.3006696871624522}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:49,386] Trial 59 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 43, 'learning_rate': 0.21521901227218576}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:49,758] Trial 60 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.0010073535954883532}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:50,232] Trial 61 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 35, 'learning_rate': 0.42039265889707744}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:50,793] Trial 62 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 100, 'learning_rate': 0.02371344048301599}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:51,368] Trial 63 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 57, 'learning_rate': 0.12063802601104126}. Best is trial 51 with value: 0.8523109243697478.\n",
      "[I 2025-10-06 13:18:51,888] Trial 64 finished with value: 0.8539915966386553 and parameters: {'n_estimators': 55, 'learning_rate': 0.2183643573364074}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:52,363] Trial 65 finished with value: 0.8523249299719889 and parameters: {'n_estimators': 56, 'learning_rate': 0.23352010820330604}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:52,919] Trial 66 finished with value: 0.8523249299719889 and parameters: {'n_estimators': 56, 'learning_rate': 0.23454898170987332}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:53,443] Trial 67 finished with value: 0.843921568627451 and parameters: {'n_estimators': 57, 'learning_rate': 0.22604240925550298}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:53,900] Trial 68 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 48, 'learning_rate': 0.14011021013782662}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:54,321] Trial 69 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 59, 'learning_rate': 0.09857865256388647}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:54,707] Trial 70 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 42, 'learning_rate': 0.17209696225721896}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:55,169] Trial 71 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 53, 'learning_rate': 0.0010000000000000002}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:55,553] Trial 72 finished with value: 0.8456022408963586 and parameters: {'n_estimators': 49, 'learning_rate': 0.2791460929282892}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:55,956] Trial 73 finished with value: 0.8221428571428572 and parameters: {'n_estimators': 31, 'learning_rate': 0.9974192592210074}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:56,324] Trial 74 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.015951484206754216}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:56,782] Trial 75 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 78, 'learning_rate': 0.3697824636102904}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:57,290] Trial 76 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 78, 'learning_rate': 0.04010882864803254}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:57,863] Trial 77 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 100, 'learning_rate': 0.39913420765943675}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:58,290] Trial 78 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 42, 'learning_rate': 0.15270447697113987}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:58,744] Trial 79 finished with value: 0.8422268907563024 and parameters: {'n_estimators': 60, 'learning_rate': 0.19304420219315527}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:59,183] Trial 80 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 85, 'learning_rate': 0.10094759608103633}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:18:59,579] Trial 81 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 36, 'learning_rate': 0.23142313303011675}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:00,029] Trial 82 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 50, 'learning_rate': 0.32768029942451576}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:00,663] Trial 83 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 47, 'learning_rate': 0.10727573387324471}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:01,053] Trial 84 finished with value: 0.8422268907563024 and parameters: {'n_estimators': 35, 'learning_rate': 0.2202632678585127}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:01,428] Trial 85 finished with value: 0.8489355742296919 and parameters: {'n_estimators': 61, 'learning_rate': 0.07846207580033018}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:01,897] Trial 86 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 83, 'learning_rate': 0.09459866348103467}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:02,297] Trial 87 finished with value: 0.8455742296918768 and parameters: {'n_estimators': 59, 'learning_rate': 0.0743998827607903}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:02,734] Trial 88 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 55, 'learning_rate': 0.35656464363378043}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:03,182] Trial 89 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 64, 'learning_rate': 0.13401943030334085}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:03,627] Trial 90 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 57, 'learning_rate': 0.15159509251490788}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:04,089] Trial 91 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 72, 'learning_rate': 0.10784645769648467}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:04,666] Trial 92 finished with value: 0.8523109243697478 and parameters: {'n_estimators': 85, 'learning_rate': 0.13595242901911883}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:05,163] Trial 93 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 80, 'learning_rate': 0.1143549035614355}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:05,614] Trial 94 finished with value: 0.843921568627451 and parameters: {'n_estimators': 82, 'learning_rate': 0.14423822807373016}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:06,153] Trial 95 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 84, 'learning_rate': 0.0743584356771483}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:06,597] Trial 96 finished with value: 0.8472689075630253 and parameters: {'n_estimators': 10, 'learning_rate': 0.3742378753425503}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:07,114] Trial 97 finished with value: 0.8238655462184873 and parameters: {'n_estimators': 100, 'learning_rate': 0.014583896920824627}. Best is trial 64 with value: 0.8539915966386553.\n",
      "[I 2025-10-06 13:19:07,483] Trial 98 finished with value: 0.8455742296918768 and parameters: {'n_estimators': 10, 'learning_rate': 0.39442878615008103}. Best is trial 64 with value: 0.8539915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:19:07,949] A new study created in memory with name: Gradient Boosting Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:19:07,949] Trial 99 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 70, 'learning_rate': 0.09732084515158487}. Best is trial 64 with value: 0.8539915966386553.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using GPSampler: {'n_estimators': 55, 'learning_rate': 0.2183643573364074}\n",
      "Best accuracy: 0.8540, at trial: 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dc37449a1d4b07a752147948fcd032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:19:08,057] Trial 0 finished with value: 0.7985994397759104 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.7985994397759104.\n",
      "[I 2025-10-06 13:19:08,229] Trial 1 finished with value: 0.83890756302521 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.0026587543983272706, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.762378215816119}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:19:08,288] Trial 2 finished with value: 0.7028991596638656 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.00383962929980417, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.5998368910791798}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:19:08,366] Trial 3 finished with value: 0.8019607843137255 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.002193048555664369, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9041986740582306}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:19:08,487] Trial 4 finished with value: 0.7129551820728292 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.0017541893487450805, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6293899908000085}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:19:08,618] Trial 5 finished with value: 0.8086834733893558 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.0023426581058204046, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.9474136752138245}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:19:08,676] Trial 6 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.0012315571723666018, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9143687545759647}. Best is trial 1 with value: 0.83890756302521.\n",
      "[I 2025-10-06 13:19:08,714] Trial 7 finished with value: 0.8456162464985993 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.040215545266902894, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.5993578407670862}. Best is trial 7 with value: 0.8456162464985993.\n",
      "[I 2025-10-06 13:19:08,802] Trial 8 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.034877126245459314, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9315517129377968}. Best is trial 8 with value: 0.8590616246498598.\n",
      "[I 2025-10-06 13:19:08,883] Trial 9 finished with value: 0.8204481792717087 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.004470608546778492, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7361074625809747}. Best is trial 8 with value: 0.8590616246498598.\n",
      "[I 2025-10-06 13:19:09,484] Trial 10 finished with value: 0.8641036414565827 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.0190236557800668, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.71143792022291}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:10,019] Trial 11 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.008208941311881587, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.8103363876867217}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:10,540] Trial 12 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.03951699406567199, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.7135974649324629}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:11,063] Trial 13 finished with value: 0.8590756302521008 and parameters: {'max_features': None, 'n_estimators': 98, 'learning_rate': 0.024904491507671555, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.5722394735386876}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:11,846] Trial 14 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.008589984362053832, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.5}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:12,317] Trial 15 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.011460569288685338, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:12,730] Trial 16 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.011697174951533561, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:13,197] Trial 17 finished with value: 0.8573669467787115 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.012540763476063503, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:13,781] Trial 18 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 10 with value: 0.8641036414565827.\n",
      "[I 2025-10-06 13:19:14,658] Trial 19 finished with value: 0.8691456582633054 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:15,324] Trial 20 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:15,798] Trial 21 finished with value: 0.8389215686274512 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0028364894680298074, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:16,308] Trial 22 finished with value: 0.8557142857142856 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.09999999999999998, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:16,698] Trial 23 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 38, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:17,317] Trial 24 finished with value: 0.8255322128851541 and parameters: {'max_features': None, 'n_estimators': 52, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:17,829] Trial 25 finished with value: 0.865798319327731 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.07600647857535593, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:18,309] Trial 26 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 56, 'learning_rate': 0.05931479568360988, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:18,877] Trial 27 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:19,314] Trial 28 finished with value: 0.8540056022408964 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.006352566184577388, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.9476815547238298}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:19,664] Trial 29 finished with value: 0.8439355742296918 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:20,266] Trial 30 finished with value: 0.8641036414565827 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.02604516090727766, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:20,811] Trial 31 finished with value: 0.8641176470588234 and parameters: {'max_features': None, 'n_estimators': 89, 'learning_rate': 0.04550661533774431, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:21,191] Trial 32 finished with value: 0.8473109243697479 and parameters: {'max_features': 'log2', 'n_estimators': 57, 'learning_rate': 0.057598179531231156, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:22,010] Trial 33 finished with value: 0.8523529411764705 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.005159850252668635, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:22,619] Trial 34 finished with value: 0.8641176470588234 and parameters: {'max_features': 'sqrt', 'n_estimators': 97, 'learning_rate': 0.028285798452561236, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:23,086] Trial 35 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:23,917] Trial 36 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.023181318988644676, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:24,335] Trial 37 finished with value: 0.85906162464986 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.023543833172098207, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:24,853] Trial 38 finished with value: 0.8506722689075629 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.02965355069687456, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:25,554] Trial 39 finished with value: 0.8440056022408964 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.01527767880504091, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:26,082] Trial 40 finished with value: 0.8473109243697478 and parameters: {'max_features': 'log2', 'n_estimators': 86, 'learning_rate': 0.014635791606577728, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:26,529] Trial 41 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.052949431962723024, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:26,953] Trial 42 finished with value: 0.8556582633053221 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.020898689337932506, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:27,477] Trial 43 finished with value: 0.8490196078431372 and parameters: {'max_features': None, 'n_estimators': 88, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:27,933] Trial 44 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 43, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:28,382] Trial 45 finished with value: 0.8624229691876749 and parameters: {'max_features': 'log2', 'n_estimators': 79, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:28,910] Trial 46 finished with value: 0.8574089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.0425370110877949, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:29,406] Trial 47 finished with value: 0.8607282913165266 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.03465610994688299, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:29,913] Trial 48 finished with value: 0.8573669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 80, 'learning_rate': 0.004548833882545665, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:30,327] Trial 49 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:30,806] Trial 50 finished with value: 0.8573949579831932 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:31,289] Trial 51 finished with value: 0.8489915966386553 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.027245727256136217, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:31,776] Trial 52 finished with value: 0.859033613445378 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.020048105028410642, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:32,469] Trial 53 finished with value: 0.8607422969187676 and parameters: {'max_features': None, 'n_estimators': 87, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:33,250] Trial 54 finished with value: 0.7566386554621849 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.0010000000000000002, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:33,781] Trial 55 finished with value: 0.8556722689075631 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.004860142974150873, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:34,370] Trial 56 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.034998129245697465, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:34,951] Trial 57 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.006220117635098627, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:35,565] Trial 58 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.038516833287558075, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:36,062] Trial 59 finished with value: 0.8539775910364146 and parameters: {'max_features': 'sqrt', 'n_estimators': 25, 'learning_rate': 0.06118262147250417, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:36,773] Trial 60 finished with value: 0.8573669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.05733058783756483, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:37,320] Trial 61 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 28, 'learning_rate': 0.028037950061019074, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:37,871] Trial 62 finished with value: 0.8557142857142856 and parameters: {'max_features': None, 'n_estimators': 65, 'learning_rate': 0.035523787247083924, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:38,428] Trial 63 finished with value: 0.8473109243697478 and parameters: {'max_features': 'log2', 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:38,967] Trial 64 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.005788694482724518, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:40,002] Trial 65 finished with value: 0.850686274509804 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.021621381376811914, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:40,683] Trial 66 finished with value: 0.8456162464985993 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.005479886314037827, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:42,447] Trial 67 finished with value: 0.8372128851540616 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.005163547006264864, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:43,032] Trial 68 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 78, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:43,618] Trial 69 finished with value: 0.8540196078431371 and parameters: {'max_features': 'log2', 'n_estimators': 89, 'learning_rate': 0.005352857701958801, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:44,454] Trial 70 finished with value: 0.855686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.012525385772455246, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:45,217] Trial 71 finished with value: 0.8674649859943978 and parameters: {'max_features': None, 'n_estimators': 36, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:45,916] Trial 72 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 88, 'learning_rate': 0.03146853476543863, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.6725533057263987}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:47,903] Trial 73 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 32, 'learning_rate': 0.037045902490938164, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:48,767] Trial 74 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.07247143565986133, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:49,532] Trial 75 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.09999999999999998, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:50,235] Trial 76 finished with value: 0.8640896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.024161682407963608, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8691456582633054.\n",
      "[I 2025-10-06 13:19:51,031] Trial 77 finished with value: 0.8691596638655463 and parameters: {'max_features': None, 'n_estimators': 52, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:51,877] Trial 78 finished with value: 0.8590616246498598 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.048016323726294115, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:52,716] Trial 79 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.017572086717906662, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:53,854] Trial 80 finished with value: 0.8456582633053221 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.03833013613040427, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:54,609] Trial 81 finished with value: 0.8607282913165266 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:55,573] Trial 82 finished with value: 0.8640896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.018681679400994796, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:56,259] Trial 83 finished with value: 0.8624229691876751 and parameters: {'max_features': None, 'n_estimators': 47, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:56,866] Trial 84 finished with value: 0.8607282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 54, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:57,876] Trial 85 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.009205949652827554, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 77 with value: 0.8691596638655463.\n",
      "[I 2025-10-06 13:19:58,610] Trial 86 finished with value: 0.8708263305322129 and parameters: {'max_features': None, 'n_estimators': 67, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:19:59,293] Trial 87 finished with value: 0.8607142857142855 and parameters: {'max_features': 'log2', 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:00,295] Trial 88 finished with value: 0.8372408963585434 and parameters: {'max_features': 'sqrt', 'n_estimators': 15, 'learning_rate': 0.04248001725419852, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:00,827] Trial 89 finished with value: 0.8473109243697478 and parameters: {'max_features': None, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:01,434] Trial 90 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 25, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:02,380] Trial 91 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.019423965231742425, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:03,069] Trial 92 finished with value: 0.8624089635854343 and parameters: {'max_features': 'log2', 'n_estimators': 25, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:03,861] Trial 93 finished with value: 0.8590616246498598 and parameters: {'max_features': None, 'n_estimators': 73, 'learning_rate': 0.07565286984786009, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:04,684] Trial 94 finished with value: 0.8590476190476192 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.0043341116394528464, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:05,433] Trial 95 finished with value: 0.8573529411764707 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.009988091720929742, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:06,134] Trial 96 finished with value: 0.8523809523809526 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:06,849] Trial 97 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:07,704] Trial 98 finished with value: 0.8590476190476192 and parameters: {'max_features': 'log2', 'n_estimators': 56, 'learning_rate': 0.017738972199879622, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "[I 2025-10-06 13:20:08,429] Trial 99 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.044676570029190954, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 86 with value: 0.8708263305322129.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using GPSampler: {'max_features': None, 'n_estimators': 67, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}\n",
      "Best accuracy: 0.8708, at trial: 86\n",
      "GP Base Models Training Time: 256.32 seconds\n"
     ]
    }
   ],
   "source": [
    "gp_base_models_training_start = time.time()\n",
    "\n",
    "# GP Hyperparameter Tuning with Cross Validation\n",
    "gp_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "gp_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "gp_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "gp_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "gp_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "gp_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "gp_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "# Model Fitting with best parameters\n",
    "gp_logistic_regression.fit(X_train, y_train)\n",
    "gp_decision_tree.fit(X_train, y_train)\n",
    "gp_random_forest.fit(X_train, y_train)\n",
    "gp_knn.fit(X_train, y_train)\n",
    "gp_svc.fit(X_train, y_train)\n",
    "gp_adaboost.fit(X_train, y_train)\n",
    "gp_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "gp_base_models_training_end = time.time()\n",
    "\n",
    "# Time taken for GP base models training\n",
    "gp_base_models_training_time = gp_base_models_training_end - gp_base_models_training_start\n",
    "print(f'GP Base Models Training Time: {gp_base_models_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:08,913] A new study created in memory with name: Logistic Regression Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0733cc706a464b8eba7835f6aebf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:09,027] Trial 0 finished with value: 0.6459803921568629 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.6459803921568629.\n",
      "[W 2025-10-06 13:20:09,060] The parameter `solver` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,108] Trial 1 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cholesky', 'C': 0.02205741280502818}. Best is trial 1 with value: 0.8489775910364145.\n",
      "[W 2025-10-06 13:20:09,110] The parameter `solver` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,162] Trial 2 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.02802913837564577}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,165] The parameter `solver` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,215] Trial 3 finished with value: 0.850658263305322 and parameters: {'solver': 'sag', 'C': 0.36204298853974154}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,218] The parameter `solver` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,268] Trial 4 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.00011850115518950796}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,272] The parameter `solver` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,322] Trial 5 finished with value: 0.8540056022408965 and parameters: {'solver': 'sag', 'C': 0.14134330802586104}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,322] The parameter `solver` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,374] Trial 6 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.05961539766989437}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,374] The parameter `solver` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,424] Trial 7 finished with value: 0.8405742296918767 and parameters: {'solver': 'newton-cg', 'C': 0.0045132014426244845}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,426] The parameter `solver` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,475] Trial 8 finished with value: 0.8506442577030813 and parameters: {'solver': 'newton-cg', 'C': 0.24126254309599532}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,475] The parameter `solver` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,527] Trial 9 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cg', 'C': 0.15465997880663593}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,529] The parameter `solver` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,580] Trial 10 finished with value: 0.8523249299719888 and parameters: {'solver': 'newton-cholesky', 'C': 0.19779199049186533}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,581] The parameter `solver` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,632] Trial 11 finished with value: 0.8523249299719889 and parameters: {'solver': 'lbfgs', 'C': 0.025964015641663823}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,632] The parameter `solver` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,683] Trial 12 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cg', 'C': 0.10688811288974731}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,687] The parameter `solver` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,737] Trial 13 finished with value: 0.8523389355742296 and parameters: {'solver': 'newton-cholesky', 'C': 0.4065041882773802}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,740] The parameter `solver` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,790] Trial 14 finished with value: 0.8540056022408965 and parameters: {'solver': 'sag', 'C': 0.15226111793174996}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,793] The parameter `solver` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,843] Trial 15 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cg', 'C': 0.10442147354833238}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,845] The parameter `solver` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,894] Trial 16 finished with value: 0.8506442577030813 and parameters: {'solver': 'newton-cholesky', 'C': 0.25389467109053104}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,898] The parameter `solver` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:09,947] Trial 17 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.06851511837548911}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:09,950] The parameter `solver` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,001] Trial 18 finished with value: 0.8540056022408965 and parameters: {'solver': 'lbfgs', 'C': 0.14615319790989853}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,004] The parameter `solver` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,052] Trial 19 finished with value: 0.8523389355742296 and parameters: {'solver': 'sag', 'C': 0.13892822690151613}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,054] The parameter `solver` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,105] Trial 20 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.06900724237892226}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,109] The parameter `solver` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,157] Trial 21 finished with value: 0.8506442577030813 and parameters: {'solver': 'sag', 'C': 0.21156290603058847}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,159] The parameter `solver` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,210] Trial 22 finished with value: 0.8556862745098041 and parameters: {'solver': 'sag', 'C': 0.05929870658716307}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,213] The parameter `solver` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,262] Trial 23 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cg', 'C': 0.11201624004375145}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,264] The parameter `solver` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,315] Trial 24 finished with value: 0.8540056022408965 and parameters: {'solver': 'lbfgs', 'C': 0.026731767616905638}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,319] The parameter `solver` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,367] Trial 25 finished with value: 0.8506442577030814 and parameters: {'solver': 'sag', 'C': 0.04415920161589667}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,369] The parameter `solver` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,419] Trial 26 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.050981974610338904}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,421] The parameter `solver` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,470] Trial 27 finished with value: 0.8556862745098041 and parameters: {'solver': 'sag', 'C': 0.028542651289300378}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,472] The parameter `solver` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,523] Trial 28 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.07135012287157454}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,527] The parameter `solver` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,575] Trial 29 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.028041786357601885}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,577] The parameter `solver` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,626] Trial 30 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.07546331649014755}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,628] The parameter `solver` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,678] Trial 31 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cholesky', 'C': 0.018138353120305817}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,680] The parameter `solver` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,729] Trial 32 finished with value: 0.8523249299719889 and parameters: {'solver': 'lbfgs', 'C': 0.03597069080742235}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,733] The parameter `solver` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,782] Trial 33 finished with value: 0.8472969187675069 and parameters: {'solver': 'newton-cg', 'C': 0.011341105611141248}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,784] The parameter `solver` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,836] Trial 34 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.027750958243175083}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:20:10,839] The parameter `solver` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,889] Trial 35 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09399685792020154}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:10,892] The parameter `solver` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,944] Trial 36 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cg', 'C': 0.014227117802719748}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:10,949] The parameter `solver` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:10,997] Trial 37 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cg', 'C': 0.05198730786641412}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,000] The parameter `solver` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,050] Trial 38 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cg', 'C': 0.0205949019304343}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,053] The parameter `solver` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,102] Trial 39 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.0662853017149824}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,106] The parameter `solver` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,155] Trial 40 finished with value: 0.8523249299719889 and parameters: {'solver': 'newton-cg', 'C': 0.03575259216921938}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,159] The parameter `solver` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,207] Trial 41 finished with value: 0.8540056022408965 and parameters: {'solver': 'lbfgs', 'C': 0.05613224674026083}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,209] The parameter `solver` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,259] Trial 42 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.06897358920160498}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,262] The parameter `solver` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,311] Trial 43 finished with value: 0.8540056022408965 and parameters: {'solver': 'sag', 'C': 0.05257646602981607}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,313] The parameter `solver` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,363] Trial 44 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09120097385055365}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,367] The parameter `solver` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,415] Trial 45 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.058718955098362745}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,417] The parameter `solver` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,466] Trial 46 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cg', 'C': 0.12156649219510612}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,469] The parameter `solver` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,519] Trial 47 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.07947534100958507}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,522] The parameter `solver` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,572] Trial 48 finished with value: 0.8540056022408965 and parameters: {'solver': 'sag', 'C': 0.16378672109295211}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,575] The parameter `solver` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,624] Trial 49 finished with value: 0.8523249299719889 and parameters: {'solver': 'lbfgs', 'C': 0.04837761034484257}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,627] The parameter `solver` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,676] Trial 50 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.07920674101131855}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,679] The parameter `solver` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,728] Trial 51 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.06329124946841239}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,728] The parameter `solver` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,780] Trial 52 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.07903711346090829}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,783] The parameter `solver` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,832] Trial 53 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.09046450638474789}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,832] The parameter `solver` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,882] Trial 54 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.06254895781310717}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,883] The parameter `solver` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,933] Trial 55 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.06687789964234207}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,933] The parameter `solver` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:11,986] Trial 56 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.07986010444110309}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:11,990] The parameter `solver` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,038] Trial 57 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.0902540617911104}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,038] The parameter `solver` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,088] Trial 58 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.0714986230072953}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,089] The parameter `solver` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,139] Trial 59 finished with value: 0.8540196078431371 and parameters: {'solver': 'sag', 'C': 0.10982031920930227}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,139] The parameter `solver` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,191] Trial 60 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.07270046128527112}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,191] The parameter `solver` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,244] Trial 61 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.06733344751197809}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,244] The parameter `solver` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,296] Trial 62 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.07913872619268242}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,296] The parameter `solver` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,348] Trial 63 finished with value: 0.8540196078431371 and parameters: {'solver': 'sag', 'C': 0.10705787250404356}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,348] The parameter `solver` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,400] Trial 64 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08333678454720747}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,404] The parameter `solver` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,452] Trial 65 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.09471481115438175}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,454] The parameter `solver` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,504] Trial 66 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.09004085267183856}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,504] The parameter `solver` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,556] Trial 67 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.07939373875915136}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,557] The parameter `solver` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,607] Trial 68 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.0828085329008999}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,607] The parameter `solver` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,661] Trial 69 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08214938573869908}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,663] The parameter `solver` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,712] Trial 70 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08738590999633207}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,712] The parameter `solver` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,763] Trial 71 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.07664077318557759}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,763] The parameter `solver` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,816] Trial 72 finished with value: 0.8556862745098041 and parameters: {'solver': 'sag', 'C': 0.0734325767442031}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,816] The parameter `solver` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,868] Trial 73 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08831476407675756}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,868] The parameter `solver` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,919] Trial 74 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08175279470473255}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,922] The parameter `solver` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:12,970] Trial 75 finished with value: 0.8556862745098041 and parameters: {'solver': 'sag', 'C': 0.07101322785256506}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:12,970] The parameter `solver` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,022] Trial 76 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08021130022185556}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,023] The parameter `solver` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,073] Trial 77 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08179927575659265}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,073] The parameter `solver` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,125] Trial 78 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08355528639311079}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,127] The parameter `solver` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,176] Trial 79 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.09040808249324561}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,176] The parameter `solver` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,228] Trial 80 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.086181241825187}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,232] The parameter `solver` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,281] Trial 81 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08841797231937372}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,281] The parameter `solver` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,333] Trial 82 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.0781537921491}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,335] The parameter `solver` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,384] Trial 83 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.07798294819855832}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,388] The parameter `solver` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,436] Trial 84 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08172924054456764}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,440] The parameter `solver` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,488] Trial 85 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08562448610011521}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,488] The parameter `solver` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,539] Trial 86 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08094505322726324}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,541] The parameter `solver` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,591] Trial 87 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.084411860647801}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,591] The parameter `solver` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,643] Trial 88 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.09133283146023745}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,645] The parameter `solver` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,694] Trial 89 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08121519866776243}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,697] The parameter `solver` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,747] Trial 90 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08344558835871677}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,750] The parameter `solver` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,799] Trial 91 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08914075890997242}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,801] The parameter `solver` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,850] Trial 92 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08523686998853151}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,855] The parameter `solver` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,903] Trial 93 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08478856273134219}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,905] The parameter `solver` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:13,955] Trial 94 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08277980444036132}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:13,959] The parameter `solver` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,008] Trial 95 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08418796813638929}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:14,011] The parameter `solver` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,061] Trial 96 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.08735246285453821}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:14,064] The parameter `solver` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,113] Trial 97 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cg', 'C': 0.08630971964009179}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:14,115] The parameter `solver` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,165] Trial 98 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.0899567681737063}. Best is trial 35 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:20:14,168] The parameter `solver` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,216] Trial 99 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.08764781537896825}. Best is trial 35 with value: 0.8573669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:14,219] A new study created in memory with name: Decision Tree Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Logistic Regression Using CmaEsSampler: {'solver': 'newton-cg', 'C': 0.09399685792020154}\n",
      "Best accuracy: 0.8574, at trial: 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160394a2c12e43cebc1817ce7cc57c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:14,267] Trial 0 finished with value: 0.8137535014005601 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[W 2025-10-06 13:20:14,278] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,281] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,311] Trial 1 finished with value: 0.813781512605042 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.813781512605042.\n",
      "[W 2025-10-06 13:20:14,316] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,319] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,347] Trial 2 finished with value: 0.8288375350140056 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,352] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,354] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,382] Trial 3 finished with value: 0.8238095238095238 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,384] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,386] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,413] Trial 4 finished with value: 0.8137535014005601 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,416] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,418] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,446] Trial 5 finished with value: 0.8086974789915965 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,449] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,451] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,479] Trial 6 finished with value: 0.7986414565826331 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,482] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,483] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,510] Trial 7 finished with value: 0.8171288515406163 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,516] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,517] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,549] Trial 8 finished with value: 0.7919607843137254 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,552] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,554] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,583] Trial 9 finished with value: 0.8204481792717087 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,588] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,590] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,616] Trial 10 finished with value: 0.813781512605042 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,619] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,621] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,649] Trial 11 finished with value: 0.7919327731092437 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,652] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,653] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,681] Trial 12 finished with value: 0.8237955182072829 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,684] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,686] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,714] Trial 13 finished with value: 0.8238375350140055 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,718] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,719] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,746] Trial 14 finished with value: 0.8255042016806723 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,749] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,751] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,780] Trial 15 finished with value: 0.8238095238095238 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,783] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,784] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,812] Trial 16 finished with value: 0.8237955182072829 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,815] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,817] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,844] Trial 17 finished with value: 0.8154341736694677 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,847] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,849] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,876] Trial 18 finished with value: 0.8255742296918769 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,879] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,882] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,909] Trial 19 finished with value: 0.8271988795518206 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,912] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,914] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,942] Trial 20 finished with value: 0.8037254901960786 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,944] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,946] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:14,973] Trial 21 finished with value: 0.8221428571428572 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8288375350140056.\n",
      "[W 2025-10-06 13:20:14,978] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:14,979] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,006] Trial 22 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 22 with value: 0.8288515406162464.\n",
      "[W 2025-10-06 13:20:15,009] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,010] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,038] Trial 23 finished with value: 0.8171148459383752 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 22 with value: 0.8288515406162464.\n",
      "[W 2025-10-06 13:20:15,040] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,042] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,069] Trial 24 finished with value: 0.8355602240896358 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,072] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,075] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,103] Trial 25 finished with value: 0.8255742296918769 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,106] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,108] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,138] Trial 26 finished with value: 0.810392156862745 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,140] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,142] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,170] Trial 27 finished with value: 0.8154481792717088 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,173] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,174] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,203] Trial 28 finished with value: 0.8255042016806723 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,207] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,209] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,237] Trial 29 finished with value: 0.8120728291316526 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,241] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,242] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,269] Trial 30 finished with value: 0.8154481792717088 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,272] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,274] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,302] Trial 31 finished with value: 0.8255742296918769 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,305] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,306] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,334] Trial 32 finished with value: 0.8271988795518206 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,337] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,338] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,366] Trial 33 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,368] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,369] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,397] Trial 34 finished with value: 0.7919327731092437 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,400] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,402] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,429] Trial 35 finished with value: 0.8086834733893558 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,432] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,434] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,461] Trial 36 finished with value: 0.8355602240896358 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,464] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,466] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,494] Trial 37 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,497] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,499] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,526] Trial 38 finished with value: 0.7985994397759104 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,529] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,530] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,557] Trial 39 finished with value: 0.8187815126050421 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,559] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,561] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,588] Trial 40 finished with value: 0.8238375350140055 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,591] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,593] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,620] Trial 41 finished with value: 0.8086834733893558 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,623] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,624] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,655] Trial 42 finished with value: 0.8187815126050421 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,660] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,662] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,690] Trial 43 finished with value: 0.8204481792717087 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,690] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,690] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,723] Trial 44 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,725] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,727] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,754] Trial 45 finished with value: 0.8137254901960784 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,755] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,755] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,786] Trial 46 finished with value: 0.8187815126050421 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,786] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,786] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,818] Trial 47 finished with value: 0.8104061624649859 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,818] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,821] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,850] Trial 48 finished with value: 0.8204621848739496 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,853] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,856] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,883] Trial 49 finished with value: 0.8255042016806723 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,883] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,883] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,916] Trial 50 finished with value: 0.8238095238095238 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,916] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,916] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,948] Trial 51 finished with value: 0.8238515406162465 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,948] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,948] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:15,980] Trial 52 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:15,982] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:15,985] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,012] Trial 53 finished with value: 0.8204481792717087 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,012] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,012] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,045] Trial 54 finished with value: 0.7919327731092437 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,045] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,048] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,079] Trial 55 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,081] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,081] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,111] Trial 56 finished with value: 0.8053641456582632 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,114] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,114] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,142] Trial 57 finished with value: 0.7969467787114847 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,145] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,145] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,177] Trial 58 finished with value: 0.813781512605042 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,180] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,183] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,211] Trial 59 finished with value: 0.8238095238095238 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,214] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,214] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,244] Trial 60 finished with value: 0.8322128851540616 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,244] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,244] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,278] Trial 61 finished with value: 0.8053641456582632 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,281] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,283] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,310] Trial 62 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,310] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,310] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,342] Trial 63 finished with value: 0.7818627450980392 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,343] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,343] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,375] Trial 64 finished with value: 0.8255462184873948 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,375] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,375] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,407] Trial 65 finished with value: 0.8288515406162464 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,409] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,409] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,439] Trial 66 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,441] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,441] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,472] Trial 67 finished with value: 0.8053501400560223 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,475] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,477] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,504] Trial 68 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,507] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,509] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,536] Trial 69 finished with value: 0.7969467787114847 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,536] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,536] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,569] Trial 70 finished with value: 0.8238515406162465 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,573] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,575] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,604] Trial 71 finished with value: 0.8238515406162465 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,607] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,607] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,637] Trial 72 finished with value: 0.8238515406162465 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,637] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,637] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,670] Trial 73 finished with value: 0.8154481792717088 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,670] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,670] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,703] Trial 74 finished with value: 0.8204481792717087 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,703] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,706] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,734] Trial 75 finished with value: 0.8288375350140056 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,737] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,737] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,766] Trial 76 finished with value: 0.8255042016806723 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,769] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,769] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,799] Trial 77 finished with value: 0.8338935574229691 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,800] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,800] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,832] Trial 78 finished with value: 0.8204621848739496 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,836] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,837] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,864] Trial 79 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,864] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,864] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,897] Trial 80 finished with value: 0.8255042016806723 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,897] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,897] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,928] Trial 81 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,932] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,933] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,961] Trial 82 finished with value: 0.8104061624649859 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,964] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,966] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:16,993] Trial 83 finished with value: 0.8171148459383752 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:16,995] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:16,997] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,026] Trial 84 finished with value: 0.8171148459383752 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,032] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,032] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,062] Trial 85 finished with value: 0.8271988795518206 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,066] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,066] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,095] Trial 86 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,097] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,097] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,126] Trial 87 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,129] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,129] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,158] Trial 88 finished with value: 0.8355602240896358 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,161] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,163] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,191] Trial 89 finished with value: 0.8338935574229691 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,191] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,191] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,223] Trial 90 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,223] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,223] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,255] Trial 91 finished with value: 0.8171148459383752 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,258] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,258] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,289] Trial 92 finished with value: 0.8355602240896358 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,289] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,289] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,320] Trial 93 finished with value: 0.8288375350140056 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,320] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,324] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,352] Trial 94 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,352] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,357] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,384] Trial 95 finished with value: 0.8322128851540616 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,387] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,389] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,418] Trial 96 finished with value: 0.8255042016806723 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,418] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,418] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,451] Trial 97 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:17,518] A new study created in memory with name: Random Forest Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-10-06 13:20:17,451] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,451] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,483] Trial 98 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:20:17,483] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,489] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,517] Trial 99 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8355602240896358.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using CmaEsSampler: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 9}\n",
      "Best accuracy: 0.8356, at trial: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e7c9ebc3ac4757a922e110dc91ada0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:17,648] Trial 0 finished with value: 0.8372408963585434 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8372408963585434.\n",
      "[W 2025-10-06 13:20:17,648] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,648] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:17,849] Trial 1 finished with value: 0.8490056022408963 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8490056022408963.\n",
      "[W 2025-10-06 13:20:17,853] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:17,854] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:18,113] Trial 2 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8523669467787116.\n",
      "[W 2025-10-06 13:20:18,117] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:18,118] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:18,291] Trial 3 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540336134453781.\n",
      "[W 2025-10-06 13:20:18,295] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:18,296] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:18,490] Trial 4 finished with value: 0.8339075630252101 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 51, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540336134453781.\n",
      "[W 2025-10-06 13:20:18,493] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:18,494] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:18,749] Trial 5 finished with value: 0.8607563025210083 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 79, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:18,755] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:18,756] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:18,885] Trial 6 finished with value: 0.8590756302521008 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 29, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:18,888] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:18,890] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:19,051] Trial 7 finished with value: 0.8523389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:19,056] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:19,057] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:19,271] Trial 8 finished with value: 0.8490056022408965 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:19,276] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:19,277] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:19,512] Trial 9 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:19,516] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:19,517] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:19,763] Trial 10 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 72, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:19,768] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:19,770] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:19,901] Trial 11 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 29, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:19,904] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:19,905] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:20,089] Trial 12 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:20,092] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:20,094] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:20,361] Trial 13 finished with value: 0.85906162464986 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:20,364] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:20,365] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:20,517] Trial 14 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:20,521] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:20,522] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:20,726] Trial 15 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 55, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:20,729] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:20,731] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:20,965] Trial 16 finished with value: 0.8540196078431371 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:20,970] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:20,971] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:21,122] Trial 17 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:21,126] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:21,127] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:21,361] Trial 18 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:21,364] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:21,365] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:21,612] Trial 19 finished with value: 0.8574229691876752 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 72, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:21,616] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:21,618] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:21,833] Trial 20 finished with value: 0.8473249299719887 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:21,837] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:21,838] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:22,041] Trial 21 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 58, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:22,044] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:22,046] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:22,240] Trial 22 finished with value: 0.8591176470588234 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 56, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:22,243] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:22,245] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:22,438] Trial 23 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 58, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:22,441] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:22,443] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:22,595] Trial 24 finished with value: 0.8389495798319327 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 39, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:22,600] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:22,600] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:22,807] Trial 25 finished with value: 0.8557142857142856 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:22,807] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:22,812] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:23,026] Trial 26 finished with value: 0.8356162464985994 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 64, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:23,030] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:23,031] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:23,265] Trial 27 finished with value: 0.8573809523809522 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:23,267] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:23,267] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:23,441] Trial 28 finished with value: 0.8507002801120448 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:23,442] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:23,442] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:23,681] Trial 29 finished with value: 0.8590616246498598 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:23,685] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:23,686] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:23,923] Trial 30 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:23,926] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:23,927] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:24,110] Trial 31 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 48, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:24,113] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:24,114] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:24,360] Trial 32 finished with value: 0.8540336134453781 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:24,365] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:24,366] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:24,612] Trial 33 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:24,616] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:24,617] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:24,800] Trial 34 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:24,803] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:24,804] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:25,072] Trial 35 finished with value: 0.8574089635854343 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 81, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:25,075] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:25,077] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:25,290] Trial 36 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 61, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:25,293] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:25,294] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:25,447] Trial 37 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 39, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:25,451] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:25,451] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:25,726] Trial 38 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 83, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:25,727] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:25,731] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:25,883] Trial 39 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:25,886] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:25,887] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:26,174] Trial 40 finished with value: 0.8607563025210083 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:26,179] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:26,181] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:26,341] Trial 41 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 41, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:26,344] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:26,344] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:26,529] Trial 42 finished with value: 0.8406302521008403 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 52, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:26,534] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:26,535] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:26,676] Trial 43 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:26,679] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:26,680] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:26,904] Trial 44 finished with value: 0.8440056022408962 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:26,907] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:26,908] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:27,143] Trial 45 finished with value: 0.8406302521008403 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 69, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:27,147] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:27,148] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:27,301] Trial 46 finished with value: 0.8573949579831932 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:27,304] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:27,306] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:27,498] Trial 47 finished with value: 0.8590756302521008 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 52, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:27,501] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:27,502] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:27,746] Trial 48 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 74, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:27,752] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:27,753] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:27,884] Trial 49 finished with value: 0.8372689075630252 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 30, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:27,888] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:27,889] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:28,029] Trial 50 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 33, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.8607563025210083.\n",
      "[W 2025-10-06 13:20:28,032] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:28,033] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:28,196] Trial 51 finished with value: 0.8624229691876751 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 42, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:28,199] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:28,201] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:28,395] Trial 52 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 55, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:28,399] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:28,400] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:28,624] Trial 53 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:28,628] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:28,629] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:28,761] Trial 54 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 27, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:28,765] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:28,766] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:28,929] Trial 55 finished with value: 0.8473109243697478 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 40, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:28,933] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:28,934] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:29,095] Trial 56 finished with value: 0.8473389355742296 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 42, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:29,099] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:29,101] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:29,315] Trial 57 finished with value: 0.8423109243697479 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 62, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:29,318] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:29,321] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:29,514] Trial 58 finished with value: 0.8557142857142856 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 53, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:29,517] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:29,519] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:29,713] Trial 59 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 56, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:29,716] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:29,717] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:29,889] Trial 60 finished with value: 0.8506862745098038 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 47, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:29,889] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:29,889] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:30,067] Trial 61 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 49, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:30,071] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:30,071] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:30,224] Trial 62 finished with value: 0.845658263305322 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 37, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:30,227] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:30,228] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:30,476] Trial 63 finished with value: 0.8540476190476189 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:30,480] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:30,481] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:30,643] Trial 64 finished with value: 0.8439915966386554 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 40, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:30,647] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:30,650] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:30,853] Trial 65 finished with value: 0.8439775910364145 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:30,857] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:30,858] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:31,040] Trial 66 finished with value: 0.8339215686274508 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:31,042] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:31,042] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:31,166] Trial 67 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 26, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:31,170] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:31,171] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:31,396] Trial 68 finished with value: 0.8557282913165265 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:31,400] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:31,400] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:31,645] Trial 69 finished with value: 0.8540476190476189 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:31,645] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:31,645] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:31,865] Trial 70 finished with value: 0.8540476190476189 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:31,868] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:31,868] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:32,062] Trial 71 finished with value: 0.8339215686274508 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 56, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:32,065] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:32,065] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:32,301] Trial 72 finished with value: 0.840644257703081 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 67, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.8624229691876751.\n",
      "[W 2025-10-06 13:20:32,305] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:32,307] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:32,530] Trial 73 finished with value: 0.8624369747899159 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 64, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:32,535] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:32,537] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:32,760] Trial 74 finished with value: 0.8406302521008403 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:32,760] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:32,760] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:33,030] Trial 75 finished with value: 0.8540476190476189 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:33,033] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:33,034] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:33,309] Trial 76 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:33,312] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:33,313] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:33,546] Trial 77 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 69, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:33,546] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:33,546] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:33,785] Trial 78 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:33,789] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:33,790] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:33,983] Trial 79 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:33,987] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:33,988] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:34,160] Trial 80 finished with value: 0.850672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:34,165] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:34,166] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:34,423] Trial 81 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 77, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:34,427] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:34,428] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:34,673] Trial 82 finished with value: 0.8574089635854343 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:34,677] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:34,679] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:34,945] Trial 83 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:34,948] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:34,949] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:35,192] Trial 84 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:35,196] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:35,197] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:35,409] Trial 85 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:35,412] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:35,413] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:35,639] Trial 86 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:35,643] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:35,644] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:35,796] Trial 87 finished with value: 0.8473389355742296 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 36, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:35,799] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:35,799] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:36,015] Trial 88 finished with value: 0.8489915966386554 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 61, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:36,020] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:36,020] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:36,266] Trial 89 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 76, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:36,269] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:36,269] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:36,525] Trial 90 finished with value: 0.845672268907563 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 77, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:36,530] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:36,530] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:36,724] Trial 91 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:36,728] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:36,729] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:36,963] Trial 92 finished with value: 0.8540476190476189 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:36,966] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:36,967] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:37,212] Trial 93 finished with value: 0.8523809523809524 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:37,216] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:37,217] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:37,472] Trial 94 finished with value: 0.8624229691876751 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 77, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:37,472] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:37,476] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:37,742] Trial 95 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 79, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:37,746] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:37,747] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:38,003] Trial 96 finished with value: 0.8489915966386553 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 80, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:38,008] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:38,010] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:38,254] Trial 97 finished with value: 0.8372689075630252 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:38,258] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:38,258] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:38,545] Trial 98 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:20:38,549] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:38,551] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:38,789] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:38,785] Trial 99 finished with value: 0.8573809523809522 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 69, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.8624369747899159.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using CmaEsSampler: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 64, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
      "Best accuracy: 0.8624, at trial: 73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e75c0b346c48c88015686363efe8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:38,871] Trial 0 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[W 2025-10-06 13:20:38,874] The parameter `algorithm` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:38,913] Trial 1 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 1 with value: 0.8540056022408965.\n",
      "[W 2025-10-06 13:20:38,917] The parameter `algorithm` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:38,978] Trial 2 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 1 with value: 0.8540056022408965.\n",
      "[W 2025-10-06 13:20:38,980] The parameter `algorithm` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,040] Trial 3 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 3 with value: 0.8590196078431372.\n",
      "[W 2025-10-06 13:20:39,043] The parameter `algorithm` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,086] Trial 4 finished with value: 0.8321568627450981 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 3 with value: 0.8590196078431372.\n",
      "[W 2025-10-06 13:20:39,089] The parameter `algorithm` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,149] Trial 5 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 1}. Best is trial 5 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:20:39,152] The parameter `algorithm` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,211] Trial 6 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 5 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:20:39,215] The parameter `algorithm` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,254] Trial 7 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 1}. Best is trial 5 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:20:39,257] The parameter `algorithm` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,295] Trial 8 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 5 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:20:39,297] The parameter `algorithm` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,357] Trial 9 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,361] The parameter `algorithm` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,399] Trial 10 finished with value: 0.8573389355742297 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,402] The parameter `algorithm` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,462] Trial 11 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 30, 'p': 2}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,465] The parameter `algorithm` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,525] Trial 12 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,528] The parameter `algorithm` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,567] Trial 13 finished with value: 0.855686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,570] The parameter `algorithm` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,639] Trial 14 finished with value: 0.855686274509804 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,641] The parameter `algorithm` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,701] Trial 15 finished with value: 0.8523249299719889 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 30, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,704] The parameter `algorithm` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,764] Trial 16 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,766] The parameter `algorithm` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,805] Trial 17 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,810] The parameter `algorithm` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,868] Trial 18 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 36, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,871] The parameter `algorithm` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,930] Trial 19 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,933] The parameter `algorithm` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:39,992] Trial 20 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:39,994] The parameter `algorithm` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,034] Trial 21 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:40,038] The parameter `algorithm` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,097] Trial 22 finished with value: 0.8523249299719889 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:40,100] The parameter `algorithm` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,139] Trial 23 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 29, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:40,143] The parameter `algorithm` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,180] Trial 24 finished with value: 0.8523249299719889 and parameters: {'algorithm': 'brute', 'n_neighbors': 27, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:40,184] The parameter `algorithm` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,244] Trial 25 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:40,247] The parameter `algorithm` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,317] Trial 26 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 1}. Best is trial 9 with value: 0.8590476190476192.\n",
      "[W 2025-10-06 13:20:40,320] The parameter `algorithm` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,358] Trial 27 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 1}. Best is trial 27 with value: 0.8607142857142858.\n",
      "[W 2025-10-06 13:20:40,362] The parameter `algorithm` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,401] Trial 28 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 27 with value: 0.8607142857142858.\n",
      "[W 2025-10-06 13:20:40,404] The parameter `algorithm` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,443] Trial 29 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 27 with value: 0.8607142857142858.\n",
      "[W 2025-10-06 13:20:40,445] The parameter `algorithm` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,484] Trial 30 finished with value: 0.855686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 1}. Best is trial 27 with value: 0.8607142857142858.\n",
      "[W 2025-10-06 13:20:40,489] The parameter `algorithm` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,548] Trial 31 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,551] The parameter `algorithm` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,611] Trial 32 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,614] The parameter `algorithm` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,674] Trial 33 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,676] The parameter `algorithm` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,735] Trial 34 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,738] The parameter `algorithm` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,798] Trial 35 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,801] The parameter `algorithm` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,840] Trial 36 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,844] The parameter `algorithm` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,882] Trial 37 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,884] The parameter `algorithm` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,923] Trial 38 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,926] The parameter `algorithm` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:40,965] Trial 39 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:40,968] The parameter `algorithm` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,027] Trial 40 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,030] The parameter `algorithm` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,068] Trial 41 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,071] The parameter `algorithm` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,131] Trial 42 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,135] The parameter `algorithm` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,174] Trial 43 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'brute', 'n_neighbors': 48, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,177] The parameter `algorithm` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,236] Trial 44 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,238] The parameter `algorithm` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,277] Trial 45 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,280] The parameter `algorithm` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,340] Trial 46 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,342] The parameter `algorithm` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,402] Trial 47 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,407] The parameter `algorithm` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,476] Trial 48 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,478] The parameter `algorithm` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,539] Trial 49 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,542] The parameter `algorithm` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,580] Trial 50 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,582] The parameter `algorithm` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,622] Trial 51 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,625] The parameter `algorithm` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,684] Trial 52 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,688] The parameter `algorithm` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,750] Trial 53 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,750] The parameter `algorithm` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,811] Trial 54 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,816] The parameter `algorithm` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,854] Trial 55 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'brute', 'n_neighbors': 49, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,857] The parameter `algorithm` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,916] Trial 56 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,920] The parameter `algorithm` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:41,978] Trial 57 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:41,980] The parameter `algorithm` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,019] Trial 58 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,022] The parameter `algorithm` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,082] Trial 59 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,084] The parameter `algorithm` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,143] Trial 60 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,144] The parameter `algorithm` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,206] Trial 61 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,206] The parameter `algorithm` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,267] Trial 62 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,267] The parameter `algorithm` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,330] Trial 63 finished with value: 0.855686274509804 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,332] The parameter `algorithm` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,372] Trial 64 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,376] The parameter `algorithm` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,445] Trial 65 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,448] The parameter `algorithm` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,508] Trial 66 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,508] The parameter `algorithm` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,571] Trial 67 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,573] The parameter `algorithm` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,632] Trial 68 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,632] The parameter `algorithm` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,673] Trial 69 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,673] The parameter `algorithm` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,714] Trial 70 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,716] The parameter `algorithm` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,756] Trial 71 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,760] The parameter `algorithm` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,829] Trial 72 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,830] The parameter `algorithm` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,894] Trial 73 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,897] The parameter `algorithm` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,935] Trial 74 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:42,937] The parameter `algorithm` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:42,997] Trial 75 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,000] The parameter `algorithm` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,070] Trial 76 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,073] The parameter `algorithm` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,112] Trial 77 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,117] The parameter `algorithm` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,156] Trial 78 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,158] The parameter `algorithm` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,198] Trial 79 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,200] The parameter `algorithm` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,259] Trial 80 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,261] The parameter `algorithm` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,302] Trial 81 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,306] The parameter `algorithm` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,365] Trial 82 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,368] The parameter `algorithm` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,427] Trial 83 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,430] The parameter `algorithm` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,468] Trial 84 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,473] The parameter `algorithm` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,531] Trial 85 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,534] The parameter `algorithm` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,593] Trial 86 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,595] The parameter `algorithm` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,655] Trial 87 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,658] The parameter `algorithm` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,720] Trial 88 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,724] The parameter `algorithm` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,763] Trial 89 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,766] The parameter `algorithm` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,835] Trial 90 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,841] The parameter `algorithm` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,913] Trial 91 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,916] The parameter `algorithm` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:43,954] Trial 92 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:43,959] The parameter `algorithm` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,017] Trial 93 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:44,020] The parameter `algorithm` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,081] Trial 94 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:44,084] The parameter `algorithm` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,122] Trial 95 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:44,125] The parameter `algorithm` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,165] Trial 96 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:44,168] The parameter `algorithm` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,207] Trial 97 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:44,210] The parameter `algorithm` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,270] Trial 98 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n",
      "[W 2025-10-06 13:20:44,273] The parameter `algorithm` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,311] Trial 99 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 31 with value: 0.8623949579831933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:44,314] A new study created in memory with name: Support Vector Machine Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using CmaEsSampler: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}\n",
      "Best accuracy: 0.8624, at trial: 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02027f1736648d9b6b72fa7fd6d90a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:44,377] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:20:44,381] The parameter `kernel` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,430] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000865808466690932}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:20:44,434] The parameter `kernel` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,484] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0009528924787594206}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:20:44,487] The parameter `kernel` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,536] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002651575859618515}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:20:44,538] The parameter `kernel` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,587] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00010702593573937491}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:20:44,591] The parameter `kernel` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,641] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0013648551870204498}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:20:44,645] The parameter `kernel` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,694] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009741063383591005}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:20:44,696] The parameter `kernel` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:44,698] The parameter `degree` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,735] Trial 7 finished with value: 0.7416386554621849 and parameters: {'kernel': 'poly', 'C': 0.00035536968608811256, 'degree': 5}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:44,738] The parameter `kernel` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:44,740] The parameter `degree` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,778] Trial 8 finished with value: 0.7214985994397759 and parameters: {'kernel': 'poly', 'C': 0.0016819495611083031, 'degree': 2}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:44,781] The parameter `kernel` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,832] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0008759044346823585}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:44,835] The parameter `kernel` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,884] Trial 10 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001056500624921517}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:44,888] The parameter `kernel` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:44,889] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,926] Trial 11 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00022482472308916733, 'degree': 3}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:44,928] The parameter `kernel` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:44,979] Trial 12 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0006609717955966292}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:44,982] The parameter `kernel` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,033] Trial 13 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0019108490072318892}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:45,036] The parameter `kernel` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:45,038] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,076] Trial 14 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0010723013500298297, 'degree': 2}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:45,078] The parameter `kernel` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,127] Trial 15 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0008589117237375147}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:45,130] The parameter `kernel` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:45,132] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,169] Trial 16 finished with value: 0.7030252100840336 and parameters: {'kernel': 'poly', 'C': 0.0014486536468361364, 'degree': 2}. Best is trial 7 with value: 0.7416386554621849.\n",
      "[W 2025-10-06 13:20:45,174] The parameter `kernel` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:45,175] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,212] Trial 17 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.0008976326764422598, 'degree': 3}. Best is trial 17 with value: 0.7516946778711484.\n",
      "[W 2025-10-06 13:20:45,214] The parameter `kernel` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,262] Trial 18 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002028201308061743}. Best is trial 17 with value: 0.7516946778711484.\n",
      "[W 2025-10-06 13:20:45,263] The parameter `kernel` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,312] Trial 19 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0019205290876413404}. Best is trial 17 with value: 0.7516946778711484.\n",
      "[W 2025-10-06 13:20:45,315] The parameter `kernel` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:45,317] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,356] Trial 20 finished with value: 0.7567366946778711 and parameters: {'kernel': 'poly', 'C': 0.0009045717044282519, 'degree': 5}. Best is trial 20 with value: 0.7567366946778711.\n",
      "[W 2025-10-06 13:20:45,360] The parameter `kernel` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:45,363] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,401] Trial 21 finished with value: 0.7718207282913164 and parameters: {'kernel': 'poly', 'C': 0.0023486280228330577, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,403] The parameter `kernel` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,454] Trial 22 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007980430671411009}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,458] The parameter `kernel` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:45,459] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,497] Trial 23 finished with value: 0.7567226890756302 and parameters: {'kernel': 'poly', 'C': 0.0013691563891479086, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,499] The parameter `kernel` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,550] Trial 24 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00040586302723760796}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,553] The parameter `kernel` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,602] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007694067089355323}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,606] The parameter `kernel` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,654] Trial 26 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0010876205606037861}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,656] The parameter `kernel` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,705] Trial 27 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00026887645802990787}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,707] The parameter `kernel` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,746] Trial 28 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0024443529519513063}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,750] The parameter `kernel` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,799] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006732714659435734}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,799] The parameter `kernel` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,840] Trial 30 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0018497769569796683}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,842] The parameter `kernel` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,880] Trial 31 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004315409797092628}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,883] The parameter `kernel` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,932] Trial 32 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0008681542053704113}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,935] The parameter `kernel` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:45,983] Trial 33 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00038462255832088756}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:45,986] The parameter `kernel` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,036] Trial 34 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000712814769716924}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,039] The parameter `kernel` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,088] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0016530271291694979}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,090] The parameter `kernel` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,140] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0004496976311879662}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,144] The parameter `kernel` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,192] Trial 37 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00029425386367444947}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,196] The parameter `kernel` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,197] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,234] Trial 38 finished with value: 0.6476610644257702 and parameters: {'kernel': 'poly', 'C': 0.00010626951959266412, 'degree': 5}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,236] The parameter `kernel` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,286] Trial 39 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00038440066321521015}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,289] The parameter `kernel` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,292] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,330] Trial 40 finished with value: 0.7114425770308124 and parameters: {'kernel': 'poly', 'C': 0.00019493450793063135, 'degree': 5}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,334] The parameter `kernel` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,336] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,375] Trial 41 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0001224246707836423, 'degree': 3}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,377] The parameter `kernel` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,428] Trial 42 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002233519628142266}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,430] The parameter `kernel` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,480] Trial 43 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00010113970697125275}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,482] The parameter `kernel` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,532] Trial 44 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005047245173707152}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,534] The parameter `kernel` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,536] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,574] Trial 45 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0006550520110398806, 'degree': 2}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,576] The parameter `kernel` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,578] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,616] Trial 46 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0004051559361817895, 'degree': 2}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,618] The parameter `kernel` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,668] Trial 47 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00010603033552478092}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,672] The parameter `kernel` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,723] Trial 48 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0010374559683555187}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,726] The parameter `kernel` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,777] Trial 49 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006875888741944901}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,781] The parameter `kernel` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,829] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007664349563634962}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,832] The parameter `kernel` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,832] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,873] Trial 51 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00027974858956023057, 'degree': 2}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,873] The parameter `kernel` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,873] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,914] Trial 52 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0007590876600144722, 'degree': 2}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,918] The parameter `kernel` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,919] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,955] Trial 53 finished with value: 0.6543837535014005 and parameters: {'kernel': 'poly', 'C': 0.0013430794438914451, 'degree': 2}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:46,958] The parameter `kernel` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:46,958] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:46,997] Trial 54 finished with value: 0.724859943977591 and parameters: {'kernel': 'poly', 'C': 0.00022326576205010547, 'degree': 5}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,000] The parameter `kernel` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:47,000] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,039] Trial 55 finished with value: 0.7063865546218487 and parameters: {'kernel': 'poly', 'C': 0.0003091314453408101, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,042] The parameter `kernel` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,092] Trial 56 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007324823190922658}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,094] The parameter `kernel` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,143] Trial 57 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00027430388209905053}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,145] The parameter `kernel` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:47,147] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,185] Trial 58 finished with value: 0.7550700280112045 and parameters: {'kernel': 'poly', 'C': 0.0006870138995635105, 'degree': 5}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,188] The parameter `kernel` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,236] Trial 59 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0009696936863176132}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,239] The parameter `kernel` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:47,241] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,279] Trial 60 finished with value: 0.7500280112044818 and parameters: {'kernel': 'poly', 'C': 0.0009084728747542748, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,283] The parameter `kernel` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:47,285] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,323] Trial 61 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00043004104547784077, 'degree': 2}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,327] The parameter `kernel` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:47,328] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,367] Trial 62 finished with value: 0.7147899159663865 and parameters: {'kernel': 'poly', 'C': 0.00035918493435851197, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,369] The parameter `kernel` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,419] Trial 63 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004273963628099257}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,419] The parameter `kernel` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,462] Trial 64 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005486453257024644}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,462] The parameter `kernel` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,515] Trial 65 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0013561921991836721}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,517] The parameter `kernel` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,557] Trial 66 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009218598858911648}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,558] The parameter `kernel` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,609] Trial 67 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00035298367678128576}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,609] The parameter `kernel` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,660] Trial 68 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00048670605090109795}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,662] The parameter `kernel` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,714] Trial 69 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004431191146635118}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,716] The parameter `kernel` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,766] Trial 70 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007209419613119367}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,769] The parameter `kernel` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,817] Trial 71 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00025650192830281154}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,820] The parameter `kernel` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,869] Trial 72 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0001831542700975128}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,873] The parameter `kernel` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:47,875] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,913] Trial 73 finished with value: 0.7265266106442577 and parameters: {'kernel': 'poly', 'C': 0.0007810193083454321, 'degree': 3}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,916] The parameter `kernel` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:47,965] Trial 74 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00042693507152490577}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:47,967] The parameter `kernel` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:47,969] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,007] Trial 75 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00014187326238107326, 'degree': 3}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,009] The parameter `kernel` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,011] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,049] Trial 76 finished with value: 0.7198179271708683 and parameters: {'kernel': 'poly', 'C': 0.0003678674339792892, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,054] The parameter `kernel` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,055] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,093] Trial 77 finished with value: 0.7500140056022409 and parameters: {'kernel': 'poly', 'C': 0.0004197283900126351, 'degree': 5}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,095] The parameter `kernel` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,097] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,136] Trial 78 finished with value: 0.7449719887955182 and parameters: {'kernel': 'poly', 'C': 0.0004942823909990689, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,138] The parameter `kernel` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,187] Trial 79 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009067579866219948}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,190] The parameter `kernel` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,191] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,229] Trial 80 finished with value: 0.7517086834733894 and parameters: {'kernel': 'poly', 'C': 0.0006272237180172149, 'degree': 5}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,232] The parameter `kernel` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,282] Trial 81 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0008757961935199113}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,284] The parameter `kernel` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,335] Trial 82 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000438776761750612}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,338] The parameter `kernel` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,387] Trial 83 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004334314427706287}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,389] The parameter `kernel` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,391] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,429] Trial 84 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0005637105881933628, 'degree': 2}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,432] The parameter `kernel` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,481] Trial 85 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007261937523655487}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,484] The parameter `kernel` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,534] Trial 86 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005026629838780354}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,536] The parameter `kernel` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,586] Trial 87 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000661458363699104}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,588] The parameter `kernel` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,639] Trial 88 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0011079839039610905}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,642] The parameter `kernel` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,689] Trial 89 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000517500134583729}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,692] The parameter `kernel` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,694] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,732] Trial 90 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.0006150163969238281, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,734] The parameter `kernel` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,786] Trial 91 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0009366937021923117}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,789] The parameter `kernel` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,837] Trial 92 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007041496309751916}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,840] The parameter `kernel` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,842] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,879] Trial 93 finished with value: 0.7550700280112045 and parameters: {'kernel': 'poly', 'C': 0.000694977083698962, 'degree': 5}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,881] The parameter `kernel` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,930] Trial 94 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006294075099257816}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,933] The parameter `kernel` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,935] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:48,972] Trial 95 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.000674854679695737, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:48,975] The parameter `kernel` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:48,977] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:49,014] Trial 96 finished with value: 0.7500280112044818 and parameters: {'kernel': 'poly', 'C': 0.0007860413734939564, 'degree': 4}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:49,017] The parameter `kernel` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:49,067] Trial 97 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007746637968600208}. Best is trial 21 with value: 0.7718207282913164.\n",
      "[W 2025-10-06 13:20:49,070] The parameter `kernel` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:20:49,073] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:49,110] Trial 98 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0009561333976210087, 'degree': 2}. Best is trial 21 with value: 0.7718207282913164.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:49,166] A new study created in memory with name: AdaBoost Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-10-06 13:20:49,113] The parameter `kernel` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:20:49,163] Trial 99 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0008377040803528004}. Best is trial 21 with value: 0.7718207282913164.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using CmaEsSampler: {'kernel': 'poly', 'C': 0.0023486280228330577, 'degree': 4}\n",
      "Best accuracy: 0.7718, at trial: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e465fa0a14f4ea48088a7868813a8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:20:49,333] Trial 0 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:20:49,468] Trial 1 finished with value: 0.813781512605042 and parameters: {'n_estimators': 43, 'learning_rate': 0.025476088134515826}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:20:49,605] Trial 2 finished with value: 0.8171428571428571 and parameters: {'n_estimators': 41, 'learning_rate': 0.029414796527869724}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:20:49,789] Trial 3 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 60, 'learning_rate': 0.13653880096488336}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:49,954] Trial 4 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 57, 'learning_rate': 0.0011072190527544395}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:50,067] Trial 5 finished with value: 0.8422268907563024 and parameters: {'n_estimators': 36, 'learning_rate': 0.08721915368491258}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:50,189] Trial 6 finished with value: 0.8455742296918768 and parameters: {'n_estimators': 39, 'learning_rate': 0.11322743764742889}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:50,315] Trial 7 finished with value: 0.8338515406162464 and parameters: {'n_estimators': 36, 'learning_rate': 0.5324134360981368}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:50,469] Trial 8 finished with value: 0.8455742296918768 and parameters: {'n_estimators': 52, 'learning_rate': 0.0867401419599742}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:50,647] Trial 9 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 59, 'learning_rate': 0.13214437214130823}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:50,855] Trial 10 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 72, 'learning_rate': 0.06948599928300515}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:51,029] Trial 11 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 60, 'learning_rate': 0.0468607020167348}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:51,203] Trial 12 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 57, 'learning_rate': 0.1430056594175902}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:51,390] Trial 13 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 63, 'learning_rate': 0.12389434044072803}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:51,606] Trial 14 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 65, 'learning_rate': 0.10317444446314156}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:51,833] Trial 15 finished with value: 0.8372128851540616 and parameters: {'n_estimators': 73, 'learning_rate': 0.5036718053287121}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:52,040] Trial 16 finished with value: 0.8355462184873949 and parameters: {'n_estimators': 65, 'learning_rate': 0.03317947317456036}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:52,257] Trial 17 finished with value: 0.8472829131652662 and parameters: {'n_estimators': 76, 'learning_rate': 0.313136038457399}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:52,432] Trial 18 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 58, 'learning_rate': 0.11414588714178284}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:52,661] Trial 19 finished with value: 0.8456022408963586 and parameters: {'n_estimators': 82, 'learning_rate': 0.2715071863338774}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:52,888] Trial 20 finished with value: 0.8472829131652662 and parameters: {'n_estimators': 71, 'learning_rate': 0.22769720110296826}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:53,105] Trial 21 finished with value: 0.8372128851540616 and parameters: {'n_estimators': 64, 'learning_rate': 0.4909843876453311}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:53,291] Trial 22 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 55, 'learning_rate': 0.05997919225325342}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:53,466] Trial 23 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 52, 'learning_rate': 0.3415929643393611}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:53,641] Trial 24 finished with value: 0.8455742296918768 and parameters: {'n_estimators': 55, 'learning_rate': 0.07359678794513416}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:53,870] Trial 25 finished with value: 0.8372268907563024 and parameters: {'n_estimators': 79, 'learning_rate': 0.5487283759528099}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:53,984] Trial 26 finished with value: 0.8438935574229692 and parameters: {'n_estimators': 34, 'learning_rate': 0.14380348670890655}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:54,170] Trial 27 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 67, 'learning_rate': 0.19140149809561188}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:54,422] Trial 28 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 81, 'learning_rate': 0.30212544487996845}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:54,631] Trial 29 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 70, 'learning_rate': 0.09149614055969885}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:54,808] Trial 30 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 56, 'learning_rate': 0.2704119009030146}. Best is trial 3 with value: 0.8489495798319326.\n",
      "[I 2025-10-06 13:20:55,041] Trial 31 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 77, 'learning_rate': 0.3176340699705348}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:55,229] Trial 32 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 61, 'learning_rate': 0.18337546686004644}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:55,457] Trial 33 finished with value: 0.843921568627451 and parameters: {'n_estimators': 75, 'learning_rate': 0.21467975901607295}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:55,665] Trial 34 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 66, 'learning_rate': 0.10180604531490976}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:55,861] Trial 35 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 62, 'learning_rate': 0.22480032725425192}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:56,068] Trial 36 finished with value: 0.8422408963585435 and parameters: {'n_estimators': 70, 'learning_rate': 0.04730469629312802}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:56,275] Trial 37 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 69, 'learning_rate': 0.40863415035825235}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:56,493] Trial 38 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 72, 'learning_rate': 0.4802836487150246}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:56,709] Trial 39 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 74, 'learning_rate': 0.4220751486328998}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:56,895] Trial 40 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 64, 'learning_rate': 0.597449488761888}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:57,111] Trial 41 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 80, 'learning_rate': 0.368379730481753}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:57,347] Trial 42 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 84, 'learning_rate': 0.6511305766641903}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:57,545] Trial 43 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 63, 'learning_rate': 0.32966636995113713}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:57,793] Trial 44 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 84, 'learning_rate': 0.5996681647211966}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:58,053] Trial 45 finished with value: 0.8422408963585435 and parameters: {'n_estimators': 93, 'learning_rate': 0.24110156844471972}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:58,335] Trial 46 finished with value: 0.8338515406162464 and parameters: {'n_estimators': 94, 'learning_rate': 0.579018602531637}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:58,576] Trial 47 finished with value: 0.8338795518207283 and parameters: {'n_estimators': 81, 'learning_rate': 0.7810663456499085}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:58,786] Trial 48 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 69, 'learning_rate': 0.3566026386272857}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:59,007] Trial 49 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 68, 'learning_rate': 0.49836681785809395}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:59,218] Trial 50 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 61, 'learning_rate': 0.26528575360151607}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:59,460] Trial 51 finished with value: 0.83890756302521 and parameters: {'n_estimators': 73, 'learning_rate': 0.5547751374824229}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:59,670] Trial 52 finished with value: 0.843921568627451 and parameters: {'n_estimators': 61, 'learning_rate': 0.2818592078940119}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:20:59,876] Trial 53 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 58, 'learning_rate': 0.26498661304264637}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:00,082] Trial 54 finished with value: 0.843921568627451 and parameters: {'n_estimators': 62, 'learning_rate': 0.2597192628876995}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:00,258] Trial 55 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 52, 'learning_rate': 0.3730985445733739}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:00,426] Trial 56 finished with value: 0.8422268907563024 and parameters: {'n_estimators': 46, 'learning_rate': 0.12850849690872107}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:00,631] Trial 57 finished with value: 0.8422408963585435 and parameters: {'n_estimators': 66, 'learning_rate': 0.16733365459584684}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:00,850] Trial 58 finished with value: 0.843921568627451 and parameters: {'n_estimators': 72, 'learning_rate': 0.21194456544634488}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:01,067] Trial 59 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 73, 'learning_rate': 0.3192508194118774}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:01,273] Trial 60 finished with value: 0.8422408963585435 and parameters: {'n_estimators': 74, 'learning_rate': 0.2148131951410117}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:01,503] Trial 61 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 78, 'learning_rate': 0.3883710129093975}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:01,742] Trial 62 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 81, 'learning_rate': 0.37748152349444714}. Best is trial 31 with value: 0.8489775910364145.\n",
      "[I 2025-10-06 13:21:01,983] Trial 63 finished with value: 0.8506442577030813 and parameters: {'n_estimators': 80, 'learning_rate': 0.2321214811077452}. Best is trial 63 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:21:02,182] Trial 64 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 67, 'learning_rate': 0.3948815537192508}. Best is trial 63 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:21:02,373] Trial 65 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 63, 'learning_rate': 0.325934722321361}. Best is trial 63 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:21:02,561] Trial 66 finished with value: 0.8456022408963586 and parameters: {'n_estimators': 60, 'learning_rate': 0.2859092964562019}. Best is trial 63 with value: 0.8506442577030813.\n",
      "[I 2025-10-06 13:21:02,749] Trial 67 finished with value: 0.8506442577030814 and parameters: {'n_estimators': 62, 'learning_rate': 0.2539350781607113}. Best is trial 67 with value: 0.8506442577030814.\n",
      "[I 2025-10-06 13:21:02,990] Trial 68 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 71, 'learning_rate': 0.38839362274099204}. Best is trial 67 with value: 0.8506442577030814.\n",
      "[I 2025-10-06 13:21:03,252] Trial 69 finished with value: 0.8506302521008402 and parameters: {'n_estimators': 78, 'learning_rate': 0.21234336001953566}. Best is trial 67 with value: 0.8506442577030814.\n",
      "[I 2025-10-06 13:21:03,462] Trial 70 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 62, 'learning_rate': 0.7318432559115968}. Best is trial 67 with value: 0.8506442577030814.\n",
      "[I 2025-10-06 13:21:03,777] Trial 71 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 96, 'learning_rate': 0.15877969643260811}. Best is trial 67 with value: 0.8506442577030814.\n",
      "[I 2025-10-06 13:21:04,049] Trial 72 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 83, 'learning_rate': 0.26845574371735237}. Best is trial 67 with value: 0.8506442577030814.\n",
      "[I 2025-10-06 13:21:04,282] Trial 73 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 71, 'learning_rate': 0.18163355505746417}. Best is trial 67 with value: 0.8506442577030814.\n",
      "[I 2025-10-06 13:21:04,461] Trial 74 finished with value: 0.8506442577030814 and parameters: {'n_estimators': 52, 'learning_rate': 0.23263124972815236}. Best is trial 67 with value: 0.8506442577030814.\n",
      "[I 2025-10-06 13:21:04,639] Trial 75 finished with value: 0.850658263305322 and parameters: {'n_estimators': 54, 'learning_rate': 0.30613278617671263}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:04,818] Trial 76 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 50, 'learning_rate': 0.23911401023615036}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:05,026] Trial 77 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 58, 'learning_rate': 0.19414126373854018}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:05,267] Trial 78 finished with value: 0.843921568627451 and parameters: {'n_estimators': 76, 'learning_rate': 0.20287629197159485}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:05,437] Trial 79 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 49, 'learning_rate': 0.33480919567988293}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:05,668] Trial 80 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 70, 'learning_rate': 0.38749575890947885}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:05,903] Trial 81 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 75, 'learning_rate': 0.3345136696373653}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:06,111] Trial 82 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 64, 'learning_rate': 0.32958225281508424}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:06,368] Trial 83 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 78, 'learning_rate': 0.4924046094866743}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:06,574] Trial 84 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 66, 'learning_rate': 0.32697112714487575}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:06,802] Trial 85 finished with value: 0.8372128851540616 and parameters: {'n_estimators': 71, 'learning_rate': 0.4009824370133923}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:07,049] Trial 86 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 80, 'learning_rate': 0.39871190596093337}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:07,318] Trial 87 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 84, 'learning_rate': 0.4206784660323783}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:07,483] Trial 88 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 51, 'learning_rate': 0.40047804061073583}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:07,753] Trial 89 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 85, 'learning_rate': 0.42132281477152494}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:07,982] Trial 90 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 78, 'learning_rate': 0.4202137617686597}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:08,223] Trial 91 finished with value: 0.8372128851540616 and parameters: {'n_estimators': 75, 'learning_rate': 0.4415967219327421}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:08,472] Trial 92 finished with value: 0.8372128851540616 and parameters: {'n_estimators': 80, 'learning_rate': 0.49963140910350756}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:08,734] Trial 93 finished with value: 0.8271708683473389 and parameters: {'n_estimators': 82, 'learning_rate': 0.8954871401998103}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:08,966] Trial 94 finished with value: 0.8506442577030814 and parameters: {'n_estimators': 73, 'learning_rate': 0.24335931195627838}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:09,260] Trial 95 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 88, 'learning_rate': 0.46082939256273947}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:09,426] Trial 96 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 47, 'learning_rate': 0.4035756235722165}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:09,668] Trial 97 finished with value: 0.8472829131652662 and parameters: {'n_estimators': 76, 'learning_rate': 0.14509397564340668}. Best is trial 75 with value: 0.850658263305322.\n",
      "[I 2025-10-06 13:21:09,896] Trial 98 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 72, 'learning_rate': 0.30929520125622517}. Best is trial 75 with value: 0.850658263305322.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:21:10,171] A new study created in memory with name: Gradient Boosting Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:21:10,167] Trial 99 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 93, 'learning_rate': 0.4891760856731245}. Best is trial 75 with value: 0.850658263305322.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using CmaEsSampler: {'n_estimators': 54, 'learning_rate': 0.30613278617671263}\n",
      "Best accuracy: 0.8507, at trial: 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443b77a5ac7549828c36ab82f08c5f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:21:10,374] Trial 0 finished with value: 0.7985994397759104 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.7985994397759104.\n",
      "[W 2025-10-06 13:21:10,378] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:10,634] Trial 1 finished with value: 0.8389495798319327 and parameters: {'max_features': None, 'n_estimators': 57, 'learning_rate': 0.008658084666909323, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8397600270730616}. Best is trial 1 with value: 0.8389495798319327.\n",
      "[W 2025-10-06 13:21:10,638] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:10,854] Trial 2 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.009528924787594208, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.8029297907760695}. Best is trial 2 with value: 0.8573809523809522.\n",
      "[W 2025-10-06 13:21:10,858] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:11,041] Trial 3 finished with value: 0.8456162464985993 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.026515758596185147, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7269530336476903}. Best is trial 2 with value: 0.8573809523809522.\n",
      "[W 2025-10-06 13:21:11,045] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:11,199] Trial 4 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 24, 'learning_rate': 0.0010702593573937475, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7677248753915946}. Best is trial 2 with value: 0.8573809523809522.\n",
      "[W 2025-10-06 13:21:11,204] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:11,438] Trial 5 finished with value: 0.8557142857142856 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.019667141639294356, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.7115398922202714}. Best is trial 2 with value: 0.8573809523809522.\n",
      "[W 2025-10-06 13:21:11,442] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:11,626] Trial 6 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 47, 'learning_rate': 0.02340459441539314, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.7681058459555117}. Best is trial 2 with value: 0.8573809523809522.\n",
      "[W 2025-10-06 13:21:11,629] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:11,786] Trial 7 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 35, 'learning_rate': 0.01959654330798669, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7131820938134579}. Best is trial 7 with value: 0.8573949579831932.\n",
      "[W 2025-10-06 13:21:11,791] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:11,997] Trial 8 finished with value: 0.8472969187675069 and parameters: {'max_features': 'sqrt', 'n_estimators': 29, 'learning_rate': 0.028171880519557702, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.8047109221769}. Best is trial 7 with value: 0.8573949579831932.\n",
      "[W 2025-10-06 13:21:12,001] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:12,320] Trial 9 finished with value: 0.8624089635854343 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.011695860437734951, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.757470058328777}. Best is trial 9 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:21:12,326] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:12,665] Trial 10 finished with value: 0.8271708683473389 and parameters: {'max_features': None, 'n_estimators': 54, 'learning_rate': 0.026659618340841438, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.8436353160445476}. Best is trial 9 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:21:12,669] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:12,999] Trial 11 finished with value: 0.8473249299719889 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.01966201980274968, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.7012857040189162}. Best is trial 9 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:21:13,003] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:13,187] Trial 12 finished with value: 0.85906162464986 and parameters: {'max_features': 'log2', 'n_estimators': 58, 'learning_rate': 0.007396948256593374, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.8095576131768336}. Best is trial 9 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:21:13,192] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:13,438] Trial 13 finished with value: 0.8540196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.005587945783503763, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.6166032182476423}. Best is trial 9 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:21:13,442] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:13,647] Trial 14 finished with value: 0.8624229691876749 and parameters: {'max_features': None, 'n_estimators': 76, 'learning_rate': 0.020436507171550232, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.5177865968055799}. Best is trial 14 with value: 0.8624229691876749.\n",
      "[W 2025-10-06 13:21:13,652] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:13,827] Trial 15 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 58, 'learning_rate': 0.010939003074230633, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6942382762025462}. Best is trial 14 with value: 0.8624229691876749.\n",
      "[W 2025-10-06 13:21:13,831] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:14,072] Trial 16 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 53, 'learning_rate': 0.025529480232214432, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.652797490392362}. Best is trial 14 with value: 0.8624229691876749.\n",
      "[W 2025-10-06 13:21:14,076] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:14,310] Trial 17 finished with value: 0.8489915966386554 and parameters: {'max_features': None, 'n_estimators': 45, 'learning_rate': 0.010288996973124563, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6878731716374475}. Best is trial 14 with value: 0.8624229691876749.\n",
      "[W 2025-10-06 13:21:14,316] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:14,610] Trial 18 finished with value: 0.8489915966386554 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.00474554049351303, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.6948634939498419}. Best is trial 14 with value: 0.8624229691876749.\n",
      "[W 2025-10-06 13:21:14,615] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:14,811] Trial 19 finished with value: 0.8624369747899159 and parameters: {'max_features': None, 'n_estimators': 65, 'learning_rate': 0.057477264513051435, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6339757260708755}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:14,815] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:15,081] Trial 20 finished with value: 0.8506862745098038 and parameters: {'max_features': 'log2', 'n_estimators': 74, 'learning_rate': 0.06622956455453201, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.7358770119300694}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:15,085] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:15,395] Trial 21 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.01624759498169918, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7745854753888483}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:15,400] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:15,510] Trial 22 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.007203303802986253, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.5658983176775862}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:15,514] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:15,762] Trial 23 finished with value: 0.8607282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.006885137845351571, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.5658116372115503}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:15,766] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:16,015] Trial 24 finished with value: 0.8573669467787115 and parameters: {'max_features': None, 'n_estimators': 65, 'learning_rate': 0.02021023215486237, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.5787792800817981}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:16,018] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:16,162] Trial 25 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 63, 'learning_rate': 0.03007560052791975, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6747314796540946}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:16,166] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:16,395] Trial 26 finished with value: 0.8540196078431371 and parameters: {'max_features': None, 'n_estimators': 70, 'learning_rate': 0.01783049211077934, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6641305479932853}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:16,400] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:16,596] Trial 27 finished with value: 0.8355602240896358 and parameters: {'max_features': 'log2', 'n_estimators': 30, 'learning_rate': 0.00581235031485966, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.727155180659639}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:16,601] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:16,989] Trial 28 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 75, 'learning_rate': 0.02695003050869644, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.6547378009570692}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:16,993] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:17,125] Trial 29 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.029259369325086913, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.6766495865165303}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:17,129] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:17,297] Trial 30 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.025944119976548122, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6583886671086541}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:17,302] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:17,477] Trial 31 finished with value: 0.8590756302521008 and parameters: {'max_features': None, 'n_estimators': 52, 'learning_rate': 0.046163519081998554, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.5093866212617424}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:17,480] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:17,719] Trial 32 finished with value: 0.8473109243697479 and parameters: {'max_features': None, 'n_estimators': 48, 'learning_rate': 0.008645019661714394, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.6237102651512088}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:17,719] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:18,011] Trial 33 finished with value: 0.8624229691876751 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.01680287024381836, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.5796608685497431}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:18,011] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:18,310] Trial 34 finished with value: 0.8574229691876752 and parameters: {'max_features': None, 'n_estimators': 90, 'learning_rate': 0.05257450729383863, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.5192355263863375}. Best is trial 19 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:18,316] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:18,538] Trial 35 finished with value: 0.8641176470588237 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.020429528342491, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.6706631931182494}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:18,541] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:18,850] Trial 36 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.026836780863608967, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.6373032142580856}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:18,855] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:18,997] Trial 37 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 63, 'learning_rate': 0.09900042067407816, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.5728322504885346}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:19,000] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:19,144] Trial 38 finished with value: 0.8456302521008402 and parameters: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.006658466655022347, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7330253749155977}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:19,148] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:19,476] Trial 39 finished with value: 0.8557282913165267 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.015441904781495826, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.7398588454253093}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:19,482] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:19,789] Trial 40 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 78, 'learning_rate': 0.015788817747995437, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6558360541739524}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:19,789] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:19,966] Trial 41 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.028421546747675896, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.5533138850475984}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:19,966] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:20,349] Trial 42 finished with value: 0.8472969187675069 and parameters: {'max_features': None, 'n_estimators': 77, 'learning_rate': 0.009732161518354487, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7622949661338374}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:20,353] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:20,641] Trial 43 finished with value: 0.850700280112045 and parameters: {'max_features': None, 'n_estimators': 66, 'learning_rate': 0.01613585217796122, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.6625600278528553}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:20,645] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:20,839] Trial 44 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 52, 'learning_rate': 0.018238055646860644, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6455740248713966}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:20,842] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:21,038] Trial 45 finished with value: 0.8624369747899159 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.031664652775427404, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6072126599113997}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:21,043] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:21,340] Trial 46 finished with value: 0.850686274509804 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.030541633315635707, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6859031028609777}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:21,342] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:21,559] Trial 47 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 61, 'learning_rate': 0.029001633307322052, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.585176297542388}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:21,562] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:21,821] Trial 48 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 60, 'learning_rate': 0.021255783529811497, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6875897221598826}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:21,826] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:22,127] Trial 49 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 70, 'learning_rate': 0.010527747502413835, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.6056452926135216}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:22,131] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:22,369] Trial 50 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.022272234239391474, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.5111378163421609}. Best is trial 35 with value: 0.8641176470588237.\n",
      "[W 2025-10-06 13:21:22,373] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:22,548] Trial 51 finished with value: 0.8674929971988796 and parameters: {'max_features': 'sqrt', 'n_estimators': 62, 'learning_rate': 0.08055325621415461, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.5120433341627953}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:22,552] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:22,728] Trial 52 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.007238219932329379, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.642176432529413}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:22,731] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:22,937] Trial 53 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.014784491266841879, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.587146888774287}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:22,940] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:23,499] Trial 54 finished with value: 0.8439635854341736 and parameters: {'max_features': None, 'n_estimators': 74, 'learning_rate': 0.014879061137677016, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7826448753323547}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:23,507] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:23,651] Trial 55 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.052570131305968465, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.5310233327870792}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:23,655] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:23,963] Trial 56 finished with value: 0.8574089635854343 and parameters: {'max_features': None, 'n_estimators': 64, 'learning_rate': 0.024108603920165752, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6008411863415146}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:23,965] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:24,286] Trial 57 finished with value: 0.865798319327731 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.027321657488322135, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.5701513174126441}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:24,287] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:24,559] Trial 58 finished with value: 0.8607703081232494 and parameters: {'max_features': None, 'n_estimators': 76, 'learning_rate': 0.05134899907623464, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.5148660152945169}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:24,560] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:24,747] Trial 59 finished with value: 0.862450980392157 and parameters: {'max_features': 'sqrt', 'n_estimators': 56, 'learning_rate': 0.0600684884166325, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.5747005789239008}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:24,751] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:24,988] Trial 60 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 58, 'learning_rate': 0.01911833990300523, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.676358772722583}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:24,992] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:25,165] Trial 61 finished with value: 0.862450980392157 and parameters: {'max_features': None, 'n_estimators': 42, 'learning_rate': 0.07806485430500258, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.5020449764118398}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:25,169] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:25,279] Trial 62 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 44, 'learning_rate': 0.04770198605599981, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.6906638597602808}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:25,284] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:25,487] Trial 63 finished with value: 0.8557282913165267 and parameters: {'max_features': None, 'n_estimators': 65, 'learning_rate': 0.03876206400231029, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.5565995740626314}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:25,490] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:25,698] Trial 64 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.016797486259753684, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6153555534774958}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:25,702] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:25,982] Trial 65 finished with value: 0.8573809523809522 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.030275404990288537, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.7329280467385181}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:25,985] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:26,148] Trial 66 finished with value: 0.8540476190476189 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.05088188832491946, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6460990212276012}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:26,151] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:26,420] Trial 67 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 70, 'learning_rate': 0.016796384202361195, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.7123585744700995}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:26,425] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:26,697] Trial 68 finished with value: 0.8591036414565828 and parameters: {'max_features': 'log2', 'n_estimators': 79, 'learning_rate': 0.044968561186396916, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.5135512383131916}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:26,700] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:26,929] Trial 69 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.04363591383929543, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.5466368792119922}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:26,933] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:27,205] Trial 70 finished with value: 0.8624369747899159 and parameters: {'max_features': 'log2', 'n_estimators': 73, 'learning_rate': 0.05016814123676101, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8, 'subsample': 0.6024628012080351}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:27,211] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:27,437] Trial 71 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.04075607228289213, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6697136182472333}. Best is trial 51 with value: 0.8674929971988796.\n",
      "[W 2025-10-06 13:21:27,448] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:27,676] Trial 72 finished with value: 0.8691596638655463 and parameters: {'max_features': 'log2', 'n_estimators': 59, 'learning_rate': 0.03291251792336746, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.583709078715611}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:27,683] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:27,919] Trial 73 finished with value: 0.8624229691876749 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.01604151291765834, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.6689782589906856}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:27,923] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:28,141] Trial 74 finished with value: 0.865798319327731 and parameters: {'max_features': 'sqrt', 'n_estimators': 50, 'learning_rate': 0.039318033095622464, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.6673829526060315}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:28,144] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:28,380] Trial 75 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 58, 'learning_rate': 0.01712373888473802, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.6725566570834869}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:28,385] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:28,618] Trial 76 finished with value: 0.8607703081232494 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.049903040044500045, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.6017399914192739}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:28,621] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:28,849] Trial 77 finished with value: 0.865798319327731 and parameters: {'max_features': 'log2', 'n_estimators': 63, 'learning_rate': 0.02961169795362455, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.588408879622164}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:28,853] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:29,088] Trial 78 finished with value: 0.8624369747899159 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.029049561019590133, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.6560195238179432}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:29,088] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:29,359] Trial 79 finished with value: 0.8557142857142856 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.008563213624068257, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.6217810442734859}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:29,363] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:29,629] Trial 80 finished with value: 0.8590896358543418 and parameters: {'max_features': 'log2', 'n_estimators': 70, 'learning_rate': 0.03330439317904163, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6399543273378516}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:29,630] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:29,776] Trial 81 finished with value: 0.8641176470588234 and parameters: {'max_features': 'sqrt', 'n_estimators': 72, 'learning_rate': 0.07900022093869663, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.5920654239117654}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:29,781] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:30,009] Trial 82 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.03246148632346329, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.5481846445063118}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:30,014] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:30,252] Trial 83 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 70, 'learning_rate': 0.035090340767239055, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.551292589488561}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:30,257] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:30,495] Trial 84 finished with value: 0.8489915966386554 and parameters: {'max_features': None, 'n_estimators': 57, 'learning_rate': 0.012405472087917905, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.6077373634721903}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:30,499] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:30,713] Trial 85 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 63, 'learning_rate': 0.020242869425487385, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.6760071848279936}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:30,717] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:30,881] Trial 86 finished with value: 0.8574089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 44, 'learning_rate': 0.03510583902575505, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.6016880943869228}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:30,884] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:31,090] Trial 87 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.029520259133103504, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.715823351665504}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:31,094] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:31,332] Trial 88 finished with value: 0.8540336134453781 and parameters: {'max_features': None, 'n_estimators': 70, 'learning_rate': 0.028201303218406953, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.6718905229356458}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:31,337] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:31,550] Trial 89 finished with value: 0.8523809523809526 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.07051566638936639, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.6218999295164696}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:31,554] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:31,790] Trial 90 finished with value: 0.8640896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 56, 'learning_rate': 0.01480155301421389, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.8043385389090336}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:31,795] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:32,008] Trial 91 finished with value: 0.8557282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 55, 'learning_rate': 0.04914754595119976, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7458950658411744}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:32,008] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:32,146] Trial 92 finished with value: 0.8523809523809522 and parameters: {'max_features': None, 'n_estimators': 33, 'learning_rate': 0.05736980485119496, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.651711781408234}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:32,146] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:32,365] Trial 93 finished with value: 0.8641036414565825 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.07482912786958107, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.6453788522431686}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:32,366] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:32,625] Trial 94 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.009769142410921616, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.7095267394701883}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:32,629] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:32,884] Trial 95 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.011431574413483222, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6316662655726507}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:32,887] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:33,146] Trial 96 finished with value: 0.850672268907563 and parameters: {'max_features': None, 'n_estimators': 47, 'learning_rate': 0.017917967071256053, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7681380456790433}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:33,146] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:33,354] Trial 97 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.019774725029443982, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.6078993814585654}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:33,359] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:33,490] Trial 98 finished with value: 0.8422969187675069 and parameters: {'max_features': None, 'n_estimators': 25, 'learning_rate': 0.04513110705832274, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.7031064682241788}. Best is trial 72 with value: 0.8691596638655463.\n",
      "[W 2025-10-06 13:21:33,495] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:33,833] Trial 99 finished with value: 0.8473389355742297 and parameters: {'max_features': None, 'n_estimators': 65, 'learning_rate': 0.017618663360269893, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.6939033588257011}. Best is trial 72 with value: 0.8691596638655463.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using CmaEsSampler: {'max_features': 'log2', 'n_estimators': 59, 'learning_rate': 0.03291251792336746, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.583709078715611}\n",
      "Best accuracy: 0.8692, at trial: 72\n",
      "CMA-ES Base Models Training Time: 85.31 seconds\n"
     ]
    }
   ],
   "source": [
    "cmaes_base_models_training_start = time.time()\n",
    "\n",
    "# CMA-ES Hyperparameter Tuning with Cross Validation\n",
    "cmaes_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "cmaes_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "cmaes_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "cmaes_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "cmaes_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "cmaes_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "cmaes_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "# Model Fitting with best parameters\n",
    "cmaes_logistic_regression.fit(X_train, y_train)\n",
    "cmaes_decision_tree.fit(X_train, y_train)\n",
    "cmaes_random_forest.fit(X_train, y_train)\n",
    "cmaes_knn.fit(X_train, y_train)\n",
    "cmaes_svc.fit(X_train, y_train)\n",
    "cmaes_adaboost.fit(X_train, y_train)\n",
    "cmaes_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "cmaes_base_models_training_end = time.time()\n",
    "\n",
    "# Time taken for CMA-ES base models training\n",
    "cmaes_base_models_training_time = cmaes_base_models_training_end - cmaes_base_models_training_start\n",
    "print(f'CMA-ES Base Models Training Time: {cmaes_base_models_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:21:34,259] A new study created in memory with name: Logistic Regression Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b7c1f7dd1c40239731a4162b66b64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:21:34,322] Trial 0 finished with value: 0.6459803921568629 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.6459803921568629.\n",
      "[W 2025-10-06 13:21:34,325] The parameter `solver` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,389] Trial 1 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cholesky', 'C': 0.00010000000000000009}. Best is trial 0 with value: 0.6459803921568629.\n",
      "[W 2025-10-06 13:21:34,393] The parameter `solver` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,445] Trial 2 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.0316227766016838}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,448] The parameter `solver` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,498] Trial 3 finished with value: 0.8489775910364145 and parameters: {'solver': 'sag', 'C': 0.5623413251903494}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,501] The parameter `solver` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,550] Trial 4 finished with value: 0.7852100840336135 and parameters: {'solver': 'sag', 'C': 0.0017782794100389236}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,552] The parameter `solver` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,603] Trial 5 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.007498942093324564}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,606] The parameter `solver` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,655] Trial 6 finished with value: 0.8355462184873949 and parameters: {'solver': 'lbfgs', 'C': 2.371373705661655}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,657] The parameter `solver` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,707] Trial 7 finished with value: 0.8523389355742296 and parameters: {'solver': 'newton-cg', 'C': 0.13335214321633232}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,710] The parameter `solver` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,758] Trial 8 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00042169650342858235}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,760] The parameter `solver` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,809] Trial 9 finished with value: 0.7315826330532212 and parameters: {'solver': 'newton-cg', 'C': 0.000865964323360066}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,811] The parameter `solver` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,861] Trial 10 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cholesky', 'C': 0.27384196342643613}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,862] The parameter `solver` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,911] Trial 11 finished with value: 0.8372268907563025 and parameters: {'solver': 'lbfgs', 'C': 4.8696752516586255}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,913] The parameter `solver` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:34,962] Trial 12 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cg', 'C': 0.015399265260594926}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:34,964] The parameter `solver` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,013] Trial 13 finished with value: 0.8237955182072829 and parameters: {'solver': 'newton-cholesky', 'C': 0.0036517412725483775}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:35,016] The parameter `solver` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,064] Trial 14 finished with value: 0.8439355742296918 and parameters: {'solver': 'sag', 'C': 1.1547819846894576}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:35,066] The parameter `solver` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,117] Trial 15 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cg', 'C': 0.06493816315762112}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:35,119] The parameter `solver` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,166] Trial 16 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cholesky', 'C': 0.0002053525026457149}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:35,168] The parameter `solver` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,218] Trial 17 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.0002942727176209287}. Best is trial 2 with value: 0.8556862745098041.\n",
      "[W 2025-10-06 13:21:35,221] The parameter `solver` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,268] Trial 18 finished with value: 0.8573669467787116 and parameters: {'solver': 'lbfgs', 'C': 0.0930572040929699}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,271] The parameter `solver` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,321] Trial 19 finished with value: 0.8388935574229691 and parameters: {'solver': 'sag', 'C': 1.6548170999431808}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,324] The parameter `solver` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,373] Trial 20 finished with value: 0.8456022408963586 and parameters: {'solver': 'lbfgs', 'C': 0.005232991146814949}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,375] The parameter `solver` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,425] Trial 21 finished with value: 0.8489775910364145 and parameters: {'solver': 'sag', 'C': 0.022067340690845896}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,427] The parameter `solver` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,476] Trial 22 finished with value: 0.8372268907563025 and parameters: {'solver': 'sag', 'C': 6.978305848598657}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,477] The parameter `solver` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,527] Trial 23 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cg', 'C': 0.3924189758484537}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,530] The parameter `solver` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,578] Trial 24 finished with value: 0.7567226890756302 and parameters: {'solver': 'lbfgs', 'C': 0.0012409377607517208}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,580] The parameter `solver` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,631] Trial 25 finished with value: 0.6476610644257704 and parameters: {'solver': 'sag', 'C': 0.0006042963902381332}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,634] The parameter `solver` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,683] Trial 26 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.19109529749704401}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,683] The parameter `solver` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,735] Trial 27 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 3.39820832894256}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,737] The parameter `solver` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,786] Trial 28 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cholesky', 'C': 0.010746078283213176}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,786] The parameter `solver` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,838] Trial 29 finished with value: 0.8087254901960783 and parameters: {'solver': 'newton-cg', 'C': 0.0025482967479793462}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,838] The parameter `solver` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,889] Trial 30 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.8058421877614811}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,889] The parameter `solver` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,941] Trial 31 finished with value: 0.8506442577030814 and parameters: {'solver': 'newton-cholesky', 'C': 0.045315836376008195}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,942] The parameter `solver` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:35,993] Trial 32 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00014330125702369644}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:35,993] The parameter `solver` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,045] Trial 33 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00017154378963428796}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,046] The parameter `solver` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,096] Trial 34 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.05424690937011324}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,096] The parameter `solver` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,149] Trial 35 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cg', 'C': 0.9646616199111994}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,149] The parameter `solver` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,213] Trial 36 finished with value: 0.8170868347338935 and parameters: {'solver': 'newton-cg', 'C': 0.0030505278902670284}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,215] The parameter `solver` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,264] Trial 37 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cg', 'C': 0.01286396944936975}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,264] The parameter `solver` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,317] Trial 38 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cg', 'C': 4.067944321083045}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,317] The parameter `solver` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,370] Trial 39 finished with value: 0.8506442577030813 and parameters: {'solver': 'lbfgs', 'C': 0.22875732003183954}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,370] The parameter `solver` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,421] Trial 40 finished with value: 0.7097619047619048 and parameters: {'solver': 'newton-cg', 'C': 0.0007233941627366753}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,421] The parameter `solver` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,472] Trial 41 finished with value: 0.7718207282913164 and parameters: {'solver': 'lbfgs', 'C': 0.0014855080171727755}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,472] The parameter `solver` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,524] Trial 42 finished with value: 0.8523389355742296 and parameters: {'solver': 'newton-cg', 'C': 0.469758881670649}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,524] The parameter `solver` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,574] Trial 43 finished with value: 0.8372268907563025 and parameters: {'solver': 'sag', 'C': 8.353625469578262}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,576] The parameter `solver` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,624] Trial 44 finished with value: 0.8523249299719889 and parameters: {'solver': 'newton-cg', 'C': 0.026416483203860926}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,624] The parameter `solver` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,676] Trial 45 finished with value: 0.8489635854341737 and parameters: {'solver': 'newton-cg', 'C': 0.00626433536656886}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,677] The parameter `solver` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,727] Trial 46 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 1.9809567785503366}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,727] The parameter `solver` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,778] Trial 47 finished with value: 0.8540196078431371 and parameters: {'solver': 'sag', 'C': 0.11139738599948026}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,780] The parameter `solver` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,829] Trial 48 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.0003522694651473105}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,830] The parameter `solver` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,881] Trial 49 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.0002458244068920199}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,881] The parameter `solver` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,931] Trial 50 finished with value: 0.8573669467787116 and parameters: {'solver': 'newton-cholesky', 'C': 0.07773650302387758}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,933] The parameter `solver` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:36,983] Trial 51 finished with value: 0.8422549019607842 and parameters: {'solver': 'newton-cholesky', 'C': 1.3823722273579002}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:36,983] The parameter `solver` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,034] Trial 52 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cholesky', 'C': 0.004371444812611091}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,034] The parameter `solver` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,087] Trial 53 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cg', 'C': 0.018434229924091116}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,087] The parameter `solver` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,137] Trial 54 finished with value: 0.8372268907563025 and parameters: {'solver': 'newton-cholesky', 'C': 5.829415347136073}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,137] The parameter `solver` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,189] Trial 55 finished with value: 0.850658263305322 and parameters: {'solver': 'lbfgs', 'C': 0.32781211513934566}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,191] The parameter `solver` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,240] Trial 56 finished with value: 0.753375350140056 and parameters: {'solver': 'newton-cg', 'C': 0.001036632928437698}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,241] The parameter `solver` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,291] Trial 57 finished with value: 0.5369187675070027 and parameters: {'solver': 'newton-cg', 'C': 0.0005048065716667473}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,291] The parameter `solver` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,343] Trial 58 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.15963385442879416}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,344] The parameter `solver` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,395] Trial 59 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 2.8387359647587527}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,395] The parameter `solver` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,445] Trial 60 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.008976871324473142}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,445] The parameter `solver` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,497] Trial 61 finished with value: 0.8053781512605042 and parameters: {'solver': 'newton-cholesky', 'C': 0.002128751661796374}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,497] The parameter `solver` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,548] Trial 62 finished with value: 0.8489775910364145 and parameters: {'solver': 'lbfgs', 'C': 0.6731703824144981}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,548] The parameter `solver` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,597] Trial 63 finished with value: 0.8523249299719889 and parameters: {'solver': 'sag', 'C': 0.03785515249258631}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,597] The parameter `solver` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,648] Trial 64 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00011970850304957301}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,650] The parameter `solver` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,698] Trial 65 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00013097472643005907}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,700] The parameter `solver` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,749] Trial 66 finished with value: 0.8506442577030814 and parameters: {'solver': 'lbfgs', 'C': 0.04141784514364404}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,751] The parameter `solver` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,800] Trial 67 finished with value: 0.8472969187675069 and parameters: {'solver': 'sag', 'C': 0.7365250122712284}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,802] The parameter `solver` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,850] Trial 68 finished with value: 0.8104061624649861 and parameters: {'solver': 'lbfgs', 'C': 0.0023290965924605465}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,852] The parameter `solver` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,902] Trial 69 finished with value: 0.8489775910364145 and parameters: {'solver': 'sag', 'C': 0.009821718891880384}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,904] The parameter `solver` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:37,953] Trial 70 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 3.105900223624704}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:37,955] The parameter `solver` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,005] Trial 71 finished with value: 0.8540056022408965 and parameters: {'solver': 'newton-cholesky', 'C': 0.17465760476621184}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,008] The parameter `solver` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,056] Trial 72 finished with value: 0.5637675070028012 and parameters: {'solver': 'sag', 'C': 0.0005523158417307104}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,058] The parameter `solver` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,108] Trial 73 finished with value: 0.7533613445378151 and parameters: {'solver': 'sag', 'C': 0.0011341944035027575}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,111] The parameter `solver` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,158] Trial 74 finished with value: 0.850658263305322 and parameters: {'solver': 'newton-cg', 'C': 0.3586637624484768}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,160] The parameter `solver` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,212] Trial 75 finished with value: 0.8372268907563025 and parameters: {'solver': 'sag', 'C': 6.378043838892169}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,215] The parameter `solver` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,262] Trial 76 finished with value: 0.850658263305322 and parameters: {'solver': 'lbfgs', 'C': 0.02016914554730331}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,264] The parameter `solver` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,314] Trial 77 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cg', 'C': 0.004782858141653791}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,317] The parameter `solver` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,365] Trial 78 finished with value: 0.8405742296918767 and parameters: {'solver': 'lbfgs', 'C': 1.512472545310622}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,367] The parameter `solver` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,416] Trial 79 finished with value: 0.8573669467787116 and parameters: {'solver': 'sag', 'C': 0.08505258154439958}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,420] The parameter `solver` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,468] Trial 80 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.00026895987855750467}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,470] The parameter `solver` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,520] Trial 81 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00038542288686231087}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,523] The parameter `solver` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,571] Trial 82 finished with value: 0.8540196078431371 and parameters: {'solver': 'newton-cholesky', 'C': 0.12188141848422895}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,573] The parameter `solver` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,622] Trial 83 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 2.167392169568416}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,625] The parameter `solver` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,676] Trial 84 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.006853895838650084}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,677] The parameter `solver` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,739] Trial 85 finished with value: 0.8556862745098041 and parameters: {'solver': 'lbfgs', 'C': 0.028902639100224517}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,741] The parameter `solver` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,791] Trial 86 finished with value: 0.8372268907563025 and parameters: {'solver': 'newton-cg', 'C': 9.139816994654893}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,793] The parameter `solver` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,843] Trial 87 finished with value: 0.8523389355742296 and parameters: {'solver': 'newton-cholesky', 'C': 0.5139696800771514}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,845] The parameter `solver` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,893] Trial 88 finished with value: 0.7801960784313725 and parameters: {'solver': 'newton-cholesky', 'C': 0.001625314837311866}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,895] The parameter `solver` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,944] Trial 89 finished with value: 0.7232072829131653 and parameters: {'solver': 'newton-cg', 'C': 0.0007914755439411164}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,947] The parameter `solver` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:38,995] Trial 90 finished with value: 0.8506442577030813 and parameters: {'solver': 'sag', 'C': 0.2502865431174607}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:38,997] The parameter `solver` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,046] Trial 91 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cg', 'C': 4.450794062355996}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:39,048] The parameter `solver` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,096] Trial 92 finished with value: 0.8489775910364145 and parameters: {'solver': 'newton-cg', 'C': 0.014074646633398432}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:39,097] The parameter `solver` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,147] Trial 93 finished with value: 0.8221148459383754 and parameters: {'solver': 'sag', 'C': 0.0033376246942920405}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:39,149] The parameter `solver` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,197] Trial 94 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cg', 'C': 1.0554496008786018}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:39,199] The parameter `solver` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,248] Trial 95 finished with value: 0.8556862745098041 and parameters: {'solver': 'newton-cholesky', 'C': 0.05935229272296987}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:39,251] The parameter `solver` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,299] Trial 96 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00018768842935762206}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:39,301] The parameter `solver` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,352] Trial 97 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00015678788438269704}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:39,354] The parameter `solver` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:21:39,459] A new study created in memory with name: Decision Tree Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:21:39,402] Trial 98 finished with value: 0.8523249299719889 and parameters: {'solver': 'newton-cholesky', 'C': 0.04958068241684656}. Best is trial 18 with value: 0.8573669467787116.\n",
      "[W 2025-10-06 13:21:39,404] The parameter `solver` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,455] Trial 99 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cholesky', 'C': 0.8816830667755706}. Best is trial 18 with value: 0.8573669467787116.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using QMCSampler: {'solver': 'lbfgs', 'C': 0.0930572040929699}\n",
      "Best accuracy: 0.8574, at trial: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed48a916ac144f5faf11556d1ab4e7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:21:39,503] Trial 0 finished with value: 0.8137535014005601 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[W 2025-10-06 13:21:39,505] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,507] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,536] Trial 1 finished with value: 0.8053641456582632 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8137535014005601.\n",
      "[W 2025-10-06 13:21:39,539] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,542] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,583] Trial 2 finished with value: 0.8254761904761905 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8254761904761905.\n",
      "[W 2025-10-06 13:21:39,588] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,589] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,617] Trial 3 finished with value: 0.7919607843137254 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8254761904761905.\n",
      "[W 2025-10-06 13:21:39,620] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,622] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,649] Trial 4 finished with value: 0.7935574229691877 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8254761904761905.\n",
      "[W 2025-10-06 13:21:39,652] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,654] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,682] Trial 5 finished with value: 0.8187675070028011 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.8254761904761905.\n",
      "[W 2025-10-06 13:21:39,684] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,686] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,714] Trial 6 finished with value: 0.8087254901960783 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8254761904761905.\n",
      "[W 2025-10-06 13:21:39,717] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,719] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,747] Trial 7 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.8254761904761905.\n",
      "[W 2025-10-06 13:21:39,749] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,752] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,779] Trial 8 finished with value: 0.8104061624649861 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8254761904761905.\n",
      "[W 2025-10-06 13:21:39,780] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,782] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,810] Trial 9 finished with value: 0.8322128851540616 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:39,812] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,814] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,842] Trial 10 finished with value: 0.8086834733893558 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:39,845] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,846] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,874] Trial 11 finished with value: 0.813781512605042 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:39,877] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,879] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,905] Trial 12 finished with value: 0.8003361344537815 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:39,907] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,909] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,937] Trial 13 finished with value: 0.8321988795518207 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:39,939] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,940] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:39,968] Trial 14 finished with value: 0.8171148459383752 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:39,971] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:39,972] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,000] Trial 15 finished with value: 0.8087675070028011 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,001] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,003] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,030] Trial 16 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,033] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,035] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,062] Trial 17 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,064] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,065] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,093] Trial 18 finished with value: 0.8238515406162465 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,095] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,096] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,125] Trial 19 finished with value: 0.7919607843137254 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,126] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,128] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,157] Trial 20 finished with value: 0.7935574229691877 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,159] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,161] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,190] Trial 21 finished with value: 0.8154481792717088 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,192] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,194] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,222] Trial 22 finished with value: 0.7818627450980392 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,225] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,226] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,254] Trial 23 finished with value: 0.8120728291316526 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,256] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,258] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,285] Trial 24 finished with value: 0.8137675070028012 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,288] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,290] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,319] Trial 25 finished with value: 0.8104061624649859 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,320] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,322] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,350] Trial 26 finished with value: 0.7952380952380953 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,352] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,354] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,383] Trial 27 finished with value: 0.8271988795518206 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,385] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,387] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,415] Trial 28 finished with value: 0.8204901960784314 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,417] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,418] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,446] Trial 29 finished with value: 0.8154481792717088 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,447] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,449] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,477] Trial 30 finished with value: 0.8204621848739496 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,480] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,481] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,510] Trial 31 finished with value: 0.8053081232492996 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,512] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,514] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,541] Trial 32 finished with value: 0.8070588235294117 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,544] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,545] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,573] Trial 33 finished with value: 0.8120728291316526 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,575] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,576] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,605] Trial 34 finished with value: 0.8204481792717087 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,608] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,608] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,637] Trial 35 finished with value: 0.8120868347338934 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,639] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,641] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,669] Trial 36 finished with value: 0.8104061624649859 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,671] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,672] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,700] Trial 37 finished with value: 0.8070448179271708 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,702] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,704] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,730] Trial 38 finished with value: 0.8187815126050421 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,732] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,733] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,762] Trial 39 finished with value: 0.7986414565826331 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,764] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,765] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,794] Trial 40 finished with value: 0.8121008403361344 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,795] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,797] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,826] Trial 41 finished with value: 0.8154481792717088 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,827] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,829] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,856] Trial 42 finished with value: 0.8255042016806723 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,859] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,860] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,888] Trial 43 finished with value: 0.7667507002801119 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,890] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,891] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,919] Trial 44 finished with value: 0.8187815126050421 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,921] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,923] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,951] Trial 45 finished with value: 0.8171148459383752 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,953] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,955] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:40,982] Trial 46 finished with value: 0.825518207282913 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:40,985] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:40,986] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,013] Trial 47 finished with value: 0.8204481792717087 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,015] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,017] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,045] Trial 48 finished with value: 0.8271708683473389 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,046] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,049] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,078] Trial 49 finished with value: 0.8271708683473389 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,080] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,081] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,109] Trial 50 finished with value: 0.8187815126050421 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,112] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,113] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,142] Trial 51 finished with value: 0.8305042016806722 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,144] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,146] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,172] Trial 52 finished with value: 0.8171008403361345 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,174] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,176] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,204] Trial 53 finished with value: 0.8120868347338936 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,206] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,208] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,236] Trial 54 finished with value: 0.8086834733893558 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,238] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,240] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,269] Trial 55 finished with value: 0.7784593837535014 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,272] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,274] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,302] Trial 56 finished with value: 0.8087114845938375 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,304] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,306] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,334] Trial 57 finished with value: 0.8120868347338936 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,336] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,338] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,365] Trial 58 finished with value: 0.8205042016806722 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,367] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,368] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,396] Trial 59 finished with value: 0.8070308123249301 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,398] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,400] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,426] Trial 60 finished with value: 0.813781512605042 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,429] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,431] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,458] Trial 61 finished with value: 0.7985994397759104 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,460] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,462] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,492] Trial 62 finished with value: 0.8121288515406162 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,495] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,496] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,524] Trial 63 finished with value: 0.8271988795518206 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,526] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,527] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,555] Trial 64 finished with value: 0.8104061624649861 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,557] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,559] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,586] Trial 65 finished with value: 0.810392156862745 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,588] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,590] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,617] Trial 66 finished with value: 0.810392156862745 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,620] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,621] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,648] Trial 67 finished with value: 0.8137254901960784 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,649] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,651] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,680] Trial 68 finished with value: 0.815406162464986 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,680] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,680] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,712] Trial 69 finished with value: 0.8238095238095238 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,712] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,712] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,743] Trial 70 finished with value: 0.8104061624649859 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,743] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,743] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,775] Trial 71 finished with value: 0.8019747899159663 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,775] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,775] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,805] Trial 72 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.8322128851540616.\n",
      "[W 2025-10-06 13:21:41,807] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,808] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,836] Trial 73 finished with value: 0.8338935574229691 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:41,836] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,836] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,870] Trial 74 finished with value: 0.8204481792717087 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:41,872] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,874] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,903] Trial 75 finished with value: 0.8053361344537816 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:41,905] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,905] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,934] Trial 76 finished with value: 0.8171148459383752 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:41,934] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,934] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,966] Trial 77 finished with value: 0.8036694677871148 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:41,966] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,966] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:41,997] Trial 78 finished with value: 0.7987114845938376 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:41,997] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:41,997] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,029] Trial 79 finished with value: 0.8187815126050418 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,029] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,029] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,061] Trial 80 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,061] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,061] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,093] Trial 81 finished with value: 0.8271708683473389 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,093] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,093] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,124] Trial 82 finished with value: 0.8086974789915967 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,124] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,124] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,156] Trial 83 finished with value: 0.8238095238095238 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,156] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,156] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,188] Trial 84 finished with value: 0.8237955182072829 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,188] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,188] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,220] Trial 85 finished with value: 0.8019747899159663 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,220] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,220] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,253] Trial 86 finished with value: 0.8187815126050421 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,253] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,253] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,285] Trial 87 finished with value: 0.8019887955182072 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,285] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,285] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,316] Trial 88 finished with value: 0.8171008403361345 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,316] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,316] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,348] Trial 89 finished with value: 0.810392156862745 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.8338935574229691.\n",
      "[W 2025-10-06 13:21:42,348] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,348] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,378] Trial 90 finished with value: 0.8355602240896358 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 90 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:21:42,378] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,378] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,410] Trial 91 finished with value: 0.7885714285714286 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 90 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:21:42,412] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,414] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,443] Trial 92 finished with value: 0.8120868347338936 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 90 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:21:42,445] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,449] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,476] Trial 93 finished with value: 0.8137535014005601 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 90 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:21:42,476] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,480] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,510] Trial 94 finished with value: 0.7969467787114847 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 90 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:21:42,512] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,512] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,543] Trial 95 finished with value: 0.8187815126050418 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 90 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:21:42,544] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,544] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,574] Trial 96 finished with value: 0.8271708683473389 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 90 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:21:42,575] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,575] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,605] Trial 97 finished with value: 0.8120868347338936 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 90 with value: 0.8355602240896358.\n",
      "[W 2025-10-06 13:21:42,607] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,607] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,637] Trial 98 finished with value: 0.810392156862745 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 90 with value: 0.8355602240896358.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:21:42,670] A new study created in memory with name: Random Forest Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-10-06 13:21:42,639] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,639] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,669] Trial 99 finished with value: 0.8002941176470587 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 90 with value: 0.8355602240896358.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using QMCSampler: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9}\n",
      "Best accuracy: 0.8356, at trial: 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282a184e505d42aebfa7dee71e536c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:21:42,798] Trial 0 finished with value: 0.8372408963585434 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8372408963585434.\n",
      "[W 2025-10-06 13:21:42,798] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,798] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:42,895] Trial 1 finished with value: 0.8355882352941176 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8372408963585434.\n",
      "[W 2025-10-06 13:21:42,895] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:42,895] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:43,092] Trial 2 finished with value: 0.8574089635854343 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8574089635854343.\n",
      "[W 2025-10-06 13:21:43,092] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:43,097] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:43,351] Trial 3 finished with value: 0.8624369747899159 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:43,351] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:43,351] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:43,498] Trial 4 finished with value: 0.8406302521008403 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 32, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:43,498] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:43,498] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:43,673] Trial 5 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:43,673] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:43,673] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:43,965] Trial 6 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:43,968] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:43,969] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:44,193] Trial 7 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:44,196] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:44,197] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:44,318] Trial 8 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 21, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:44,320] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:44,321] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:44,451] Trial 9 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 27, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:44,455] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:44,457] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:44,701] Trial 10 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 72, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:44,704] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:44,706] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:44,991] Trial 11 finished with value: 0.8472969187675069 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 95, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:44,994] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:44,995] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:45,176] Trial 12 finished with value: 0.8506722689075629 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:45,179] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:45,181] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:45,344] Trial 13 finished with value: 0.8473389355742296 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:45,347] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:45,348] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:45,613] Trial 14 finished with value: 0.8540476190476189 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:45,616] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:45,617] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:45,830] Trial 15 finished with value: 0.8490056022408965 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:45,834] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:45,835] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:45,935] Trial 16 finished with value: 0.8439775910364146 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 15, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:45,938] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:45,939] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:46,038] Trial 17 finished with value: 0.850672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 18, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:46,041] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:46,042] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:46,267] Trial 18 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:46,270] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:46,271] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:46,545] Trial 19 finished with value: 0.850658263305322 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:46,548] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:46,549] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:46,712] Trial 20 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:46,715] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:46,716] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:46,910] Trial 21 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:46,912] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:46,913] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:47,209] Trial 22 finished with value: 0.8473109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 98, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:47,212] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:47,213] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:47,457] Trial 23 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:47,460] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:47,461] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:47,592] Trial 24 finished with value: 0.8440056022408964 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 29, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:47,595] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:47,597] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:47,717] Trial 25 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 24, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:47,717] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:47,722] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:47,956] Trial 26 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 69, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:47,958] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:47,959] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:48,247] Trial 27 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:48,250] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:48,250] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:48,412] Trial 28 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:48,414] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:48,414] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:48,569] Trial 29 finished with value: 0.8557002801120447 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 35, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:48,571] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:48,573] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:48,840] Trial 30 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:48,843] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:48,844] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:49,038] Trial 31 finished with value: 0.8473389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:49,041] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:49,042] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:49,132] Trial 32 finished with value: 0.8456442577030814 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 12, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:49,134] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:49,135] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:49,235] Trial 33 finished with value: 0.833935574229692 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 14, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:49,238] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:49,239] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:49,444] Trial 34 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:49,445] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:49,445] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:49,716] Trial 35 finished with value: 0.8372408963585434 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:49,720] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:49,722] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:49,873] Trial 36 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:49,875] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:49,877] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:50,059] Trial 37 finished with value: 0.845658263305322 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:50,062] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:50,063] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:50,347] Trial 38 finished with value: 0.8473109243697478 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:50,350] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:50,351] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:50,594] Trial 39 finished with value: 0.8607563025210083 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:50,596] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:50,597] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:50,728] Trial 40 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 25, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:50,731] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:50,733] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:50,864] Trial 41 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 31, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:50,867] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:50,868] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:51,124] Trial 42 finished with value: 0.8456582633053223 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:51,127] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:51,128] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:51,423] Trial 43 finished with value: 0.8473249299719889 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:51,425] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:51,426] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:51,608] Trial 44 finished with value: 0.8490336134453781 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 54, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:51,611] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:51,612] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:51,775] Trial 45 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 42, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:51,779] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:51,780] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:52,057] Trial 46 finished with value: 0.8456442577030814 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:52,060] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:52,061] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:52,277] Trial 47 finished with value: 0.8490056022408965 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:52,279] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:52,281] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:52,393] Trial 48 finished with value: 0.8473109243697479 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 19, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:52,395] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:52,397] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:52,507] Trial 49 finished with value: 0.8372689075630252 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 17, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:52,510] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:52,511] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:52,726] Trial 50 finished with value: 0.850672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:52,729] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:52,732] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:53,016] Trial 51 finished with value: 0.8523389355742296 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 85, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:53,019] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:53,021] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:53,182] Trial 52 finished with value: 0.8372549019607842 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 39, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:53,184] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:53,186] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:53,381] Trial 53 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:53,384] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:53,385] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:53,694] Trial 54 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:53,698] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:53,698] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:53,956] Trial 55 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:53,959] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:53,960] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:54,091] Trial 56 finished with value: 0.833921568627451 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:54,091] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:54,096] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:54,216] Trial 57 finished with value: 0.8490056022408963 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 22, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:54,217] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:54,217] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:54,456] Trial 58 finished with value: 0.8489915966386553 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:54,459] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:54,460] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:54,756] Trial 59 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:54,759] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:54,762] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:54,933] Trial 60 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:54,935] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:54,936] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:55,088] Trial 61 finished with value: 0.8456442577030814 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:55,091] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:55,093] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:55,369] Trial 62 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 79, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:55,370] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:55,370] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:55,576] Trial 63 finished with value: 0.845658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:55,579] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:55,580] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:55,671] Trial 64 finished with value: 0.8288795518207281 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 11, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:55,674] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:55,676] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:55,776] Trial 65 finished with value: 0.8205182072829131 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 12, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:55,779] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:55,780] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:55,995] Trial 66 finished with value: 0.8339215686274508 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:55,998] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:55,999] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:56,265] Trial 67 finished with value: 0.8389355742296918 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 80, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:56,268] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:56,269] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:56,411] Trial 68 finished with value: 0.8439775910364146 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:56,413] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:56,414] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:56,587] Trial 69 finished with value: 0.845658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:56,590] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:56,591] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:56,879] Trial 70 finished with value: 0.8456302521008402 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:56,883] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:56,884] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:57,120] Trial 71 finished with value: 0.8406162464985993 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 69, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:57,123] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:57,124] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:57,244] Trial 72 finished with value: 0.8288795518207281 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 23, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:57,247] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:57,248] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:57,378] Trial 73 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 29, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:57,381] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:57,382] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:57,628] Trial 74 finished with value: 0.8406302521008403 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 74, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:57,631] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:57,632] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:57,929] Trial 75 finished with value: 0.8489775910364145 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 97, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:57,933] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:57,934] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:58,118] Trial 76 finished with value: 0.8489915966386554 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:58,121] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:58,122] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:58,283] Trial 77 finished with value: 0.8406162464985993 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 40, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:58,285] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:58,286] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:58,564] Trial 78 finished with value: 0.8439355742296918 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:58,567] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:58,568] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:58,782] Trial 79 finished with value: 0.842282913165266 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:58,785] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:58,787] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:58,897] Trial 80 finished with value: 0.8456302521008403 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 17, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:58,900] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:58,901] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:59,010] Trial 81 finished with value: 0.8422829131652663 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 20, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:59,013] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:59,014] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:59,249] Trial 82 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:59,252] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:59,254] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:59,548] Trial 83 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:59,550] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:59,552] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:59,725] Trial 84 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:59,728] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:59,728] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:21:59,923] Trial 85 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:21:59,926] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:21:59,927] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:00,244] Trial 86 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:00,247] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:00,247] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:00,504] Trial 87 finished with value: 0.8356022408963584 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 77, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:00,505] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:00,505] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:00,650] Trial 88 finished with value: 0.8607563025210083 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 32, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:00,653] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:00,654] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:00,784] Trial 89 finished with value: 0.8440196078431372 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 26, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:00,784] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:00,790] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:01,034] Trial 90 finished with value: 0.8439775910364148 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:01,037] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:01,037] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:01,346] Trial 91 finished with value: 0.850658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 94, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:01,349] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:01,349] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:01,534] Trial 92 finished with value: 0.8607422969187676 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:01,537] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:01,538] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:01,690] Trial 93 finished with value: 0.8523389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:01,694] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:01,695] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:01,972] Trial 94 finished with value: 0.8489915966386554 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:01,975] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:01,977] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:02,190] Trial 95 finished with value: 0.8489915966386553 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:02,194] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:02,195] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:02,296] Trial 96 finished with value: 0.8473249299719887 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 14, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:02,299] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:02,300] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:02,403] Trial 97 finished with value: 0.8406582633053222 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 13, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:02,407] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:02,409] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:02,621] Trial 98 finished with value: 0.8506862745098038 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8624369747899159.\n",
      "[W 2025-10-06 13:22:02,624] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:02,625] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:22:02,905] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:02,901] Trial 99 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8624369747899159.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using QMCSampler: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
      "Best accuracy: 0.8624, at trial: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2960191bff4c437ea2c72419089cb661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:02,990] Trial 0 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[W 2025-10-06 13:22:02,992] The parameter `algorithm` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,033] Trial 1 finished with value: 0.8304761904761906 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 1}. Best is trial 0 with value: 0.8523249299719888.\n",
      "[W 2025-10-06 13:22:03,036] The parameter `algorithm` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,106] Trial 2 finished with value: 0.8523249299719889 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 2 with value: 0.8523249299719889.\n",
      "[W 2025-10-06 13:22:03,108] The parameter `algorithm` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,180] Trial 3 finished with value: 0.855686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 3 with value: 0.855686274509804.\n",
      "[W 2025-10-06 13:22:03,183] The parameter `algorithm` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,225] Trial 4 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'brute', 'n_neighbors': 15, 'p': 2}. Best is trial 3 with value: 0.855686274509804.\n",
      "[W 2025-10-06 13:22:03,227] The parameter `algorithm` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,298] Trial 5 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 3 with value: 0.855686274509804.\n",
      "[W 2025-10-06 13:22:03,300] The parameter `algorithm` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,370] Trial 6 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 6 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:22:03,372] The parameter `algorithm` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,412] Trial 7 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 6 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:22:03,416] The parameter `algorithm` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,454] Trial 8 finished with value: 0.8439635854341736 and parameters: {'algorithm': 'brute', 'n_neighbors': 9, 'p': 2}. Best is trial 6 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:22:03,456] The parameter `algorithm` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,515] Trial 9 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 11, 'p': 1}. Best is trial 6 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:22:03,517] The parameter `algorithm` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,556] Trial 10 finished with value: 0.8573389355742297 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 6 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:22:03,558] The parameter `algorithm` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,618] Trial 11 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 6 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:22:03,621] The parameter `algorithm` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,679] Trial 12 finished with value: 0.850658263305322 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 23, 'p': 2}. Best is trial 6 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:22:03,680] The parameter `algorithm` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,718] Trial 13 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 1}. Best is trial 6 with value: 0.8590336134453782.\n",
      "[W 2025-10-06 13:22:03,718] The parameter `algorithm` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,780] Trial 14 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:03,782] The parameter `algorithm` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,844] Trial 15 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:03,844] The parameter `algorithm` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,906] Trial 16 finished with value: 0.8305042016806722 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:03,906] The parameter `algorithm` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:03,948] Trial 17 finished with value: 0.8490196078431372 and parameters: {'algorithm': 'brute', 'n_neighbors': 7, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:03,950] The parameter `algorithm` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,022] Trial 18 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,025] The parameter `algorithm` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,083] Trial 19 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,086] The parameter `algorithm` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,146] Trial 20 finished with value: 0.8506442577030813 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 19, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,146] The parameter `algorithm` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,186] Trial 21 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,188] The parameter `algorithm` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,248] Trial 22 finished with value: 0.8590056022408963 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,248] The parameter `algorithm` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,289] Trial 23 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,291] The parameter `algorithm` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,331] Trial 24 finished with value: 0.8422549019607842 and parameters: {'algorithm': 'brute', 'n_neighbors': 13, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,332] The parameter `algorithm` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,393] Trial 25 finished with value: 0.8389495798319327 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,396] The parameter `algorithm` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,455] Trial 26 finished with value: 0.8539915966386555 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,456] The parameter `algorithm` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,496] Trial 27 finished with value: 0.8607002801120448 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,499] The parameter `algorithm` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,538] Trial 28 finished with value: 0.850658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,540] The parameter `algorithm` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,579] Trial 29 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'brute', 'n_neighbors': 16, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,580] The parameter `algorithm` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,619] Trial 30 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,621] The parameter `algorithm` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,692] Trial 31 finished with value: 0.8540056022408964 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 28, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,694] The parameter `algorithm` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,766] Trial 32 finished with value: 0.8238095238095238 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 4, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,766] The parameter `algorithm` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,837] Trial 33 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,840] The parameter `algorithm` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,909] Trial 34 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,912] The parameter `algorithm` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:04,971] Trial 35 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:04,974] The parameter `algorithm` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,012] Trial 36 finished with value: 0.8573669467787115 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,012] The parameter `algorithm` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,053] Trial 37 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,055] The parameter `algorithm` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,094] Trial 38 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,097] The parameter `algorithm` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,136] Trial 39 finished with value: 0.8573529411764707 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,138] The parameter `algorithm` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,207] Trial 40 finished with value: 0.842282913165266 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 11, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,209] The parameter `algorithm` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,249] Trial 41 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'brute', 'n_neighbors': 14, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,251] The parameter `algorithm` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,311] Trial 42 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,312] The parameter `algorithm` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,352] Trial 43 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,352] The parameter `algorithm` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,424] Trial 44 finished with value: 0.8506442577030813 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,426] The parameter `algorithm` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,465] Trial 45 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,465] The parameter `algorithm` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,537] Trial 46 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,540] The parameter `algorithm` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,610] Trial 47 finished with value: 0.8506442577030813 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,610] The parameter `algorithm` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,672] Trial 48 finished with value: 0.8439775910364146 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 8, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,674] The parameter `algorithm` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,732] Trial 49 finished with value: 0.830546218487395 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,735] The parameter `algorithm` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,775] Trial 50 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,777] The parameter `algorithm` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,816] Trial 51 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,818] The parameter `algorithm` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,877] Trial 52 finished with value: 0.8506442577030813 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 18, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,879] The parameter `algorithm` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:05,938] Trial 53 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 24, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:05,941] The parameter `algorithm` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,000] Trial 54 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,002] The parameter `algorithm` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,041] Trial 55 finished with value: 0.8590476190476192 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,043] The parameter `algorithm` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,102] Trial 56 finished with value: 0.8355602240896358 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 12, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,105] The parameter `algorithm` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,177] Trial 57 finished with value: 0.8557002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 9, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,179] The parameter `algorithm` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,218] Trial 58 finished with value: 0.8556862745098041 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,221] The parameter `algorithm` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,292] Trial 59 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,294] The parameter `algorithm` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,365] Trial 60 finished with value: 0.850658263305322 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,367] The parameter `algorithm` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,438] Trial 61 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 15, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,440] The parameter `algorithm` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,500] Trial 62 finished with value: 0.8607282913165267 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,502] The parameter `algorithm` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,562] Trial 63 finished with value: 0.8523249299719889 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,564] The parameter `algorithm` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,605] Trial 64 finished with value: 0.8321568627450981 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,607] The parameter `algorithm` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,667] Trial 65 finished with value: 0.8221008403361345 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 4, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,669] The parameter `algorithm` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,729] Trial 66 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,732] The parameter `algorithm` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,792] Trial 67 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,794] The parameter `algorithm` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,863] Trial 68 finished with value: 0.8456022408963586 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 16, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,865] The parameter `algorithm` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,903] Trial 69 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,905] The parameter `algorithm` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,944] Trial 70 finished with value: 0.8623809523809524 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,946] The parameter `algorithm` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:06,985] Trial 71 finished with value: 0.8590336134453782 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:06,988] The parameter `algorithm` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,058] Trial 72 finished with value: 0.8406162464985993 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,061] The parameter `algorithm` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,122] Trial 73 finished with value: 0.8472969187675069 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,125] The parameter `algorithm` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,164] Trial 74 finished with value: 0.8590196078431372 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,166] The parameter `algorithm` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,236] Trial 75 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,239] The parameter `algorithm` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,296] Trial 76 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,299] The parameter `algorithm` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,337] Trial 77 finished with value: 0.850658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 19, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,339] The parameter `algorithm` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,379] Trial 78 finished with value: 0.8607142857142858 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,380] The parameter `algorithm` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,419] Trial 79 finished with value: 0.8523249299719888 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,421] The parameter `algorithm` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,482] Trial 80 finished with value: 0.8490196078431372 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,485] The parameter `algorithm` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,523] Trial 81 finished with value: 0.8355602240896358 and parameters: {'algorithm': 'brute', 'n_neighbors': 8, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,525] The parameter `algorithm` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,584] Trial 82 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,586] The parameter `algorithm` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,646] Trial 83 finished with value: 0.8623949579831933 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,647] The parameter `algorithm` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,686] Trial 84 finished with value: 0.8472829131652662 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,689] The parameter `algorithm` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,748] Trial 85 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,750] The parameter `algorithm` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,819] Trial 86 finished with value: 0.8556582633053221 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,822] The parameter `algorithm` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,882] Trial 87 finished with value: 0.8573669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,884] The parameter `algorithm` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,944] Trial 88 finished with value: 0.8472689075630251 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,947] The parameter `algorithm` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:07,986] Trial 89 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'brute', 'n_neighbors': 11, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:07,988] The parameter `algorithm` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,059] Trial 90 finished with value: 0.8573389355742297 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,062] The parameter `algorithm` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,123] Trial 91 finished with value: 0.8556722689075631 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,126] The parameter `algorithm` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,164] Trial 92 finished with value: 0.850658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,167] The parameter `algorithm` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,227] Trial 93 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 17, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,228] The parameter `algorithm` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,288] Trial 94 finished with value: 0.8624089635854343 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,291] The parameter `algorithm` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:22:08,517] A new study created in memory with name: Support Vector Machine Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:08,329] Trial 95 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 29, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,331] The parameter `algorithm` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,370] Trial 96 finished with value: 0.8305042016806722 and parameters: {'algorithm': 'brute', 'n_neighbors': 5, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,371] The parameter `algorithm` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,411] Trial 97 finished with value: 0.8221008403361345 and parameters: {'algorithm': 'brute', 'n_neighbors': 4, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,413] The parameter `algorithm` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,473] Trial 98 finished with value: 0.8489635854341737 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 14 with value: 0.8624089635854343.\n",
      "[W 2025-10-06 13:22:08,475] The parameter `algorithm` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,513] Trial 99 finished with value: 0.8540056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 14 with value: 0.8624089635854343.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using QMCSampler: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}\n",
      "Best accuracy: 0.8624, at trial: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88de836b4bdf4cc4af3630bfaeb9a69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:08,583] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:22:08,585] The parameter `kernel` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,637] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00010000000000000009}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:22:08,641] The parameter `kernel` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,690] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0010000000000000002}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:22:08,692] The parameter `kernel` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,741] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.003162277660168382}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:22:08,743] The parameter `kernel` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,793] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003162277660168384}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:22:08,796] The parameter `kernel` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,846] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005623413251903495}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:22:08,849] The parameter `kernel` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,898] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005623413251903492}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-10-06 13:22:08,900] The parameter `kernel` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:08,903] The parameter `degree` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,941] Trial 7 finished with value: 0.7735014005602242 and parameters: {'kernel': 'poly', 'C': 0.0017782794100389236, 'degree': 5}. Best is trial 7 with value: 0.7735014005602242.\n",
      "[W 2025-10-06 13:22:08,943] The parameter `kernel` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:08,945] The parameter `degree` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:08,983] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00017782794100389232, 'degree': 2}. Best is trial 7 with value: 0.7735014005602242.\n",
      "[W 2025-10-06 13:22:08,986] The parameter `kernel` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,036] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023713737056616573}. Best is trial 7 with value: 0.7735014005602242.\n",
      "[W 2025-10-06 13:22:09,038] The parameter `kernel` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,088] Trial 10 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002371373705661656}. Best is trial 7 with value: 0.7735014005602242.\n",
      "[W 2025-10-06 13:22:09,091] The parameter `kernel` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:09,092] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,131] Trial 11 finished with value: 0.7835574229691877 and parameters: {'kernel': 'poly', 'C': 0.007498942093324564, 'degree': 3}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,133] The parameter `kernel` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,182] Trial 12 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007498942093324562}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,185] The parameter `kernel` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,235] Trial 13 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00042169650342858235}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,238] The parameter `kernel` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:09,239] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,279] Trial 14 finished with value: 0.7785154061624651 and parameters: {'kernel': 'poly', 'C': 0.004216965034285825, 'degree': 2}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,281] The parameter `kernel` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,331] Trial 15 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0013335214321633251}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,332] The parameter `kernel` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:09,335] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,373] Trial 16 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0001333521432163326, 'degree': 2}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,375] The parameter `kernel` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:09,376] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,416] Trial 17 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00015399265260594933, 'degree': 3}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,418] The parameter `kernel` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,467] Trial 18 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015399265260594922}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,469] The parameter `kernel` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,519] Trial 19 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004869675251658635}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,522] The parameter `kernel` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:09,524] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,562] Trial 20 finished with value: 0.7500140056022409 and parameters: {'kernel': 'poly', 'C': 0.00048696752516586337, 'degree': 5}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,564] The parameter `kernel` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:09,565] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,604] Trial 21 finished with value: 0.7500280112044818 and parameters: {'kernel': 'poly', 'C': 0.000865964323360066, 'degree': 4}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,606] The parameter `kernel` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,655] Trial 22 finished with value: 0.5436414565826331 and parameters: {'kernel': 'sigmoid', 'C': 0.008659643233600654}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,657] The parameter `kernel` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:09,659] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,697] Trial 23 finished with value: 0.7718207282913164 and parameters: {'kernel': 'poly', 'C': 0.0027384196342643626, 'degree': 4}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,699] The parameter `kernel` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,749] Trial 24 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002738419634264362}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,751] The parameter `kernel` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,802] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0002053525026457149}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,805] The parameter `kernel` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,854] Trial 26 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0020535250264571477}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,856] The parameter `kernel` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,905] Trial 27 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0064938163157621165}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,907] The parameter `kernel` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:09,956] Trial 28 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006493816315762115}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:09,959] The parameter `kernel` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,009] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000365174127254838}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,010] The parameter `kernel` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,061] Trial 30 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0036517412725483775}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,062] The parameter `kernel` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,112] Trial 31 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0011547819846894588}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,114] The parameter `kernel` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,163] Trial 32 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00011547819846894585}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,164] The parameter `kernel` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,214] Trial 33 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00012409377607517218}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,216] The parameter `kernel` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,268] Trial 34 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0012409377607517208}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,270] The parameter `kernel` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,319] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.003924189758484535}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,321] The parameter `kernel` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,371] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003924189758484538}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,373] The parameter `kernel` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,423] Trial 37 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006978305848598669}. Best is trial 11 with value: 0.7835574229691877.\n",
      "[W 2025-10-06 13:22:10,424] The parameter `kernel` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:10,427] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,464] Trial 38 finished with value: 0.8170448179271708 and parameters: {'kernel': 'poly', 'C': 0.006978305848598664, 'degree': 5}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,466] The parameter `kernel` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,515] Trial 39 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002206734069084591}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,518] The parameter `kernel` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:10,519] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,558] Trial 40 finished with value: 0.724859943977591 and parameters: {'kernel': 'poly', 'C': 0.00022067340690845924, 'degree': 5}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,559] The parameter `kernel` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:10,561] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,601] Trial 41 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0002942727176209287, 'degree': 3}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,602] The parameter `kernel` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,653] Trial 42 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.002942727176209285}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,656] The parameter `kernel` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,705] Trial 43 finished with value: 0.7315406162464987 and parameters: {'kernel': 'rbf', 'C': 0.009305720409296997}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,707] The parameter `kernel` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,757] Trial 44 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009305720409296995}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,758] The parameter `kernel` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:10,760] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,797] Trial 45 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0005232991146814953, 'degree': 2}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,799] The parameter `kernel` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:10,801] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,839] Trial 46 finished with value: 0.7785154061624651 and parameters: {'kernel': 'poly', 'C': 0.005232991146814949, 'degree': 2}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,841] The parameter `kernel` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,892] Trial 47 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0016548170999431827}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,894] The parameter `kernel` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,944] Trial 48 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00016548170999431823}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,947] The parameter `kernel` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:10,996] Trial 49 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00014330125702369644}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:10,997] The parameter `kernel` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,047] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0014330125702369636}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:11,050] The parameter `kernel` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,051] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,089] Trial 51 finished with value: 0.7768347338935575 and parameters: {'kernel': 'poly', 'C': 0.0045315836376008225, 'degree': 2}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:11,091] The parameter `kernel` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,093] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,130] Trial 52 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00045315836376008217, 'degree': 2}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:11,131] The parameter `kernel` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,133] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,172] Trial 53 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0008058421877614828, 'degree': 2}. Best is trial 38 with value: 0.8170448179271708.\n",
      "[W 2025-10-06 13:22:11,174] The parameter `kernel` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,175] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,213] Trial 54 finished with value: 0.8288095238095238 and parameters: {'kernel': 'poly', 'C': 0.008058421877614822, 'degree': 5}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,216] The parameter `kernel` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,217] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,257] Trial 55 finished with value: 0.7718207282913164 and parameters: {'kernel': 'poly', 'C': 0.0025482967479793484, 'degree': 4}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,259] The parameter `kernel` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,309] Trial 56 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002548296747979348}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,311] The parameter `kernel` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,360] Trial 57 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00019109529749704405}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,362] The parameter `kernel` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,364] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,401] Trial 58 finished with value: 0.7751820728291318 and parameters: {'kernel': 'poly', 'C': 0.0019109529749704425, 'degree': 5}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,403] The parameter `kernel` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,453] Trial 59 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.006042963902381333}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,454] The parameter `kernel` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,456] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,495] Trial 60 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.0006042963902381332, 'degree': 4}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,499] The parameter `kernel` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,500] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,537] Trial 61 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00033982083289425634, 'degree': 2}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,539] The parameter `kernel` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:11,542] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,580] Trial 62 finished with value: 0.7751820728291318 and parameters: {'kernel': 'poly', 'C': 0.003398208328942561, 'degree': 4}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,582] The parameter `kernel` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,621] Trial 63 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010746078283213184}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,623] The parameter `kernel` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,673] Trial 64 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00010746078283213182}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,675] The parameter `kernel` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,726] Trial 65 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0001113973859994803}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,727] The parameter `kernel` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,776] Trial 66 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001113973859994803}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,779] The parameter `kernel` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,827] Trial 67 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0035226946514731027}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,829] The parameter `kernel` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,879] Trial 68 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003522694651473105}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,881] The parameter `kernel` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,932] Trial 69 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0006264335366568858}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,934] The parameter `kernel` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:11,983] Trial 70 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00626433536656886}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:11,985] The parameter `kernel` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,034] Trial 71 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001980956778550341}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,035] The parameter `kernel` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,086] Trial 72 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0001980956778550342}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,090] The parameter `kernel` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:12,092] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,130] Trial 73 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00026416483203860934, 'degree': 3}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,132] The parameter `kernel` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,181] Trial 74 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0026416483203860943}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,183] The parameter `kernel` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:12,184] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,223] Trial 75 finished with value: 0.7852240896358543 and parameters: {'kernel': 'poly', 'C': 0.008353625469578265, 'degree': 3}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,226] The parameter `kernel` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:12,227] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,265] Trial 76 finished with value: 0.7500280112044818 and parameters: {'kernel': 'poly', 'C': 0.000835362546957827, 'degree': 4}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,267] The parameter `kernel` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:12,269] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,308] Trial 77 finished with value: 0.7500140056022409 and parameters: {'kernel': 'poly', 'C': 0.0004697588816706495, 'degree': 5}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,310] The parameter `kernel` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:12,312] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,350] Trial 78 finished with value: 0.7718067226890757 and parameters: {'kernel': 'poly', 'C': 0.004697588816706496, 'degree': 4}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,352] The parameter `kernel` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,402] Trial 79 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0014855080171727755}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,404] The parameter `kernel` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:12,406] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,444] Trial 80 finished with value: 0.7063865546218487 and parameters: {'kernel': 'poly', 'C': 0.00014855080171727767, 'degree': 5}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,446] The parameter `kernel` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,496] Trial 81 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00017154378963428796}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,499] The parameter `kernel` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,549] Trial 82 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0017154378963428801}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,552] The parameter `kernel` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,605] Trial 83 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005424690937011328}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,607] The parameter `kernel` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:12,610] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,649] Trial 84 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0005424690937011332, 'degree': 2}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,651] The parameter `kernel` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,701] Trial 85 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009646616199111995}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,703] The parameter `kernel` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,754] Trial 86 finished with value: 0.7416106442577031 and parameters: {'kernel': 'rbf', 'C': 0.009646616199111998}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,755] The parameter `kernel` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,804] Trial 87 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0030505278902670284}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,806] The parameter `kernel` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,854] Trial 88 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00030505278902670253}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,855] The parameter `kernel` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,905] Trial 89 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002287573200318398}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,907] The parameter `kernel` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:12,909] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,947] Trial 90 finished with value: 0.7718207282913164 and parameters: {'kernel': 'poly', 'C': 0.0022875732003183966, 'degree': 4}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:12,949] The parameter `kernel` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:12,998] Trial 91 finished with value: 0.5436414565826331 and parameters: {'kernel': 'rbf', 'C': 0.007233941627366754}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:13,000] The parameter `kernel` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:13,049] Trial 92 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007233941627366753}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:13,051] The parameter `kernel` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:13,053] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:13,092] Trial 93 finished with value: 0.7500140056022409 and parameters: {'kernel': 'poly', 'C': 0.0004067944321083049, 'degree': 5}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:13,094] The parameter `kernel` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:13,144] Trial 94 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0040679443210830495}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:13,146] The parameter `kernel` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:13,147] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:13,186] Trial 95 finished with value: 0.7584033613445378 and parameters: {'kernel': 'poly', 'C': 0.0012863969449369757, 'degree': 4}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:13,188] The parameter `kernel` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:13,189] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:13,227] Trial 96 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00012863969449369766, 'degree': 4}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:13,230] The parameter `kernel` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:13,279] Trial 97 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00011970850304957301}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:13,281] The parameter `kernel` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:22:13,283] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:22:13,376] A new study created in memory with name: AdaBoost Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:13,320] Trial 98 finished with value: 0.5436414565826331 and parameters: {'kernel': 'poly', 'C': 0.0011970850304957315, 'degree': 2}. Best is trial 54 with value: 0.8288095238095238.\n",
      "[W 2025-10-06 13:22:13,322] The parameter `kernel` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:13,373] Trial 99 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00378551524925863}. Best is trial 54 with value: 0.8288095238095238.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using QMCSampler: {'kernel': 'poly', 'C': 0.008058421877614822, 'degree': 5}\n",
      "Best accuracy: 0.8288, at trial: 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fafb42d9b14d84bb229f408b6cedbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:13,532] Trial 0 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:22:13,592] Trial 1 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.0010000000000000002}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:22:13,774] Trial 2 finished with value: 0.8338375350140057 and parameters: {'n_estimators': 55, 'learning_rate': 0.0316227766016838}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:22:14,032] Trial 3 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 78, 'learning_rate': 0.005623413251903492}. Best is trial 0 with value: 0.8422549019607842.\n",
      "[I 2025-10-06 13:22:14,154] Trial 4 finished with value: 0.8489495798319329 and parameters: {'n_estimators': 32, 'learning_rate': 0.1778279410038923}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:14,307] Trial 5 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 44, 'learning_rate': 0.013335214321633242}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:14,584] Trial 6 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 89, 'learning_rate': 0.4216965034285823}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:14,780] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 66, 'learning_rate': 0.002371373705661656}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:14,861] Trial 8 finished with value: 0.8371988795518208 and parameters: {'n_estimators': 21, 'learning_rate': 0.07498942093324559}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:14,970] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 27, 'learning_rate': 0.008659643233600654}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:15,197] Trial 10 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 72, 'learning_rate': 0.27384196342643613}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:15,474] Trial 11 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 95, 'learning_rate': 0.0015399265260594922}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:15,629] Trial 12 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 49, 'learning_rate': 0.04869675251658632}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:15,762] Trial 13 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 38, 'learning_rate': 0.0036517412725483775}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:16,023] Trial 14 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 83, 'learning_rate': 0.11547819846894583}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:16,231] Trial 15 finished with value: 0.8171428571428571 and parameters: {'n_estimators': 61, 'learning_rate': 0.020535250264571463}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:16,303] Trial 16 finished with value: 0.8338375350140057 and parameters: {'n_estimators': 15, 'learning_rate': 0.6493816315762113}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:16,384] Trial 17 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 18, 'learning_rate': 0.025482967479793468}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:16,585] Trial 18 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 64, 'learning_rate': 0.8058421877614819}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:16,853] Trial 19 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 86, 'learning_rate': 0.004531583637600819}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:17,010] Trial 20 finished with value: 0.84390756302521 and parameters: {'n_estimators': 41, 'learning_rate': 0.14330125702369628}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:17,196] Trial 21 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 52, 'learning_rate': 0.001910952974970441}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:17,508] Trial 22 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 98, 'learning_rate': 0.060429639023813285}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:17,747] Trial 23 finished with value: 0.813781512605042 and parameters: {'n_estimators': 75, 'learning_rate': 0.010746078283213176}. Best is trial 4 with value: 0.8489495798319329.\n",
      "[I 2025-10-06 13:22:17,860] Trial 24 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 29, 'learning_rate': 0.33982083289425596}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:17,951] Trial 25 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029427271762092824}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:18,165] Trial 26 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 69, 'learning_rate': 0.0930572040929699}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:18,446] Trial 27 finished with value: 0.8371988795518208 and parameters: {'n_estimators': 92, 'learning_rate': 0.016548170999431816}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:18,601] Trial 28 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 46, 'learning_rate': 0.5232991146814947}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:18,722] Trial 29 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 35, 'learning_rate': 0.006978305848598664}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:18,970] Trial 30 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 81, 'learning_rate': 0.220673406908459}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:19,154] Trial 31 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 58, 'learning_rate': 0.0012409377607517198}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:19,214] Trial 32 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 12, 'learning_rate': 0.039241897584845364}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:19,272] Trial 33 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 14, 'learning_rate': 0.006264335366568854}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:19,458] Trial 34 finished with value: 0.84390756302521 and parameters: {'n_estimators': 59, 'learning_rate': 0.1980956778550338}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:19,717] Trial 35 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 82, 'learning_rate': 0.0011139738599948022}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:19,847] Trial 36 finished with value: 0.8171428571428571 and parameters: {'n_estimators': 37, 'learning_rate': 0.03522694651473102}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:20,010] Trial 37 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 48, 'learning_rate': 0.0026416483203860917}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:20,297] Trial 38 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 93, 'learning_rate': 0.08353625469578259}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:20,513] Trial 39 finished with value: 0.813781512605042 and parameters: {'n_estimators': 71, 'learning_rate': 0.014855080171727746}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:20,615] Trial 40 finished with value: 0.8456022408963586 and parameters: {'n_estimators': 25, 'learning_rate': 0.469758881670649}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:20,736] Trial 41 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 31, 'learning_rate': 0.0017154378963428786}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:20,974] Trial 42 finished with value: 0.8455742296918768 and parameters: {'n_estimators': 76, 'learning_rate': 0.05424690937011326}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:21,280] Trial 43 finished with value: 0.813781512605042 and parameters: {'n_estimators': 99, 'learning_rate': 0.00964661619911199}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:21,465] Trial 44 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 54, 'learning_rate': 0.3050527890267024}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:21,608] Trial 45 finished with value: 0.813781512605042 and parameters: {'n_estimators': 42, 'learning_rate': 0.02287573200318396}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:21,880] Trial 46 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 88, 'learning_rate': 0.7233941627366745}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:22,088] Trial 47 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 65, 'learning_rate': 0.004067944321083046}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:22,171] Trial 48 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 19, 'learning_rate': 0.12863969449369742}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:22,239] Trial 49 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 17, 'learning_rate': 0.005048065716667474}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:22,448] Trial 50 finished with value: 0.8472829131652662 and parameters: {'n_estimators': 62, 'learning_rate': 0.1596338544287943}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:22,739] Trial 51 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 85, 'learning_rate': 0.02838735964758755}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:22,886] Trial 52 finished with value: 0.8204341736694678 and parameters: {'n_estimators': 39, 'learning_rate': 0.8976871324473146}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:23,052] Trial 53 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 51, 'learning_rate': 0.011970850304957308}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:23,345] Trial 54 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 96, 'learning_rate': 0.3785515249258632}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:23,584] Trial 55 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 73, 'learning_rate': 0.002128751661796374}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:23,706] Trial 56 finished with value: 0.8338375350140057 and parameters: {'n_estimators': 28, 'learning_rate': 0.06731703824144986}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:23,798] Trial 57 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 22, 'learning_rate': 0.018434229924091106}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:24,012] Trial 58 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 68, 'learning_rate': 0.5829415347136077}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:24,313] Trial 59 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 91, 'learning_rate': 0.003278121151393461}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:24,466] Trial 60 finished with value: 0.8472689075630251 and parameters: {'n_estimators': 45, 'learning_rate': 0.10366329284376985}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:24,590] Trial 61 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 34, 'learning_rate': 0.0013823722273579005}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:24,836] Trial 62 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 79, 'learning_rate': 0.0437144481261109}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:25,020] Trial 63 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 56, 'learning_rate': 0.007773650302387762}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:25,082] Trial 64 finished with value: 0.8355462184873949 and parameters: {'n_estimators': 11, 'learning_rate': 0.24582440689201987}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:25,140] Trial 65 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 12, 'learning_rate': 0.01567878843826971}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:25,339] Trial 66 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 57, 'learning_rate': 0.4958068241684657}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:25,575] Trial 67 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 80, 'learning_rate': 0.0027881266654131345}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:25,698] Trial 68 finished with value: 0.8422408963585435 and parameters: {'n_estimators': 34, 'learning_rate': 0.08816830667755711}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:25,866] Trial 69 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 46, 'learning_rate': 0.0011757432659207114}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:26,159] Trial 70 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 91, 'learning_rate': 0.037180266639144754}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:26,367] Trial 71 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 69, 'learning_rate': 0.006611690262414818}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:26,448] Trial 72 finished with value: 0.8422268907563024 and parameters: {'n_estimators': 23, 'learning_rate': 0.20908000412787187}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:26,561] Trial 73 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 29, 'learning_rate': 0.004293510210083484}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:26,803] Trial 74 finished with value: 0.8489495798319326 and parameters: {'n_estimators': 74, 'learning_rate': 0.13577271421051842}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:27,092] Trial 75 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 97, 'learning_rate': 0.024144182212566402}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:27,259] Trial 76 finished with value: 0.8405602240896359 and parameters: {'n_estimators': 51, 'learning_rate': 0.7635060803383348}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:27,414] Trial 77 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 40, 'learning_rate': 0.010181517217181822}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:27,675] Trial 78 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 86, 'learning_rate': 0.321967844425138}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:27,880] Trial 79 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 63, 'learning_rate': 0.0018105582430271226}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:27,952] Trial 80 finished with value: 0.813781512605042 and parameters: {'n_estimators': 17, 'learning_rate': 0.05725487884358381}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:28,031] Trial 81 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 20, 'learning_rate': 0.0022467900918126454}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:28,239] Trial 82 finished with value: 0.8455742296918768 and parameters: {'n_estimators': 66, 'learning_rate': 0.07104974114426789}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:28,496] Trial 83 finished with value: 0.813781512605042 and parameters: {'n_estimators': 88, 'learning_rate': 0.01263462917654469}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:28,631] Trial 84 finished with value: 0.8388935574229691 and parameters: {'n_estimators': 43, 'learning_rate': 0.39954205589498876}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:28,806] Trial 85 finished with value: 0.8371988795518208 and parameters: {'n_estimators': 54, 'learning_rate': 0.029961427410043647}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:29,105] Trial 86 finished with value: 0.8372408963585434 and parameters: {'n_estimators': 100, 'learning_rate': 0.9474635256553756}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:29,332] Trial 87 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 77, 'learning_rate': 0.005327978945865643}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:29,443] Trial 88 finished with value: 0.8455882352941175 and parameters: {'n_estimators': 32, 'learning_rate': 0.16848548794358392}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:29,545] Trial 89 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.008204696109024995}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:29,769] Trial 90 finished with value: 0.8472829131652663 and parameters: {'n_estimators': 71, 'learning_rate': 0.2594552721404016}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:30,060] Trial 91 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 94, 'learning_rate': 0.0014590242156305613}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:30,225] Trial 92 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 49, 'learning_rate': 0.04613839682733216}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:30,358] Trial 93 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 37, 'learning_rate': 0.003459891660869934}. Best is trial 24 with value: 0.8489635854341737.\n",
      "[I 2025-10-06 13:22:30,619] Trial 94 finished with value: 0.8539915966386555 and parameters: {'n_estimators': 83, 'learning_rate': 0.10941138105771861}. Best is trial 94 with value: 0.8539915966386555.\n",
      "[I 2025-10-06 13:22:30,808] Trial 95 finished with value: 0.8171428571428571 and parameters: {'n_estimators': 60, 'learning_rate': 0.019456400615886365}. Best is trial 94 with value: 0.8539915966386555.\n",
      "[I 2025-10-06 13:22:30,869] Trial 96 finished with value: 0.8388795518207284 and parameters: {'n_estimators': 14, 'learning_rate': 0.6152654101490374}. Best is trial 94 with value: 0.8539915966386555.\n",
      "[I 2025-10-06 13:22:30,927] Trial 97 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 13, 'learning_rate': 0.0025028654311746077}. Best is trial 94 with value: 0.8539915966386555.\n",
      "[I 2025-10-06 13:22:31,116] Trial 98 finished with value: 0.8472549019607843 and parameters: {'n_estimators': 59, 'learning_rate': 0.0791475543941116}. Best is trial 94 with value: 0.8539915966386555.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:22:31,358] A new study created in memory with name: Gradient Boosting Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:31,355] Trial 99 finished with value: 0.813781512605042 and parameters: {'n_estimators': 81, 'learning_rate': 0.014074646633398432}. Best is trial 94 with value: 0.8539915966386555.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using QMCSampler: {'n_estimators': 83, 'learning_rate': 0.10941138105771861}\n",
      "Best accuracy: 0.8540, at trial: 94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625538d32a1f4e3f811152c9977b1308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:31,541] Trial 0 finished with value: 0.7985994397759104 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.7985994397759104.\n",
      "[W 2025-10-06 13:22:31,544] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:31,595] Trial 1 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 10, 'learning_rate': 0.0010000000000000002, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 0 with value: 0.7985994397759104.\n",
      "[W 2025-10-06 13:22:31,597] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:31,887] Trial 2 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.010000000000000004, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.75}. Best is trial 2 with value: 0.8590756302521008.\n",
      "[W 2025-10-06 13:22:31,890] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:32,204] Trial 3 finished with value: 0.8372689075630252 and parameters: {'max_features': None, 'n_estimators': 78, 'learning_rate': 0.003162277660168382, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.875}. Best is trial 2 with value: 0.8590756302521008.\n",
      "[W 2025-10-06 13:22:32,207] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:32,425] Trial 4 finished with value: 0.8355742296918767 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.03162277660168381, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.625}. Best is trial 2 with value: 0.8590756302521008.\n",
      "[W 2025-10-06 13:22:32,429] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:32,658] Trial 5 finished with value: 0.8439635854341738 and parameters: {'max_features': None, 'n_estimators': 44, 'learning_rate': 0.005623413251903492, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.5625}. Best is trial 2 with value: 0.8590756302521008.\n",
      "[W 2025-10-06 13:22:32,661] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:32,825] Trial 6 finished with value: 0.8674789915966385 and parameters: {'max_features': 'log2', 'n_estimators': 89, 'learning_rate': 0.05623413251903493, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.8125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:32,828] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:33,129] Trial 7 finished with value: 0.8069747899159664 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.0017782794100389236, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.9375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:33,132] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:33,235] Trial 8 finished with value: 0.8439495798319326 and parameters: {'max_features': 'sqrt', 'n_estimators': 21, 'learning_rate': 0.01778279410038924, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.6875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:33,238] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:33,391] Trial 9 finished with value: 0.7901960784313726 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.004216965034285825, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.65625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:33,395] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:33,738] Trial 10 finished with value: 0.8406302521008403 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.04216965034285825, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.90625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:33,740] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:34,357] Trial 11 finished with value: 0.803627450980392 and parameters: {'max_features': None, 'n_estimators': 95, 'learning_rate': 0.0013335214321633238, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.78125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:34,360] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:34,505] Trial 12 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.013335214321633242, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.53125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:34,508] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:34,641] Trial 13 finished with value: 0.6945798319327732 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.002371373705661656, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.71875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:34,644] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:35,293] Trial 14 finished with value: 0.8473389355742296 and parameters: {'max_features': None, 'n_estimators': 83, 'learning_rate': 0.023713737056616564, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.96875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:35,296] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:35,441] Trial 15 finished with value: 0.850658263305322 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.007498942093324564, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.84375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:35,445] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:35,526] Trial 16 finished with value: 0.8590896358543418 and parameters: {'max_features': 'log2', 'n_estimators': 15, 'learning_rate': 0.07498942093324566, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.59375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:35,528] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:35,663] Trial 17 finished with value: 0.8137535014005601 and parameters: {'max_features': None, 'n_estimators': 18, 'learning_rate': 0.008659643233600654, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.984375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:35,667] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:35,995] Trial 18 finished with value: 0.8590896358543418 and parameters: {'max_features': None, 'n_estimators': 64, 'learning_rate': 0.08659643233600657, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.734375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:35,995] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:36,242] Trial 19 finished with value: 0.8338795518207283 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.0027384196342643626, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.609375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:36,243] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:36,552] Trial 20 finished with value: 0.8523669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.027384196342643632, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.859375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:36,556] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:37,019] Trial 21 finished with value: 0.6659663865546218 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.0015399265260594922, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.921875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:37,022] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:37,289] Trial 22 finished with value: 0.867450980392157 and parameters: {'max_features': 'log2', 'n_estimators': 98, 'learning_rate': 0.015399265260594926, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.671875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:37,293] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:37,484] Trial 23 finished with value: 0.8573669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.004869675251658635, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.546875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:37,488] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:37,569] Trial 24 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 29, 'learning_rate': 0.04869675251658634, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.796875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:37,569] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:37,672] Trial 25 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 24, 'learning_rate': 0.0020535250264571477, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.828125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:37,675] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:37,851] Trial 26 finished with value: 0.8523389355742298 and parameters: {'max_features': None, 'n_estimators': 69, 'learning_rate': 0.020535250264571474, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.578125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:37,854] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:38,545] Trial 27 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.0064938163157621165, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'subsample': 0.703125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:38,549] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:38,753] Trial 28 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.06493816315762117, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.953125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:38,756] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:38,869] Trial 29 finished with value: 0.8019607843137255 and parameters: {'max_features': 'log2', 'n_estimators': 35, 'learning_rate': 0.0036517412725483775, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.765625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:38,872] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:39,256] Trial 30 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.03651741272548378, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.515625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:39,259] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:39,519] Trial 31 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.0011547819846894588, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.640625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:39,523] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:39,604] Trial 32 finished with value: 0.7952380952380953 and parameters: {'max_features': None, 'n_estimators': 12, 'learning_rate': 0.01154781984689459, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.890625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:39,606] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:39,751] Trial 33 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 14, 'learning_rate': 0.003398208328942561, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.9609375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:39,754] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:39,940] Trial 34 finished with value: 0.8641036414565825 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.03398208328942562, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.7109375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:39,943] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:40,231] Trial 35 finished with value: 0.6761064425770309 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.0010746078283213173, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.5859375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:40,234] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:40,431] Trial 36 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 37, 'learning_rate': 0.010746078283213186, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.8359375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:40,435] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:40,548] Trial 37 finished with value: 0.694593837535014 and parameters: {'max_features': 'log2', 'n_estimators': 48, 'learning_rate': 0.001910952974970441, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8984375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:40,551] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:40,881] Trial 38 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 93, 'learning_rate': 0.019109529749704413, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.6484375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:40,883] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:41,132] Trial 39 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 71, 'learning_rate': 0.006042963902381328, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.5234375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:41,135] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:41,341] Trial 40 finished with value: 0.8490056022408965 and parameters: {'max_features': 'log2', 'n_estimators': 25, 'learning_rate': 0.06042963902381334, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.7734375}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:41,344] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:41,467] Trial 41 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 31, 'learning_rate': 0.0014330125702369636, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.8671875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:41,471] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:42,018] Trial 42 finished with value: 0.8456442577030812 and parameters: {'max_features': None, 'n_estimators': 76, 'learning_rate': 0.014330125702369625, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.6171875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:42,018] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:42,243] Trial 43 finished with value: 0.8456302521008403 and parameters: {'max_features': None, 'n_estimators': 99, 'learning_rate': 0.004531583637600819, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7421875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:42,245] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:42,460] Trial 44 finished with value: 0.8540616246498601 and parameters: {'max_features': 'log2', 'n_estimators': 54, 'learning_rate': 0.045315836376008195, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.9921875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:42,460] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:42,657] Trial 45 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 42, 'learning_rate': 0.008058421877614822, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8046875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:42,660] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:42,988] Trial 46 finished with value: 0.8439495798319328 and parameters: {'max_features': None, 'n_estimators': 88, 'learning_rate': 0.08058421877614824, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.5546875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:42,988] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:43,441] Trial 47 finished with value: 0.8372268907563024 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.0025482967479793462, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.6796875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:43,442] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:43,514] Trial 48 finished with value: 0.8456302521008402 and parameters: {'max_features': 'sqrt', 'n_estimators': 19, 'learning_rate': 0.02548296747979348, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.9296875}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:43,516] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:43,618] Trial 49 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.0029427271762092824, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.5390625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:43,621] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:43,815] Trial 50 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.02942727176209283, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.7890625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:43,818] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:44,166] Trial 51 finished with value: 0.8657703081232494 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.009305720409296989, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.9140625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:44,168] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:44,260] Trial 52 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.09305720409296998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.6640625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:44,262] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:44,499] Trial 53 finished with value: 0.8473109243697478 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.005232991146814949, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.6015625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:44,503] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:45,129] Trial 54 finished with value: 0.8490196078431375 and parameters: {'max_features': None, 'n_estimators': 96, 'learning_rate': 0.052329911468149505, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.8515625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:45,130] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:45,347] Trial 55 finished with value: 0.8019467787114845 and parameters: {'max_features': 'log2', 'n_estimators': 73, 'learning_rate': 0.0016548170999431814, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.9765625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:45,347] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:45,584] Trial 56 finished with value: 0.8339075630252101 and parameters: {'max_features': None, 'n_estimators': 28, 'learning_rate': 0.01654817099943183, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7265625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:45,585] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:45,668] Trial 57 finished with value: 0.8053221288515406 and parameters: {'max_features': 'log2', 'n_estimators': 22, 'learning_rate': 0.006978305848598664, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.6328125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:45,670] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:46,114] Trial 58 finished with value: 0.8540616246498599 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.06978305848598666, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.8828125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:46,116] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:46,526] Trial 59 finished with value: 0.8472969187675069 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.002206734069084591, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7578125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:46,528] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:46,703] Trial 60 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 45, 'learning_rate': 0.022067340690845913, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.5078125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:46,706] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:46,880] Trial 61 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 34, 'learning_rate': 0.0012409377607517198, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6953125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:46,883] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:47,056] Trial 62 finished with value: 0.8590476190476192 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.0124093776075172, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9453125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:47,059] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:47,446] Trial 63 finished with value: 0.8305182072829131 and parameters: {'max_features': None, 'n_estimators': 56, 'learning_rate': 0.003924189758484535, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.8203125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:47,449] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:47,510] Trial 64 finished with value: 0.8439355742296918 and parameters: {'max_features': 'sqrt', 'n_estimators': 11, 'learning_rate': 0.03924189758484538, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9, 'subsample': 0.5703125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:47,512] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:47,602] Trial 65 finished with value: 0.6324509803921569 and parameters: {'max_features': None, 'n_estimators': 12, 'learning_rate': 0.00626433536656886, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.72265625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:47,606] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:47,842] Trial 66 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.06264335366568861, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.97265625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:47,843] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:48,268] Trial 67 finished with value: 0.835532212885154 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.001980956778550339, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.84765625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:48,271] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:48,361] Trial 68 finished with value: 0.8573669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 34, 'learning_rate': 0.019809567785503402, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.59765625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:48,361] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:48,538] Trial 69 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.001113973859994803, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.66015625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:48,541] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:49,193] Trial 70 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 91, 'learning_rate': 0.011139738599948034, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.91015625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:49,195] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:49,390] Trial 71 finished with value: 0.8422689075630251 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.0035226946514731027, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.78515625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:49,394] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:49,495] Trial 72 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 23, 'learning_rate': 0.03522694651473104, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.53515625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:49,498] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:49,588] Trial 73 finished with value: 0.5821288515406162 and parameters: {'max_features': 'log2', 'n_estimators': 29, 'learning_rate': 0.0026416483203860943, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.56640625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:49,588] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:49,902] Trial 74 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.026416483203860936, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.81640625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:49,905] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:50,257] Trial 75 finished with value: 0.8624089635854342 and parameters: {'max_features': 'log2', 'n_estimators': 97, 'learning_rate': 0.008353625469578265, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.94140625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:50,260] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:50,531] Trial 76 finished with value: 0.8523809523809524 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.08353625469578266, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.69140625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:50,534] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:50,709] Trial 77 finished with value: 0.823781512605042 and parameters: {'max_features': 'log2', 'n_estimators': 40, 'learning_rate': 0.004697588816706496, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.50390625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:50,712] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:50,878] Trial 78 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 86, 'learning_rate': 0.04697588816706495, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.75390625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:50,880] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:51,276] Trial 79 finished with value: 0.754985994397759 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.0014855080171727755, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.87890625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:51,279] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:51,359] Trial 80 finished with value: 0.8456162464985993 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.01485508017172776, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.62890625}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:51,361] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:51,453] Trial 81 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 20, 'learning_rate': 0.0017154378963428801, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.76953125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:51,455] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:51,643] Trial 82 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.017154378963428803, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.51953125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:51,646] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:52,494] Trial 83 finished with value: 0.8523249299719888 and parameters: {'max_features': 'log2', 'n_estimators': 88, 'learning_rate': 0.005424690937011328, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.64453125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:52,498] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:52,735] Trial 84 finished with value: 0.8557142857142856 and parameters: {'max_features': None, 'n_estimators': 43, 'learning_rate': 0.05424690937011329, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.89453125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:52,738] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:52,872] Trial 85 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.009646616199111998, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.83203125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:52,875] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:53,532] Trial 86 finished with value: 0.8523809523809526 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.09646616199112, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.58203125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:53,536] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:53,826] Trial 87 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.003050527890267026, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.70703125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:53,828] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:54,036] Trial 88 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.030505278902670276, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.95703125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:54,040] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:54,165] Trial 89 finished with value: 0.780126050420168 and parameters: {'max_features': 'sqrt', 'n_estimators': 26, 'learning_rate': 0.0040679443210830495, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.92578125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:54,168] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:54,439] Trial 90 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.04067944321083049, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.67578125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:54,442] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:54,650] Trial 91 finished with value: 0.775140056022409 and parameters: {'max_features': 'log2', 'n_estimators': 94, 'learning_rate': 0.0012863969449369746, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.55078125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:54,653] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:54,977] Trial 92 finished with value: 0.8406162464985993 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.01286396944936975, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3, 'subsample': 0.80078125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:54,980] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:55,301] Trial 93 finished with value: 0.7583613445378151 and parameters: {'max_features': None, 'n_estimators': 37, 'learning_rate': 0.0022875732003183966, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.98828125}. Best is trial 6 with value: 0.8674789915966385.\n",
      "[W 2025-10-06 13:22:55,304] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:55,648] Trial 94 finished with value: 0.8691456582633054 and parameters: {'max_features': 'log2', 'n_estimators': 83, 'learning_rate': 0.02287573200318397, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.73828125}. Best is trial 94 with value: 0.8691456582633054.\n",
      "[W 2025-10-06 13:22:55,653] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:55,892] Trial 95 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 60, 'learning_rate': 0.007233941627366754, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.61328125}. Best is trial 94 with value: 0.8691456582633054.\n",
      "[W 2025-10-06 13:22:55,895] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:55,965] Trial 96 finished with value: 0.8372268907563024 and parameters: {'max_features': None, 'n_estimators': 14, 'learning_rate': 0.0723394162736675, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.86328125}. Best is trial 94 with value: 0.8691456582633054.\n",
      "[W 2025-10-06 13:22:55,967] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:56,050] Trial 97 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 13, 'learning_rate': 0.0018434229924091112, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.80859375}. Best is trial 94 with value: 0.8691456582633054.\n",
      "[W 2025-10-06 13:22:56,054] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:56,439] Trial 98 finished with value: 0.8456302521008402 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.018434229924091116, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1, 'subsample': 0.55859375}. Best is trial 94 with value: 0.8691456582633054.\n",
      "[W 2025-10-06 13:22:56,443] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:22:56,701] Trial 99 finished with value: 0.8489775910364147 and parameters: {'max_features': None, 'n_estimators': 81, 'learning_rate': 0.005829415347136074, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.68359375}. Best is trial 94 with value: 0.8691456582633054.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using QMCSampler: {'max_features': 'log2', 'n_estimators': 83, 'learning_rate': 0.02287573200318397, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.73828125}\n",
      "Best accuracy: 0.8691, at trial: 94\n",
      "QMC Base Models Training Time: 83.02 seconds\n"
     ]
    }
   ],
   "source": [
    "qmc_base_models_training_start = time.time()\n",
    "\n",
    "# QMC Hyperparameter Tuning with Cross Validation\n",
    "qmc_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "qmc_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "qmc_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "qmc_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "qmc_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "qmc_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "qmc_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "# Model Fitting with best parameters\n",
    "qmc_logistic_regression.fit(X_train, y_train)\n",
    "qmc_decision_tree.fit(X_train, y_train)\n",
    "qmc_random_forest.fit(X_train, y_train)\n",
    "qmc_knn.fit(X_train, y_train)\n",
    "qmc_svc.fit(X_train, y_train)\n",
    "qmc_adaboost.fit(X_train, y_train)\n",
    "qmc_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "qmc_base_models_training_end = time.time()\n",
    "\n",
    "# Time taken for QMC base models training\n",
    "qmc_base_models_training_time = qmc_base_models_training_end - qmc_base_models_training_start\n",
    "print(f'QMC Base Models Training Time: {qmc_base_models_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5 Save Every Best Model Config for each Tuning Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Models Storage for all sampler types\n",
    "base_models = {\n",
    "    'TPE': {\n",
    "        'Logistic Regression': tpe_logistic_regression,\n",
    "        'Decision Tree': tpe_decision_tree,\n",
    "        'Random Forest': tpe_random_forest,\n",
    "        'K-Nearest Neighbors': tpe_knn,\n",
    "        'Support Vector Machine': tpe_svc,\n",
    "        'AdaBoost': tpe_adaboost,\n",
    "        'Gradient Boosting': tpe_gradient_boosting\n",
    "    },\n",
    "    'GP': {\n",
    "        'Logistic Regression': gp_logistic_regression,\n",
    "        'Decision Tree': gp_decision_tree,\n",
    "        'Random Forest': gp_random_forest,\n",
    "        'K-Nearest Neighbors': gp_knn,\n",
    "        'Support Vector Machine': gp_svc,\n",
    "        'AdaBoost': gp_adaboost,\n",
    "        'Gradient Boosting': gp_gradient_boosting\n",
    "    },\n",
    "    'CMA-ES': {\n",
    "        'Logistic Regression': cmaes_logistic_regression,\n",
    "        'Decision Tree': cmaes_decision_tree,\n",
    "        'Random Forest': cmaes_random_forest,\n",
    "        'K-Nearest Neighbors': cmaes_knn,\n",
    "        'Support Vector Machine': cmaes_svc,\n",
    "        'AdaBoost': cmaes_adaboost,\n",
    "        'Gradient Boosting': cmaes_gradient_boosting\n",
    "    },\n",
    "    'QMC': {\n",
    "        'Logistic Regression': qmc_logistic_regression,\n",
    "        'Decision Tree': qmc_decision_tree,\n",
    "        'Random Forest': qmc_random_forest,\n",
    "        'K-Nearest Neighbors': qmc_knn,\n",
    "        'Support Vector Machine': qmc_svc,\n",
    "        'AdaBoost': qmc_adaboost,\n",
    "        'Gradient Boosting': qmc_gradient_boosting\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Meta Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters to be tuned are:\n",
    "- Selection of the number and type of base models used\n",
    "- Number of layers in the neural network: 1 - 5\n",
    "- Number of neurons per layer: 10 - 100\n",
    "- Learning rate behavior: Constant or Adaptive\n",
    "- Learning rate value: 0.0001 - 0.01\n",
    "- L2 Regularization value: 0.0001 - 0.01\n",
    "\n",
    "Unchanged Preset hyperparameters:\n",
    "- Activation function: ReLU\n",
    "- Optimizer (Solver): Adam\n",
    "- Epochs (Max Iter): 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:57,425] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (TPESampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8301d05dc5545e7b2d8f204b03f1cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:22:59,141] Trial 0 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.9066666666666666.\n",
      "[I 2025-10-06 13:23:01,375] Trial 1 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 37, 'n_neurons_2': 18, 'n_neurons_3': 72, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112}. Best is trial 1 with value: 0.9133333333333333.\n",
      "[I 2025-10-06 13:23:02,561] Trial 2 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:23:04,469] Trial 3 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00013400367243354819, 'alpha': 0.0004187594718900631}. Best is trial 1 with value: 0.9133333333333333.\n",
      "[I 2025-10-06 13:23:06,056] Trial 4 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0010402587615883842, 'alpha': 0.006533305220227739}. Best is trial 1 with value: 0.9133333333333333.\n",
      "[I 2025-10-06 13:23:08,423] Trial 5 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007148510793512986, 'alpha': 0.00432543242796456}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:10,490] Trial 6 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.001656260589333597, 'alpha': 0.0010124137770478635}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:10,955] Trial 7 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 18, 'n_neurons_2': 86, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0015197980620034217, 'alpha': 0.0022653156413948872}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:10,958] Trial 8 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:13,053] Trial 9 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 17, 'n_neurons_2': 24, 'n_neurons_3': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.00015956700210656633, 'alpha': 0.002123261760236048}. Best is trial 5 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:23:15,871] Trial 10 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 100, 'n_neurons_2': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00037534149445827934, 'alpha': 0.009589912729074808}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:17,592] Trial 11 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 93, 'n_neurons_1': 62, 'n_neurons_2': 14, 'n_neurons_3': 79, 'n_neurons_4': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.008607419445086114, 'alpha': 0.003912571148565144}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:19,759] Trial 12 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 76, 'n_neurons_1': 65, 'n_neurons_2': 40, 'n_neurons_3': 13, 'n_neurons_4': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00025768484269632976, 'alpha': 0.0038696086878070445}. Best is trial 5 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:23:22,139] Trial 13 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 82, 'n_neurons_1': 46, 'n_neurons_2': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045286696635910966, 'alpha': 0.001300981293606397}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:23,680] Trial 14 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 82, 'n_neurons_1': 82, 'n_neurons_2': 13, 'n_neurons_3': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002835763224668411, 'alpha': 0.005150337427356152}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:25,787] Trial 15 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 64, 'n_neurons_1': 79, 'n_neurons_2': 71, 'n_neurons_3': 48, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002879641540267691, 'alpha': 0.00012209958612672113}. Best is trial 5 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:23:28,207] Trial 16 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 80, 'n_neurons_2': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0034110846211399424, 'alpha': 0.0032153481775151396}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:30,059] Trial 17 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 86, 'n_neurons_1': 99, 'n_neurons_2': 34, 'n_neurons_3': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007064602049678133, 'alpha': 0.009237126438812622}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:31,608] Trial 18 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 100, 'n_neurons_1': 74, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009222415248526744, 'alpha': 0.001691553510586203}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:33,207] Trial 19 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 72, 'n_neurons_1': 89, 'n_neurons_2': 11, 'n_neurons_3': 67, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0021646207659656793, 'alpha': 0.005451108276053914}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:34,975] Trial 20 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 90, 'n_neurons_1': 65, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004629755269793791, 'alpha': 0.0007204715634751574}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:37,168] Trial 21 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 80, 'n_neurons_1': 33, 'n_neurons_2': 21, 'n_neurons_3': 66, 'n_neurons_4': 94, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00020075401739066018, 'alpha': 0.0058458636408358884}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:39,608] Trial 22 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 47, 'n_neurons_2': 26, 'n_neurons_3': 63, 'n_neurons_4': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011238625428458185, 'alpha': 0.002814350696410409}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:41,594] Trial 23 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 75, 'n_neurons_1': 29, 'n_neurons_2': 10, 'n_neurons_3': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003795672686102916, 'alpha': 0.00499044055325719}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:43,805] Trial 24 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 64, 'n_neurons_1': 53, 'n_neurons_2': 36, 'n_neurons_3': 79, 'n_neurons_4': 19, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0011026644317860671, 'alpha': 0.007732440896831594}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:45,836] Trial 25 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 48, 'n_neurons_1': 89, 'n_neurons_2': 22, 'n_neurons_3': 51, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000577488920097972, 'alpha': 0.004220628216791456}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:47,987] Trial 26 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 72, 'n_neurons_2': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00025671211795864234, 'alpha': 0.00023225833895540828}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:49,519] Trial 27 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 94, 'n_neurons_1': 44, 'n_neurons_2': 64, 'n_neurons_3': 81, 'n_neurons_4': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006431700824884849, 'alpha': 0.0015310816824702334}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:51,358] Trial 28 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 25, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014893163374976415, 'alpha': 0.0026777892056410895}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:53,234] Trial 29 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 68, 'n_neurons_1': 93, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014782724366955034, 'alpha': 0.0025359454895011436}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:54,798] Trial 30 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 57, 'n_neurons_1': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008136782936034671, 'alpha': 0.0010648155154955375}. Best is trial 5 with value: 0.92.\n",
      "[I 2025-10-06 13:23:56,772] Trial 31 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 78, 'n_neurons_1': 13, 'n_neurons_2': 17, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002333004997873897, 'alpha': 0.0033635345142886885}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:23:58,404] Trial 32 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 74, 'n_neurons_1': 10, 'n_neurons_2': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0023114510315342778, 'alpha': 0.003254566929696062}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:24:00,147] Trial 33 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 77, 'n_neurons_1': 13, 'n_neurons_2': 98, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0019380508883718327, 'alpha': 0.001849385294436153}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:24:01,879] Trial 34 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 90, 'n_neurons_1': 11, 'n_neurons_2': 89, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003747692198941229, 'alpha': 0.0018560928334551824}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:24:02,876] Trial 35 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 81, 'n_neurons_1': 19, 'n_neurons_2': 79, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002195767018843578, 'alpha': 0.004536874537285731}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:24:04,533] Trial 36 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 63, 'n_neurons_1': 83, 'n_neurons_2': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.00531960952887234, 'alpha': 0.0007091325328436792}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:24:04,826] Trial 37 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 27, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010735008630000176, 'alpha': 0.007245524818342599}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:24:06,562] Trial 38 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 78, 'n_neurons_1': 40, 'n_neurons_2': 60, 'learning_rate': 'constant', 'learning_rate_init': 0.003097714472418153, 'alpha': 0.0033322658960528435}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:24:07,075] Trial 39 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 88, 'n_neurons_1': 94, 'n_neurons_2': 42, 'n_neurons_3': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.002545498693566785, 'alpha': 0.0012935943306626378}. Best is trial 31 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:24:09,008] Trial 40 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 52, 'n_neurons_1': 15, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001244030248083268, 'alpha': 0.006114818319251142}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:10,780] Trial 41 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 47, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017153616608685577, 'alpha': 0.006409933221587155}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:12,544] Trial 42 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 32, 'n_neurons_1': 15, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012462637174718704, 'alpha': 0.0021064452333941558}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:14,386] Trial 43 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 54, 'n_neurons_1': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008489958020444834, 'alpha': 0.005054366991534436}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:16,433] Trial 44 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 52, 'n_neurons_1': 14, 'n_neurons_2': 17, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006091558504338245, 'alpha': 0.008363196872626474}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:18,388] Trial 45 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 39, 'n_neurons_1': 14, 'n_neurons_2': 18, 'learning_rate': 'constant', 'learning_rate_init': 0.0005251166062230713, 'alpha': 0.008243762672675759}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:20,945] Trial 46 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 52, 'n_neurons_1': 33, 'n_neurons_2': 48, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006374525543864157, 'alpha': 0.009714835484852356}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:22,912] Trial 47 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 59, 'n_neurons_1': 19, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0019203833564832146, 'alpha': 0.0037645714683383594}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:24,759] Trial 48 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009326585416924029, 'alpha': 0.006462120682467643}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:26,504] Trial 49 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0018700423601720562, 'alpha': 0.0035050045620961725}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:28,599] Trial 50 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 51, 'n_neurons_1': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013549642272442527, 'alpha': 0.002278352244167462}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:30,741] Trial 51 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 50, 'n_neurons_1': 27, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012828882175923981, 'alpha': 0.0021772483262863865}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:32,653] Trial 52 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 38, 'n_neurons_1': 27, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012564070694569536, 'alpha': 0.0020961317084951846}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:34,689] Trial 53 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 36, 'n_neurons_1': 28, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013064925295639838, 'alpha': 0.0022376846221938466}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:36,418] Trial 54 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 11, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012010083856045185, 'alpha': 0.001400656737514613}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:38,279] Trial 55 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 41, 'n_neurons_1': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015872630985318897, 'alpha': 0.0028066926031613845}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:40,386] Trial 56 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 42, 'n_neurons_1': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014127438694049536, 'alpha': 0.001150028299210954}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:42,097] Trial 57 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 19, 'n_neurons_1': 28, 'learning_rate': 'constant', 'learning_rate_init': 0.0009429105470782446, 'alpha': 0.0008396871688368404}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:44,242] Trial 58 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 35, 'n_neurons_1': 39, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0018964479139751665, 'alpha': 0.0024594616860633706}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:46,201] Trial 59 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 50, 'n_neurons_1': 18, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001681992719712214, 'alpha': 0.002862532650617427}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:48,024] Trial 60 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007712602721244435, 'alpha': 0.0040573172175463815}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:50,025] Trial 61 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 42, 'n_neurons_1': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013645951578959068, 'alpha': 0.0004965221119103132}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:24:52,118] Trial 62 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 60, 'n_neurons_1': 25, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001041583763908605, 'alpha': 0.0020126060602141753}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:54,052] Trial 63 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 30, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015641437808038773, 'alpha': 0.001221250703747963}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:56,123] Trial 64 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 40, 'n_neurons_1': 35, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014141811798517034, 'alpha': 0.0010621908750192406}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:24:58,083] Trial 65 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 50, 'n_neurons_1': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009546692578447761, 'alpha': 0.0017893088512673223}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:00,023] Trial 66 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 36, 'n_neurons_1': 28, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012120524397297488, 'alpha': 0.0016268018309884807}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:01,823] Trial 67 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002036774938831415, 'alpha': 0.0029985299212633857}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:03,566] Trial 68 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 46, 'n_neurons_1': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002578213963347725, 'alpha': 0.0008887367969978619}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:05,500] Trial 69 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 39, 'n_neurons_1': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017213978208952825, 'alpha': 0.0002989396594583551}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:07,582] Trial 70 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 62, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007054921370438998, 'alpha': 0.0024115864877722387}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:25:09,589] Trial 71 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 45, 'n_neurons_1': 37, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013179248087097164, 'alpha': 0.0005079555705605645}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:25:11,570] Trial 72 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 40, 'n_neurons_1': 25, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014923454726986874, 'alpha': 0.00012958176588257522}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:13,547] Trial 73 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 42, 'n_neurons_1': 35, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012031648484548238, 'alpha': 0.0005959288021788999}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:15,559] Trial 74 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 33, 'n_neurons_1': 21, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010639421947656116, 'alpha': 0.0003308266985437432}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:17,577] Trial 75 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 49, 'n_neurons_1': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014253502924213264, 'alpha': 0.0036757744152030236}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:19,389] Trial 76 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 57, 'n_neurons_1': 17, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0036454676086074777, 'alpha': 0.00017223089846152254}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:21,058] Trial 77 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 53, 'n_neurons_1': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.0008596875748109178, 'alpha': 0.00438835384247387}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:25:22,951] Trial 78 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017114737396336165, 'alpha': 0.001484090301525844}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:25:24,968] Trial 79 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 22, 'n_neurons_1': 27, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0028147265454339064, 'alpha': 0.00044835082589714736}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:26,832] Trial 80 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 47, 'n_neurons_1': 23, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002041481991252536, 'alpha': 0.0011503875299547514}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:28,793] Trial 81 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 61, 'n_neurons_1': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001079401834616133, 'alpha': 0.0020618585769907292}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:30,756] Trial 82 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 60, 'n_neurons_1': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0011189655832681813, 'alpha': 0.001982007102838997}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:25:32,800] Trial 83 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 66, 'n_neurons_1': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013078822003154667, 'alpha': 0.0025902546614367263}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:34,746] Trial 84 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 57, 'n_neurons_1': 25, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009624768540356744, 'alpha': 0.001704930413301062}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:36,666] Trial 85 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 51, 'n_neurons_1': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015605383506797949, 'alpha': 0.002214669403330572}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:38,613] Trial 86 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 66, 'n_neurons_1': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0023745903221680385, 'alpha': 0.0029057932893041785}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:40,360] Trial 87 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017756234652242678, 'alpha': 0.0059047733296454}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:42,123] Trial 88 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 48, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0008554533093598889, 'alpha': 0.0013654376817380978}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:44,018] Trial 89 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 38, 'n_neurons_1': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007026449062853758, 'alpha': 0.0009145498475625444}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:25:46,086] Trial 90 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013279239813153776, 'alpha': 0.004859954630614169}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:25:48,086] Trial 91 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 28, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015719346990100151, 'alpha': 0.0012237527450592613}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:49,906] Trial 92 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 31, 'n_neurons_1': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001135893121757121, 'alpha': 0.0006478047812715195}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:51,707] Trial 93 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 37, 'n_neurons_1': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014441489719225196, 'alpha': 0.0015646849132143412}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:25:53,647] Trial 94 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 25, 'n_neurons_1': 19, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010307167998605071, 'alpha': 0.0007834959532655303}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:55,433] Trial 95 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 30, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0021507832212143596, 'alpha': 0.0018666801991830003}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:57,334] Trial 96 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 35, 'n_neurons_1': 27, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0019171978772814023, 'alpha': 0.0038487321373151715}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:25:59,222] Trial 97 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 42, 'n_neurons_1': 11, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015839419514422255, 'alpha': 0.0031390064364748243}. Best is trial 40 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:26:01,485] Trial 98 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 33, 'n_neurons_1': 23, 'n_neurons_2': 84, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013438897931327218, 'alpha': 0.0009732323501083444}. Best is trial 40 with value: 0.9333333333333333.\n",
      "[I 2025-10-06 13:26:03,296] Trial 99 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012031834276669733, 'alpha': 0.0026745911980157063}. Best is trial 40 with value: 0.9333333333333333.\n",
      "\n",
      "Selected Base Models for Stacking using TPESampler:\n",
      "- Decision Tree\n",
      "- AdaBoost\n",
      "- Gradient Boosting\n",
      "Best Hyperparameters for Meta Model (MLP) using TPESampler: {'learning_rate': 'adaptive', 'learning_rate_init': 0.001244030248083268, 'alpha': 0.006114818319251142, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (52, 15), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9333, at trial: 40\n",
      "TPE base models training time: 85.58 seconds\n",
      "TPE SEl-NNML Training Time: 187.73 seconds\n",
      "Total TPE Training Time (Base + Meta): 273.31 seconds\n"
     ]
    }
   ],
   "source": [
    "tpe_meta_model_training_start = time.time()\n",
    "\n",
    "# Meta Model Tuning and Final Stacking Model Fitting\n",
    "tpe_sel_nnml = meta_model_tuning(base_models['TPE'], X_train, y_train, X_test, y_test, sampler='TPESampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "tpe_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "tpe_meta_model_training_end = time.time()\n",
    "\n",
    "# Time taken for TPE SEl-NNML training\n",
    "tpe_meta_model_training_time = tpe_meta_model_training_end - tpe_meta_model_training_start\n",
    "print(f'TPE base models training time: {tpe_base_models_training_time:.2f} seconds')\n",
    "print(f'TPE SEl-NNML Training Time: {tpe_meta_model_training_time:.2f} seconds')\n",
    "print(f'Total TPE Training Time (Base + Meta): {tpe_base_models_training_time + tpe_meta_model_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:178: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:26:05,202] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (GPSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a316bec8c24c0dbc78d4ae98c9a6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:26:06,689] Trial 0 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.9133333333333333.\n",
      "[I 2025-10-06 13:26:08,450] Trial 1 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 37, 'n_neurons_2': 18, 'n_neurons_3': 72, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112}. Best is trial 0 with value: 0.9133333333333333.\n",
      "[I 2025-10-06 13:26:09,755] Trial 2 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:26:11,158] Trial 3 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00013400367243354819, 'alpha': 0.0004187594718900631}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-10-06 13:26:12,526] Trial 4 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0010402587615883842, 'alpha': 0.006533305220227739}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-10-06 13:26:14,373] Trial 5 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007148510793512986, 'alpha': 0.00432543242796456}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-10-06 13:26:16,124] Trial 6 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.001656260589333597, 'alpha': 0.0010124137770478635}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-10-06 13:26:16,604] Trial 7 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 18, 'n_neurons_2': 86, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0015197980620034217, 'alpha': 0.0022653156413948872}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-10-06 13:26:16,608] Trial 8 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:26:18,817] Trial 9 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 17, 'n_neurons_2': 24, 'n_neurons_3': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.00015956700210656633, 'alpha': 0.002123261760236048}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:18,952] The parameter `n_layers` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:18,953] The parameter `n_neurons_0` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:18,954] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:18,955] The parameter `learning_rate_init` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:18,956] The parameter `alpha` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:20,217] Trial 10 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0020133650202440474, 'alpha': 0.0002808915139812627}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:20,364] The parameter `n_layers` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:20,366] The parameter `n_neurons_0` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:20,367] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:20,367] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:20,368] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:20,369] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:20,369] The parameter `learning_rate_init` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:20,370] The parameter `alpha` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:22,313] Trial 11 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 31, 'n_neurons_1': 39, 'n_neurons_2': 77, 'n_neurons_3': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.0013696739838480055, 'alpha': 0.00015393931002140855}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:22,425] The parameter `n_layers` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:22,426] The parameter `n_neurons_0` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:22,427] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:22,428] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:22,428] The parameter `learning_rate_init` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:22,429] The parameter `alpha` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:23,891] Trial 12 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 34, 'n_neurons_1': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.0060826539606401225, 'alpha': 0.0018292676411745708}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:23,994] The parameter `n_layers` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:23,994] The parameter `n_neurons_0` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:23,994] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:23,997] The parameter `n_neurons_2` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:23,997] The parameter `n_neurons_3` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:23,997] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:23,997] The parameter `learning_rate_init` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:23,999] The parameter `alpha` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:26,022] Trial 13 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 55, 'n_neurons_1': 62, 'n_neurons_2': 54, 'n_neurons_3': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0001118489555166451, 'alpha': 0.001954090133022007}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:26,128] The parameter `n_layers` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:26,129] The parameter `n_neurons_0` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:26,130] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:26,130] The parameter `learning_rate_init` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:26,131] The parameter `alpha` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:27,555] Trial 14 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.000549942648034561, 'alpha': 0.00010737748632897979}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:27,648] The parameter `n_layers` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:27,649] The parameter `n_neurons_0` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:27,651] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:27,652] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:27,653] The parameter `n_neurons_3` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:27,653] The parameter `n_neurons_4` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:27,654] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:27,655] The parameter `learning_rate_init` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:27,655] The parameter `alpha` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:29,756] Trial 15 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 48, 'n_neurons_1': 97, 'n_neurons_2': 97, 'n_neurons_3': 87, 'n_neurons_4': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004303720019143252, 'alpha': 0.00021826570038901196}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:29,851] The parameter `n_layers` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:29,852] The parameter `n_neurons_0` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:29,853] The parameter `n_neurons_1` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:29,854] The parameter `n_neurons_2` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:29,854] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:29,855] The parameter `learning_rate_init` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:29,856] The parameter `alpha` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:31,188] Trial 16 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 95, 'n_neurons_1': 73, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009552294429449873, 'alpha': 0.00019061980918553997}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:31,279] The parameter `n_layers` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:31,280] The parameter `n_neurons_0` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:31,281] The parameter `n_neurons_1` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:31,282] The parameter `n_neurons_2` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:31,283] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:31,283] The parameter `learning_rate_init` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:31,284] The parameter `alpha` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:32,085] Trial 17 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 77, 'n_neurons_2': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.0003865304288032154, 'alpha': 0.004156447611486069}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:32,197] The parameter `n_layers` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:32,199] The parameter `n_neurons_0` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:32,200] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:32,201] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:32,201] The parameter `n_neurons_3` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:32,203] The parameter `n_neurons_4` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:32,203] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:32,203] The parameter `learning_rate_init` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:32,205] The parameter `alpha` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:33,624] Trial 18 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 93, 'n_neurons_2': 56, 'n_neurons_3': 55, 'n_neurons_4': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0039046790191830895, 'alpha': 0.0060257440920984265}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:33,728] The parameter `n_layers` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:33,729] The parameter `n_neurons_0` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:33,730] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:33,731] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:33,732] The parameter `learning_rate_init` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:33,732] The parameter `alpha` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:26:35,047] Trial 19 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 18, 'learning_rate': 'constant', 'learning_rate_init': 0.0008534852819566894, 'alpha': 0.0012169963323841}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:35,137] The parameter `n_layers` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:35,138] The parameter `n_neurons_0` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:35,139] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:35,140] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:35,140] The parameter `learning_rate_init` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:35,141] The parameter `alpha` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:26:36,826] Trial 20 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 63, 'n_neurons_1': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005252684100000482, 'alpha': 0.00017952338368491265}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:36,921] The parameter `n_layers` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:36,921] The parameter `n_neurons_0` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:36,923] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:36,923] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:36,924] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:36,924] The parameter `learning_rate_init` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:36,925] The parameter `alpha` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:26:38,935] Trial 21 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 80, 'n_neurons_1': 29, 'n_neurons_2': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0011553385460530909, 'alpha': 0.0012057860169848358}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:39,036] The parameter `n_layers` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:39,037] The parameter `n_neurons_0` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:39,038] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:39,039] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:39,040] The parameter `n_neurons_3` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:39,040] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:39,041] The parameter `learning_rate_init` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:39,042] The parameter `alpha` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:41,238] Trial 22 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 76, 'n_neurons_1': 98, 'n_neurons_2': 56, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0007549928546183039, 'alpha': 0.00014352011136230925}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:41,343] The parameter `n_layers` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:41,344] The parameter `n_neurons_0` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:41,345] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:41,345] The parameter `learning_rate_init` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:41,346] The parameter `alpha` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:42,783] Trial 23 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.000657515339012736, 'alpha': 0.000222120498838994}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-10-06 13:26:42,889] Trial 24 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:43,047] The parameter `n_layers` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:43,049] The parameter `n_neurons_0` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:43,050] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:43,051] The parameter `learning_rate_init` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:43,051] The parameter `alpha` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:44,328] Trial 25 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0020911960669713066, 'alpha': 0.00036296754488993613}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:44,456] The parameter `n_layers` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:44,458] The parameter `n_neurons_0` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:44,458] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:44,460] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:44,460] The parameter `n_neurons_3` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:44,461] The parameter `n_neurons_4` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:44,461] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:44,463] The parameter `learning_rate_init` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:44,463] The parameter `alpha` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:45,452] Trial 26 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 77, 'n_neurons_1': 60, 'n_neurons_2': 65, 'n_neurons_3': 48, 'n_neurons_4': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010685306331940677, 'alpha': 0.00017066532063900338}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:45,567] The parameter `n_layers` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:45,568] The parameter `n_neurons_0` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:45,569] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:45,570] The parameter `learning_rate_init` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:45,571] The parameter `alpha` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:47,098] Trial 27 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 13, 'learning_rate': 'constant', 'learning_rate_init': 0.0008878664758716851, 'alpha': 0.00015691639471778163}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:47,199] The parameter `n_layers` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:47,200] The parameter `n_neurons_0` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:47,201] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:47,201] The parameter `n_neurons_2` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:47,202] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:47,203] The parameter `learning_rate_init` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:47,204] The parameter `alpha` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:26:48,697] Trial 28 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 53, 'n_neurons_1': 25, 'n_neurons_2': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001862890387420621, 'alpha': 0.00012319923739394199}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:48,801] The parameter `n_layers` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:48,802] The parameter `n_neurons_0` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:48,803] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:48,803] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:48,804] The parameter `learning_rate_init` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:48,805] The parameter `alpha` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:50,325] Trial 29 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 66, 'n_neurons_1': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.0002117721540886054, 'alpha': 0.00013840044764106221}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:50,435] The parameter `n_layers` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:50,437] The parameter `n_neurons_0` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:50,437] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:50,438] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:50,439] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:50,440] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:50,440] The parameter `learning_rate_init` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:50,441] The parameter `alpha` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:52,187] Trial 30 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 12, 'n_neurons_1': 63, 'n_neurons_2': 95, 'n_neurons_3': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008250984684608617, 'alpha': 0.0012337682181468137}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:52,307] The parameter `n_layers` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:52,308] The parameter `n_neurons_0` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:52,309] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:52,310] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:52,311] The parameter `n_neurons_3` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:52,311] The parameter `n_neurons_4` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:52,312] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:52,312] The parameter `learning_rate_init` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:52,313] The parameter `alpha` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:54,337] Trial 31 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 45, 'n_neurons_1': 97, 'n_neurons_2': 92, 'n_neurons_3': 27, 'n_neurons_4': 16, 'learning_rate': 'constant', 'learning_rate_init': 0.00015448485924752335, 'alpha': 0.0023228092500006277}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-10-06 13:26:54,449] The parameter `n_layers` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:54,450] The parameter `n_neurons_0` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:54,451] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:54,452] The parameter `learning_rate_init` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:54,452] The parameter `alpha` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:55,590] Trial 32 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004255366449682059, 'alpha': 0.00036619258793526205}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:26:55,706] The parameter `n_layers` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:55,707] The parameter `n_neurons_0` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:55,708] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:55,709] The parameter `learning_rate_init` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:55,709] The parameter `alpha` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:57,057] Trial 33 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002952174928235019, 'alpha': 0.004045403638787863}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:26:57,156] The parameter `n_layers` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:57,157] The parameter `n_neurons_0` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:57,157] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:57,158] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:57,159] The parameter `learning_rate_init` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:57,160] The parameter `alpha` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:26:58,706] Trial 34 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 78, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006687062061347505, 'alpha': 0.0005546719086332962}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:26:58,814] The parameter `n_layers` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:58,815] The parameter `n_neurons_0` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:58,816] The parameter `n_neurons_1` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:58,817] The parameter `n_neurons_2` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:58,817] The parameter `n_neurons_3` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:58,818] The parameter `learning_rate` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:58,819] The parameter `learning_rate_init` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:26:58,819] The parameter `alpha` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:01,014] Trial 35 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 41, 'n_neurons_1': 94, 'n_neurons_2': 88, 'n_neurons_3': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001607858173371064, 'alpha': 0.006384190143734895}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:01,109] The parameter `n_layers` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:01,110] The parameter `n_neurons_0` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:01,111] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:01,112] The parameter `n_neurons_2` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:01,113] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:01,113] The parameter `learning_rate_init` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:01,114] The parameter `alpha` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:02,015] Trial 36 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 39, 'n_neurons_2': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.006467909772210833, 'alpha': 0.00015225562752457967}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:27:02,124] Trial 37 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:02,278] The parameter `n_layers` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:02,280] The parameter `n_neurons_0` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:02,280] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:02,283] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:02,284] The parameter `learning_rate_init` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:02,284] The parameter `alpha` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:04,096] Trial 38 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 96, 'n_neurons_1': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007886622327732802, 'alpha': 0.00038585269984779924}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:04,210] The parameter `n_layers` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:04,211] The parameter `n_neurons_0` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:04,212] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:04,213] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:04,214] The parameter `learning_rate_init` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:04,215] The parameter `alpha` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:05,791] Trial 39 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 78, 'learning_rate': 'constant', 'learning_rate_init': 0.00015219914267510963, 'alpha': 0.0009746318720288899}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:05,918] The parameter `n_layers` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:05,918] The parameter `n_neurons_0` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:05,921] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:05,921] The parameter `learning_rate_init` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:05,921] The parameter `alpha` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:07,260] Trial 40 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005033035864411288, 'alpha': 0.00017144863541673278}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:07,369] The parameter `n_layers` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:07,370] The parameter `n_neurons_0` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:07,371] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:07,371] The parameter `learning_rate_init` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:07,372] The parameter `alpha` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:27:08,951] Trial 41 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.00014730368526805275, 'alpha': 0.002523122072859775}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:09,066] The parameter `n_layers` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:09,067] The parameter `n_neurons_0` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:09,068] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:09,068] The parameter `learning_rate_init` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:09,069] The parameter `alpha` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:27:10,762] Trial 42 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.00014780033831850363, 'alpha': 0.00940327542674712}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:10,909] The parameter `n_layers` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:10,910] The parameter `n_neurons_0` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:10,911] The parameter `n_neurons_1` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:10,912] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:10,913] The parameter `learning_rate_init` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:10,914] The parameter `alpha` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:12,730] Trial 43 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0032118582525883237, 'alpha': 0.0005656127243812504}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:27:12,847] Trial 44 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:13,022] The parameter `n_layers` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:13,023] The parameter `n_neurons_0` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:13,024] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:13,025] The parameter `learning_rate_init` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:13,026] The parameter `alpha` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:14,350] Trial 45 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0064969387159423365, 'alpha': 0.0001668764162919581}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:14,501] The parameter `n_layers` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:14,502] The parameter `n_neurons_0` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:14,503] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:14,504] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:14,504] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:14,505] The parameter `learning_rate_init` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:14,506] The parameter `alpha` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:15,763] Trial 46 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 11, 'n_neurons_1': 52, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0019880193364014637, 'alpha': 0.003105201294430152}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:15,879] The parameter `n_layers` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:15,879] The parameter `n_neurons_0` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:15,881] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:15,881] The parameter `n_neurons_2` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:15,883] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:15,883] The parameter `learning_rate_init` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:15,883] The parameter `alpha` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:17,060] Trial 47 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 44, 'n_neurons_2': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.008441994772287123, 'alpha': 0.00010575695778888723}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:17,198] The parameter `n_layers` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:17,200] The parameter `n_neurons_0` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:17,200] The parameter `n_neurons_1` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:17,202] The parameter `n_neurons_2` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:17,202] The parameter `n_neurons_3` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:17,203] The parameter `n_neurons_4` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:17,204] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:17,205] The parameter `learning_rate_init` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:17,205] The parameter `alpha` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:18,552] Trial 48 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 13, 'n_neurons_1': 91, 'n_neurons_2': 58, 'n_neurons_3': 100, 'n_neurons_4': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001112232774304946, 'alpha': 0.0018146683984526406}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:27:18,678] Trial 49 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:18,822] The parameter `n_layers` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:18,823] The parameter `n_neurons_0` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:18,824] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:18,825] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:18,826] The parameter `n_neurons_3` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:18,826] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:18,827] The parameter `learning_rate_init` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:18,827] The parameter `alpha` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:20,068] Trial 50 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 51, 'n_neurons_1': 67, 'n_neurons_2': 63, 'n_neurons_3': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007958348774085428, 'alpha': 0.006032920019762461}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:20,172] The parameter `n_layers` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:20,173] The parameter `n_neurons_0` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:20,174] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:20,176] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:20,176] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:20,178] The parameter `learning_rate_init` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:20,180] The parameter `alpha` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:21,821] Trial 51 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 66, 'n_neurons_1': 35, 'n_neurons_2': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0014699827002313925, 'alpha': 0.00014304387745680657}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:21,932] The parameter `n_layers` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:21,933] The parameter `n_neurons_0` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:21,934] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:21,935] The parameter `n_neurons_2` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:21,936] The parameter `n_neurons_3` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:21,937] The parameter `n_neurons_4` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:21,937] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:21,938] The parameter `learning_rate_init` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:21,939] The parameter `alpha` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:23,391] Trial 52 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 99, 'n_neurons_1': 73, 'n_neurons_2': 58, 'n_neurons_3': 38, 'n_neurons_4': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.006635205362126859, 'alpha': 0.004416461875953999}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:23,481] The parameter `n_layers` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:23,482] The parameter `n_neurons_0` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:23,483] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:23,484] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:23,484] The parameter `n_neurons_3` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:23,485] The parameter `n_neurons_4` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:23,486] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:23,486] The parameter `learning_rate_init` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:23,487] The parameter `alpha` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:25,238] Trial 53 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 76, 'n_neurons_1': 65, 'n_neurons_2': 48, 'n_neurons_3': 94, 'n_neurons_4': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0005661437715302432, 'alpha': 0.004179329972699849}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:25,357] The parameter `n_layers` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:25,358] The parameter `n_neurons_0` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:25,359] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:25,359] The parameter `n_neurons_2` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:25,360] The parameter `n_neurons_3` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:25,360] The parameter `n_neurons_4` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:25,360] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:25,362] The parameter `learning_rate_init` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:25,362] The parameter `alpha` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:27:28,179] Trial 54 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 23, 'n_neurons_1': 64, 'n_neurons_2': 44, 'n_neurons_3': 98, 'n_neurons_4': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0006755212335411566, 'alpha': 0.00035222010634042685}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:28,273] The parameter `n_layers` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,274] The parameter `n_neurons_0` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,275] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,276] The parameter `learning_rate_init` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,277] The parameter `alpha` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:28,768] Trial 55 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009846313836604142, 'alpha': 0.0012908132395505268}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:28,885] The parameter `n_layers` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,886] The parameter `n_neurons_0` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,887] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,888] The parameter `n_neurons_2` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,889] The parameter `n_neurons_3` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,890] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,890] The parameter `learning_rate_init` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:28,891] The parameter `alpha` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:30,132] Trial 56 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 95, 'n_neurons_1': 87, 'n_neurons_2': 32, 'n_neurons_3': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0016306068743545592, 'alpha': 0.00028660621978595627}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:30,236] The parameter `n_layers` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:30,238] The parameter `n_neurons_0` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:30,238] The parameter `n_neurons_1` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:30,240] The parameter `n_neurons_2` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:30,240] The parameter `n_neurons_3` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:30,242] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:30,242] The parameter `learning_rate_init` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:30,242] The parameter `alpha` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:32,030] Trial 57 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 42, 'n_neurons_2': 20, 'n_neurons_3': 71, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010973041007839744, 'alpha': 0.005062476271565486}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:32,138] The parameter `n_layers` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:32,139] The parameter `n_neurons_0` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:32,140] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:32,141] The parameter `n_neurons_2` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:32,142] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:32,143] The parameter `learning_rate_init` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:32,143] The parameter `alpha` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:33,997] Trial 58 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 89, 'n_neurons_2': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.003237982605211301, 'alpha': 0.001740279894124974}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:34,098] The parameter `n_layers` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:34,101] The parameter `n_neurons_0` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:34,101] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:34,103] The parameter `n_neurons_2` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:34,103] The parameter `n_neurons_3` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:34,103] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:34,105] The parameter `learning_rate_init` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:34,105] The parameter `alpha` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:35,514] Trial 59 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 29, 'n_neurons_1': 22, 'n_neurons_2': 11, 'n_neurons_3': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0007498076102892463, 'alpha': 0.006431575749069943}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:35,638] The parameter `n_layers` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:35,638] The parameter `n_neurons_0` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:35,640] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:35,640] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:35,640] The parameter `learning_rate_init` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:35,642] The parameter `alpha` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:36,868] Trial 60 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005305513421197475, 'alpha': 0.007925766022280026}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:27:36,988] Trial 61 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:37,129] The parameter `n_layers` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:37,130] The parameter `n_neurons_0` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:37,131] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:37,132] The parameter `learning_rate_init` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:37,133] The parameter `alpha` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:38,389] Trial 62 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.0008284599389099161, 'alpha': 0.009121476646815571}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:38,500] The parameter `n_layers` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:38,501] The parameter `n_neurons_0` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:38,502] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:38,503] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:38,504] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:38,505] The parameter `learning_rate_init` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:38,506] The parameter `alpha` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:40,322] Trial 63 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 39, 'n_neurons_1': 67, 'n_neurons_2': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018033983912317568, 'alpha': 0.0002012822076129274}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:40,421] The parameter `n_layers` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:40,421] The parameter `n_neurons_0` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:40,423] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:40,423] The parameter `learning_rate_init` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:40,423] The parameter `alpha` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:41,487] Trial 64 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0062169420588097215, 'alpha': 0.000886999307004117}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:41,599] The parameter `n_layers` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:41,601] The parameter `n_neurons_0` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:41,602] The parameter `n_neurons_1` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:41,602] The parameter `n_neurons_2` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:41,604] The parameter `n_neurons_3` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:41,605] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:41,605] The parameter `learning_rate_init` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:41,606] The parameter `alpha` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:43,091] Trial 65 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 25, 'n_neurons_1': 27, 'n_neurons_2': 13, 'n_neurons_3': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0001504544604259194, 'alpha': 0.000174289707961261}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:43,197] The parameter `n_layers` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:43,199] The parameter `n_neurons_0` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:43,200] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:43,200] The parameter `n_neurons_2` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:43,201] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:43,202] The parameter `learning_rate_init` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:43,203] The parameter `alpha` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:44,392] Trial 66 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 43, 'n_neurons_2': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.003970276908151301, 'alpha': 0.0018021908442002565}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:44,514] The parameter `n_layers` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:44,516] The parameter `n_neurons_0` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:44,516] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:44,517] The parameter `learning_rate_init` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:44,518] The parameter `alpha` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:45,885] Trial 67 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.00035789472410260544, 'alpha': 0.004096401906445582}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:46,005] The parameter `n_layers` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:46,006] The parameter `n_neurons_0` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:46,006] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:46,007] The parameter `n_neurons_2` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:46,008] The parameter `n_neurons_3` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:46,008] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:46,009] The parameter `learning_rate_init` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:46,009] The parameter `alpha` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:47,852] Trial 68 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 26, 'n_neurons_1': 29, 'n_neurons_2': 43, 'n_neurons_3': 54, 'learning_rate': 'constant', 'learning_rate_init': 0.0008415296693542193, 'alpha': 0.003125661016787662}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:47,986] The parameter `n_layers` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:47,987] The parameter `n_neurons_0` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:47,988] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:47,989] The parameter `learning_rate_init` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:47,990] The parameter `alpha` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:49,300] Trial 69 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010552488419684378, 'alpha': 0.0011593831134486484}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:49,411] The parameter `n_layers` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:49,412] The parameter `n_neurons_0` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:49,413] The parameter `learning_rate` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:49,413] The parameter `learning_rate_init` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:49,414] The parameter `alpha` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:50,938] Trial 70 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 50, 'learning_rate': 'constant', 'learning_rate_init': 0.0003455305583136833, 'alpha': 0.0005682877914899339}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:51,065] The parameter `n_layers` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:51,066] The parameter `n_neurons_0` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:51,067] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:51,067] The parameter `learning_rate_init` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:51,068] The parameter `alpha` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:27:52,413] Trial 71 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017358982432215278, 'alpha': 0.006040245096887873}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:52,533] The parameter `n_layers` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:52,535] The parameter `n_neurons_0` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:52,536] The parameter `n_neurons_1` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:52,536] The parameter `n_neurons_2` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:52,537] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:52,538] The parameter `learning_rate_init` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:52,538] The parameter `alpha` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:54,508] Trial 72 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 71, 'n_neurons_1': 81, 'n_neurons_2': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014917025634138866, 'alpha': 0.0030965560706362177}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:54,617] The parameter `n_layers` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:54,619] The parameter `n_neurons_0` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:54,619] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:54,620] The parameter `n_neurons_2` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:54,621] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:54,621] The parameter `learning_rate_init` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:54,622] The parameter `alpha` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:56,372] Trial 73 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 21, 'n_neurons_1': 35, 'n_neurons_2': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.0005154581987502424, 'alpha': 0.009397893033412784}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:56,510] The parameter `n_layers` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:56,511] The parameter `n_neurons_0` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:56,512] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:56,513] The parameter `n_neurons_2` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:56,513] The parameter `n_neurons_3` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:56,514] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:56,514] The parameter `learning_rate_init` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:56,515] The parameter `alpha` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:58,316] Trial 74 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 31, 'n_neurons_1': 19, 'n_neurons_2': 23, 'n_neurons_3': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00037169809679792504, 'alpha': 0.00022220160448344761}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:58,455] The parameter `n_layers` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:58,456] The parameter `n_neurons_0` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:58,457] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:58,458] The parameter `n_neurons_2` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:58,459] The parameter `n_neurons_3` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:58,459] The parameter `n_neurons_4` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:58,460] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:58,461] The parameter `learning_rate_init` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:58,462] The parameter `alpha` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:27:59,751] Trial 75 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 17, 'n_neurons_1': 57, 'n_neurons_2': 47, 'n_neurons_3': 99, 'n_neurons_4': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005382874466428148, 'alpha': 0.004306695255529367}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:27:59,876] The parameter `n_layers` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:59,877] The parameter `n_neurons_0` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:59,878] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:59,878] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:59,878] The parameter `learning_rate_init` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:27:59,878] The parameter `alpha` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:01,602] Trial 76 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 25, 'n_neurons_1': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.001390674140149984, 'alpha': 0.0003630431002952846}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:01,722] The parameter `n_layers` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:01,723] The parameter `n_neurons_0` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:01,724] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:01,725] The parameter `n_neurons_2` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:01,726] The parameter `n_neurons_3` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:01,726] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:01,727] The parameter `learning_rate_init` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:01,727] The parameter `alpha` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:03,152] Trial 77 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 27, 'n_neurons_1': 39, 'n_neurons_2': 48, 'n_neurons_3': 56, 'learning_rate': 'constant', 'learning_rate_init': 0.001664332465507855, 'alpha': 0.000377799263089713}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:03,254] The parameter `n_layers` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:03,256] The parameter `n_neurons_0` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:03,257] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:03,258] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:03,258] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:03,259] The parameter `learning_rate_init` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:03,260] The parameter `alpha` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:04,913] Trial 78 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 24, 'n_neurons_1': 53, 'n_neurons_2': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001857074616553881, 'alpha': 0.0001338905547392675}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:05,058] The parameter `n_layers` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:05,059] The parameter `n_neurons_0` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:05,060] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:05,060] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:05,061] The parameter `n_neurons_3` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:05,062] The parameter `n_neurons_4` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:05,063] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:05,064] The parameter `learning_rate_init` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:05,064] The parameter `alpha` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:06,834] Trial 79 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 83, 'n_neurons_2': 33, 'n_neurons_3': 72, 'n_neurons_4': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.000666318433858052, 'alpha': 0.0004985819284806489}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:06,944] The parameter `n_layers` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:06,944] The parameter `n_neurons_0` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:06,944] The parameter `n_neurons_1` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:06,946] The parameter `n_neurons_2` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:06,946] The parameter `n_neurons_3` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:06,948] The parameter `n_neurons_4` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:06,948] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:06,948] The parameter `learning_rate_init` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:06,950] The parameter `alpha` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:08,585] Trial 80 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 97, 'n_neurons_2': 21, 'n_neurons_3': 76, 'n_neurons_4': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.0030355773144056086, 'alpha': 0.0014091143133651608}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:08,724] The parameter `n_layers` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:08,725] The parameter `n_neurons_0` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:08,726] The parameter `n_neurons_1` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:08,727] The parameter `n_neurons_2` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:08,727] The parameter `n_neurons_3` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:08,728] The parameter `n_neurons_4` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:08,729] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:08,729] The parameter `learning_rate_init` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:08,730] The parameter `alpha` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:10,157] Trial 81 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 22, 'n_neurons_1': 82, 'n_neurons_2': 28, 'n_neurons_3': 24, 'n_neurons_4': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0011120667338401567, 'alpha': 0.0005219885398322653}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:10,263] The parameter `n_layers` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:10,264] The parameter `n_neurons_0` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:10,266] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:10,266] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:10,267] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:10,268] The parameter `n_neurons_4` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:10,268] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:10,269] The parameter `learning_rate_init` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:10,270] The parameter `alpha` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:11,954] Trial 82 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 45, 'n_neurons_1': 84, 'n_neurons_2': 49, 'n_neurons_3': 44, 'n_neurons_4': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010126066617091951, 'alpha': 0.0002913569554515852}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:12,084] The parameter `n_layers` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:12,085] The parameter `n_neurons_0` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:12,086] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:12,087] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:12,087] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:12,088] The parameter `n_neurons_4` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:12,089] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:12,089] The parameter `learning_rate_init` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:12,090] The parameter `alpha` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:14,586] Trial 83 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 44, 'n_neurons_1': 59, 'n_neurons_2': 92, 'n_neurons_3': 66, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.00046753187944355057, 'alpha': 0.00018990838710732203}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:14,695] The parameter `n_layers` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:14,697] The parameter `n_neurons_0` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:14,697] The parameter `n_neurons_1` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:14,699] The parameter `n_neurons_2` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:14,699] The parameter `n_neurons_3` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:14,701] The parameter `learning_rate` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:14,701] The parameter `learning_rate_init` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:14,701] The parameter `alpha` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:17,264] Trial 84 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 58, 'n_neurons_2': 91, 'n_neurons_3': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00031403516315342447, 'alpha': 0.0030753360921253873}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:17,399] The parameter `n_layers` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:17,400] The parameter `n_neurons_0` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:17,401] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:17,401] The parameter `learning_rate_init` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:17,402] The parameter `alpha` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:17,937] Trial 85 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004832406918522534, 'alpha': 0.0043905063473000955}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:18,044] The parameter `n_layers` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:18,045] The parameter `n_neurons_0` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:18,046] The parameter `learning_rate` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:18,047] The parameter `learning_rate_init` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:18,048] The parameter `alpha` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:19,385] Trial 86 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003931793782370637, 'alpha': 0.00019945037385407478}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:19,504] The parameter `n_layers` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:19,505] The parameter `n_neurons_0` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:19,506] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:19,507] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:19,507] The parameter `learning_rate_init` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:19,508] The parameter `alpha` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:20,482] Trial 87 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 75, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012174437001359676, 'alpha': 0.00031885858743643943}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:20,589] The parameter `n_layers` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:20,589] The parameter `n_neurons_0` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:20,589] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:20,591] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:20,591] The parameter `learning_rate_init` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:20,591] The parameter `alpha` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:22,181] Trial 88 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.000839482422872308, 'alpha': 0.007844525502343443}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[I 2025-10-06 13:28:22,301] Trial 89 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:22,478] The parameter `n_layers` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:22,479] The parameter `n_neurons_0` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:22,480] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:22,481] The parameter `learning_rate_init` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:22,481] The parameter `alpha` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:23,623] Trial 90 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001086977032427697, 'alpha': 0.005549422847797102}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:23,735] The parameter `n_layers` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:23,736] The parameter `n_neurons_0` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:23,737] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:23,738] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:23,738] The parameter `n_neurons_3` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:23,739] The parameter `n_neurons_4` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:23,740] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:23,740] The parameter `learning_rate_init` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:23,741] The parameter `alpha` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:25,085] Trial 91 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 61, 'n_neurons_1': 73, 'n_neurons_2': 93, 'n_neurons_3': 74, 'n_neurons_4': 23, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007051172552124139, 'alpha': 0.0029709029926915354}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:25,202] The parameter `n_layers` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:25,203] The parameter `n_neurons_0` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:25,204] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:25,205] The parameter `n_neurons_2` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:25,206] The parameter `n_neurons_3` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:25,207] The parameter `n_neurons_4` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:25,208] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:25,208] The parameter `learning_rate_init` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:25,209] The parameter `alpha` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:26,682] Trial 92 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 94, 'n_neurons_1': 51, 'n_neurons_2': 20, 'n_neurons_3': 99, 'n_neurons_4': 86, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005492786568761941, 'alpha': 0.0010906266715261731}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:26,792] The parameter `n_layers` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:26,793] The parameter `n_neurons_0` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:26,794] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:26,795] The parameter `n_neurons_2` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:26,795] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:26,796] The parameter `learning_rate_init` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:26,797] The parameter `alpha` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:28,309] Trial 93 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 14, 'n_neurons_2': 40, 'learning_rate': 'constant', 'learning_rate_init': 0.0004645135033311032, 'alpha': 0.0006256585548186114}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:28,428] The parameter `n_layers` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:28,429] The parameter `n_neurons_0` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:28,430] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:28,430] The parameter `n_neurons_2` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:28,431] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:28,431] The parameter `learning_rate_init` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:28,432] The parameter `alpha` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:30,093] Trial 94 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 93, 'n_neurons_1': 41, 'n_neurons_2': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0002813258539870692, 'alpha': 0.0008033023403902318}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:30,213] The parameter `n_layers` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:30,215] The parameter `n_neurons_0` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:30,216] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:30,217] The parameter `learning_rate_init` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:30,218] The parameter `alpha` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:31,409] Trial 95 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.006756033620862479, 'alpha': 0.0005306251107511992}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:31,549] The parameter `n_layers` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:31,550] The parameter `n_neurons_0` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:31,551] The parameter `n_neurons_1` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:31,552] The parameter `n_neurons_2` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:31,553] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:31,553] The parameter `learning_rate_init` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:31,554] The parameter `alpha` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:33,175] Trial 96 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 11, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00019830125168914512, 'alpha': 0.0006749137054804921}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:33,296] The parameter `n_layers` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:33,297] The parameter `n_neurons_0` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:33,298] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:33,299] The parameter `learning_rate_init` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:33,300] The parameter `alpha` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:34,906] Trial 97 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013619242560057148, 'alpha': 0.0031617020498319144}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:35,016] The parameter `n_layers` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:35,016] The parameter `n_neurons_0` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:35,016] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:35,018] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:35,018] The parameter `learning_rate_init` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:35,018] The parameter `alpha` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:36,405] Trial 98 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 91, 'n_neurons_1': 28, 'learning_rate': 'constant', 'learning_rate_init': 0.0008792935556463842, 'alpha': 0.0013479763309946922}. Best is trial 32 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:36,512] The parameter `n_layers` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:36,513] The parameter `n_neurons_0` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:36,514] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:36,514] The parameter `learning_rate_init` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:36,515] The parameter `alpha` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:37,758] Trial 99 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007612468242681232, 'alpha': 0.0006331784446999807}. Best is trial 32 with value: 0.9266666666666666.\n",
      "\n",
      "Selected Base Models for Stacking using GPSampler:\n",
      "- Random Forest\n",
      "- AdaBoost\n",
      "Best Hyperparameters for Meta Model (MLP) using GPSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.004255366449682059, 'alpha': 0.00036619258793526205, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (39,), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9267, at trial: 32\n",
      "GP base models training time: 256.32 seconds\n",
      "GP SEl-NNML Training Time: 153.70 seconds\n",
      "Total GP Training Time (Base + Meta): 410.02 seconds\n"
     ]
    }
   ],
   "source": [
    "gp_meta_model_training_start = time.time()\n",
    "\n",
    "# Meta Model Tuning and Final Stacking Model Fitting\n",
    "gp_sel_nnml = meta_model_tuning(base_models['GP'], X_train, y_train, X_test, y_test, sampler='GPSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "gp_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "gp_meta_model_training_end = time.time()\n",
    "\n",
    "# Time taken for GP SEl-NNML training\n",
    "gp_meta_model_training_time = gp_meta_model_training_end - gp_meta_model_training_start\n",
    "print(f'GP base models training time: {gp_base_models_training_time:.2f} seconds')\n",
    "print(f'GP SEl-NNML Training Time: {gp_meta_model_training_time:.2f} seconds')\n",
    "print(f'Total GP Training Time (Base + Meta): {gp_base_models_training_time + gp_meta_model_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:38,923] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (CmaEsSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90e4aadbb3c4404a586081266aee01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:40,421] Trial 0 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:28:40,425] The parameter `use_Logistic Regression` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:40,425] The parameter `use_Decision Tree` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:40,425] The parameter `use_Random Forest` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:40,430] The parameter `use_K-Nearest Neighbors` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:40,430] The parameter `use_Support Vector Machine` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:40,430] The parameter `use_AdaBoost` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:40,430] The parameter `use_Gradient Boosting` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:40,430] The parameter `n_neurons_1` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:40,430] The parameter `learning_rate` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:41,591] Trial 1 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.0005404052553935483, 'alpha': 0.000865808466690932}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:28:41,595] The parameter `use_Logistic Regression` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:41,595] The parameter `use_Decision Tree` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:41,595] The parameter `use_Random Forest` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:41,595] The parameter `use_K-Nearest Neighbors` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:41,595] The parameter `use_Support Vector Machine` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:41,595] The parameter `use_AdaBoost` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:41,601] The parameter `use_Gradient Boosting` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:41,601] The parameter `n_neurons_1` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:41,601] The parameter `learning_rate` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:43,128] Trial 2 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 72, 'n_neurons_1': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0004843830630951302, 'alpha': 0.0009528924787594206}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:28:43,133] The parameter `use_Logistic Regression` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,134] The parameter `use_Decision Tree` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,135] The parameter `use_Random Forest` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,135] The parameter `use_K-Nearest Neighbors` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,136] The parameter `use_Support Vector Machine` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,137] The parameter `use_AdaBoost` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,137] The parameter `use_Gradient Boosting` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,138] The parameter `n_neurons_1` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,139] The parameter `n_neurons_2` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,140] The parameter `learning_rate` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:43,948] Trial 3 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 16, 'n_neurons_2': 99, 'learning_rate': 'constant', 'learning_rate_init': 0.001284803071084827, 'alpha': 0.002651575859618515}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:28:43,950] The parameter `use_Logistic Regression` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,950] The parameter `use_Decision Tree` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,954] The parameter `use_Random Forest` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,954] The parameter `use_K-Nearest Neighbors` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,954] The parameter `use_Support Vector Machine` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,956] The parameter `use_AdaBoost` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,956] The parameter `use_Gradient Boosting` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,956] The parameter `n_neurons_1` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,958] The parameter `n_neurons_2` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:43,958] The parameter `learning_rate` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:28:46,065] Trial 4 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 51, 'n_neurons_1': 76, 'n_neurons_2': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.0010997756098965073, 'alpha': 0.00010702593573937491}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:28:46,069] The parameter `use_Logistic Regression` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,070] The parameter `use_Decision Tree` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,071] The parameter `use_Random Forest` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,072] The parameter `use_K-Nearest Neighbors` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,073] The parameter `use_Support Vector Machine` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,074] The parameter `use_AdaBoost` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,074] The parameter `use_Gradient Boosting` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,075] The parameter `n_neurons_1` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,076] The parameter `n_neurons_2` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,077] The parameter `n_neurons_3` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:46,077] The parameter `learning_rate` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:47,793] Trial 5 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 79, 'n_neurons_1': 92, 'n_neurons_2': 32, 'n_neurons_3': 47, 'learning_rate': 'constant', 'learning_rate_init': 0.00037679762657228646, 'alpha': 0.001966714163929435}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:28:47,800] The parameter `use_Logistic Regression` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,800] The parameter `use_Decision Tree` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,802] The parameter `use_Random Forest` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,802] The parameter `use_K-Nearest Neighbors` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,802] The parameter `use_Support Vector Machine` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,802] The parameter `use_AdaBoost` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,802] The parameter `use_Gradient Boosting` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,802] The parameter `n_neurons_1` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,802] The parameter `n_neurons_2` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:47,802] The parameter `learning_rate` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:49,230] Trial 6 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 29, 'n_neurons_1': 20, 'n_neurons_2': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045488589409482236, 'alpha': 0.0023404594415393147}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:28:49,234] The parameter `use_Logistic Regression` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:49,236] The parameter `use_Decision Tree` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:49,236] The parameter `use_Random Forest` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:49,237] The parameter `use_K-Nearest Neighbors` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:49,238] The parameter `use_Support Vector Machine` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:49,238] The parameter `use_AdaBoost` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:49,238] The parameter `use_Gradient Boosting` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:49,240] The parameter `n_neurons_1` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:49,240] The parameter `learning_rate` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:50,671] Trial 7 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 38, 'n_neurons_1': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.00039738988185359975, 'alpha': 0.00195965433079867}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:50,676] The parameter `use_Logistic Regression` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:50,678] The parameter `use_Decision Tree` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:50,678] The parameter `use_Random Forest` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:50,679] The parameter `use_K-Nearest Neighbors` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:50,680] The parameter `use_Support Vector Machine` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:50,680] The parameter `use_AdaBoost` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:50,681] The parameter `use_Gradient Boosting` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:50,682] The parameter `n_neurons_1` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:50,683] The parameter `learning_rate` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:52,007] Trial 8 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 60, 'n_neurons_1': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.0022097738266210138, 'alpha': 0.00281718805195577}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:52,013] The parameter `use_Logistic Regression` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:52,014] The parameter `use_Decision Tree` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:52,015] The parameter `use_Random Forest` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:52,016] The parameter `use_K-Nearest Neighbors` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:52,017] The parameter `use_Support Vector Machine` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:52,018] The parameter `use_AdaBoost` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:52,020] The parameter `use_Gradient Boosting` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:52,020] The parameter `n_neurons_1` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:52,020] The parameter `learning_rate` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:53,213] Trial 9 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 61, 'n_neurons_1': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0003870149531783572, 'alpha': 0.001757315262446436}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:53,220] The parameter `use_Logistic Regression` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:53,220] The parameter `use_Decision Tree` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:53,220] The parameter `use_Random Forest` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:53,220] The parameter `use_K-Nearest Neighbors` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:53,220] The parameter `use_Support Vector Machine` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:53,220] The parameter `use_AdaBoost` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:53,220] The parameter `use_Gradient Boosting` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:53,226] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:54,606] Trial 10 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.00033494043244536764, 'alpha': 0.0012431196087695905}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:54,611] The parameter `use_Logistic Regression` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:54,612] The parameter `use_Decision Tree` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:54,612] The parameter `use_Random Forest` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:54,613] The parameter `use_K-Nearest Neighbors` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:54,614] The parameter `use_Support Vector Machine` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:54,614] The parameter `use_AdaBoost` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:54,615] The parameter `use_Gradient Boosting` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:54,616] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:55,751] Trial 11 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0016561472675196004, 'alpha': 0.004112785598618711}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:55,755] The parameter `use_Logistic Regression` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:55,756] The parameter `use_Decision Tree` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:55,758] The parameter `use_Random Forest` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:55,758] The parameter `use_K-Nearest Neighbors` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:55,758] The parameter `use_Support Vector Machine` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:55,758] The parameter `use_AdaBoost` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:55,758] The parameter `use_Gradient Boosting` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:55,758] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:57,013] Trial 12 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 51, 'learning_rate': 'constant', 'learning_rate_init': 0.0006238283174843963, 'alpha': 0.0006535248517420081}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:57,026] The parameter `use_Logistic Regression` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:57,027] The parameter `use_Decision Tree` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:57,028] The parameter `use_Random Forest` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:57,029] The parameter `use_K-Nearest Neighbors` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:57,029] The parameter `use_Support Vector Machine` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:57,030] The parameter `use_AdaBoost` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:57,031] The parameter `use_Gradient Boosting` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:57,032] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:57,032] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:28:58,903] Trial 13 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 61, 'n_neurons_1': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.00013543078948754798, 'alpha': 0.001932715489422311}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:28:58,907] The parameter `use_Logistic Regression` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:58,909] The parameter `use_Decision Tree` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:58,909] The parameter `use_Random Forest` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:58,910] The parameter `use_K-Nearest Neighbors` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:58,911] The parameter `use_Support Vector Machine` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:58,911] The parameter `use_AdaBoost` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:58,912] The parameter `use_Gradient Boosting` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:58,913] The parameter `n_neurons_1` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:28:58,914] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:00,249] Trial 14 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 42, 'n_neurons_1': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.0010595918733603078, 'alpha': 0.0021950577239561423}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:00,256] The parameter `use_Logistic Regression` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:00,257] The parameter `use_Decision Tree` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:00,258] The parameter `use_Random Forest` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:00,259] The parameter `use_K-Nearest Neighbors` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:00,259] The parameter `use_Support Vector Machine` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:00,260] The parameter `use_AdaBoost` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:00,261] The parameter `use_Gradient Boosting` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:00,261] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:01,558] Trial 15 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 52, 'learning_rate': 'constant', 'learning_rate_init': 0.0005027183510462943, 'alpha': 0.0008521307450705895}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:01,565] The parameter `use_Logistic Regression` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,566] The parameter `use_Decision Tree` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,567] The parameter `use_Random Forest` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,568] The parameter `use_K-Nearest Neighbors` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,569] The parameter `use_Support Vector Machine` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,570] The parameter `use_AdaBoost` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,570] The parameter `use_Gradient Boosting` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,572] The parameter `n_neurons_1` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,572] The parameter `n_neurons_2` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:01,573] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:02,938] Trial 16 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 55, 'n_neurons_1': 12, 'n_neurons_2': 13, 'learning_rate': 'constant', 'learning_rate_init': 0.00022789775976040784, 'alpha': 0.003725606530666624}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:02,944] The parameter `use_Logistic Regression` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,946] The parameter `use_Decision Tree` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,946] The parameter `use_Random Forest` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,947] The parameter `use_K-Nearest Neighbors` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,948] The parameter `use_Support Vector Machine` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,948] The parameter `use_AdaBoost` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,949] The parameter `use_Gradient Boosting` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,950] The parameter `n_neurons_1` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,951] The parameter `n_neurons_2` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:02,952] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:04,605] Trial 17 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 69, 'n_neurons_1': 82, 'n_neurons_2': 34, 'learning_rate': 'constant', 'learning_rate_init': 0.0002974342499146115, 'alpha': 0.0025048225720770245}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:04,610] The parameter `use_Logistic Regression` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:04,611] The parameter `use_Decision Tree` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:04,611] The parameter `use_Random Forest` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:04,612] The parameter `use_K-Nearest Neighbors` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:04,613] The parameter `use_Support Vector Machine` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:04,614] The parameter `use_AdaBoost` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:04,614] The parameter `use_Gradient Boosting` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:04,615] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:06,182] Trial 18 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00025256372326135323, 'alpha': 0.0016028464519090547}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:06,185] The parameter `use_Logistic Regression` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:06,188] The parameter `use_Decision Tree` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:06,188] The parameter `use_Random Forest` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:06,191] The parameter `use_K-Nearest Neighbors` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:06,191] The parameter `use_Support Vector Machine` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:06,192] The parameter `use_AdaBoost` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:06,193] The parameter `use_Gradient Boosting` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:06,194] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:07,608] Trial 19 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005562277602190652, 'alpha': 0.0013792541491205827}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:07,612] The parameter `use_Logistic Regression` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:07,613] The parameter `use_Decision Tree` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:07,614] The parameter `use_Random Forest` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:07,615] The parameter `use_K-Nearest Neighbors` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:07,616] The parameter `use_Support Vector Machine` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:07,616] The parameter `use_AdaBoost` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:07,617] The parameter `use_Gradient Boosting` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:07,617] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:07,617] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:08,434] Trial 20 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 84, 'n_neurons_1': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.0006717830313614763, 'alpha': 0.0008926986990989873}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:08,438] The parameter `use_Logistic Regression` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:08,439] The parameter `use_Decision Tree` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:08,440] The parameter `use_Random Forest` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:08,441] The parameter `use_K-Nearest Neighbors` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:08,442] The parameter `use_Support Vector Machine` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:08,443] The parameter `use_AdaBoost` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:08,443] The parameter `use_Gradient Boosting` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:08,444] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:08,445] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:09,680] Trial 21 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 52, 'n_neurons_1': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.00045034656483935087, 'alpha': 0.0010150860056613955}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:09,684] The parameter `use_Logistic Regression` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:09,685] The parameter `use_Decision Tree` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:09,686] The parameter `use_Random Forest` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:09,687] The parameter `use_K-Nearest Neighbors` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:09,688] The parameter `use_Support Vector Machine` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:09,689] The parameter `use_AdaBoost` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:09,689] The parameter `use_Gradient Boosting` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:09,690] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:09,691] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:11,230] Trial 22 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.0003092568911587821, 'alpha': 0.0017264853776462225}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:11,235] The parameter `use_Logistic Regression` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:11,235] The parameter `use_Decision Tree` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:11,236] The parameter `use_Random Forest` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:11,237] The parameter `use_K-Nearest Neighbors` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:11,238] The parameter `use_Support Vector Machine` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:11,238] The parameter `use_AdaBoost` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:11,239] The parameter `use_Gradient Boosting` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:11,240] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:12,726] Trial 23 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001771462437564892, 'alpha': 0.0016887200664840141}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:12,732] The parameter `use_Logistic Regression` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,733] The parameter `use_Decision Tree` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,733] The parameter `use_Random Forest` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,734] The parameter `use_K-Nearest Neighbors` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,735] The parameter `use_Support Vector Machine` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,736] The parameter `use_AdaBoost` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,736] The parameter `use_Gradient Boosting` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,737] The parameter `n_neurons_1` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,738] The parameter `n_neurons_2` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:12,739] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:14,700] Trial 24 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 86, 'n_neurons_1': 60, 'n_neurons_2': 50, 'learning_rate': 'constant', 'learning_rate_init': 0.00039496472992089394, 'alpha': 0.002619913438497463}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:14,706] The parameter `use_Logistic Regression` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:14,706] The parameter `use_Decision Tree` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:14,708] The parameter `use_Random Forest` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:14,708] The parameter `use_K-Nearest Neighbors` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:14,709] The parameter `use_Support Vector Machine` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:14,710] The parameter `use_AdaBoost` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:14,711] The parameter `use_Gradient Boosting` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:14,711] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:16,312] Trial 25 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000132193345426879, 'alpha': 0.0036658627786041683}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:16,317] The parameter `use_Logistic Regression` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,318] The parameter `use_Decision Tree` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,319] The parameter `use_Random Forest` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,320] The parameter `use_K-Nearest Neighbors` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,320] The parameter `use_Support Vector Machine` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,321] The parameter `use_AdaBoost` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,322] The parameter `use_Gradient Boosting` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,323] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,324] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,324] The parameter `n_neurons_3` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,325] The parameter `n_neurons_4` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:16,326] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:18,841] Trial 26 finished with value: 0.8733333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 70, 'n_neurons_1': 20, 'n_neurons_2': 20, 'n_neurons_3': 69, 'n_neurons_4': 77, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005203957610291437, 'alpha': 0.006673939239041471}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:18,847] The parameter `use_Logistic Regression` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,847] The parameter `use_Decision Tree` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,847] The parameter `use_Random Forest` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,851] The parameter `use_K-Nearest Neighbors` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,851] The parameter `use_Support Vector Machine` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,853] The parameter `use_AdaBoost` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,853] The parameter `use_Gradient Boosting` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,854] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,855] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:18,856] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:20,317] Trial 27 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 44, 'n_neurons_1': 57, 'n_neurons_2': 67, 'learning_rate': 'constant', 'learning_rate_init': 0.00018572401088696338, 'alpha': 0.0030137036354473245}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:20,322] The parameter `use_Logistic Regression` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,323] The parameter `use_Decision Tree` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,324] The parameter `use_Random Forest` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,325] The parameter `use_K-Nearest Neighbors` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,325] The parameter `use_Support Vector Machine` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,326] The parameter `use_AdaBoost` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,327] The parameter `use_Gradient Boosting` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,328] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,328] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:20,750] Trial 28 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 72, 'n_neurons_1': 17, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006808426995605315, 'alpha': 0.0024563837855569905}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:20,753] The parameter `use_Logistic Regression` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,754] The parameter `use_Decision Tree` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,755] The parameter `use_Random Forest` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,756] The parameter `use_K-Nearest Neighbors` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,757] The parameter `use_Support Vector Machine` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,757] The parameter `use_AdaBoost` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,758] The parameter `use_Gradient Boosting` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,759] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:20,760] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:22,506] Trial 29 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 70, 'n_neurons_1': 14, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015722756728306708, 'alpha': 0.0014391274586480363}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:29:22,510] The parameter `use_Logistic Regression` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,511] The parameter `use_Decision Tree` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,512] The parameter `use_Random Forest` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,513] The parameter `use_K-Nearest Neighbors` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,513] The parameter `use_Support Vector Machine` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,514] The parameter `use_AdaBoost` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,515] The parameter `use_Gradient Boosting` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,516] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,516] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:22,517] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:24,920] Trial 30 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 52, 'n_neurons_1': 100, 'n_neurons_2': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001952045318704599, 'alpha': 0.0016312041807207015}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:24,925] The parameter `use_Logistic Regression` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:24,926] The parameter `use_Decision Tree` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:24,927] The parameter `use_Random Forest` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:24,928] The parameter `use_K-Nearest Neighbors` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:24,929] The parameter `use_Support Vector Machine` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:24,930] The parameter `use_AdaBoost` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:24,930] The parameter `use_Gradient Boosting` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:24,931] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:24,932] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:26,838] Trial 31 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 76, 'n_neurons_1': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005891282661675585, 'alpha': 0.0007408027230893923}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:26,843] The parameter `use_Logistic Regression` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:26,844] The parameter `use_Decision Tree` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:26,845] The parameter `use_Random Forest` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:26,846] The parameter `use_K-Nearest Neighbors` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:26,846] The parameter `use_Support Vector Machine` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:26,847] The parameter `use_AdaBoost` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:26,848] The parameter `use_Gradient Boosting` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:26,849] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:28,282] Trial 32 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 41, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011311170526148385, 'alpha': 0.0018579747174356693}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:28,291] The parameter `use_Logistic Regression` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:28,292] The parameter `use_Decision Tree` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:28,293] The parameter `use_Random Forest` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:28,294] The parameter `use_K-Nearest Neighbors` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:28,294] The parameter `use_Support Vector Machine` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:28,295] The parameter `use_AdaBoost` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:28,296] The parameter `use_Gradient Boosting` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:28,296] The parameter `n_neurons_1` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:28,297] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:29,727] Trial 33 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 54, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000176392717609602, 'alpha': 0.004344662433431111}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:29,732] The parameter `use_Logistic Regression` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,733] The parameter `use_Decision Tree` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,733] The parameter `use_Random Forest` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,734] The parameter `use_K-Nearest Neighbors` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,735] The parameter `use_Support Vector Machine` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,735] The parameter `use_AdaBoost` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,736] The parameter `use_Gradient Boosting` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,737] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,738] The parameter `n_neurons_2` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,738] The parameter `n_neurons_3` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:29,739] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:31,027] Trial 34 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 13, 'n_neurons_2': 25, 'n_neurons_3': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.0002823178227883597, 'alpha': 0.002054902921340497}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:31,032] The parameter `use_Logistic Regression` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,033] The parameter `use_Decision Tree` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,034] The parameter `use_Random Forest` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,034] The parameter `use_K-Nearest Neighbors` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,035] The parameter `use_Support Vector Machine` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,036] The parameter `use_AdaBoost` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,036] The parameter `use_Gradient Boosting` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:31,037] Trial 35 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:31,039] The parameter `use_Logistic Regression` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,040] The parameter `use_Decision Tree` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,041] The parameter `use_Random Forest` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,042] The parameter `use_K-Nearest Neighbors` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,042] The parameter `use_Support Vector Machine` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,043] The parameter `use_AdaBoost` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,044] The parameter `use_Gradient Boosting` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,045] The parameter `n_layers` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,049] The parameter `n_neurons_0` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,050] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,051] The parameter `n_neurons_2` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,052] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,052] The parameter `learning_rate_init` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,053] The parameter `alpha` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:31,566] Trial 36 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 58, 'n_neurons_1': 19, 'n_neurons_2': 50, 'learning_rate': 'constant', 'learning_rate_init': 0.0003455305583136833, 'alpha': 0.0005682877914899339}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:31,568] The parameter `use_Logistic Regression` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,569] The parameter `use_Decision Tree` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,570] The parameter `use_Random Forest` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,570] The parameter `use_K-Nearest Neighbors` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,571] The parameter `use_Support Vector Machine` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,572] The parameter `use_AdaBoost` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,572] The parameter `use_Gradient Boosting` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:31,573] Trial 37 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:31,574] The parameter `use_Logistic Regression` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,576] The parameter `use_Decision Tree` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,576] The parameter `use_Random Forest` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,577] The parameter `use_K-Nearest Neighbors` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,578] The parameter `use_Support Vector Machine` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,579] The parameter `use_AdaBoost` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,580] The parameter `use_Gradient Boosting` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,580] The parameter `n_layers` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,581] The parameter `n_neurons_0` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,582] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,583] The parameter `learning_rate_init` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:31,583] The parameter `alpha` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:33,043] Trial 38 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 35, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00014469965355704128, 'alpha': 0.0011194966005419896}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:33,046] The parameter `use_Logistic Regression` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,048] The parameter `use_Decision Tree` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,048] The parameter `use_Random Forest` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,049] The parameter `use_K-Nearest Neighbors` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,050] The parameter `use_Support Vector Machine` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,051] The parameter `use_AdaBoost` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,051] The parameter `use_Gradient Boosting` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,052] The parameter `n_layers` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,053] The parameter `n_neurons_0` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,053] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,054] The parameter `n_neurons_2` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,055] The parameter `n_neurons_3` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,055] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,056] The parameter `learning_rate_init` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:33,057] The parameter `alpha` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:34,598] Trial 39 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 27, 'n_neurons_1': 39, 'n_neurons_2': 48, 'n_neurons_3': 56, 'learning_rate': 'constant', 'learning_rate_init': 0.001664332465507855, 'alpha': 0.000377799263089713}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:34,601] The parameter `use_Logistic Regression` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,602] The parameter `use_Decision Tree` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,603] The parameter `use_Random Forest` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,604] The parameter `use_K-Nearest Neighbors` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,604] The parameter `use_Support Vector Machine` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,605] The parameter `use_AdaBoost` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,605] The parameter `use_Gradient Boosting` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,606] The parameter `n_layers` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,607] The parameter `n_neurons_0` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,608] The parameter `n_neurons_1` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,608] The parameter `n_neurons_2` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,609] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,610] The parameter `learning_rate_init` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:34,610] The parameter `alpha` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:35,609] Trial 40 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 52, 'n_neurons_1': 47, 'n_neurons_2': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.008512435247428878, 'alpha': 0.0001772533479956596}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:35,612] The parameter `use_Logistic Regression` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,614] The parameter `use_Decision Tree` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,614] The parameter `use_Random Forest` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,615] The parameter `use_K-Nearest Neighbors` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,616] The parameter `use_Support Vector Machine` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,617] The parameter `use_AdaBoost` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,618] The parameter `use_Gradient Boosting` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,618] The parameter `n_layers` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,619] The parameter `n_neurons_0` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,620] The parameter `n_neurons_1` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,621] The parameter `n_neurons_2` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,621] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,622] The parameter `learning_rate_init` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:35,622] The parameter `alpha` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:37,815] Trial 41 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 89, 'n_neurons_2': 45, 'learning_rate': 'constant', 'learning_rate_init': 0.0005673993825415947, 'alpha': 0.0008420920578362944}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:37,815] The parameter `use_Logistic Regression` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,815] The parameter `use_Decision Tree` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,815] The parameter `use_Random Forest` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,815] The parameter `use_K-Nearest Neighbors` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,815] The parameter `use_Support Vector Machine` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,815] The parameter `use_AdaBoost` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,815] The parameter `use_Gradient Boosting` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,824] The parameter `n_layers` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,824] The parameter `n_neurons_0` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,824] The parameter `n_neurons_1` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,827] The parameter `n_neurons_2` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,827] The parameter `n_neurons_3` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,828] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,828] The parameter `learning_rate_init` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:37,829] The parameter `alpha` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:40,528] Trial 42 finished with value: 0.8733333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 58, 'n_neurons_2': 91, 'n_neurons_3': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00031403516315342447, 'alpha': 0.0030753360921253873}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:40,531] The parameter `use_Logistic Regression` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,532] The parameter `use_Decision Tree` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,533] The parameter `use_Random Forest` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,534] The parameter `use_K-Nearest Neighbors` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,534] The parameter `use_Support Vector Machine` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,535] The parameter `use_AdaBoost` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,536] The parameter `use_Gradient Boosting` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:40,537] Trial 43 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:40,538] The parameter `use_Logistic Regression` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,539] The parameter `use_Decision Tree` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,540] The parameter `use_Random Forest` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,541] The parameter `use_K-Nearest Neighbors` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,542] The parameter `use_Support Vector Machine` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,542] The parameter `use_AdaBoost` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,543] The parameter `use_Gradient Boosting` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,544] The parameter `n_layers` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,545] The parameter `n_neurons_0` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,545] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,546] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,547] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,547] The parameter `learning_rate_init` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,548] The parameter `alpha` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:40,965] Trial 44 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 65, 'n_neurons_1': 11, 'n_neurons_2': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.0024734415258704863, 'alpha': 0.006998400016066854}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:40,968] The parameter `use_Logistic Regression` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,969] The parameter `use_Decision Tree` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,970] The parameter `use_Random Forest` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,970] The parameter `use_K-Nearest Neighbors` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,971] The parameter `use_Support Vector Machine` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,972] The parameter `use_AdaBoost` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,972] The parameter `use_Gradient Boosting` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,973] The parameter `n_layers` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,974] The parameter `n_neurons_0` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,975] The parameter `n_neurons_1` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,975] The parameter `n_neurons_2` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,976] The parameter `n_neurons_3` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,977] The parameter `n_neurons_4` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,977] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,978] The parameter `learning_rate_init` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:40,979] The parameter `alpha` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:42,903] Trial 45 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 57, 'n_neurons_1': 63, 'n_neurons_2': 46, 'n_neurons_3': 14, 'n_neurons_4': 40, 'learning_rate': 'constant', 'learning_rate_init': 0.0004645135033311032, 'alpha': 0.0006256585548186114}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:42,906] The parameter `use_Logistic Regression` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,908] The parameter `use_Decision Tree` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,908] The parameter `use_Random Forest` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,909] The parameter `use_K-Nearest Neighbors` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,910] The parameter `use_Support Vector Machine` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,911] The parameter `use_AdaBoost` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,911] The parameter `use_Gradient Boosting` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,912] The parameter `n_layers` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,913] The parameter `n_neurons_0` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,913] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,914] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,915] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,915] The parameter `learning_rate_init` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:42,916] The parameter `alpha` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:44,589] Trial 46 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 11, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00019830125168914512, 'alpha': 0.0006749137054804921}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:44,591] The parameter `use_Logistic Regression` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,591] The parameter `use_Decision Tree` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `use_Random Forest` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `use_K-Nearest Neighbors` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `use_Support Vector Machine` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `use_AdaBoost` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `use_Gradient Boosting` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `n_layers` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `n_neurons_0` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,595] The parameter `n_neurons_2` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,601] The parameter `n_neurons_3` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,601] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,601] The parameter `learning_rate_init` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:44,601] The parameter `alpha` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:46,613] Trial 47 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 51, 'n_neurons_1': 57, 'n_neurons_2': 50, 'n_neurons_3': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.00023112996897053792, 'alpha': 0.005291407907847561}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:46,615] The parameter `use_Logistic Regression` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,617] The parameter `use_Decision Tree` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,618] The parameter `use_Random Forest` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,618] The parameter `use_K-Nearest Neighbors` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,619] The parameter `use_Support Vector Machine` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,620] The parameter `use_AdaBoost` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,621] The parameter `use_Gradient Boosting` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,621] The parameter `n_layers` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,622] The parameter `n_neurons_0` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,623] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,623] The parameter `learning_rate_init` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:46,624] The parameter `alpha` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:48,126] Trial 48 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000299478439928207, 'alpha': 0.00015808213238348277}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:48,128] The parameter `use_Logistic Regression` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,130] The parameter `use_Decision Tree` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,130] The parameter `use_Random Forest` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,131] The parameter `use_K-Nearest Neighbors` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,132] The parameter `use_Support Vector Machine` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `use_AdaBoost` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `use_Gradient Boosting` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `n_layers` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `n_neurons_0` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `n_neurons_1` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `n_neurons_2` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `learning_rate_init` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:48,133] The parameter `alpha` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:49,013] Trial 49 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 48, 'n_neurons_1': 91, 'n_neurons_2': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.0005746253963762425, 'alpha': 0.0015156184556529744}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `use_Logistic Regression` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `use_Decision Tree` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `use_Random Forest` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `use_K-Nearest Neighbors` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `use_Support Vector Machine` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `use_AdaBoost` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `use_Gradient Boosting` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `n_layers` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `n_neurons_0` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `learning_rate_init` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:49,013] The parameter `alpha` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:50,494] Trial 50 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003279256370202935, 'alpha': 0.00018998186562844776}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:50,497] The parameter `use_Logistic Regression` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,499] The parameter `use_Decision Tree` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,499] The parameter `use_Random Forest` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,500] The parameter `use_K-Nearest Neighbors` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,501] The parameter `use_Support Vector Machine` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,502] The parameter `use_AdaBoost` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,503] The parameter `use_Gradient Boosting` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,503] The parameter `n_layers` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,504] The parameter `n_neurons_0` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,505] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,505] The parameter `learning_rate_init` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:50,506] The parameter `alpha` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:51,766] Trial 51 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 22, 'learning_rate': 'constant', 'learning_rate_init': 0.001566124214205962, 'alpha': 0.001588670096363}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:51,769] The parameter `use_Logistic Regression` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,770] The parameter `use_Decision Tree` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,771] The parameter `use_Random Forest` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,772] The parameter `use_K-Nearest Neighbors` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,772] The parameter `use_Support Vector Machine` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,773] The parameter `use_AdaBoost` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,774] The parameter `use_Gradient Boosting` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,774] The parameter `n_layers` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,775] The parameter `n_neurons_0` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,776] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,777] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,777] The parameter `learning_rate_init` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:51,778] The parameter `alpha` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:29:53,546] Trial 52 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0021249187599503977, 'alpha': 0.007475831061488737}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:53,549] The parameter `use_Logistic Regression` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,550] The parameter `use_Decision Tree` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,551] The parameter `use_Random Forest` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,552] The parameter `use_K-Nearest Neighbors` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,553] The parameter `use_Support Vector Machine` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,553] The parameter `use_AdaBoost` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,554] The parameter `use_Gradient Boosting` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,555] The parameter `n_layers` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,556] The parameter `n_neurons_0` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,556] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,557] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,558] The parameter `n_neurons_3` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,558] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,560] The parameter `learning_rate_init` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:53,561] The parameter `alpha` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:54,974] Trial 53 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 49, 'n_neurons_1': 32, 'n_neurons_2': 84, 'n_neurons_3': 82, 'learning_rate': 'constant', 'learning_rate_init': 0.0015151698985443685, 'alpha': 0.0005271664874398606}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:54,974] The parameter `use_Logistic Regression` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,974] The parameter `use_Decision Tree` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,974] The parameter `use_Random Forest` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,987] The parameter `use_K-Nearest Neighbors` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,987] The parameter `use_Support Vector Machine` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,987] The parameter `use_AdaBoost` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,987] The parameter `use_Gradient Boosting` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,987] The parameter `n_layers` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,987] The parameter `n_neurons_0` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,987] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,987] The parameter `n_neurons_2` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,992] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,992] The parameter `learning_rate_init` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:54,993] The parameter `alpha` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:56,405] Trial 54 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 30, 'n_neurons_1': 99, 'n_neurons_2': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007087558145736653, 'alpha': 0.00022969454974259052}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:56,409] The parameter `use_Logistic Regression` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,410] The parameter `use_Decision Tree` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,411] The parameter `use_Random Forest` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,411] The parameter `use_K-Nearest Neighbors` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,412] The parameter `use_Support Vector Machine` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,413] The parameter `use_AdaBoost` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,414] The parameter `use_Gradient Boosting` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,414] The parameter `n_layers` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,415] The parameter `n_neurons_0` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,416] The parameter `n_neurons_1` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,416] The parameter `n_neurons_2` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,417] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,418] The parameter `learning_rate_init` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:56,418] The parameter `alpha` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:57,812] Trial 55 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 30, 'n_neurons_1': 20, 'n_neurons_2': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.002815357452964348, 'alpha': 0.00013511783615174891}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:57,815] The parameter `use_Logistic Regression` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,817] The parameter `use_Decision Tree` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,818] The parameter `use_Random Forest` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,819] The parameter `use_K-Nearest Neighbors` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,822] The parameter `use_Support Vector Machine` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,823] The parameter `use_AdaBoost` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,824] The parameter `use_Gradient Boosting` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,826] The parameter `n_layers` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,827] The parameter `n_neurons_0` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,828] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,829] The parameter `n_neurons_2` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,830] The parameter `n_neurons_3` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,831] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,831] The parameter `learning_rate_init` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:57,832] The parameter `alpha` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:29:58,235] Trial 56 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 100, 'n_neurons_1': 41, 'n_neurons_2': 79, 'n_neurons_3': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005589258917257331, 'alpha': 0.009293235406855402}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:29:58,238] The parameter `use_Logistic Regression` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,239] The parameter `use_Decision Tree` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,240] The parameter `use_Random Forest` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,241] The parameter `use_K-Nearest Neighbors` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,242] The parameter `use_Support Vector Machine` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,243] The parameter `use_AdaBoost` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,243] The parameter `use_Gradient Boosting` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,244] The parameter `n_layers` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,245] The parameter `n_neurons_0` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,246] The parameter `n_neurons_1` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,247] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,247] The parameter `learning_rate_init` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:29:58,248] The parameter `alpha` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:00,027] Trial 57 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 29, 'learning_rate': 'constant', 'learning_rate_init': 0.00015094613753824642, 'alpha': 0.0006841661003247827}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:00,030] The parameter `use_Logistic Regression` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,031] The parameter `use_Decision Tree` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,032] The parameter `use_Random Forest` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,032] The parameter `use_K-Nearest Neighbors` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,033] The parameter `use_Support Vector Machine` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,034] The parameter `use_AdaBoost` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,035] The parameter `use_Gradient Boosting` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,036] The parameter `n_layers` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,036] The parameter `n_neurons_0` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,036] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,036] The parameter `learning_rate_init` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:00,036] The parameter `alpha` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:01,077] Trial 58 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.008673717241575788, 'alpha': 0.00585560495923566}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:01,079] The parameter `use_Logistic Regression` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,079] The parameter `use_Decision Tree` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,079] The parameter `use_Random Forest` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,079] The parameter `use_K-Nearest Neighbors` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,085] The parameter `use_Support Vector Machine` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,085] The parameter `use_AdaBoost` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,087] The parameter `use_Gradient Boosting` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,087] The parameter `n_layers` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,087] The parameter `n_neurons_0` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,087] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,087] The parameter `n_neurons_2` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,087] The parameter `n_neurons_3` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,091] The parameter `n_neurons_4` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,091] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,092] The parameter `learning_rate_init` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:01,092] The parameter `alpha` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:03,256] Trial 59 finished with value: 0.86 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 34, 'n_neurons_1': 21, 'n_neurons_2': 90, 'n_neurons_3': 96, 'n_neurons_4': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0012639059001467116, 'alpha': 0.0001492703392407429}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:03,259] The parameter `use_Logistic Regression` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,260] The parameter `use_Decision Tree` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,261] The parameter `use_Random Forest` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,262] The parameter `use_K-Nearest Neighbors` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,263] The parameter `use_Support Vector Machine` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,263] The parameter `use_AdaBoost` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,264] The parameter `use_Gradient Boosting` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,265] The parameter `n_layers` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,266] The parameter `n_neurons_0` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,266] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,267] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,268] The parameter `learning_rate_init` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:03,268] The parameter `alpha` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:04,320] Trial 60 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003934160224360252, 'alpha': 0.0020744533327664858}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:04,323] The parameter `use_Logistic Regression` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,324] The parameter `use_Decision Tree` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,325] The parameter `use_Random Forest` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,326] The parameter `use_K-Nearest Neighbors` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,326] The parameter `use_Support Vector Machine` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,327] The parameter `use_AdaBoost` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,328] The parameter `use_Gradient Boosting` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,329] The parameter `n_layers` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,329] The parameter `n_neurons_0` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,330] The parameter `n_neurons_1` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,331] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,331] The parameter `learning_rate_init` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:04,332] The parameter `alpha` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:05,682] Trial 61 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010349883647557926, 'alpha': 0.00010298447122215186}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:05,685] The parameter `use_Logistic Regression` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,686] The parameter `use_Decision Tree` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,687] The parameter `use_Random Forest` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,688] The parameter `use_K-Nearest Neighbors` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,689] The parameter `use_Support Vector Machine` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,691] The parameter `use_AdaBoost` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,692] The parameter `use_Gradient Boosting` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:05,693] Trial 62 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:05,695] The parameter `use_Logistic Regression` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,697] The parameter `use_Decision Tree` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,698] The parameter `use_Random Forest` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,699] The parameter `use_K-Nearest Neighbors` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,700] The parameter `use_Support Vector Machine` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,701] The parameter `use_AdaBoost` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,702] The parameter `use_Gradient Boosting` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,703] The parameter `n_layers` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,704] The parameter `n_neurons_0` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,704] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,705] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,706] The parameter `n_neurons_3` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,707] The parameter `n_neurons_4` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,708] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,708] The parameter `learning_rate_init` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:05,709] The parameter `alpha` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:07,012] Trial 63 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 78, 'n_neurons_1': 21, 'n_neurons_2': 79, 'n_neurons_3': 12, 'n_neurons_4': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0034738801863753908, 'alpha': 0.002325898471109331}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:07,015] The parameter `use_Logistic Regression` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,016] The parameter `use_Decision Tree` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,018] The parameter `use_Random Forest` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,019] The parameter `use_K-Nearest Neighbors` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,020] The parameter `use_Support Vector Machine` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,021] The parameter `use_AdaBoost` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,022] The parameter `use_Gradient Boosting` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,023] The parameter `n_layers` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,024] The parameter `n_neurons_0` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,024] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,025] The parameter `learning_rate_init` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:07,026] The parameter `alpha` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:08,295] Trial 64 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 49, 'learning_rate': 'constant', 'learning_rate_init': 0.0018925697547456676, 'alpha': 0.0006240060436145399}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:08,298] The parameter `use_Logistic Regression` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,300] The parameter `use_Decision Tree` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,300] The parameter `use_Random Forest` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,300] The parameter `use_K-Nearest Neighbors` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,303] The parameter `use_Support Vector Machine` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,304] The parameter `use_AdaBoost` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,304] The parameter `use_Gradient Boosting` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:08,305] Trial 65 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:08,307] The parameter `use_Logistic Regression` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,309] The parameter `use_Decision Tree` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,310] The parameter `use_Random Forest` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,311] The parameter `use_K-Nearest Neighbors` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,311] The parameter `use_Support Vector Machine` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,312] The parameter `use_AdaBoost` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,312] The parameter `use_Gradient Boosting` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,313] The parameter `n_layers` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,314] The parameter `n_neurons_0` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,315] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,315] The parameter `n_neurons_2` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,315] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,315] The parameter `learning_rate_init` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:08,315] The parameter `alpha` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:09,633] Trial 66 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 54, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.003936572019640482, 'alpha': 0.00041756483518393106}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:09,637] The parameter `use_Logistic Regression` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,639] The parameter `use_Decision Tree` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,639] The parameter `use_Random Forest` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,641] The parameter `use_K-Nearest Neighbors` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,641] The parameter `use_Support Vector Machine` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,643] The parameter `use_AdaBoost` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,643] The parameter `use_Gradient Boosting` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,645] The parameter `n_layers` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,645] The parameter `n_neurons_0` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,647] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,647] The parameter `n_neurons_2` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,649] The parameter `n_neurons_3` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,651] The parameter `n_neurons_4` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,651] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,652] The parameter `learning_rate_init` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:09,653] The parameter `alpha` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:10,245] Trial 67 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 22, 'n_neurons_1': 55, 'n_neurons_2': 66, 'n_neurons_3': 73, 'n_neurons_4': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010849838825181713, 'alpha': 0.00014987631213878993}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:10,248] The parameter `use_Logistic Regression` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,249] The parameter `use_Decision Tree` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,250] The parameter `use_Random Forest` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,251] The parameter `use_K-Nearest Neighbors` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,252] The parameter `use_Support Vector Machine` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,253] The parameter `use_AdaBoost` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,253] The parameter `use_Gradient Boosting` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,254] The parameter `n_layers` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,255] The parameter `n_neurons_0` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,255] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,256] The parameter `n_neurons_2` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,257] The parameter `n_neurons_3` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,258] The parameter `n_neurons_4` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,259] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,259] The parameter `learning_rate_init` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:10,260] The parameter `alpha` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:11,458] Trial 68 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 59, 'n_neurons_2': 74, 'n_neurons_3': 89, 'n_neurons_4': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.004262360980898247, 'alpha': 0.0001446204447457985}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:11,462] The parameter `use_Logistic Regression` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,463] The parameter `use_Decision Tree` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,464] The parameter `use_Random Forest` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,465] The parameter `use_K-Nearest Neighbors` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,465] The parameter `use_Support Vector Machine` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,466] The parameter `use_AdaBoost` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,467] The parameter `use_Gradient Boosting` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,467] The parameter `n_layers` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,468] The parameter `n_neurons_0` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,469] The parameter `n_neurons_1` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,469] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,470] The parameter `learning_rate_init` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:11,471] The parameter `alpha` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:12,686] Trial 69 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 81, 'learning_rate': 'constant', 'learning_rate_init': 0.001290408163534379, 'alpha': 0.0027441228904630938}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:12,691] The parameter `use_Logistic Regression` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,692] The parameter `use_Decision Tree` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,694] The parameter `use_Random Forest` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,695] The parameter `use_K-Nearest Neighbors` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,695] The parameter `use_Support Vector Machine` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,696] The parameter `use_AdaBoost` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,697] The parameter `use_Gradient Boosting` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,698] The parameter `n_layers` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,698] The parameter `n_neurons_0` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,698] The parameter `n_neurons_1` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,698] The parameter `learning_rate` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,698] The parameter `learning_rate_init` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:12,698] The parameter `alpha` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:14,736] Trial 70 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014366494705598603, 'alpha': 0.0007537560974952886}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:14,740] The parameter `use_Logistic Regression` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,742] The parameter `use_Decision Tree` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,743] The parameter `use_Random Forest` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,744] The parameter `use_K-Nearest Neighbors` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,745] The parameter `use_Support Vector Machine` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,745] The parameter `use_AdaBoost` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,746] The parameter `use_Gradient Boosting` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,747] The parameter `n_layers` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,748] The parameter `n_neurons_0` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,748] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,749] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,750] The parameter `n_neurons_3` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,751] The parameter `n_neurons_4` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,751] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,752] The parameter `learning_rate_init` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:14,752] The parameter `alpha` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:16,026] Trial 71 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 26, 'n_neurons_1': 31, 'n_neurons_2': 98, 'n_neurons_3': 26, 'n_neurons_4': 87, 'learning_rate': 'constant', 'learning_rate_init': 0.005514419516648056, 'alpha': 0.0007773390943180892}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:16,028] The parameter `use_Logistic Regression` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,030] The parameter `use_Decision Tree` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,031] The parameter `use_Random Forest` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,032] The parameter `use_K-Nearest Neighbors` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,032] The parameter `use_Support Vector Machine` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,033] The parameter `use_AdaBoost` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,034] The parameter `use_Gradient Boosting` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,034] The parameter `n_layers` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,035] The parameter `n_neurons_0` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,036] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,037] The parameter `learning_rate_init` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:16,037] The parameter `alpha` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:17,163] Trial 72 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.004547437426011357, 'alpha': 0.0007274029320947825}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:17,165] The parameter `use_Logistic Regression` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,166] The parameter `use_Decision Tree` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,167] The parameter `use_Random Forest` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,168] The parameter `use_K-Nearest Neighbors` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,169] The parameter `use_Support Vector Machine` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,169] The parameter `use_AdaBoost` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,170] The parameter `use_Gradient Boosting` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,171] The parameter `n_layers` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,171] The parameter `n_neurons_0` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,172] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,173] The parameter `learning_rate_init` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:17,173] The parameter `alpha` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:18,501] Trial 73 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007468121665987528, 'alpha': 0.00011986353489802667}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:18,505] The parameter `use_Logistic Regression` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,507] The parameter `use_Decision Tree` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,508] The parameter `use_Random Forest` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,509] The parameter `use_K-Nearest Neighbors` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,510] The parameter `use_Support Vector Machine` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,511] The parameter `use_AdaBoost` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,512] The parameter `use_Gradient Boosting` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,513] The parameter `n_layers` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,513] The parameter `n_neurons_0` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,514] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,515] The parameter `n_neurons_2` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,515] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,516] The parameter `learning_rate_init` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:18,517] The parameter `alpha` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:20,250] Trial 74 finished with value: 0.86 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 70, 'n_neurons_2': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002566619712518178, 'alpha': 0.0002533418305370726}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:20,253] The parameter `use_Logistic Regression` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,254] The parameter `use_Decision Tree` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,255] The parameter `use_Random Forest` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,256] The parameter `use_K-Nearest Neighbors` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,256] The parameter `use_Support Vector Machine` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,257] The parameter `use_AdaBoost` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,258] The parameter `use_Gradient Boosting` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:20,259] Trial 75 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:20,260] The parameter `use_Logistic Regression` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,261] The parameter `use_Decision Tree` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,262] The parameter `use_Random Forest` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,263] The parameter `use_K-Nearest Neighbors` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,264] The parameter `use_Support Vector Machine` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,264] The parameter `use_AdaBoost` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,265] The parameter `use_Gradient Boosting` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,266] The parameter `n_layers` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,267] The parameter `n_neurons_0` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,267] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,268] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,269] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,269] The parameter `learning_rate_init` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:20,270] The parameter `alpha` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:22,375] Trial 76 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 81, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006431031596032392, 'alpha': 0.00045088555611044626}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:22,378] The parameter `use_Logistic Regression` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,379] The parameter `use_Decision Tree` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,379] The parameter `use_Random Forest` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,379] The parameter `use_K-Nearest Neighbors` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,379] The parameter `use_Support Vector Machine` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,379] The parameter `use_AdaBoost` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,384] The parameter `use_Gradient Boosting` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:22,385] Trial 77 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:22,386] The parameter `use_Logistic Regression` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,386] The parameter `use_Decision Tree` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,386] The parameter `use_Random Forest` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,386] The parameter `use_K-Nearest Neighbors` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,386] The parameter `use_Support Vector Machine` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,386] The parameter `use_AdaBoost` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,391] The parameter `use_Gradient Boosting` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,391] The parameter `n_layers` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,392] The parameter `n_neurons_0` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,393] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,394] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,395] The parameter `learning_rate_init` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:22,395] The parameter `alpha` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:24,113] Trial 78 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.0016436531848333894, 'alpha': 0.00338662042319669}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:24,116] The parameter `use_Logistic Regression` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,117] The parameter `use_Decision Tree` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,118] The parameter `use_Random Forest` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,119] The parameter `use_K-Nearest Neighbors` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,120] The parameter `use_Support Vector Machine` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,120] The parameter `use_AdaBoost` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,121] The parameter `use_Gradient Boosting` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,122] The parameter `n_layers` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,123] The parameter `n_neurons_0` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,124] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,124] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,125] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,126] The parameter `learning_rate_init` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:24,126] The parameter `alpha` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:25,657] Trial 79 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 33, 'n_neurons_1': 35, 'n_neurons_2': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0004193874191709548, 'alpha': 0.001662139868133609}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:25,660] The parameter `use_Logistic Regression` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,661] The parameter `use_Decision Tree` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,662] The parameter `use_Random Forest` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,663] The parameter `use_K-Nearest Neighbors` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,663] The parameter `use_Support Vector Machine` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,664] The parameter `use_AdaBoost` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,665] The parameter `use_Gradient Boosting` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,665] The parameter `n_layers` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,666] The parameter `n_neurons_0` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,667] The parameter `n_neurons_1` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,668] The parameter `n_neurons_2` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,668] The parameter `n_neurons_3` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,669] The parameter `n_neurons_4` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,670] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,670] The parameter `learning_rate_init` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:25,671] The parameter `alpha` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:28,303] Trial 80 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 60, 'n_neurons_1': 13, 'n_neurons_2': 67, 'n_neurons_3': 96, 'n_neurons_4': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002858640510403272, 'alpha': 0.00026551537824360454}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:28,306] The parameter `use_Logistic Regression` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,307] The parameter `use_Decision Tree` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,308] The parameter `use_Random Forest` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,309] The parameter `use_K-Nearest Neighbors` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,309] The parameter `use_Support Vector Machine` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,311] The parameter `use_AdaBoost` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,312] The parameter `use_Gradient Boosting` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,313] The parameter `n_layers` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,314] The parameter `n_neurons_0` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,314] The parameter `n_neurons_1` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,315] The parameter `n_neurons_2` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,315] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,315] The parameter `learning_rate_init` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:28,315] The parameter `alpha` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:30,349] Trial 81 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 25, 'n_neurons_1': 77, 'n_neurons_2': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00011150059170836743, 'alpha': 0.0019228393487042126}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:30,352] The parameter `use_Logistic Regression` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,353] The parameter `use_Decision Tree` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,354] The parameter `use_Random Forest` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,355] The parameter `use_K-Nearest Neighbors` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,356] The parameter `use_Support Vector Machine` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,356] The parameter `use_AdaBoost` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,357] The parameter `use_Gradient Boosting` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,358] The parameter `n_layers` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,358] The parameter `n_neurons_0` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,359] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,360] The parameter `learning_rate_init` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:30,360] The parameter `alpha` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:31,604] Trial 82 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.0003534445856055918, 'alpha': 0.0001441579965339067}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:31,607] The parameter `use_Logistic Regression` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,609] The parameter `use_Decision Tree` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,610] The parameter `use_Random Forest` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,610] The parameter `use_K-Nearest Neighbors` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,611] The parameter `use_Support Vector Machine` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,612] The parameter `use_AdaBoost` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,612] The parameter `use_Gradient Boosting` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:31,613] Trial 83 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:31,614] The parameter `use_Logistic Regression` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,616] The parameter `use_Decision Tree` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,617] The parameter `use_Random Forest` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,617] The parameter `use_K-Nearest Neighbors` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,618] The parameter `use_Support Vector Machine` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,619] The parameter `use_AdaBoost` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,619] The parameter `use_Gradient Boosting` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,620] The parameter `n_layers` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,621] The parameter `n_neurons_0` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,622] The parameter `n_neurons_1` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,623] The parameter `learning_rate` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,623] The parameter `learning_rate_init` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:31,624] The parameter `alpha` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:32,759] Trial 84 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 58, 'n_neurons_1': 18, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004956134097083741, 'alpha': 0.002137093133753237}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:32,764] The parameter `use_Logistic Regression` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,764] The parameter `use_Decision Tree` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,766] The parameter `use_Random Forest` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,767] The parameter `use_K-Nearest Neighbors` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,768] The parameter `use_Support Vector Machine` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,769] The parameter `use_AdaBoost` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,769] The parameter `use_Gradient Boosting` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,770] The parameter `n_layers` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,771] The parameter `n_neurons_0` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,771] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,772] The parameter `n_neurons_2` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,773] The parameter `n_neurons_3` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,774] The parameter `n_neurons_4` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,774] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,775] The parameter `learning_rate_init` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:32,776] The parameter `alpha` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:34,298] Trial 85 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 81, 'n_neurons_1': 74, 'n_neurons_2': 13, 'n_neurons_3': 37, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.007480241960748882, 'alpha': 0.001281163276357022}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:34,302] The parameter `use_Logistic Regression` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,303] The parameter `use_Decision Tree` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,304] The parameter `use_Random Forest` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,305] The parameter `use_K-Nearest Neighbors` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,306] The parameter `use_Support Vector Machine` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,306] The parameter `use_AdaBoost` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,307] The parameter `use_Gradient Boosting` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,308] The parameter `n_layers` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,308] The parameter `n_neurons_0` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,309] The parameter `n_neurons_1` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,310] The parameter `n_neurons_2` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,310] The parameter `n_neurons_3` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,311] The parameter `n_neurons_4` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,312] The parameter `learning_rate` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,312] The parameter `learning_rate_init` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:34,313] The parameter `alpha` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:35,836] Trial 86 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 83, 'n_neurons_2': 81, 'n_neurons_3': 37, 'n_neurons_4': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.0024541560696713445, 'alpha': 0.0004922655605142162}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:35,836] The parameter `use_Logistic Regression` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,836] The parameter `use_Decision Tree` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,836] The parameter `use_Random Forest` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,842] The parameter `use_K-Nearest Neighbors` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,843] The parameter `use_Support Vector Machine` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,844] The parameter `use_AdaBoost` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,844] The parameter `use_Gradient Boosting` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,845] The parameter `n_layers` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,846] The parameter `n_neurons_0` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,846] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,847] The parameter `learning_rate_init` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:35,848] The parameter `alpha` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:36,874] Trial 87 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012562008177756832, 'alpha': 0.008543667186048135}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:36,874] The parameter `use_Logistic Regression` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,886] The parameter `use_Decision Tree` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,886] The parameter `use_Random Forest` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,886] The parameter `use_K-Nearest Neighbors` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,889] The parameter `use_Support Vector Machine` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,889] The parameter `use_AdaBoost` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,889] The parameter `use_Gradient Boosting` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,891] The parameter `n_layers` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,892] The parameter `n_neurons_0` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,892] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,893] The parameter `n_neurons_2` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,894] The parameter `n_neurons_3` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,894] The parameter `n_neurons_4` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,895] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,895] The parameter `learning_rate_init` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:36,896] The parameter `alpha` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:39,454] Trial 88 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 15, 'n_neurons_1': 73, 'n_neurons_2': 99, 'n_neurons_3': 31, 'n_neurons_4': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015925446667814006, 'alpha': 0.002422828554185797}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:39,457] The parameter `use_Logistic Regression` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,459] The parameter `use_Decision Tree` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,459] The parameter `use_Random Forest` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,460] The parameter `use_K-Nearest Neighbors` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,461] The parameter `use_Support Vector Machine` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,462] The parameter `use_AdaBoost` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,463] The parameter `use_Gradient Boosting` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,463] The parameter `n_layers` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,464] The parameter `n_neurons_0` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,465] The parameter `n_neurons_1` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,466] The parameter `n_neurons_2` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,467] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,467] The parameter `learning_rate_init` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:39,468] The parameter `alpha` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:41,679] Trial 89 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 76, 'n_neurons_2': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009176737380720279, 'alpha': 0.00010924071993869074}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:41,682] The parameter `use_Logistic Regression` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,684] The parameter `use_Decision Tree` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,684] The parameter `use_Random Forest` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,685] The parameter `use_K-Nearest Neighbors` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,686] The parameter `use_Support Vector Machine` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,687] The parameter `use_AdaBoost` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,687] The parameter `use_Gradient Boosting` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,688] The parameter `n_layers` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,689] The parameter `n_neurons_0` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,690] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,691] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,691] The parameter `n_neurons_3` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,692] The parameter `n_neurons_4` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,693] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,693] The parameter `learning_rate_init` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:41,694] The parameter `alpha` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:43,549] Trial 90 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 18, 'n_neurons_1': 54, 'n_neurons_2': 23, 'n_neurons_3': 39, 'n_neurons_4': 77, 'learning_rate': 'constant', 'learning_rate_init': 0.0006151096737070389, 'alpha': 0.0008296473623735454}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:43,551] The parameter `use_Logistic Regression` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,553] The parameter `use_Decision Tree` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,553] The parameter `use_Random Forest` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,554] The parameter `use_K-Nearest Neighbors` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,555] The parameter `use_Support Vector Machine` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,555] The parameter `use_AdaBoost` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,556] The parameter `use_Gradient Boosting` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,557] The parameter `n_layers` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,558] The parameter `n_neurons_0` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,558] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,559] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,560] The parameter `n_neurons_3` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,560] The parameter `n_neurons_4` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,561] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,562] The parameter `learning_rate_init` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:43,562] The parameter `alpha` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:44,692] Trial 91 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 67, 'n_neurons_1': 65, 'n_neurons_2': 16, 'n_neurons_3': 57, 'n_neurons_4': 23, 'learning_rate': 'constant', 'learning_rate_init': 0.0022932719467128214, 'alpha': 0.00012115624400696192}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:44,695] The parameter `use_Logistic Regression` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,696] The parameter `use_Decision Tree` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,697] The parameter `use_Random Forest` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,698] The parameter `use_K-Nearest Neighbors` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,698] The parameter `use_Support Vector Machine` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,699] The parameter `use_AdaBoost` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,700] The parameter `use_Gradient Boosting` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,701] The parameter `n_layers` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,701] The parameter `n_neurons_0` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,702] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,703] The parameter `learning_rate_init` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:44,703] The parameter `alpha` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:46,250] Trial 92 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.00011012601445612862, 'alpha': 0.0001459967993464517}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:46,253] The parameter `use_Logistic Regression` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,254] The parameter `use_Decision Tree` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,255] The parameter `use_Random Forest` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,256] The parameter `use_K-Nearest Neighbors` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,256] The parameter `use_Support Vector Machine` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,257] The parameter `use_AdaBoost` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,258] The parameter `use_Gradient Boosting` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,259] The parameter `n_layers` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,259] The parameter `n_neurons_0` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,260] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,261] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,261] The parameter `learning_rate_init` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:46,262] The parameter `alpha` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:47,855] Trial 93 finished with value: 0.86 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004202808250827565, 'alpha': 0.0020556880660352003}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:47,858] The parameter `use_Logistic Regression` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,859] The parameter `use_Decision Tree` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,860] The parameter `use_Random Forest` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,861] The parameter `use_K-Nearest Neighbors` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,862] The parameter `use_Support Vector Machine` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,862] The parameter `use_AdaBoost` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,863] The parameter `use_Gradient Boosting` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,864] The parameter `n_layers` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,865] The parameter `n_neurons_0` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,865] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,866] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,866] The parameter `learning_rate_init` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:47,867] The parameter `alpha` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:49,450] Trial 94 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 84, 'n_neurons_1': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003195082233827963, 'alpha': 0.0032365614534194923}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:49,453] The parameter `use_Logistic Regression` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,454] The parameter `use_Decision Tree` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,455] The parameter `use_Random Forest` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,456] The parameter `use_K-Nearest Neighbors` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,457] The parameter `use_Support Vector Machine` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,457] The parameter `use_AdaBoost` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,458] The parameter `use_Gradient Boosting` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,459] The parameter `n_layers` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,460] The parameter `n_neurons_0` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,460] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,461] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,462] The parameter `learning_rate_init` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:49,462] The parameter `alpha` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:50,850] Trial 95 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0015159866641908737, 'alpha': 0.0010392525381080842}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:50,852] The parameter `use_Logistic Regression` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,855] The parameter `use_Decision Tree` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,855] The parameter `use_Random Forest` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,856] The parameter `use_K-Nearest Neighbors` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,857] The parameter `use_Support Vector Machine` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,858] The parameter `use_AdaBoost` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,858] The parameter `use_Gradient Boosting` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:50,859] Trial 96 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:50,859] The parameter `use_Logistic Regression` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,859] The parameter `use_Decision Tree` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,859] The parameter `use_Random Forest` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,859] The parameter `use_K-Nearest Neighbors` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,859] The parameter `use_Support Vector Machine` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,865] The parameter `use_AdaBoost` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,866] The parameter `use_Gradient Boosting` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,866] The parameter `n_layers` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,867] The parameter `n_neurons_0` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,868] The parameter `n_neurons_1` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,869] The parameter `n_neurons_2` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,869] The parameter `n_neurons_3` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,870] The parameter `n_neurons_4` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,871] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,871] The parameter `learning_rate_init` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:50,872] The parameter `alpha` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:53,381] Trial 97 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 39, 'n_neurons_2': 23, 'n_neurons_3': 37, 'n_neurons_4': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.0007892621240300501, 'alpha': 0.0027806214997722505}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:53,384] The parameter `use_Logistic Regression` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,385] The parameter `use_Decision Tree` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,387] The parameter `use_Random Forest` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,387] The parameter `use_K-Nearest Neighbors` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,388] The parameter `use_Support Vector Machine` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,389] The parameter `use_AdaBoost` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,390] The parameter `use_Gradient Boosting` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,391] The parameter `n_layers` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,391] The parameter `n_neurons_0` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,392] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,393] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,393] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,394] The parameter `learning_rate_init` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:53,395] The parameter `alpha` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:30:55,675] Trial 98 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 61, 'n_neurons_2': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003464506976855204, 'alpha': 0.004467852431220893}. Best is trial 30 with value: 0.9333333333333333.\n",
      "[W 2025-10-06 13:30:55,678] The parameter `use_Logistic Regression` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,679] The parameter `use_Decision Tree` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,680] The parameter `use_Random Forest` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,680] The parameter `use_K-Nearest Neighbors` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,681] The parameter `use_Support Vector Machine` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,682] The parameter `use_AdaBoost` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,683] The parameter `use_Gradient Boosting` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,683] The parameter `n_layers` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,684] The parameter `n_neurons_0` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,685] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,686] The parameter `n_neurons_2` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,686] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,687] The parameter `learning_rate_init` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:30:55,688] The parameter `alpha` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:30:57,571] Trial 99 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 76, 'n_neurons_1': 100, 'n_neurons_2': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.0018722107277466084, 'alpha': 0.0037265181101734106}. Best is trial 30 with value: 0.9333333333333333.\n",
      "\n",
      "Selected Base Models for Stacking using CmaEsSampler:\n",
      "- K-Nearest Neighbors\n",
      "- Support Vector Machine\n",
      "- AdaBoost\n",
      "- Gradient Boosting\n",
      "Best Hyperparameters for Meta Model (MLP) using CmaEsSampler: {'learning_rate': 'adaptive', 'learning_rate_init': 0.0001952045318704599, 'alpha': 0.0016312041807207015, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (52, 100, 100), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9333, at trial: 30\n",
      "CMA-ES base models training time: 85.31 seconds\n",
      "CMA-ES SEl-NNML Training Time: 140.97 seconds\n",
      "Total CMA-ES Training Time (Base + Meta): 226.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cmaes_meta_model_training_start = time.time()\n",
    "\n",
    "# Meta Model Tuning and Final Stacking Model Fitting\n",
    "cmaes_sel_nnml = meta_model_tuning(base_models['CMA-ES'], X_train, y_train, X_test, y_test, sampler='CmaEsSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE) \n",
    "cmaes_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "cmaes_meta_model_training_end = time.time()\n",
    "\n",
    "# Time taken for CMA-ES SEl-NNML training\n",
    "cmaes_meta_model_training_time = cmaes_meta_model_training_end - cmaes_meta_model_training_start\n",
    "print(f'CMA-ES base models training time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "print(f'CMA-ES SEl-NNML Training Time: {cmaes_meta_model_training_time:.2f} seconds')\n",
    "print(f'Total CMA-ES Training Time (Base + Meta): {cmaes_base_models_training_time + cmaes_meta_model_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\Eksperimen\\3_most_final_experiment\\notebooks\\src\\model_tuning_algorithm.py:178: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-10-06 13:30:59,921] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (QMCSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e87e29137ab43b0969d901db16b381b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:31:01,998] Trial 0 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:02,002] The parameter `use_Logistic Regression` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:02,004] The parameter `use_Decision Tree` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:02,005] The parameter `use_Random Forest` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:02,005] The parameter `use_K-Nearest Neighbors` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:02,006] The parameter `use_Support Vector Machine` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:02,007] The parameter `use_AdaBoost` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:02,008] The parameter `use_Gradient Boosting` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:02,009] The parameter `learning_rate` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:31:03,569] Trial 1 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 10, 'learning_rate': 'constant', 'learning_rate_init': 0.00010000000000000009, 'alpha': 0.00010000000000000009}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:03,572] The parameter `use_Logistic Regression` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,574] The parameter `use_Decision Tree` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,574] The parameter `use_Random Forest` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,575] The parameter `use_K-Nearest Neighbors` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,576] The parameter `use_Support Vector Machine` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,576] The parameter `use_AdaBoost` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,577] The parameter `use_Gradient Boosting` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,578] The parameter `n_neurons_1` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,578] The parameter `n_neurons_2` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:03,579] The parameter `learning_rate` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:06,137] Trial 2 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 55, 'n_neurons_1': 98, 'n_neurons_2': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0010000000000000002, 'alpha': 0.0010000000000000002}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:06,140] The parameter `use_Logistic Regression` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,141] The parameter `use_Decision Tree` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,142] The parameter `use_Random Forest` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,143] The parameter `use_K-Nearest Neighbors` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,144] The parameter `use_Support Vector Machine` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,145] The parameter `use_AdaBoost` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,145] The parameter `use_Gradient Boosting` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,146] The parameter `n_neurons_1` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,147] The parameter `n_neurons_2` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,147] The parameter `n_neurons_3` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,148] The parameter `learning_rate` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:06,947] Trial 3 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 16, 'n_neurons_2': 99, 'n_neurons_3': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0003162277660168384, 'alpha': 0.0003162277660168384}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:06,951] The parameter `use_Logistic Regression` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,952] The parameter `use_Decision Tree` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,953] The parameter `use_Random Forest` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,953] The parameter `use_K-Nearest Neighbors` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,954] The parameter `use_Support Vector Machine` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,955] The parameter `use_AdaBoost` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,956] The parameter `use_Gradient Boosting` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,957] The parameter `n_neurons_1` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:06,957] The parameter `learning_rate` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:07,288] Trial 4 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 78, 'n_neurons_1': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.003162277660168382, 'alpha': 0.003162277660168382}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:07,291] The parameter `use_Logistic Regression` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:07,292] The parameter `use_Decision Tree` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:07,293] The parameter `use_Random Forest` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:07,294] The parameter `use_K-Nearest Neighbors` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:07,295] The parameter `use_Support Vector Machine` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:07,295] The parameter `use_AdaBoost` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:07,296] The parameter `use_Gradient Boosting` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:07,297] The parameter `n_neurons_1` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:07,298] The parameter `learning_rate` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:08,775] Trial 5 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017782794100389236, 'alpha': 0.005623413251903492}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:08,778] The parameter `use_Logistic Regression` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,779] The parameter `use_Decision Tree` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,780] The parameter `use_Random Forest` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,781] The parameter `use_K-Nearest Neighbors` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,781] The parameter `use_Support Vector Machine` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,782] The parameter `use_AdaBoost` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,783] The parameter `use_Gradient Boosting` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,784] The parameter `n_neurons_1` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,785] The parameter `n_neurons_2` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,785] The parameter `n_neurons_3` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,786] The parameter `n_neurons_4` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:08,787] The parameter `learning_rate` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:10,027] Trial 6 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 89, 'n_neurons_1': 91, 'n_neurons_2': 38, 'n_neurons_3': 20, 'n_neurons_4': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017782794100389232, 'alpha': 0.0005623413251903495}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:10,030] The parameter `use_Logistic Regression` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,031] The parameter `use_Decision Tree` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,032] The parameter `use_Random Forest` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,033] The parameter `use_K-Nearest Neighbors` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,034] The parameter `use_Support Vector Machine` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,035] The parameter `use_AdaBoost` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,036] The parameter `use_Gradient Boosting` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,037] The parameter `n_neurons_1` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,037] The parameter `n_neurons_2` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,038] The parameter `n_neurons_3` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:10,039] The parameter `learning_rate` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:12,037] Trial 7 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 21, 'n_neurons_1': 32, 'n_neurons_2': 55, 'n_neurons_3': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.005623413251903492, 'alpha': 0.0017782794100389236}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:12,040] The parameter `use_Logistic Regression` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:12,041] The parameter `use_Decision Tree` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:12,042] The parameter `use_Random Forest` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:12,043] The parameter `use_K-Nearest Neighbors` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:12,043] The parameter `use_Support Vector Machine` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:12,044] The parameter `use_AdaBoost` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:12,045] The parameter `use_Gradient Boosting` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:12,046] The parameter `learning_rate` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:13,350] Trial 8 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 66, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005623413251903495, 'alpha': 0.00017782794100389232}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:13,353] The parameter `use_Logistic Regression` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:13,354] The parameter `use_Decision Tree` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:13,355] The parameter `use_Random Forest` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:13,355] The parameter `use_K-Nearest Neighbors` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:13,356] The parameter `use_Support Vector Machine` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:13,356] The parameter `use_AdaBoost` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:13,357] The parameter `use_Gradient Boosting` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:13,358] The parameter `learning_rate` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:15,453] Trial 9 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 38, 'learning_rate': 'constant', 'learning_rate_init': 0.007498942093324564, 'alpha': 0.0007498942093324562}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:15,456] The parameter `use_Logistic Regression` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,457] The parameter `use_Decision Tree` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,458] The parameter `use_Random Forest` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,458] The parameter `use_K-Nearest Neighbors` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,460] The parameter `use_Support Vector Machine` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,460] The parameter `use_AdaBoost` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,460] The parameter `use_Gradient Boosting` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,460] The parameter `n_neurons_1` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,460] The parameter `n_neurons_2` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,460] The parameter `n_neurons_3` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:15,460] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:31:18,318] Trial 10 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 67, 'n_neurons_3': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007498942093324562, 'alpha': 0.007498942093324564}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:18,324] The parameter `use_Logistic Regression` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,326] The parameter `use_Decision Tree` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,327] The parameter `use_Random Forest` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,327] The parameter `use_K-Nearest Neighbors` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,329] The parameter `use_Support Vector Machine` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,330] The parameter `use_AdaBoost` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,330] The parameter `use_Gradient Boosting` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,331] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,332] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,333] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,333] The parameter `n_neurons_4` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:18,334] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:20,025] Trial 11 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 15, 'n_neurons_1': 72, 'n_neurons_2': 69, 'n_neurons_3': 30, 'n_neurons_4': 74, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002371373705661656, 'alpha': 0.00023713737056616573}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:20,028] The parameter `use_Logistic Regression` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,029] The parameter `use_Decision Tree` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,030] The parameter `use_Random Forest` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,030] The parameter `use_K-Nearest Neighbors` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,031] The parameter `use_Support Vector Machine` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,032] The parameter `use_AdaBoost` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,033] The parameter `use_Gradient Boosting` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,034] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,034] The parameter `n_neurons_2` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:20,035] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:21,669] Trial 12 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 55, 'n_neurons_2': 62, 'learning_rate': 'constant', 'learning_rate_init': 0.00023713737056616573, 'alpha': 0.002371373705661656}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:21,673] The parameter `use_Logistic Regression` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:21,674] The parameter `use_Decision Tree` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:21,675] The parameter `use_Random Forest` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:21,676] The parameter `use_K-Nearest Neighbors` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:21,676] The parameter `use_Support Vector Machine` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:21,677] The parameter `use_AdaBoost` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:21,678] The parameter `use_Gradient Boosting` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:21,678] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:21,679] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:23,869] Trial 13 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 27, 'n_neurons_1': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00042169650342858235, 'alpha': 0.0013335214321633251}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:23,872] The parameter `use_Logistic Regression` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,873] The parameter `use_Decision Tree` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,873] The parameter `use_Random Forest` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,875] The parameter `use_K-Nearest Neighbors` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,875] The parameter `use_Support Vector Machine` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,876] The parameter `use_AdaBoost` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,876] The parameter `use_Gradient Boosting` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,878] The parameter `n_neurons_1` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,878] The parameter `n_neurons_2` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,878] The parameter `n_neurons_3` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,878] The parameter `n_neurons_4` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:23,878] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:26,126] Trial 14 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 72, 'n_neurons_1': 73, 'n_neurons_2': 73, 'n_neurons_3': 42, 'n_neurons_4': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004216965034285825, 'alpha': 0.0001333521432163326}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:26,129] The parameter `use_Logistic Regression` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,130] The parameter `use_Decision Tree` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,131] The parameter `use_Random Forest` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,132] The parameter `use_K-Nearest Neighbors` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,132] The parameter `use_Support Vector Machine` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,133] The parameter `use_AdaBoost` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,134] The parameter `use_Gradient Boosting` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,135] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,136] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:26,136] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:28,550] Trial 15 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 52, 'n_neurons_2': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001333521432163326, 'alpha': 0.004216965034285825}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:28,553] The parameter `use_Logistic Regression` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,554] The parameter `use_Decision Tree` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,555] The parameter `use_Random Forest` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,556] The parameter `use_K-Nearest Neighbors` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,557] The parameter `use_Support Vector Machine` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,557] The parameter `use_AdaBoost` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,558] The parameter `use_Gradient Boosting` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,559] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:28,923] Trial 16 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013335214321633251, 'alpha': 0.00042169650342858235}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:28,926] The parameter `use_Logistic Regression` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,927] The parameter `use_Decision Tree` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,928] The parameter `use_Random Forest` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,928] The parameter `use_K-Nearest Neighbors` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,929] The parameter `use_Support Vector Machine` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,930] The parameter `use_AdaBoost` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,930] The parameter `use_Gradient Boosting` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:28,931] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:30,494] Trial 17 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000865964323360066, 'alpha': 0.0020535250264571477}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:30,498] The parameter `use_Logistic Regression` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,499] The parameter `use_Decision Tree` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,499] The parameter `use_Random Forest` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,500] The parameter `use_K-Nearest Neighbors` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,501] The parameter `use_Support Vector Machine` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,502] The parameter `use_AdaBoost` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,502] The parameter `use_Gradient Boosting` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,503] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,504] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:30,505] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:32,277] Trial 18 finished with value: 0.8733333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 98, 'n_neurons_1': 87, 'n_neurons_2': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.008659643233600654, 'alpha': 0.0002053525026457149}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:32,280] The parameter `use_Logistic Regression` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,281] The parameter `use_Decision Tree` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,282] The parameter `use_Random Forest` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,283] The parameter `use_K-Nearest Neighbors` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,284] The parameter `use_Support Vector Machine` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,284] The parameter `use_AdaBoost` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,285] The parameter `use_Gradient Boosting` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,286] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,287] The parameter `n_neurons_2` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,288] The parameter `n_neurons_3` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,288] The parameter `n_neurons_4` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:32,289] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:34,318] Trial 19 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 29, 'n_neurons_1': 16, 'n_neurons_2': 68, 'n_neurons_3': 12, 'n_neurons_4': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.0002738419634264362, 'alpha': 0.0064938163157621165}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:34,326] The parameter `use_Logistic Regression` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:34,327] The parameter `use_Decision Tree` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:34,328] The parameter `use_Random Forest` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:34,328] The parameter `use_K-Nearest Neighbors` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:34,329] The parameter `use_Support Vector Machine` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:34,331] The parameter `use_AdaBoost` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:34,332] The parameter `use_Gradient Boosting` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:34,333] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:34,333] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:31:36,329] Trial 20 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0027384196342643626, 'alpha': 0.0006493816315762115}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:36,333] The parameter `use_Logistic Regression` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,334] The parameter `use_Decision Tree` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,335] The parameter `use_Random Forest` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,336] The parameter `use_K-Nearest Neighbors` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,337] The parameter `use_Support Vector Machine` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,337] The parameter `use_AdaBoost` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,338] The parameter `use_Gradient Boosting` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,339] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,340] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:36,340] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:37,832] Trial 21 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 18, 'n_neurons_1': 47, 'n_neurons_2': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.004869675251658635, 'alpha': 0.000365174127254838}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:37,837] The parameter `use_Logistic Regression` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,838] The parameter `use_Decision Tree` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,839] The parameter `use_Random Forest` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,839] The parameter `use_K-Nearest Neighbors` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,839] The parameter `use_Support Vector Machine` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,839] The parameter `use_AdaBoost` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,841] The parameter `use_Gradient Boosting` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,841] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,843] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,843] The parameter `n_neurons_3` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,843] The parameter `n_neurons_4` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:37,845] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:31:40,847] Trial 22 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 64, 'n_neurons_1': 18, 'n_neurons_2': 39, 'n_neurons_3': 96, 'n_neurons_4': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00048696752516586337, 'alpha': 0.0036517412725483775}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:40,851] The parameter `use_Logistic Regression` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,852] The parameter `use_Decision Tree` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,853] The parameter `use_Random Forest` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,854] The parameter `use_K-Nearest Neighbors` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,854] The parameter `use_Support Vector Machine` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,855] The parameter `use_AdaBoost` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,856] The parameter `use_Gradient Boosting` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,857] The parameter `n_neurons_1` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,858] The parameter `n_neurons_2` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,858] The parameter `n_neurons_3` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:40,859] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:43,576] Trial 23 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 41, 'n_neurons_1': 20, 'n_neurons_2': 23, 'n_neurons_3': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.0015399265260594922, 'alpha': 0.00011547819846894585}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:43,576] The parameter `use_Logistic Regression` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:43,576] The parameter `use_Decision Tree` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:43,576] The parameter `use_Random Forest` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:43,583] The parameter `use_K-Nearest Neighbors` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:43,583] The parameter `use_Support Vector Machine` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:43,585] The parameter `use_AdaBoost` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:43,585] The parameter `use_Gradient Boosting` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:43,587] The parameter `n_neurons_1` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:43,587] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:45,899] Trial 24 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 86, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015399265260594933, 'alpha': 0.0011547819846894588}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:45,903] The parameter `use_Logistic Regression` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:45,905] The parameter `use_Decision Tree` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:45,905] The parameter `use_Random Forest` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:45,907] The parameter `use_K-Nearest Neighbors` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:45,907] The parameter `use_Support Vector Machine` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:45,908] The parameter `use_AdaBoost` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:45,909] The parameter `use_Gradient Boosting` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:45,910] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:47,113] Trial 25 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0011547819846894588, 'alpha': 0.004869675251658635}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:47,113] The parameter `use_Logistic Regression` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,113] The parameter `use_Decision Tree` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,113] The parameter `use_Random Forest` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,113] The parameter `use_K-Nearest Neighbors` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,113] The parameter `use_Support Vector Machine` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,122] The parameter `use_AdaBoost` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,122] The parameter `use_Gradient Boosting` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,122] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,122] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,122] The parameter `n_neurons_3` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:47,125] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:48,900] Trial 26 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 69, 'n_neurons_1': 73, 'n_neurons_2': 51, 'n_neurons_3': 67, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011547819846894585, 'alpha': 0.00048696752516586337}. Best is trial 0 with value: 0.92.\n",
      "[W 2025-10-06 13:31:48,903] The parameter `use_Logistic Regression` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,904] The parameter `use_Decision Tree` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,907] The parameter `use_Random Forest` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,908] The parameter `use_K-Nearest Neighbors` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,909] The parameter `use_Support Vector Machine` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,910] The parameter `use_AdaBoost` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,911] The parameter `use_Gradient Boosting` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,913] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,914] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,914] The parameter `n_neurons_3` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,915] The parameter `n_neurons_4` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:48,916] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:50,376] Trial 27 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 46, 'n_neurons_1': 73, 'n_neurons_2': 58, 'n_neurons_3': 38, 'n_neurons_4': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.0036517412725483775, 'alpha': 0.0015399265260594922}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:31:50,379] The parameter `use_Logistic Regression` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,381] The parameter `use_Decision Tree` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,382] The parameter `use_Random Forest` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,382] The parameter `use_K-Nearest Neighbors` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,383] The parameter `use_Support Vector Machine` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,384] The parameter `use_AdaBoost` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,385] The parameter `use_Gradient Boosting` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,386] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,386] The parameter `n_neurons_2` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:50,387] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:31:53,279] Trial 28 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 92, 'n_neurons_1': 64, 'n_neurons_2': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.000365174127254838, 'alpha': 0.00015399265260594933}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:31:53,283] The parameter `use_Logistic Regression` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:53,285] The parameter `use_Decision Tree` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:53,285] The parameter `use_Random Forest` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:53,286] The parameter `use_K-Nearest Neighbors` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:53,287] The parameter `use_Support Vector Machine` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:53,288] The parameter `use_AdaBoost` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:53,288] The parameter `use_Gradient Boosting` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:53,289] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:53,290] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:55,577] Trial 29 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 35, 'n_neurons_1': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002053525026457149, 'alpha': 0.0002738419634264362}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:31:55,579] The parameter `use_Logistic Regression` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,581] The parameter `use_Decision Tree` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,581] The parameter `use_Random Forest` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,581] The parameter `use_K-Nearest Neighbors` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,581] The parameter `use_Support Vector Machine` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,581] The parameter `use_AdaBoost` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,581] The parameter `use_Gradient Boosting` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,586] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,587] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,587] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:55,587] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:57,983] Trial 30 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 81, 'n_neurons_1': 46, 'n_neurons_2': 22, 'n_neurons_3': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0020535250264571477, 'alpha': 0.0027384196342643626}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:31:57,987] The parameter `use_Logistic Regression` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,988] The parameter `use_Decision Tree` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,990] The parameter `use_Random Forest` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,991] The parameter `use_K-Nearest Neighbors` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,991] The parameter `use_Support Vector Machine` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,992] The parameter `use_AdaBoost` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,993] The parameter `use_Gradient Boosting` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,994] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,995] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:57,995] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:31:58,738] Trial 31 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 12, 'n_neurons_1': 88, 'n_neurons_2': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006493816315762115, 'alpha': 0.000865964323360066}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:31:58,741] The parameter `use_Logistic Regression` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:58,743] The parameter `use_Decision Tree` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:58,744] The parameter `use_Random Forest` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:58,744] The parameter `use_K-Nearest Neighbors` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:58,745] The parameter `use_Support Vector Machine` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:58,746] The parameter `use_AdaBoost` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:58,747] The parameter `use_Gradient Boosting` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:31:58,747] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:00,148] Trial 32 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0064938163157621165, 'alpha': 0.008659643233600654}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:00,151] The parameter `use_Logistic Regression` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:00,152] The parameter `use_Decision Tree` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:00,153] The parameter `use_Random Forest` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:00,153] The parameter `use_K-Nearest Neighbors` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:00,154] The parameter `use_Support Vector Machine` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:00,155] The parameter `use_AdaBoost` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:00,155] The parameter `use_Gradient Boosting` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:00,156] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:01,483] Trial 33 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0025482967479793484, 'alpha': 0.0012409377607517208}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:01,487] The parameter `use_Logistic Regression` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,489] The parameter `use_Decision Tree` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,489] The parameter `use_Random Forest` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,491] The parameter `use_K-Nearest Neighbors` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,493] The parameter `use_Support Vector Machine` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,493] The parameter `use_AdaBoost` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,494] The parameter `use_Gradient Boosting` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,495] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,495] The parameter `n_neurons_2` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,496] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:01,954] Trial 34 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 79, 'n_neurons_1': 66, 'n_neurons_2': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002548296747979348, 'alpha': 0.00012409377607517218}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:01,957] The parameter `use_Logistic Regression` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,958] The parameter `use_Decision Tree` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,960] The parameter `use_Random Forest` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,961] The parameter `use_K-Nearest Neighbors` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,961] The parameter `use_Support Vector Machine` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,962] The parameter `use_AdaBoost` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,963] The parameter `use_Gradient Boosting` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:01,963] Trial 35 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:01,965] The parameter `use_Logistic Regression` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,966] The parameter `use_Decision Tree` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,967] The parameter `use_Random Forest` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,968] The parameter `use_K-Nearest Neighbors` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,969] The parameter `use_Support Vector Machine` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,969] The parameter `use_AdaBoost` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,970] The parameter `use_Gradient Boosting` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,971] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:01,972] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:03,893] Trial 36 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 35, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008058421877614828, 'alpha': 0.0003924189758484538}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:03,897] The parameter `use_Logistic Regression` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,897] The parameter `use_Decision Tree` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,897] The parameter `use_Random Forest` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,897] The parameter `use_K-Nearest Neighbors` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,897] The parameter `use_Support Vector Machine` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,897] The parameter `use_AdaBoost` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,897] The parameter `use_Gradient Boosting` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,897] The parameter `n_neurons_1` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,903] The parameter `n_neurons_2` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:03,904] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:06,445] Trial 37 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 22, 'n_neurons_1': 57, 'n_neurons_2': 47, 'learning_rate': 'constant', 'learning_rate_init': 0.00014330125702369644, 'alpha': 0.0006978305848598669}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:06,449] The parameter `use_Logistic Regression` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,450] The parameter `use_Decision Tree` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,451] The parameter `use_Random Forest` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,452] The parameter `use_K-Nearest Neighbors` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,452] The parameter `use_Support Vector Machine` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,453] The parameter `use_AdaBoost` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,454] The parameter `use_Gradient Boosting` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,455] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,455] The parameter `n_neurons_2` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,456] The parameter `n_neurons_3` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,457] The parameter `n_neurons_4` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:06,457] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:08,000] Trial 38 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 68, 'n_neurons_1': 48, 'n_neurons_2': 56, 'n_neurons_3': 32, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.0014330125702369636, 'alpha': 0.006978305848598664}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:08,003] The parameter `use_Logistic Regression` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,005] The parameter `use_Decision Tree` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,005] The parameter `use_Random Forest` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,007] The parameter `use_K-Nearest Neighbors` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,007] The parameter `use_Support Vector Machine` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,008] The parameter `use_AdaBoost` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,009] The parameter `use_Gradient Boosting` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,010] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,010] The parameter `n_neurons_2` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,011] The parameter `n_neurons_3` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:08,012] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:09,918] Trial 39 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 45, 'n_neurons_1': 64, 'n_neurons_2': 52, 'n_neurons_3': 47, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045315836376008217, 'alpha': 0.00022067340690845924}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:09,921] The parameter `use_Logistic Regression` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:09,922] The parameter `use_Decision Tree` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:09,923] The parameter `use_Random Forest` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:09,924] The parameter `use_K-Nearest Neighbors` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:09,925] The parameter `use_Support Vector Machine` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:09,925] The parameter `use_AdaBoost` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:09,926] The parameter `use_Gradient Boosting` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:09,927] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:11,639] Trial 40 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0045315836376008225, 'alpha': 0.002206734069084591}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:11,642] The parameter `use_Logistic Regression` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:11,643] The parameter `use_Decision Tree` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:11,644] The parameter `use_Random Forest` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:11,645] The parameter `use_K-Nearest Neighbors` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:11,646] The parameter `use_Support Vector Machine` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:11,646] The parameter `use_AdaBoost` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:11,647] The parameter `use_Gradient Boosting` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:11,648] The parameter `n_neurons_1` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:11,649] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:13,252] Trial 41 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 17, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00033982083289425634, 'alpha': 0.009305720409296997}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:13,255] The parameter `use_Logistic Regression` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,257] The parameter `use_Decision Tree` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,258] The parameter `use_Random Forest` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,258] The parameter `use_K-Nearest Neighbors` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,259] The parameter `use_Support Vector Machine` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,260] The parameter `use_AdaBoost` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,260] The parameter `use_Gradient Boosting` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,261] The parameter `n_neurons_1` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,262] The parameter `n_neurons_2` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,263] The parameter `n_neurons_3` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:13,263] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:15,235] Trial 42 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 62, 'n_neurons_1': 77, 'n_neurons_2': 13, 'n_neurons_3': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003398208328942561, 'alpha': 0.0009305720409296995}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:15,237] The parameter `use_Logistic Regression` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,239] The parameter `use_Decision Tree` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,239] The parameter `use_Random Forest` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,240] The parameter `use_K-Nearest Neighbors` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,241] The parameter `use_Support Vector Machine` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,242] The parameter `use_AdaBoost` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,242] The parameter `use_Gradient Boosting` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,243] The parameter `n_neurons_1` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,244] The parameter `n_neurons_2` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,244] The parameter `n_neurons_3` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,245] The parameter `n_neurons_4` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:15,246] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:17,793] Trial 43 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 32, 'n_neurons_2': 41, 'n_neurons_3': 26, 'n_neurons_4': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.00010746078283213182, 'alpha': 0.002942727176209285}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:17,797] The parameter `use_Logistic Regression` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,798] The parameter `use_Decision Tree` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,798] The parameter `use_Random Forest` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,799] The parameter `use_K-Nearest Neighbors` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,800] The parameter `use_Support Vector Machine` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,801] The parameter `use_AdaBoost` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,801] The parameter `use_Gradient Boosting` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,802] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,803] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:17,803] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:20,154] Trial 44 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 62, 'n_neurons_2': 65, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010746078283213184, 'alpha': 0.0002942727176209287}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:20,158] The parameter `use_Logistic Regression` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:20,160] The parameter `use_Decision Tree` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:20,160] The parameter `use_Random Forest` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:20,160] The parameter `use_K-Nearest Neighbors` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:20,162] The parameter `use_Support Vector Machine` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:20,163] The parameter `use_AdaBoost` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:20,163] The parameter `use_Gradient Boosting` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:20,165] The parameter `n_neurons_1` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:20,165] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:22,019] Trial 45 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 51, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006042963902381333, 'alpha': 0.00016548170999431823}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:22,023] The parameter `use_Logistic Regression` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,024] The parameter `use_Decision Tree` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,025] The parameter `use_Random Forest` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,026] The parameter `use_K-Nearest Neighbors` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,026] The parameter `use_Support Vector Machine` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,027] The parameter `use_AdaBoost` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,028] The parameter `use_Gradient Boosting` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,029] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,029] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,030] The parameter `n_neurons_3` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,031] The parameter `n_neurons_4` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:22,031] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:32:23,690] Trial 46 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 96, 'n_neurons_1': 42, 'n_neurons_2': 62, 'n_neurons_3': 67, 'n_neurons_4': 11, 'learning_rate': 'constant', 'learning_rate_init': 0.0006042963902381332, 'alpha': 0.0016548170999431827}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:23,694] The parameter `use_Logistic Regression` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,695] The parameter `use_Decision Tree` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,696] The parameter `use_Random Forest` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,696] The parameter `use_K-Nearest Neighbors` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,697] The parameter `use_Support Vector Machine` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,698] The parameter `use_AdaBoost` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,698] The parameter `use_Gradient Boosting` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,699] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,700] The parameter `n_neurons_2` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,701] The parameter `n_neurons_3` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:23,701] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:32:26,548] Trial 47 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 28, 'n_neurons_1': 52, 'n_neurons_2': 61, 'n_neurons_3': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0019109529749704425, 'alpha': 0.0005232991146814953}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:26,552] The parameter `use_Logistic Regression` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:26,553] The parameter `use_Decision Tree` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:26,554] The parameter `use_Random Forest` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:26,555] The parameter `use_K-Nearest Neighbors` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:26,556] The parameter `use_Support Vector Machine` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:26,557] The parameter `use_AdaBoost` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:26,557] The parameter `use_Gradient Boosting` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:26,558] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:32:28,236] Trial 48 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.00019109529749704405, 'alpha': 0.005232991146814949}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:28,240] The parameter `use_Logistic Regression` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,242] The parameter `use_Decision Tree` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,242] The parameter `use_Random Forest` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,243] The parameter `use_K-Nearest Neighbors` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,243] The parameter `use_Support Vector Machine` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,244] The parameter `use_AdaBoost` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,245] The parameter `use_Gradient Boosting` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,245] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:28,481] Trial 49 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.003924189758484535, 'alpha': 0.00019109529749704405}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:28,485] The parameter `use_Logistic Regression` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,485] The parameter `use_Decision Tree` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,487] The parameter `use_Random Forest` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,487] The parameter `use_K-Nearest Neighbors` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,487] The parameter `use_Support Vector Machine` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,487] The parameter `use_AdaBoost` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,487] The parameter `use_Gradient Boosting` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,491] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,491] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:28,492] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:30,405] Trial 50 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 76, 'n_neurons_1': 33, 'n_neurons_2': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.0003924189758484538, 'alpha': 0.0019109529749704425}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:30,409] The parameter `use_Logistic Regression` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,410] The parameter `use_Decision Tree` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,411] The parameter `use_Random Forest` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,412] The parameter `use_K-Nearest Neighbors` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,412] The parameter `use_Support Vector Machine` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,413] The parameter `use_AdaBoost` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,414] The parameter `use_Gradient Boosting` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,415] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,415] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,416] The parameter `n_neurons_3` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,417] The parameter `n_neurons_4` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:30,417] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:33,180] Trial 51 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 54, 'n_neurons_1': 34, 'n_neurons_2': 59, 'n_neurons_3': 67, 'n_neurons_4': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012409377607517208, 'alpha': 0.0006042963902381332}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:33,183] The parameter `use_Logistic Regression` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:33,184] The parameter `use_Decision Tree` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:33,185] The parameter `use_Random Forest` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:33,186] The parameter `use_K-Nearest Neighbors` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:33,187] The parameter `use_Support Vector Machine` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:33,187] The parameter `use_AdaBoost` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:33,188] The parameter `use_Gradient Boosting` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:33,189] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:33,189] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:32:35,414] Trial 52 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 22, 'learning_rate': 'constant', 'learning_rate_init': 0.00012409377607517218, 'alpha': 0.006042963902381333}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:35,417] The parameter `use_Logistic Regression` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,417] The parameter `use_Decision Tree` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,420] The parameter `use_Random Forest` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,420] The parameter `use_K-Nearest Neighbors` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,420] The parameter `use_Support Vector Machine` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,423] The parameter `use_AdaBoost` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,423] The parameter `use_Gradient Boosting` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,424] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,425] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:35,426] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:37,678] Trial 53 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 45, 'n_neurons_2': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006978305848598669, 'alpha': 0.003398208328942561}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:37,681] The parameter `use_Logistic Regression` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,683] The parameter `use_Decision Tree` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,683] The parameter `use_Random Forest` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,684] The parameter `use_K-Nearest Neighbors` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,685] The parameter `use_Support Vector Machine` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,686] The parameter `use_AdaBoost` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,686] The parameter `use_Gradient Boosting` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,687] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,688] The parameter `n_neurons_2` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,689] The parameter `n_neurons_3` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,690] The parameter `n_neurons_4` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:37,690] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:39,570] Trial 54 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 80, 'n_neurons_2': 19, 'n_neurons_3': 16, 'n_neurons_4': 76, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006978305848598664, 'alpha': 0.00033982083289425634}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:39,573] The parameter `use_Logistic Regression` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,575] The parameter `use_Decision Tree` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,576] The parameter `use_Random Forest` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,576] The parameter `use_K-Nearest Neighbors` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,577] The parameter `use_Support Vector Machine` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,578] The parameter `use_AdaBoost` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,578] The parameter `use_Gradient Boosting` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,579] The parameter `n_neurons_1` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,580] The parameter `n_neurons_2` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,581] The parameter `n_neurons_3` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:39,581] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:42,604] Trial 55 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 19, 'n_neurons_1': 59, 'n_neurons_2': 89, 'n_neurons_3': 76, 'learning_rate': 'constant', 'learning_rate_init': 0.00022067340690845924, 'alpha': 0.0010746078283213184}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:42,607] The parameter `use_Logistic Regression` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:42,609] The parameter `use_Decision Tree` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:42,610] The parameter `use_Random Forest` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:42,610] The parameter `use_K-Nearest Neighbors` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:42,611] The parameter `use_Support Vector Machine` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:42,612] The parameter `use_AdaBoost` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:42,613] The parameter `use_Gradient Boosting` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:42,614] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:42,615] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:44,749] Trial 56 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 65, 'n_neurons_1': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002206734069084591, 'alpha': 0.00010746078283213182}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:44,752] The parameter `use_Logistic Regression` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:44,753] The parameter `use_Decision Tree` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:44,754] The parameter `use_Random Forest` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:44,755] The parameter `use_K-Nearest Neighbors` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:44,755] The parameter `use_Support Vector Machine` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:44,756] The parameter `use_AdaBoost` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:44,757] The parameter `use_Gradient Boosting` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:44,757] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:46,956] Trial 57 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 48, 'learning_rate': 'constant', 'learning_rate_init': 0.0002942727176209287, 'alpha': 0.00045315836376008217}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:46,956] The parameter `use_Logistic Regression` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,956] The parameter `use_Decision Tree` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,956] The parameter `use_Random Forest` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,963] The parameter `use_K-Nearest Neighbors` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,963] The parameter `use_Support Vector Machine` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,964] The parameter `use_AdaBoost` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,964] The parameter `use_Gradient Boosting` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,965] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,966] The parameter `n_neurons_2` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,967] The parameter `n_neurons_3` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:46,968] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:47,235] Trial 58 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 93, 'n_neurons_1': 82, 'n_neurons_2': 100, 'n_neurons_3': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.002942727176209285, 'alpha': 0.0045315836376008225}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:47,241] The parameter `use_Logistic Regression` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,241] The parameter `use_Decision Tree` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,241] The parameter `use_Random Forest` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,241] The parameter `use_K-Nearest Neighbors` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,247] The parameter `use_Support Vector Machine` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,247] The parameter `use_AdaBoost` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,247] The parameter `use_Gradient Boosting` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,247] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,247] The parameter `n_neurons_2` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,247] The parameter `n_neurons_3` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,247] The parameter `n_neurons_4` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:47,247] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:32:50,266] Trial 59 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 25, 'n_neurons_1': 13, 'n_neurons_2': 11, 'n_neurons_3': 99, 'n_neurons_4': 48, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009305720409296995, 'alpha': 0.00014330125702369644}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:50,270] The parameter `use_Logistic Regression` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:50,272] The parameter `use_Decision Tree` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:50,273] The parameter `use_Random Forest` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:50,273] The parameter `use_K-Nearest Neighbors` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:50,274] The parameter `use_Support Vector Machine` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:50,275] The parameter `use_AdaBoost` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:50,275] The parameter `use_Gradient Boosting` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:50,275] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:50,275] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:52,316] Trial 60 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 65, 'learning_rate': 'constant', 'learning_rate_init': 0.009305720409296997, 'alpha': 0.0014330125702369636}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:52,320] The parameter `use_Logistic Regression` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:52,321] The parameter `use_Decision Tree` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:52,322] The parameter `use_Random Forest` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:52,323] The parameter `use_K-Nearest Neighbors` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:52,323] The parameter `use_Support Vector Machine` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:52,324] The parameter `use_AdaBoost` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:52,325] The parameter `use_Gradient Boosting` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:52,326] The parameter `n_neurons_1` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:52,326] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:54,163] Trial 61 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 14, 'n_neurons_1': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0016548170999431827, 'alpha': 0.0025482967479793484}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:54,168] The parameter `use_Logistic Regression` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,169] The parameter `use_Decision Tree` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,170] The parameter `use_Random Forest` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,171] The parameter `use_K-Nearest Neighbors` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,171] The parameter `use_Support Vector Machine` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,173] The parameter `use_AdaBoost` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,173] The parameter `use_Gradient Boosting` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,174] The parameter `n_neurons_1` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,175] The parameter `n_neurons_2` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,176] The parameter `n_neurons_3` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:54,176] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:56,769] Trial 62 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 59, 'n_neurons_1': 17, 'n_neurons_2': 47, 'n_neurons_3': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00016548170999431823, 'alpha': 0.0002548296747979348}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:56,772] The parameter `use_Logistic Regression` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,773] The parameter `use_Decision Tree` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,774] The parameter `use_Random Forest` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,774] The parameter `use_K-Nearest Neighbors` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,775] The parameter `use_Support Vector Machine` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,776] The parameter `use_AdaBoost` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,776] The parameter `use_Gradient Boosting` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,777] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,778] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:56,779] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:32:58,660] Trial 63 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 37, 'n_neurons_1': 89, 'n_neurons_2': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005232991146814949, 'alpha': 0.008058421877614822}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:32:58,665] The parameter `use_Logistic Regression` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:58,666] The parameter `use_Decision Tree` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:58,666] The parameter `use_Random Forest` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:58,667] The parameter `use_K-Nearest Neighbors` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:58,668] The parameter `use_Support Vector Machine` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:58,669] The parameter `use_AdaBoost` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:58,669] The parameter `use_Gradient Boosting` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:32:58,671] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:00,176] Trial 64 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 82, 'learning_rate': 'constant', 'learning_rate_init': 0.0005232991146814953, 'alpha': 0.0008058421877614828}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:00,179] The parameter `use_Logistic Regression` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,180] The parameter `use_Decision Tree` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,181] The parameter `use_Random Forest` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,182] The parameter `use_K-Nearest Neighbors` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,183] The parameter `use_Support Vector Machine` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,183] The parameter `use_AdaBoost` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,184] The parameter `use_Gradient Boosting` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,184] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:00,403] Trial 65 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004371444812611091, 'alpha': 0.004697588816706496}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:00,406] The parameter `use_Logistic Regression` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,408] The parameter `use_Decision Tree` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,408] The parameter `use_Random Forest` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,409] The parameter `use_K-Nearest Neighbors` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,410] The parameter `use_Support Vector Machine` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,410] The parameter `use_AdaBoost` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,411] The parameter `use_Gradient Boosting` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,412] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,413] The parameter `n_neurons_2` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:00,413] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:33:03,556] Trial 66 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 91, 'n_neurons_1': 89, 'n_neurons_2': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.0004371444812611094, 'alpha': 0.0004697588816706495}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:03,560] The parameter `use_Logistic Regression` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,561] The parameter `use_Decision Tree` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,562] The parameter `use_Random Forest` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,562] The parameter `use_K-Nearest Neighbors` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,563] The parameter `use_Support Vector Machine` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,564] The parameter `use_AdaBoost` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,565] The parameter `use_Gradient Boosting` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,565] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,566] The parameter `n_neurons_2` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,567] The parameter `n_neurons_3` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:03,567] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:05,731] Trial 67 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 23, 'n_neurons_1': 82, 'n_neurons_2': 73, 'n_neurons_3': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013823722273579005, 'alpha': 0.0014855080171727755}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:05,734] The parameter `use_Logistic Regression` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:05,735] The parameter `use_Decision Tree` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:05,736] The parameter `use_Random Forest` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:05,737] The parameter `use_K-Nearest Neighbors` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:05,738] The parameter `use_Support Vector Machine` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:05,739] The parameter `use_AdaBoost` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:05,739] The parameter `use_Gradient Boosting` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:05,740] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:05,741] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:08,060] Trial 68 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 69, 'n_neurons_1': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013823722273579014, 'alpha': 0.00014855080171727767}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:08,060] The parameter `use_Logistic Regression` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:08,066] The parameter `use_Decision Tree` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:08,067] The parameter `use_Random Forest` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:08,068] The parameter `use_K-Nearest Neighbors` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:08,068] The parameter `use_Support Vector Machine` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:08,069] The parameter `use_AdaBoost` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:08,070] The parameter `use_Gradient Boosting` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:08,070] The parameter `n_neurons_1` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:08,071] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:09,567] Trial 69 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 12, 'n_neurons_1': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0007773650302387768, 'alpha': 0.00026416483203860934}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:09,571] The parameter `use_Logistic Regression` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,572] The parameter `use_Decision Tree` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,574] The parameter `use_Random Forest` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,574] The parameter `use_K-Nearest Neighbors` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,575] The parameter `use_Support Vector Machine` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,576] The parameter `use_AdaBoost` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,576] The parameter `use_Gradient Boosting` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:09,577] Trial 70 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:09,577] The parameter `use_Logistic Regression` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,580] The parameter `use_Decision Tree` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,580] The parameter `use_Random Forest` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,580] The parameter `use_K-Nearest Neighbors` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,580] The parameter `use_Support Vector Machine` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,580] The parameter `use_AdaBoost` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,583] The parameter `use_Gradient Boosting` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,585] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,585] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,586] The parameter `n_neurons_3` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:09,587] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:10,202] Trial 71 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 34, 'n_neurons_1': 66, 'n_neurons_2': 73, 'n_neurons_3': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002458244068920199, 'alpha': 0.000835362546957827}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:10,206] The parameter `use_Logistic Regression` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:10,207] The parameter `use_Decision Tree` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:10,208] The parameter `use_Random Forest` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:10,208] The parameter `use_K-Nearest Neighbors` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:10,209] The parameter `use_Support Vector Machine` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:10,210] The parameter `use_AdaBoost` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:10,211] The parameter `use_Gradient Boosting` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:10,211] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:11,541] Trial 72 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0024582440689201977, 'alpha': 0.008353625469578265}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:11,545] The parameter `use_Logistic Regression` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:11,547] The parameter `use_Decision Tree` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:11,548] The parameter `use_Random Forest` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:11,549] The parameter `use_K-Nearest Neighbors` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:11,550] The parameter `use_Support Vector Machine` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:11,551] The parameter `use_AdaBoost` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:11,551] The parameter `use_Gradient Boosting` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:11,552] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:11,553] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:13,838] Trial 73 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 29, 'n_neurons_1': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018434229924091107, 'alpha': 0.001980956778550341}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:13,845] The parameter `use_Logistic Regression` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,845] The parameter `use_Decision Tree` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,845] The parameter `use_Random Forest` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,845] The parameter `use_K-Nearest Neighbors` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,845] The parameter `use_Support Vector Machine` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,845] The parameter `use_AdaBoost` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,845] The parameter `use_Gradient Boosting` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,851] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,851] The parameter `n_neurons_2` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,852] The parameter `n_neurons_3` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:13,853] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:15,855] Trial 74 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 74, 'n_neurons_1': 30, 'n_neurons_2': 100, 'n_neurons_3': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.0018434229924091127, 'alpha': 0.0001980956778550342}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:15,859] The parameter `use_Logistic Regression` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,860] The parameter `use_Decision Tree` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,861] The parameter `use_Random Forest` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,862] The parameter `use_K-Nearest Neighbors` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,863] The parameter `use_Support Vector Machine` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,863] The parameter `use_AdaBoost` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,864] The parameter `use_Gradient Boosting` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,865] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,866] The parameter `n_neurons_2` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,867] The parameter `n_neurons_3` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,867] The parameter `n_neurons_4` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:15,868] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:16,745] Trial 75 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 51, 'n_neurons_1': 62, 'n_neurons_2': 49, 'n_neurons_3': 75, 'n_neurons_4': 54, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005829415347136078, 'alpha': 0.00626433536656886}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:16,749] The parameter `use_Logistic Regression` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,750] The parameter `use_Decision Tree` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,751] The parameter `use_Random Forest` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,752] The parameter `use_K-Nearest Neighbors` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,752] The parameter `use_Support Vector Machine` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,753] The parameter `use_AdaBoost` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,754] The parameter `use_Gradient Boosting` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,755] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,755] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:16,756] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:18,039] Trial 76 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 26, 'n_neurons_2': 87, 'learning_rate': 'constant', 'learning_rate_init': 0.0058294153471360795, 'alpha': 0.0006264335366568858}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:18,042] The parameter `use_Logistic Regression` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:18,043] The parameter `use_Decision Tree` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:18,044] The parameter `use_Random Forest` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:18,045] The parameter `use_K-Nearest Neighbors` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:18,045] The parameter `use_Support Vector Machine` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:18,046] The parameter `use_AdaBoost` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:18,047] The parameter `use_Gradient Boosting` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:18,048] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:18,051] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:19,481] Trial 77 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 40, 'n_neurons_1': 51, 'learning_rate': 'constant', 'learning_rate_init': 0.001036632928437698, 'alpha': 0.0003522694651473105}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:19,485] The parameter `use_Logistic Regression` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,487] The parameter `use_Decision Tree` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,487] The parameter `use_Random Forest` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,488] The parameter `use_K-Nearest Neighbors` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,489] The parameter `use_Support Vector Machine` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,489] The parameter `use_AdaBoost` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,490] The parameter `use_Gradient Boosting` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,491] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,492] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,492] The parameter `n_neurons_3` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,493] The parameter `n_neurons_4` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:19,494] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:22,379] Trial 78 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 86, 'n_neurons_2': 83, 'n_neurons_3': 63, 'n_neurons_4': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.00010366329284376988, 'alpha': 0.0035226946514731027}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:22,383] The parameter `use_Logistic Regression` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,384] The parameter `use_Decision Tree` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,385] The parameter `use_Random Forest` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,385] The parameter `use_K-Nearest Neighbors` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,386] The parameter `use_Support Vector Machine` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,387] The parameter `use_AdaBoost` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,388] The parameter `use_Gradient Boosting` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,389] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,390] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:22,390] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:24,459] Trial 79 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 17, 'n_neurons_1': 10, 'n_neurons_2': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003278121151393461, 'alpha': 0.0001113973859994803}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:24,462] The parameter `use_Logistic Regression` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:24,463] The parameter `use_Decision Tree` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:24,464] The parameter `use_Random Forest` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:24,465] The parameter `use_K-Nearest Neighbors` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:24,466] The parameter `use_Support Vector Machine` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:24,466] The parameter `use_AdaBoost` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:24,467] The parameter `use_Gradient Boosting` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:24,468] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:33:26,646] Trial 80 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.00032781211513934627, 'alpha': 0.001113973859994803}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:26,650] The parameter `use_Logistic Regression` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:26,651] The parameter `use_Decision Tree` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:26,652] The parameter `use_Random Forest` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:26,652] The parameter `use_K-Nearest Neighbors` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:26,653] The parameter `use_Support Vector Machine` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:26,654] The parameter `use_AdaBoost` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:26,654] The parameter `use_Gradient Boosting` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:26,655] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:28,047] Trial 81 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002128751661796374, 'alpha': 0.0009646616199111995}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:28,050] The parameter `use_Logistic Regression` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,051] The parameter `use_Decision Tree` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,052] The parameter `use_Random Forest` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,053] The parameter `use_K-Nearest Neighbors` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,054] The parameter `use_Support Vector Machine` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,054] The parameter `use_AdaBoost` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,055] The parameter `use_Gradient Boosting` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,056] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,057] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,057] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:28,058] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:30,289] Trial 82 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 83, 'n_neurons_2': 79, 'n_neurons_3': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00021287516617963755, 'alpha': 0.009646616199111998}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:30,293] The parameter `use_Logistic Regression` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,294] The parameter `use_Decision Tree` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,295] The parameter `use_Random Forest` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,296] The parameter `use_K-Nearest Neighbors` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,296] The parameter `use_Support Vector Machine` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,297] The parameter `use_AdaBoost` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,298] The parameter `use_Gradient Boosting` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,299] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,299] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,300] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,301] The parameter `n_neurons_4` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:30,301] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:32,023] Trial 83 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 70, 'n_neurons_2': 66, 'n_neurons_3': 52, 'n_neurons_4': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.006731703824144984, 'alpha': 0.00030505278902670253}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:32,026] The parameter `use_Logistic Regression` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,027] The parameter `use_Decision Tree` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,028] The parameter `use_Random Forest` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,029] The parameter `use_K-Nearest Neighbors` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,030] The parameter `use_Support Vector Machine` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,030] The parameter `use_AdaBoost` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,031] The parameter `use_Gradient Boosting` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:32,032] Trial 84 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:32,033] The parameter `use_Logistic Regression` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,034] The parameter `use_Decision Tree` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,035] The parameter `use_Random Forest` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,036] The parameter `use_K-Nearest Neighbors` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,037] The parameter `use_Support Vector Machine` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,037] The parameter `use_AdaBoost` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,038] The parameter `use_Gradient Boosting` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,039] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,040] The parameter `n_neurons_2` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:32,040] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:33,861] Trial 85 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 59, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011970850304957301, 'alpha': 0.0017154378963428801}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:33,865] The parameter `use_Logistic Regression` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,866] The parameter `use_Decision Tree` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,867] The parameter `use_Random Forest` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,868] The parameter `use_K-Nearest Neighbors` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,868] The parameter `use_Support Vector Machine` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,869] The parameter `use_AdaBoost` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,869] The parameter `use_Gradient Boosting` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:33,870] Trial 86 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:33,872] The parameter `use_Logistic Regression` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,873] The parameter `use_Decision Tree` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,874] The parameter `use_Random Forest` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,875] The parameter `use_K-Nearest Neighbors` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,876] The parameter `use_Support Vector Machine` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,876] The parameter `use_AdaBoost` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,877] The parameter `use_Gradient Boosting` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,878] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,879] The parameter `n_neurons_2` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,879] The parameter `n_neurons_3` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:33,880] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:33:36,571] Trial 87 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 31, 'n_neurons_2': 81, 'n_neurons_3': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.0003785515249258633, 'alpha': 0.005424690937011328}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:36,575] The parameter `use_Logistic Regression` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:36,576] The parameter `use_Decision Tree` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:36,576] The parameter `use_Random Forest` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:36,576] The parameter `use_K-Nearest Neighbors` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:36,576] The parameter `use_Support Vector Machine` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:36,576] The parameter `use_AdaBoost` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:36,576] The parameter `use_Gradient Boosting` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:36,582] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:36,582] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:38,701] Trial 88 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00378551524925863, 'alpha': 0.0005424690937011332}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:38,704] The parameter `use_Logistic Regression` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:38,706] The parameter `use_Decision Tree` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:38,707] The parameter `use_Random Forest` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:38,707] The parameter `use_K-Nearest Neighbors` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:38,708] The parameter `use_Support Vector Machine` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:38,709] The parameter `use_AdaBoost` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:38,709] The parameter `use_Gradient Boosting` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:38,710] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:40,585] Trial 89 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 37, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005048065716667477, 'alpha': 0.00012863969449369766}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:40,589] The parameter `use_Logistic Regression` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,589] The parameter `use_Decision Tree` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,589] The parameter `use_Random Forest` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,589] The parameter `use_K-Nearest Neighbors` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,589] The parameter `use_Support Vector Machine` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,592] The parameter `use_AdaBoost` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,592] The parameter `use_Gradient Boosting` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,594] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,594] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,594] The parameter `n_neurons_3` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:40,594] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:42,527] Trial 90 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 83, 'n_neurons_1': 39, 'n_neurons_2': 40, 'n_neurons_3': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.005048065716667474, 'alpha': 0.0012863969449369757}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:42,531] The parameter `use_Logistic Regression` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,532] The parameter `use_Decision Tree` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,533] The parameter `use_Random Forest` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,534] The parameter `use_K-Nearest Neighbors` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,534] The parameter `use_Support Vector Machine` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,535] The parameter `use_AdaBoost` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,536] The parameter `use_Gradient Boosting` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,537] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,538] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,538] The parameter `n_neurons_3` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,539] The parameter `n_neurons_4` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:42,540] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:45,360] Trial 91 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 70, 'n_neurons_2': 82, 'n_neurons_3': 94, 'n_neurons_4': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.00015963385442879435, 'alpha': 0.0004067944321083049}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:45,363] The parameter `use_Logistic Regression` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,365] The parameter `use_Decision Tree` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,365] The parameter `use_Random Forest` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,366] The parameter `use_K-Nearest Neighbors` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,367] The parameter `use_Support Vector Machine` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,367] The parameter `use_AdaBoost` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,368] The parameter `use_Gradient Boosting` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,369] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,370] The parameter `n_neurons_2` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:45,370] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:46,725] Trial 92 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 60, 'n_neurons_1': 33, 'n_neurons_2': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015963385442879423, 'alpha': 0.0040679443210830495}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:46,729] The parameter `use_Logistic Regression` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:46,730] The parameter `use_Decision Tree` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:46,731] The parameter `use_Random Forest` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:46,732] The parameter `use_K-Nearest Neighbors` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:46,733] The parameter `use_Support Vector Machine` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:46,734] The parameter `use_AdaBoost` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:46,735] The parameter `use_Gradient Boosting` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:46,736] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:46,737] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:48,059] Trial 93 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.00897687132447315, 'alpha': 0.007233941627366754}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:48,065] The parameter `use_Logistic Regression` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,066] The parameter `use_Decision Tree` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,067] The parameter `use_Random Forest` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,068] The parameter `use_K-Nearest Neighbors` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,069] The parameter `use_Support Vector Machine` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,070] The parameter `use_AdaBoost` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,070] The parameter `use_Gradient Boosting` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,071] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,072] The parameter `n_neurons_2` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,073] The parameter `n_neurons_3` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,073] The parameter `n_neurons_4` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:48,074] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:33:51,082] Trial 94 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 71, 'n_neurons_1': 54, 'n_neurons_2': 65, 'n_neurons_3': 79, 'n_neurons_4': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0008976871324473148, 'alpha': 0.0007233941627366753}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:51,085] The parameter `use_Logistic Regression` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,086] The parameter `use_Decision Tree` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,087] The parameter `use_Random Forest` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,088] The parameter `use_K-Nearest Neighbors` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,088] The parameter `use_Support Vector Machine` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,089] The parameter `use_AdaBoost` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,090] The parameter `use_Gradient Boosting` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,091] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,092] The parameter `n_neurons_2` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:51,093] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:52,507] Trial 95 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 29, 'n_neurons_2': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0028387359647587583, 'alpha': 0.0022875732003183966}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:52,510] The parameter `use_Logistic Regression` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:52,511] The parameter `use_Decision Tree` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:52,513] The parameter `use_Random Forest` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:52,514] The parameter `use_K-Nearest Neighbors` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:52,514] The parameter `use_Support Vector Machine` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:52,515] The parameter `use_AdaBoost` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:52,516] The parameter `use_Gradient Boosting` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:52,517] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:53,997] Trial 96 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 94, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002838735964758755, 'alpha': 0.0002287573200318398}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:54,002] The parameter `use_Logistic Regression` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:54,003] The parameter `use_Decision Tree` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:54,003] The parameter `use_Random Forest` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:54,004] The parameter `use_K-Nearest Neighbors` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:54,005] The parameter `use_Support Vector Machine` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:54,005] The parameter `use_AdaBoost` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:54,006] The parameter `use_Gradient Boosting` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:54,007] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:55,325] Trial 97 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006264335366568858, 'alpha': 0.0005048065716667477}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:55,330] The parameter `use_Logistic Regression` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,331] The parameter `use_Decision Tree` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,332] The parameter `use_Random Forest` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,334] The parameter `use_K-Nearest Neighbors` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,334] The parameter `use_Support Vector Machine` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,335] The parameter `use_AdaBoost` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,336] The parameter `use_Gradient Boosting` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,337] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,338] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,338] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-10-06 13:33:55,613] Trial 98 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 54, 'n_neurons_2': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.00626433536656886, 'alpha': 0.005048065716667474}. Best is trial 27 with value: 0.9266666666666666.\n",
      "[W 2025-10-06 13:33:55,616] The parameter `use_Logistic Regression` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,617] The parameter `use_Decision Tree` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,617] The parameter `use_Random Forest` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,617] The parameter `use_K-Nearest Neighbors` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,617] The parameter `use_Support Vector Machine` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,617] The parameter `use_AdaBoost` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,617] The parameter `use_Gradient Boosting` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,617] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,617] The parameter `n_neurons_2` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,623] The parameter `n_neurons_3` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-10-06 13:33:55,623] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\ml_kit\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 13:33:58,347] Trial 99 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 44, 'n_neurons_1': 38, 'n_neurons_2': 72, 'n_neurons_3': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001980956778550342, 'alpha': 0.00015963385442879435}. Best is trial 27 with value: 0.9266666666666666.\n",
      "\n",
      "Selected Base Models for Stacking using QMCSampler:\n",
      "- Decision Tree\n",
      "- K-Nearest Neighbors\n",
      "- Support Vector Machine\n",
      "- AdaBoost\n",
      "Best Hyperparameters for Meta Model (MLP) using QMCSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.0036517412725483775, 'alpha': 0.0015399265260594922, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (46, 73, 58, 38, 84), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9267, at trial: 27\n",
      "QMC base models training time: 83.02 seconds\n",
      "QMC SEl-NNML Training Time: 179.82 seconds\n",
      "Total QMC Training Time (Base + Meta): 262.84 seconds\n"
     ]
    }
   ],
   "source": [
    "qmc_meta_model_training_start = time.time()\n",
    "\n",
    "# Meta Model Tuning and Final Stacking Model Fitting\n",
    "qmc_sel_nnml = meta_model_tuning(base_models['QMC'], X_train, y_train, X_test, y_test, sampler='QMCSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "qmc_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "qmc_meta_model_training_end = time.time()\n",
    "\n",
    "# Time taken for QMC SEl-NNML training\n",
    "qmc_meta_model_training_time = qmc_meta_model_training_end - qmc_meta_model_training_start\n",
    "print(f'QMC base models training time: {qmc_base_models_training_time:.2f} seconds')\n",
    "print(f'QMC SEl-NNML Training Time: {qmc_meta_model_training_time:.2f} seconds')\n",
    "print(f'Total QMC Training Time (Base + Meta): {qmc_base_models_training_time + qmc_meta_model_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sampler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Best Hyperparameters",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "acf8ff69-e8d4-4840-8b47-05225eb2ba38",
       "rows": [
        [
         "0",
         "TPE",
         "Logistic Regression",
         "{'C': 0.09767265811237319, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "1",
         "TPE",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "2",
         "TPE",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 71, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "3",
         "TPE",
         "K-Nearest Neighbors",
         "{'algorithm': 'ball_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 41, 'p': 2, 'weights': 'uniform'}"
        ],
        [
         "4",
         "TPE",
         "Support Vector Machine",
         "{'C': 0.009980295032795012, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 5, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "5",
         "TPE",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.2511295868890071, 'n_estimators': 84, 'random_state': 42}"
        ],
        [
         "6",
         "TPE",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.014113282033022877, 'loss': 'log_loss', 'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 7, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 53, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.8334644059485119, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "7",
         "TPE",
         "SEl-NNML",
         "{'cv': None, 'estimators': [('Decision Tree', DecisionTreeClassifier(criterion='log_loss', max_depth=4, min_samples_leaf=3,\n                       min_samples_split=10, random_state=42)), ('AdaBoost', AdaBoostClassifier(learning_rate=0.2511295868890071, n_estimators=84,\n                   random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(learning_rate=0.014113282033022877, max_depth=6,\n                           max_features='sqrt', min_samples_leaf=7,\n                           min_samples_split=8, n_estimators=53,\n                           random_state=42, subsample=0.8334644059485119))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.006114818319251142, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (52, 15), 'final_estimator__learning_rate': 'adaptive', 'final_estimator__learning_rate_init': 0.001244030248083268, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.006114818319251142, hidden_layer_sizes=(52, 15),\n              learning_rate='adaptive', learning_rate_init=0.001244030248083268,\n              max_iter=300, random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Decision Tree': DecisionTreeClassifier(criterion='log_loss', max_depth=4, min_samples_leaf=3,\n                       min_samples_split=10, random_state=42), 'AdaBoost': AdaBoostClassifier(learning_rate=0.2511295868890071, n_estimators=84,\n                   random_state=42), 'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.014113282033022877, max_depth=6,\n                           max_features='sqrt', min_samples_leaf=7,\n                           min_samples_split=8, n_estimators=53,\n                           random_state=42, subsample=0.8334644059485119), 'Decision Tree__ccp_alpha': 0.0, 'Decision Tree__class_weight': None, 'Decision Tree__criterion': 'log_loss', 'Decision Tree__max_depth': 4, 'Decision Tree__max_features': None, 'Decision Tree__max_leaf_nodes': None, 'Decision Tree__min_impurity_decrease': 0.0, 'Decision Tree__min_samples_leaf': 3, 'Decision Tree__min_samples_split': 10, 'Decision Tree__min_weight_fraction_leaf': 0.0, 'Decision Tree__monotonic_cst': None, 'Decision Tree__random_state': 42, 'Decision Tree__splitter': 'best', 'AdaBoost__algorithm': 'deprecated', 'AdaBoost__estimator': None, 'AdaBoost__learning_rate': 0.2511295868890071, 'AdaBoost__n_estimators': 84, 'AdaBoost__random_state': 42, 'Gradient Boosting__ccp_alpha': 0.0, 'Gradient Boosting__criterion': 'friedman_mse', 'Gradient Boosting__init': None, 'Gradient Boosting__learning_rate': 0.014113282033022877, 'Gradient Boosting__loss': 'log_loss', 'Gradient Boosting__max_depth': 6, 'Gradient Boosting__max_features': 'sqrt', 'Gradient Boosting__max_leaf_nodes': None, 'Gradient Boosting__min_impurity_decrease': 0.0, 'Gradient Boosting__min_samples_leaf': 7, 'Gradient Boosting__min_samples_split': 8, 'Gradient Boosting__min_weight_fraction_leaf': 0.0, 'Gradient Boosting__n_estimators': 53, 'Gradient Boosting__n_iter_no_change': None, 'Gradient Boosting__random_state': 42, 'Gradient Boosting__subsample': 0.8334644059485119, 'Gradient Boosting__tol': 0.0001, 'Gradient Boosting__validation_fraction': 0.1, 'Gradient Boosting__verbose': 0, 'Gradient Boosting__warm_start': False}"
        ],
        [
         "8",
         "GP",
         "Logistic Regression",
         "{'C': 0.08257791600771174, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "9",
         "GP",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "10",
         "GP",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 75, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "11",
         "GP",
         "K-Nearest Neighbors",
         "{'algorithm': 'ball_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 41, 'p': 2, 'weights': 'uniform'}"
        ],
        [
         "12",
         "GP",
         "Support Vector Machine",
         "{'C': 0.01, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 5, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "13",
         "GP",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.2183643573364074, 'n_estimators': 55, 'random_state': 42}"
        ],
        [
         "14",
         "GP",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 10, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 67, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "15",
         "GP",
         "SEl-NNML",
         "{'cv': None, 'estimators': [('Random Forest', RandomForestClassifier(criterion='entropy', max_depth=6, n_estimators=75,\n                       n_jobs=-1, random_state=42)), ('AdaBoost', AdaBoostClassifier(learning_rate=0.2183643573364074, n_estimators=55,\n                   random_state=42))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.00036619258793526205, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (39,), 'final_estimator__learning_rate': 'constant', 'final_estimator__learning_rate_init': 0.004255366449682059, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.00036619258793526205, hidden_layer_sizes=(39,),\n              learning_rate_init=0.004255366449682059, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Random Forest': RandomForestClassifier(criterion='entropy', max_depth=6, n_estimators=75,\n                       n_jobs=-1, random_state=42), 'AdaBoost': AdaBoostClassifier(learning_rate=0.2183643573364074, n_estimators=55,\n                   random_state=42), 'Random Forest__bootstrap': True, 'Random Forest__ccp_alpha': 0.0, 'Random Forest__class_weight': None, 'Random Forest__criterion': 'entropy', 'Random Forest__max_depth': 6, 'Random Forest__max_features': 'sqrt', 'Random Forest__max_leaf_nodes': None, 'Random Forest__max_samples': None, 'Random Forest__min_impurity_decrease': 0.0, 'Random Forest__min_samples_leaf': 1, 'Random Forest__min_samples_split': 2, 'Random Forest__min_weight_fraction_leaf': 0.0, 'Random Forest__monotonic_cst': None, 'Random Forest__n_estimators': 75, 'Random Forest__n_jobs': -1, 'Random Forest__oob_score': False, 'Random Forest__random_state': 42, 'Random Forest__verbose': 0, 'Random Forest__warm_start': False, 'AdaBoost__algorithm': 'deprecated', 'AdaBoost__estimator': None, 'AdaBoost__learning_rate': 0.2183643573364074, 'AdaBoost__n_estimators': 55, 'AdaBoost__random_state': 42}"
        ],
        [
         "16",
         "CMA-ES",
         "Logistic Regression",
         "{'C': 0.09399685792020154, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "17",
         "CMA-ES",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 9, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "18",
         "CMA-ES",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 8, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 64, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "19",
         "CMA-ES",
         "K-Nearest Neighbors",
         "{'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 44, 'p': 1, 'weights': 'uniform'}"
        ],
        [
         "20",
         "CMA-ES",
         "Support Vector Machine",
         "{'C': 0.0023486280228330577, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 4, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "21",
         "CMA-ES",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.30613278617671263, 'n_estimators': 54, 'random_state': 42}"
        ],
        [
         "22",
         "CMA-ES",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.03291251792336746, 'loss': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 9, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 59, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.583709078715611, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "23",
         "CMA-ES",
         "SEl-NNML",
         "{'cv': None, 'estimators': [('K-Nearest Neighbors', KNeighborsClassifier(algorithm='kd_tree', n_jobs=-1, n_neighbors=44, p=1)), ('Support Vector Machine', SVC(C=0.0023486280228330577, degree=4, kernel='poly', random_state=42)), ('AdaBoost', AdaBoostClassifier(learning_rate=0.30613278617671263, n_estimators=54,\n                   random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(learning_rate=0.03291251792336746, max_depth=5,\n                           max_features='log2', min_samples_leaf=6,\n                           min_samples_split=9, n_estimators=59,\n                           random_state=42, subsample=0.583709078715611))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.0016312041807207015, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (52, 100, 100), 'final_estimator__learning_rate': 'adaptive', 'final_estimator__learning_rate_init': 0.0001952045318704599, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.0016312041807207015, hidden_layer_sizes=(52, 100, 100),\n              learning_rate='adaptive',\n              learning_rate_init=0.0001952045318704599, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'K-Nearest Neighbors': KNeighborsClassifier(algorithm='kd_tree', n_jobs=-1, n_neighbors=44, p=1), 'Support Vector Machine': SVC(C=0.0023486280228330577, degree=4, kernel='poly', random_state=42), 'AdaBoost': AdaBoostClassifier(learning_rate=0.30613278617671263, n_estimators=54,\n                   random_state=42), 'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.03291251792336746, max_depth=5,\n                           max_features='log2', min_samples_leaf=6,\n                           min_samples_split=9, n_estimators=59,\n                           random_state=42, subsample=0.583709078715611), 'K-Nearest Neighbors__algorithm': 'kd_tree', 'K-Nearest Neighbors__leaf_size': 30, 'K-Nearest Neighbors__metric': 'minkowski', 'K-Nearest Neighbors__metric_params': None, 'K-Nearest Neighbors__n_jobs': -1, 'K-Nearest Neighbors__n_neighbors': 44, 'K-Nearest Neighbors__p': 1, 'K-Nearest Neighbors__weights': 'uniform', 'Support Vector Machine__C': 0.0023486280228330577, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 4, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False, 'AdaBoost__algorithm': 'deprecated', 'AdaBoost__estimator': None, 'AdaBoost__learning_rate': 0.30613278617671263, 'AdaBoost__n_estimators': 54, 'AdaBoost__random_state': 42, 'Gradient Boosting__ccp_alpha': 0.0, 'Gradient Boosting__criterion': 'friedman_mse', 'Gradient Boosting__init': None, 'Gradient Boosting__learning_rate': 0.03291251792336746, 'Gradient Boosting__loss': 'log_loss', 'Gradient Boosting__max_depth': 5, 'Gradient Boosting__max_features': 'log2', 'Gradient Boosting__max_leaf_nodes': None, 'Gradient Boosting__min_impurity_decrease': 0.0, 'Gradient Boosting__min_samples_leaf': 6, 'Gradient Boosting__min_samples_split': 9, 'Gradient Boosting__min_weight_fraction_leaf': 0.0, 'Gradient Boosting__n_estimators': 59, 'Gradient Boosting__n_iter_no_change': None, 'Gradient Boosting__random_state': 42, 'Gradient Boosting__subsample': 0.583709078715611, 'Gradient Boosting__tol': 0.0001, 'Gradient Boosting__validation_fraction': 0.1, 'Gradient Boosting__verbose': 0, 'Gradient Boosting__warm_start': False}"
        ],
        [
         "24",
         "QMC",
         "Logistic Regression",
         "{'C': 0.0930572040929699, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "25",
         "QMC",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 9, 'min_samples_split': 9, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "26",
         "QMC",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 78, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "27",
         "QMC",
         "K-Nearest Neighbors",
         "{'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 41, 'p': 2, 'weights': 'uniform'}"
        ],
        [
         "28",
         "QMC",
         "Support Vector Machine",
         "{'C': 0.008058421877614822, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 5, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "29",
         "QMC",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.10941138105771861, 'n_estimators': 83, 'random_state': 42}"
        ],
        [
         "30",
         "QMC",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.02287573200318397, 'loss': 'log_loss', 'max_depth': 6, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 7, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 83, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.73828125, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "31",
         "QMC",
         "SEl-NNML",
         "{'cv': None, 'estimators': [('Decision Tree', DecisionTreeClassifier(max_depth=8, max_features='log2', min_samples_leaf=9,\n                       min_samples_split=9, random_state=42)), ('K-Nearest Neighbors', KNeighborsClassifier(algorithm='kd_tree', n_jobs=-1, n_neighbors=41)), ('Support Vector Machine', SVC(C=0.008058421877614822, degree=5, kernel='poly', random_state=42)), ('AdaBoost', AdaBoostClassifier(learning_rate=0.10941138105771861, n_estimators=83,\n                   random_state=42))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.0015399265260594922, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (46, 73, 58, 38, 84), 'final_estimator__learning_rate': 'constant', 'final_estimator__learning_rate_init': 0.0036517412725483775, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.0015399265260594922,\n              hidden_layer_sizes=(46, 73, 58, 38, 84),\n              learning_rate_init=0.0036517412725483775, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Decision Tree': DecisionTreeClassifier(max_depth=8, max_features='log2', min_samples_leaf=9,\n                       min_samples_split=9, random_state=42), 'K-Nearest Neighbors': KNeighborsClassifier(algorithm='kd_tree', n_jobs=-1, n_neighbors=41), 'Support Vector Machine': SVC(C=0.008058421877614822, degree=5, kernel='poly', random_state=42), 'AdaBoost': AdaBoostClassifier(learning_rate=0.10941138105771861, n_estimators=83,\n                   random_state=42), 'Decision Tree__ccp_alpha': 0.0, 'Decision Tree__class_weight': None, 'Decision Tree__criterion': 'gini', 'Decision Tree__max_depth': 8, 'Decision Tree__max_features': 'log2', 'Decision Tree__max_leaf_nodes': None, 'Decision Tree__min_impurity_decrease': 0.0, 'Decision Tree__min_samples_leaf': 9, 'Decision Tree__min_samples_split': 9, 'Decision Tree__min_weight_fraction_leaf': 0.0, 'Decision Tree__monotonic_cst': None, 'Decision Tree__random_state': 42, 'Decision Tree__splitter': 'best', 'K-Nearest Neighbors__algorithm': 'kd_tree', 'K-Nearest Neighbors__leaf_size': 30, 'K-Nearest Neighbors__metric': 'minkowski', 'K-Nearest Neighbors__metric_params': None, 'K-Nearest Neighbors__n_jobs': -1, 'K-Nearest Neighbors__n_neighbors': 41, 'K-Nearest Neighbors__p': 2, 'K-Nearest Neighbors__weights': 'uniform', 'Support Vector Machine__C': 0.008058421877614822, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 5, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False, 'AdaBoost__algorithm': 'deprecated', 'AdaBoost__estimator': None, 'AdaBoost__learning_rate': 0.10941138105771861, 'AdaBoost__n_estimators': 83, 'AdaBoost__random_state': 42}"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 32
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Best Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.09767265811237319, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPE</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 30, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.009980295032795012, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPE</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TPE</td>\n",
       "      <td>SEl-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Decision Tree', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GP</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.08257791600771174, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GP</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GP</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 30, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GP</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.01, 'break_ties': False, 'cache_size':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GP</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GP</td>\n",
       "      <td>SEl-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Random Forest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.09399685792020154, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 30, 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.0023486280228330577, 'break_ties': Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>SEl-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('K-Nearest Neighb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.0930572040929699, 'class_weight': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>QMC</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 30, 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.008058421877614822, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>QMC</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>QMC</td>\n",
       "      <td>SEl-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Decision Tree', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sampler              Model Name  \\\n",
       "0      TPE     Logistic Regression   \n",
       "1      TPE           Decision Tree   \n",
       "2      TPE           Random Forest   \n",
       "3      TPE     K-Nearest Neighbors   \n",
       "4      TPE  Support Vector Machine   \n",
       "5      TPE                AdaBoost   \n",
       "6      TPE       Gradient Boosting   \n",
       "7      TPE                SEl-NNML   \n",
       "8       GP     Logistic Regression   \n",
       "9       GP           Decision Tree   \n",
       "10      GP           Random Forest   \n",
       "11      GP     K-Nearest Neighbors   \n",
       "12      GP  Support Vector Machine   \n",
       "13      GP                AdaBoost   \n",
       "14      GP       Gradient Boosting   \n",
       "15      GP                SEl-NNML   \n",
       "16  CMA-ES     Logistic Regression   \n",
       "17  CMA-ES           Decision Tree   \n",
       "18  CMA-ES           Random Forest   \n",
       "19  CMA-ES     K-Nearest Neighbors   \n",
       "20  CMA-ES  Support Vector Machine   \n",
       "21  CMA-ES                AdaBoost   \n",
       "22  CMA-ES       Gradient Boosting   \n",
       "23  CMA-ES                SEl-NNML   \n",
       "24     QMC     Logistic Regression   \n",
       "25     QMC           Decision Tree   \n",
       "26     QMC           Random Forest   \n",
       "27     QMC     K-Nearest Neighbors   \n",
       "28     QMC  Support Vector Machine   \n",
       "29     QMC                AdaBoost   \n",
       "30     QMC       Gradient Boosting   \n",
       "31     QMC                SEl-NNML   \n",
       "\n",
       "                                 Best Hyperparameters  \n",
       "0   {'C': 0.09767265811237319, 'class_weight': Non...  \n",
       "1   {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "2   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "3   {'algorithm': 'ball_tree', 'leaf_size': 30, 'm...  \n",
       "4   {'C': 0.009980295032795012, 'break_ties': Fals...  \n",
       "5   {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "6   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "7   {'cv': None, 'estimators': [('Decision Tree', ...  \n",
       "8   {'C': 0.08257791600771174, 'class_weight': Non...  \n",
       "9   {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "10  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "11  {'algorithm': 'ball_tree', 'leaf_size': 30, 'm...  \n",
       "12  {'C': 0.01, 'break_ties': False, 'cache_size':...  \n",
       "13  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "14  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "15  {'cv': None, 'estimators': [('Random Forest', ...  \n",
       "16  {'C': 0.09399685792020154, 'class_weight': Non...  \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "18  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "19  {'algorithm': 'kd_tree', 'leaf_size': 30, 'met...  \n",
       "20  {'C': 0.0023486280228330577, 'break_ties': Fal...  \n",
       "21  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "22  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "23  {'cv': None, 'estimators': [('K-Nearest Neighb...  \n",
       "24  {'C': 0.0930572040929699, 'class_weight': None...  \n",
       "25  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "26  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "27  {'algorithm': 'kd_tree', 'leaf_size': 30, 'met...  \n",
       "28  {'C': 0.008058421877614822, 'break_ties': Fals...  \n",
       "29  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "30  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "31  {'cv': None, 'estimators': [('Decision Tree', ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All Models Storage for all sampler types\n",
    "all_models = {\n",
    "    'TPE': {\n",
    "        'Logistic Regression': tpe_logistic_regression,\n",
    "        'Decision Tree': tpe_decision_tree,\n",
    "        'Random Forest': tpe_random_forest,\n",
    "        'K-Nearest Neighbors': tpe_knn,\n",
    "        'Support Vector Machine': tpe_svc,\n",
    "        'AdaBoost': tpe_adaboost,\n",
    "        'Gradient Boosting': tpe_gradient_boosting,\n",
    "        'SEl-NNML': tpe_sel_nnml\n",
    "    },\n",
    "    'GP': {\n",
    "        'Logistic Regression': gp_logistic_regression,\n",
    "        'Decision Tree': gp_decision_tree,\n",
    "        'Random Forest': gp_random_forest,\n",
    "        'K-Nearest Neighbors': gp_knn,\n",
    "        'Support Vector Machine': gp_svc,\n",
    "        'AdaBoost': gp_adaboost,\n",
    "        'Gradient Boosting': gp_gradient_boosting,\n",
    "        'SEl-NNML': gp_sel_nnml\n",
    "    },\n",
    "    'CMA-ES': {\n",
    "        'Logistic Regression': cmaes_logistic_regression,\n",
    "        'Decision Tree': cmaes_decision_tree,\n",
    "        'Random Forest': cmaes_random_forest,\n",
    "        'K-Nearest Neighbors': cmaes_knn,\n",
    "        'Support Vector Machine': cmaes_svc,\n",
    "        'AdaBoost': cmaes_adaboost,\n",
    "        'Gradient Boosting': cmaes_gradient_boosting,\n",
    "        'SEl-NNML': cmaes_sel_nnml\n",
    "    },\n",
    "    'QMC': {\n",
    "        'Logistic Regression': qmc_logistic_regression,\n",
    "        'Decision Tree': qmc_decision_tree,\n",
    "        'Random Forest': qmc_random_forest,\n",
    "        'K-Nearest Neighbors': qmc_knn,\n",
    "        'Support Vector Machine': qmc_svc,\n",
    "        'AdaBoost': qmc_adaboost,\n",
    "        'Gradient Boosting': qmc_gradient_boosting,\n",
    "        'SEl-NNML': qmc_sel_nnml\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save Every Best Model Config for each Tuning Method (Base + Meta) as CSV\n",
    "all_model_hyperparameters = []\n",
    "for sampler, models in all_models.items():\n",
    "    for model_name, model in models.items():\n",
    "        # Some meta models (e.g., stacking) may not have get_params, handle gracefully\n",
    "        params = model.get_params() if hasattr(model, 'get_params') else None\n",
    "        all_model_hyperparameters.append({\n",
    "            'Sampler': sampler,\n",
    "            'Model Name': model_name,\n",
    "            'Best Hyperparameters': params\n",
    "        })\n",
    "all_model_hyperparameters_df = pd.DataFrame(all_model_hyperparameters)\n",
    "all_model_hyperparameters_df.to_csv('../artifacts/ds1/models/all_model_hyperparameters.csv', index=False)\n",
    "\n",
    "# Show All Model Hyperparameters for all samplers\n",
    "all_model_hyperparameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Logistic Regression model tuned with TPE to ../artifacts/ds1/models/tpe/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with TPE to ../artifacts/ds1/models/tpe/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with TPE to ../artifacts/ds1/models/tpe/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with TPE to ../artifacts/ds1/models/tpe/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with TPE to ../artifacts/ds1/models/tpe/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with TPE to ../artifacts/ds1/models/tpe/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with TPE to ../artifacts/ds1/models/tpe/gradient_boosting_best_model.pkl\n",
      "Saved SEl-NNML model tuned with TPE to ../artifacts/ds1/models/tpe/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with GP to ../artifacts/ds1/models/gp/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with GP to ../artifacts/ds1/models/gp/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with GP to ../artifacts/ds1/models/gp/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with GP to ../artifacts/ds1/models/gp/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with GP to ../artifacts/ds1/models/gp/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with GP to ../artifacts/ds1/models/gp/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with GP to ../artifacts/ds1/models/gp/gradient_boosting_best_model.pkl\n",
      "Saved SEl-NNML model tuned with GP to ../artifacts/ds1/models/gp/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/gradient_boosting_best_model.pkl\n",
      "Saved SEl-NNML model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with QMC to ../artifacts/ds1/models/qmc/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with QMC to ../artifacts/ds1/models/qmc/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with QMC to ../artifacts/ds1/models/qmc/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with QMC to ../artifacts/ds1/models/qmc/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with QMC to ../artifacts/ds1/models/qmc/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with QMC to ../artifacts/ds1/models/qmc/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with QMC to ../artifacts/ds1/models/qmc/gradient_boosting_best_model.pkl\n",
      "Saved SEl-NNML model tuned with QMC to ../artifacts/ds1/models/qmc/sel-nnml_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save Every Best Meta Model for each Tuning Method as .pkl\n",
    "for sampler, models in all_models.items():\n",
    "    folder = sampler.lower().replace(\"-\", \"\")\n",
    "    for model_name, model in models.items():\n",
    "        filename = f'../artifacts/ds1/models/{folder}/{model_name.replace(\" \", \"_\").lower()}_best_model.pkl'\n",
    "        joblib.dump(model, filename)\n",
    "        print(f'Saved {model_name} model tuned with {sampler} to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sampler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Base Models Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Meta Model Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "62bf6a9d-8100-4cc2-b418-18d27c838872",
       "rows": [
        [
         "0",
         "TPE",
         "85.57969903945923",
         "187.73406410217285",
         "273.3137631416321"
        ],
        [
         "1",
         "GP",
         "256.32170391082764",
         "153.69617462158203",
         "410.01787853240967"
        ],
        [
         "2",
         "CMA-ES",
         "85.31165909767151",
         "140.96581029891968",
         "226.2774693965912"
        ],
        [
         "3",
         "QMC",
         "83.02041721343994",
         "179.8220932483673",
         "262.84251046180725"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Base Models Training Time (seconds)</th>\n",
       "      <th>Meta Model Training Time (seconds)</th>\n",
       "      <th>Total Training Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPE</td>\n",
       "      <td>85.579699</td>\n",
       "      <td>187.734064</td>\n",
       "      <td>273.313763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>256.321704</td>\n",
       "      <td>153.696175</td>\n",
       "      <td>410.017879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>85.311659</td>\n",
       "      <td>140.965810</td>\n",
       "      <td>226.277469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QMC</td>\n",
       "      <td>83.020417</td>\n",
       "      <td>179.822093</td>\n",
       "      <td>262.842510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sampler  Base Models Training Time (seconds)  \\\n",
       "0     TPE                            85.579699   \n",
       "1      GP                           256.321704   \n",
       "2  CMA-ES                            85.311659   \n",
       "3     QMC                            83.020417   \n",
       "\n",
       "   Meta Model Training Time (seconds)  Total Training Time (seconds)  \n",
       "0                          187.734064                     273.313763  \n",
       "1                          153.696175                     410.017879  \n",
       "2                          140.965810                     226.277469  \n",
       "3                          179.822093                     262.842510  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVE TRAIN TIME FOR EACH SAMPLER TYPE (BASE + META) IN A FILE\n",
    "train_times = {\n",
    "    'Sampler': ['TPE', 'GP', 'CMA-ES', 'QMC'],\n",
    "    'Base Models Training Time (seconds)': [\n",
    "        tpe_base_models_training_time,\n",
    "        gp_base_models_training_time,\n",
    "        cmaes_base_models_training_time,\n",
    "        qmc_base_models_training_time\n",
    "    ],\n",
    "    'Meta Model Training Time (seconds)': [\n",
    "        tpe_meta_model_training_time,\n",
    "        gp_meta_model_training_time,\n",
    "        cmaes_meta_model_training_time,\n",
    "        qmc_meta_model_training_time\n",
    "    ],\n",
    "    'Total Training Time (seconds)': [\n",
    "        tpe_base_models_training_time + tpe_meta_model_training_time,\n",
    "        gp_base_models_training_time + gp_meta_model_training_time,\n",
    "        cmaes_base_models_training_time + cmaes_meta_model_training_time,\n",
    "        qmc_base_models_training_time + qmc_meta_model_training_time\n",
    "    ]\n",
    "}\n",
    "\n",
    "train_times_df = pd.DataFrame(train_times)\n",
    "train_times_df.to_csv('../artifacts/ds1/models/training_times.csv', index=False)\n",
    "train_times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skip step 4 and uncomment this code to load every best model for each tuning method so we dont have to retrain them\n",
    "# all_models = {sampler: {\n",
    "#         'Logistic Regression': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/logistic_regression_best_model.pkl'),\n",
    "#         'Decision Tree': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/decision_tree_best_model.pkl'),\n",
    "#         'Random Forest': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/random_forest_best_model.pkl'),\n",
    "#         'K-Nearest Neighbors': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/k-nearest_neighbors_best_model.pkl'),\n",
    "#         'Support Vector Machine': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/support_vector_machine_best_model.pkl'),\n",
    "#         'AdaBoost': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/adaboost_best_model.pkl'),\n",
    "#         'Gradient Boosting': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/gradient_boosting_best_model.pkl'),\n",
    "#         'SEL-NNML': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/sel-nnml_best_model.pkl')\n",
    "#     } for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;Decision Tree&#x27;,\n",
       "                                DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;,\n",
       "                                                       max_depth=4,\n",
       "                                                       min_samples_leaf=3,\n",
       "                                                       min_samples_split=10,\n",
       "                                                       random_state=42)),\n",
       "                               (&#x27;AdaBoost&#x27;,\n",
       "                                AdaBoostClassifier(learning_rate=0.2511295868890071,\n",
       "                                                   n_estimators=84,\n",
       "                                                   random_state=42)),\n",
       "                               (&#x27;Gradient Boosting&#x27;,\n",
       "                                GradientBoostingClassifier(learning_rate=0.014113282033022877,\n",
       "                                                           max_depth=6,\n",
       "                                                           max_features=&#x27;sqrt&#x27;,\n",
       "                                                           min_samples_leaf=7,\n",
       "                                                           min_samples_split=8,\n",
       "                                                           n_estimators=53,\n",
       "                                                           random_state=42,\n",
       "                                                           subsample=0.8334644059485119))],\n",
       "                   final_estimator=MLPClassifier(alpha=0.006114818319251142,\n",
       "                                                 hidden_layer_sizes=(52, 15),\n",
       "                                                 learning_rate=&#x27;adaptive&#x27;,\n",
       "                                                 learning_rate_init=0.001244030248083268,\n",
       "                                                 max_iter=300,\n",
       "                                                 random_state=42),\n",
       "                   n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StackingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimators&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;Decision Tree&#x27;, ...), (&#x27;AdaBoost&#x27;, ...), ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('final_estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">final_estimator&nbsp;</td>\n",
       "            <td class=\"value\">MLPClassifier...ndom_state=42)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stack_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stack_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('passthrough',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">passthrough&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>Decision Tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"Decision Tree__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;log_loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">splitter&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>AdaBoost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>AdaBoostClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"AdaBoost__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">84</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.2511295868890071</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('algorithm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">algorithm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>Gradient Boosting</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"Gradient Boosting__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;log_loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.014113282033022877</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">53</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8334644059485119</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;friedman_mse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('init',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">init&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"final_estimator__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('hidden_layer_sizes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">hidden_layer_sizes&nbsp;</td>\n",
       "            <td class=\"value\">(52, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('activation',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">activation&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;relu&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;adam&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.006114818319251142</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('batch_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">batch_size&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;adaptive&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate_init',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate_init&nbsp;</td>\n",
       "            <td class=\"value\">0.001244030248083268</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_t',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">power_t&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shuffle',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shuffle&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('momentum',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">momentum&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('nesterovs_momentum',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">nesterovs_momentum&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('beta_1',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">beta_1&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('beta_2',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">beta_2&nbsp;</td>\n",
       "            <td class=\"value\">0.999</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('epsilon',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">epsilon&nbsp;</td>\n",
       "            <td class=\"value\">1e-08</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_fun',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_fun&nbsp;</td>\n",
       "            <td class=\"value\">15000</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('Decision Tree',\n",
       "                                DecisionTreeClassifier(criterion='log_loss',\n",
       "                                                       max_depth=4,\n",
       "                                                       min_samples_leaf=3,\n",
       "                                                       min_samples_split=10,\n",
       "                                                       random_state=42)),\n",
       "                               ('AdaBoost',\n",
       "                                AdaBoostClassifier(learning_rate=0.2511295868890071,\n",
       "                                                   n_estimators=84,\n",
       "                                                   random_state=42)),\n",
       "                               ('Gradient Boosting',\n",
       "                                GradientBoostingClassifier(learning_rate=0.014113282033022877,\n",
       "                                                           max_depth=6,\n",
       "                                                           max_features='sqrt',\n",
       "                                                           min_samples_leaf=7,\n",
       "                                                           min_samples_split=8,\n",
       "                                                           n_estimators=53,\n",
       "                                                           random_state=42,\n",
       "                                                           subsample=0.8334644059485119))],\n",
       "                   final_estimator=MLPClassifier(alpha=0.006114818319251142,\n",
       "                                                 hidden_layer_sizes=(52, 15),\n",
       "                                                 learning_rate='adaptive',\n",
       "                                                 learning_rate_init=0.001244030248083268,\n",
       "                                                 max_iter=300,\n",
       "                                                 random_state=42),\n",
       "                   n_jobs=-1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models['TPE']['SEL-NNML']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage contains model evaluation on the test set, with details as follows:\n",
    "- `plot_evaluation_metrics()`: Shows the confusion matrix graph & scores for accuracy, precision, recall, and F1-Score\n",
    "- `Model Performance Comparison Plot`: Displays accuracy, precision, recall, F1-Score, and ROC AUC scores\n",
    "- `overfitting_index_plot()`: Shows the percentage of the difference between model scores on test data versus training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Model Evaluation Dashboard\n",
    "def evaluation_metrics_plot(y_true, y_pred):\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "    }\n",
    "    metric_order = ['F1-Score', 'Recall', 'Precision', 'Accuracy']\n",
    "    values = [metrics[name] for name in metric_order]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    cm_pos = [0.08, 0.15, 0.53, 0.7]\n",
    "    metrics_pos = [0.75, 0.15, 0.21, 0.7]\n",
    "\n",
    "    # Confusion Matrix\n",
    "    ax_cm = fig.add_axes(cm_pos)\n",
    "    im = ax_cm.imshow(cm, cmap='Blues', interpolation='nearest', aspect='equal')\n",
    "    cbar_ax = fig.add_axes([cm_pos[0] + cm_pos[2] + 0.02, cm_pos[1], 0.02, cm_pos[3]])\n",
    "    fig.colorbar(im, cax=cbar_ax).ax.tick_params(labelsize=16)\n",
    "\n",
    "    cm_pct = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            count, pct = int(cm[i, j]), cm_pct[i, j]\n",
    "            color = 'white' if count > cm.max() / 2 else 'black'\n",
    "            ax_cm.text(j, i, f'{count}\\n({pct:.1f}%)', ha='center', va='center',\n",
    "                    color=color, fontsize=18, fontweight='bold', linespacing=1.1)\n",
    "\n",
    "    ax_cm.set_xticks([0, 1])\n",
    "    ax_cm.set_yticks([0, 1])\n",
    "    ax_cm.set_xticklabels(['No\\n(0)', 'Disease\\n(1)'], fontsize=16)\n",
    "    ax_cm.set_yticklabels(['No (0)', 'Disease (1)'], fontsize=16, rotation=90, va='center')\n",
    "    ax_cm.set_xlabel('Predicted', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_ylabel('Actual', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_title('Confusion Matrix', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_cm.set_ylim(1.5, -0.5)\n",
    "\n",
    "    # Metrics Bar\n",
    "    ax_metrics = fig.add_axes(metrics_pos)\n",
    "    y_positions = np.arange(len(metric_order)) * 2\n",
    "    bars = ax_metrics.barh(y_positions, values, height=0.8, color='#31688E', alpha=0.8)\n",
    "\n",
    "    for bar, value in zip(bars, values):\n",
    "        color = 'white' if value > 0.5 else 'black'\n",
    "        x_pos = value - 0.02 if value > 0.5 else value + 0.02\n",
    "        ha = 'right' if value > 0.5 else 'left'\n",
    "        ax_metrics.text(x_pos, bar.get_y() + bar.get_height()/2, f'{value:.3f}',\n",
    "                        ha=ha, va='center', fontsize=18, fontweight='bold', color=color)\n",
    "\n",
    "    ax_metrics.set_xlim(-0.05, 1.05)\n",
    "    ax_metrics.set_ylim(-0.8, len(metric_order) * 2 - 0.2)\n",
    "    ax_metrics.set_xticks([0, 0.5, 1.0])\n",
    "    ax_metrics.set_xticklabels(['0.0', '0.5', '1.0'], fontsize=16)\n",
    "    ax_metrics.set_yticks(y_positions)\n",
    "    ax_metrics.set_yticklabels(metric_order, fontsize=16, rotation=90, ha='left', va='center')\n",
    "    ax_metrics.tick_params(axis='y', pad=15)\n",
    "    ax_metrics.tick_params(axis='x', pad=8)\n",
    "    ax_metrics.set_xlabel('Score', fontsize=16, fontweight='bold')\n",
    "    ax_metrics.set_title('Performance Metrics', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_metrics.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    for spine in ['top', 'right', 'left']:\n",
    "        ax_metrics.spines[spine].set_visible(False)\n",
    "    ax_metrics.spines['bottom'].set_alpha(0.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Model Comparison Dashboard (for comparing all models)\n",
    "def model_comparison_plot(models, x_test, y_test):\n",
    "    metrics = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'F1-Score': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "    \n",
    "    # Map full names to short names\n",
    "    short_names = {\n",
    "        'Logistic Regression': 'LR',\n",
    "        'Decision Tree': 'DT',\n",
    "        'Random Forest': 'RF',\n",
    "        'K-Nearest Neighbors': 'KNN',\n",
    "        'Support Vector Machine': 'SVM',\n",
    "        'AdaBoost': 'AdaBoost',\n",
    "        'Gradient Boosting': 'Gradient Boosting',\n",
    "        'SEL-NNML': 'SEL-NNML'\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics for each model\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(x_test)\n",
    "        metrics['Model'].append(short_names[model_name])\n",
    "        metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        metrics['F1-Score'].append(f1_score(y_test, y_pred))\n",
    "        metrics['Precision'].append(precision_score(y_test, y_pred))\n",
    "        metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "        \n",
    "        # Calculate AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        metrics['AUC'].append(roc_auc)\n",
    "    \n",
    "    # Convert metrics to DataFrame for sorting\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "    fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold') \n",
    "    \n",
    "    # Helper function to plot sorted bar charts\n",
    "    def plot_sorted_bar_chart(ax, metric_name):\n",
    "        sorted_df = metrics_df.sort_values(by=metric_name, ascending=False)\n",
    "        colors = ['tab:orange' if model == 'SEL-NNML' else 'tab:blue' for model in sorted_df['Model']]\n",
    "        ax.bar(sorted_df['Model'], sorted_df[metric_name], color=colors)\n",
    "        ax.set_title(metric_name)\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_xticks(range(len(sorted_df['Model'])))\n",
    "        ax.set_xticklabels(sorted_df['Model'], rotation=30, ha='center')\n",
    "        for i, v in enumerate(sorted_df[metric_name]):\n",
    "            ax.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "    # Plot each metric\n",
    "    plot_sorted_bar_chart(axes[0, 0], 'Accuracy')\n",
    "    plot_sorted_bar_chart(axes[0, 1], 'F1-Score')\n",
    "    plot_sorted_bar_chart(axes[1, 0], 'Precision')\n",
    "    plot_sorted_bar_chart(axes[1, 1], 'Recall')\n",
    "    \n",
    "    # ROC Curve\n",
    "    ax_roc = axes[2, 0]\n",
    "    for model_name, model in models.items():\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax_roc.plot(fpr, tpr, lw=2, label=f'{short_names[model_name]} (AUC = {roc_auc:.3f})')\n",
    "    ax_roc.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_title('Receiver Operating Characteristic')\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Bar chart for AUC\n",
    "    plot_sorted_bar_chart(axes[2, 1], 'AUC')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfitting_index_plot(all_models, x_train, y_train, x_test, y_test):\n",
    "    metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "    overfitting_indices = {metric: [] for metric in metrics}\n",
    "\n",
    "    for _, model in all_models.items():\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "        overfitting_indices['Accuracy'].append(abs(accuracy_score(y_train, y_train_pred) - accuracy_score(y_test, y_test_pred)) / accuracy_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['F1-Score'].append(abs(f1_score(y_train, y_train_pred) - f1_score(y_test, y_test_pred)) / f1_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Precision'].append(abs(precision_score(y_train, y_train_pred) - precision_score(y_test, y_test_pred)) / precision_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Recall'].append(abs(recall_score(y_train, y_train_pred) - recall_score(y_test, y_test_pred)) / recall_score(y_train, y_train_pred) * 100)\n",
    "\n",
    "    overfitting_df = pd.DataFrame(overfitting_indices, index=all_models.keys())\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Overfitting Index for All Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "    def get_bar_colors(models, highlight_model='SEL-NNML', default_color='tab:blue', highlight_color='tab:orange'):\n",
    "        return [highlight_color if model == highlight_model else default_color for model in models]\n",
    "\n",
    "    # Accuracy\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Accuracy', ascending=False)\n",
    "    axes[0, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Accuracy'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 0].set_title('Accuracy Overfitting Index')\n",
    "    axes[0, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 0].set_ylim([0, 100])\n",
    "    axes[0, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Accuracy']):\n",
    "        axes[0, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # F1-Score\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='F1-Score', ascending=False)\n",
    "    axes[0, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['F1-Score'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 1].set_title('F1-Score Overfitting Index')\n",
    "    axes[0, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 1].set_ylim([0, 100])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['F1-Score']):\n",
    "        axes[0, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Precision\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Precision', ascending=False)\n",
    "    axes[1, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Precision'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 0].set_title('Precision Overfitting Index')\n",
    "    axes[1, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 0].set_ylim([0, 100])\n",
    "    axes[1, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Precision']):\n",
    "        axes[1, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Recall\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Recall', ascending=False)\n",
    "    axes[1, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['Recall'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 1].set_title('Recall Overfitting Index')\n",
    "    axes[1, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 1].set_ylim([0, 100])\n",
    "    axes[1, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Recall']):\n",
    "        axes[1, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 Single Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show SEL-NNML Evaluation Metrics\n",
    "y_pred_stack = sel_nnml.predict(X_test)\n",
    "evaluation_metrics_plot(y_test, y_pred_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: [0.86666667 0.87394958 0.87394958 0.81512605 0.87394958]\n",
      "Mean: 0.8607\n",
      "Standard Deviation: 0.0230\n"
     ]
    }
   ],
   "source": [
    "# Show SEL-NNM: all fold scores with mean and std \n",
    "sel_nnml_cv_scores = cross_val_score(sel_nnml, X_train, y_train, cv=CV_FOLDS, scoring='accuracy', n_jobs=N_JOBS)\n",
    "print(f'SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: {sel_nnml_cv_scores}')\n",
    "print(f'Mean: {sel_nnml_cv_scores.mean():.4f}')\n",
    "print(f'Standard Deviation: {sel_nnml_cv_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Models Tuning & Training Time: 73.47 seconds\n",
      "Meta Model Tuning & Training Time: 120.10 seconds\n",
      "Total SEL-NNML Tuning & Training Time: 193.57 seconds\n"
     ]
    }
   ],
   "source": [
    "# Show SELL-NNML Training Time\n",
    "Total_training_time = base_models_training_time + meta_model_training_time\n",
    "print(f'Base Models Tuning & Training Time: {base_models_training_time:.2f} seconds')\n",
    "print(f'Meta Model Tuning & Training Time: {meta_model_training_time:.2f} seconds')\n",
    "print(f'Total SEL-NNML Tuning & Training Time: {Total_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Multiple Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_comparison_plot(all_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overfitting_index_plot(all_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
