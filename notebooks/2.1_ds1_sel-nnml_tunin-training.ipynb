{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SEL-NNML Tuning - Kaggle Heart Failure Prediction Dataset**\n",
    "\n",
    "This notebook implements several tuning methods on the `Stacking Ensemble Learning with a Neural Network Meta-Learner (SEL-NNML)` model using the `Kaggle Heart Failure Prediction Dataset (KHFPD)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Global Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Data splitting configuration\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Cross-validation configuration\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Hyperparameter tuning configuration\n",
    "OPTIMIZATION_ITERATIONS = 100\n",
    "OPTIMIZATION_METRIC = 'accuracy'\n",
    "OPTIMIZATION_DIRECTION='maximize'\n",
    "\n",
    "# Parallel processing configuration\n",
    "N_JOBS = -1 \n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_PATH = '../datasets/processed/ds1_kaggle_heart_clean.csv'\n",
    "TARGET_COLUMN = 'HeartDisease'\n",
    "\n",
    "# Training configuration\n",
    "SKIP_TRAINING = False  # Set to True to load pre-existing models instead of training\n",
    "\n",
    "print('Global configuration loaded successfully!')\n",
    "print(f'Random State: {RANDOM_STATE}')\n",
    "print(f'Test Size: {TEST_SIZE}')\n",
    "print(f'CV Folds: {CV_FOLDS}')\n",
    "print(f'Optimization Iterations: {OPTIMIZATION_ITERATIONS}')\n",
    "print(f'Optimization Metric: {OPTIMIZATION_METRIC}')\n",
    "print(f'Optimization Direction: {OPTIMIZATION_DIRECTION}')\n",
    "print(f'Skip Training: {SKIP_TRAINING}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src import base_model_tuning, meta_model_tuning\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into desired training and testing\n",
    "- After that, Scaling the data using Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling\n",
    "# Separate numeric and boolean columns\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "bool_cols = X_train.select_dtypes(include=['bool', 'uint8']).columns  # includes one-hot from get_dummies\n",
    "\n",
    "# Initialize scaler and fit_transform only on numeric data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=num_cols, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=num_cols, index=X_test.index)\n",
    "\n",
    "# Concatenate back with boolean features (without modification)\n",
    "X_train = pd.concat([X_train_scaled, X_train[bool_cols]], axis=1)\n",
    "X_test = pd.concat([X_test_scaled, X_test[bool_cols]], axis=1)\n",
    "\n",
    "# Save Min-Max Scaler\n",
    "scaler_filename = '../artifacts/ds1/models/min_max_scaler.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f'Saved Min-Max Scaler function for this dataset to {scaler_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Base Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Set `SKIP_TRAINING = True` in the global configuration to skip steps 4 and 5 and load pre-existing models instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    tpe_base_models_training_start = time.time()\n",
    "\n",
    "    # TPE Hyperparameter Tuning with Cross Validation\n",
    "    tpe_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    tpe_logistic_regression.fit(X_train, y_train)\n",
    "    tpe_decision_tree.fit(X_train, y_train)\n",
    "    tpe_random_forest.fit(X_train, y_train)\n",
    "    tpe_knn.fit(X_train, y_train)\n",
    "    tpe_svc.fit(X_train, y_train)\n",
    "    tpe_adaboost.fit(X_train, y_train)\n",
    "    tpe_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    tpe_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for TPE base models training\n",
    "    tpe_base_models_training_time = tpe_base_models_training_end - tpe_base_models_training_start\n",
    "    print(f'TPE Base Models Training Time: {tpe_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping TPE base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    gp_base_models_training_start = time.time()\n",
    "\n",
    "    # GP Hyperparameter Tuning with Cross Validation\n",
    "    gp_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    gp_logistic_regression.fit(X_train, y_train)\n",
    "    gp_decision_tree.fit(X_train, y_train)\n",
    "    gp_random_forest.fit(X_train, y_train)\n",
    "    gp_knn.fit(X_train, y_train)\n",
    "    gp_svc.fit(X_train, y_train)\n",
    "    gp_adaboost.fit(X_train, y_train)\n",
    "    gp_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    gp_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for GP base models training\n",
    "    gp_base_models_training_time = gp_base_models_training_end - gp_base_models_training_start\n",
    "    print(f'GP Base Models Training Time: {gp_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping GP base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    cmaes_base_models_training_start = time.time()\n",
    "\n",
    "    # CMA-ES Hyperparameter Tuning with Cross Validation\n",
    "    cmaes_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    cmaes_logistic_regression.fit(X_train, y_train)\n",
    "    cmaes_decision_tree.fit(X_train, y_train)\n",
    "    cmaes_random_forest.fit(X_train, y_train)\n",
    "    cmaes_knn.fit(X_train, y_train)\n",
    "    cmaes_svc.fit(X_train, y_train)\n",
    "    cmaes_adaboost.fit(X_train, y_train)\n",
    "    cmaes_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    cmaes_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for CMA-ES base models training\n",
    "    cmaes_base_models_training_time = cmaes_base_models_training_end - cmaes_base_models_training_start\n",
    "    print(f'CMA-ES Base Models Training Time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping CMA-ES base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    qmc_base_models_training_start = time.time()\n",
    "\n",
    "    # QMC Hyperparameter Tuning with Cross Validation\n",
    "    qmc_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    qmc_logistic_regression.fit(X_train, y_train)\n",
    "    qmc_decision_tree.fit(X_train, y_train)\n",
    "    qmc_random_forest.fit(X_train, y_train)\n",
    "    qmc_knn.fit(X_train, y_train)\n",
    "    qmc_svc.fit(X_train, y_train)\n",
    "    qmc_adaboost.fit(X_train, y_train)\n",
    "    qmc_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    qmc_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for QMC base models training\n",
    "    qmc_base_models_training_time = qmc_base_models_training_end - qmc_base_models_training_start\n",
    "    print(f'QMC Base Models Training Time: {qmc_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping QMC base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5 Save Every Best Model Config for each Tuning Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # Base Models Storage for all sampler types\n",
    "    base_models = {\n",
    "        'TPE': {\n",
    "            'Logistic Regression': tpe_logistic_regression,\n",
    "            'Decision Tree': tpe_decision_tree,\n",
    "            'Random Forest': tpe_random_forest,\n",
    "            'K-Nearest Neighbors': tpe_knn,\n",
    "            'Support Vector Machine': tpe_svc,\n",
    "            'AdaBoost': tpe_adaboost,\n",
    "            'Gradient Boosting': tpe_gradient_boosting\n",
    "        },\n",
    "        'GP': {\n",
    "            'Logistic Regression': gp_logistic_regression,\n",
    "            'Decision Tree': gp_decision_tree,\n",
    "            'Random Forest': gp_random_forest,\n",
    "            'K-Nearest Neighbors': gp_knn,\n",
    "            'Support Vector Machine': gp_svc,\n",
    "            'AdaBoost': gp_adaboost,\n",
    "            'Gradient Boosting': gp_gradient_boosting\n",
    "        },\n",
    "        'CMA-ES': {\n",
    "            'Logistic Regression': cmaes_logistic_regression,\n",
    "            'Decision Tree': cmaes_decision_tree,\n",
    "            'Random Forest': cmaes_random_forest,\n",
    "            'K-Nearest Neighbors': cmaes_knn,\n",
    "            'Support Vector Machine': cmaes_svc,\n",
    "            'AdaBoost': cmaes_adaboost,\n",
    "            'Gradient Boosting': cmaes_gradient_boosting\n",
    "        },\n",
    "        'QMC': {\n",
    "            'Logistic Regression': qmc_logistic_regression,\n",
    "            'Decision Tree': qmc_decision_tree,\n",
    "            'Random Forest': qmc_random_forest,\n",
    "            'K-Nearest Neighbors': qmc_knn,\n",
    "            'Support Vector Machine': qmc_svc,\n",
    "            'AdaBoost': qmc_adaboost,\n",
    "            'Gradient Boosting': qmc_gradient_boosting\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    print(\"Skipping base models storage (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Meta Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters to be tuned are:\n",
    "- Selection of the number and type of base models used\n",
    "- Number of layers in the neural network: 1 - 5\n",
    "- Number of neurons per layer: 10 - 100\n",
    "- Learning rate behavior: Constant or Adaptive\n",
    "- Learning rate value: 0.0001 - 0.01\n",
    "- L2 Regularization value: 0.0001 - 0.01\n",
    "\n",
    "Unchanged Preset hyperparameters:\n",
    "- Activation function: ReLU\n",
    "- Optimizer (Solver): Adam\n",
    "- Epochs (Max Iter): 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    tpe_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    tpe_sel_nnml = meta_model_tuning(base_models['TPE'], X_train, y_train, X_test, y_test, sampler='TPESampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    tpe_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for TPE SEl-NNML training\n",
    "    tpe_meta_model_training_time = tpe_meta_model_training_end - tpe_meta_model_training_start\n",
    "    print(f'TPE base models training time: {tpe_base_models_training_time:.2f} seconds')\n",
    "    print(f'TPE SEl-NNML Training Time: {tpe_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total TPE Training Time (Base + Meta): {tpe_base_models_training_time + tpe_meta_model_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping TPE meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    gp_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    gp_sel_nnml = meta_model_tuning(base_models['GP'], X_train, y_train, X_test, y_test, sampler='GPSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    gp_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for GP SEl-NNML training\n",
    "    gp_meta_model_training_time = gp_meta_model_training_end - gp_meta_model_training_start\n",
    "    print(f'GP base models training time: {gp_base_models_training_time:.2f} seconds')\n",
    "    print(f'GP SEl-NNML Training Time: {gp_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total GP Training Time (Base + Meta): {gp_base_models_training_time + gp_meta_model_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping GP meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    cmaes_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    cmaes_sel_nnml = meta_model_tuning(base_models['CMA-ES'], X_train, y_train, X_test, y_test, sampler='CmaEsSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE) \n",
    "    cmaes_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    cmaes_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for CMA-ES SEl-NNML training\n",
    "    cmaes_meta_model_training_time = cmaes_meta_model_training_end - cmaes_meta_model_training_start\n",
    "    print(f'CMA-ES base models training time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "    print(f'CMA-ES SEl-NNML Training Time: {cmaes_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total CMA-ES Training Time (Base + Meta): {cmaes_base_models_training_time + cmaes_meta_model_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping CMA-ES meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    qmc_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    qmc_sel_nnml = meta_model_tuning(base_models['QMC'], X_train, y_train, X_test, y_test, sampler='QMCSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    qmc_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for QMC SEl-NNML training\n",
    "    qmc_meta_model_training_time = qmc_meta_model_training_end - qmc_meta_model_training_start\n",
    "    print(f'QMC base models training time: {qmc_base_models_training_time:.2f} seconds')\n",
    "    print(f'QMC SEl-NNML Training Time: {qmc_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total QMC Training Time (Base + Meta): {qmc_base_models_training_time + qmc_meta_model_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping QMC meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # All Models Storage for all sampler types\n",
    "    all_models = {\n",
    "        'TPE': {\n",
    "            'Logistic Regression': tpe_logistic_regression,\n",
    "            'Decision Tree': tpe_decision_tree,\n",
    "            'Random Forest': tpe_random_forest,\n",
    "            'K-Nearest Neighbors': tpe_knn,\n",
    "            'Support Vector Machine': tpe_svc,\n",
    "            'AdaBoost': tpe_adaboost,\n",
    "            'Gradient Boosting': tpe_gradient_boosting,\n",
    "            'SEL-NNML': tpe_sel_nnml\n",
    "        },\n",
    "        'GP': {\n",
    "            'Logistic Regression': gp_logistic_regression,\n",
    "            'Decision Tree': gp_decision_tree,\n",
    "            'Random Forest': gp_random_forest,\n",
    "            'K-Nearest Neighbors': gp_knn,\n",
    "            'Support Vector Machine': gp_svc,\n",
    "            'AdaBoost': gp_adaboost,\n",
    "            'Gradient Boosting': gp_gradient_boosting,\n",
    "            'SEL-NNML': gp_sel_nnml\n",
    "        },\n",
    "        'CMA-ES': {\n",
    "            'Logistic Regression': cmaes_logistic_regression,\n",
    "            'Decision Tree': cmaes_decision_tree,\n",
    "            'Random Forest': cmaes_random_forest,\n",
    "            'K-Nearest Neighbors': cmaes_knn,\n",
    "            'Support Vector Machine': cmaes_svc,\n",
    "            'AdaBoost': cmaes_adaboost,\n",
    "            'Gradient Boosting': cmaes_gradient_boosting,\n",
    "            'SEL-NNML': cmaes_sel_nnml\n",
    "        },\n",
    "        'QMC': {\n",
    "            'Logistic Regression': qmc_logistic_regression,\n",
    "            'Decision Tree': qmc_decision_tree,\n",
    "            'Random Forest': qmc_random_forest,\n",
    "            'K-Nearest Neighbors': qmc_knn,\n",
    "            'Support Vector Machine': qmc_svc,\n",
    "            'AdaBoost': qmc_adaboost,\n",
    "            'Gradient Boosting': qmc_gradient_boosting,\n",
    "            'SEL-NNML': qmc_sel_nnml\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save Every Best Model Config for each Tuning Method (Base + Meta) as CSV\n",
    "    all_model_hyperparameters = []\n",
    "    for sampler, models in all_models.items():\n",
    "        for model_name, model in models.items():\n",
    "            # Some meta models (e.g., stacking) may not have get_params, handle gracefully\n",
    "            params = model.get_params() if hasattr(model, 'get_params') else None\n",
    "            all_model_hyperparameters.append({\n",
    "                'Sampler': sampler,\n",
    "                'Model Name': model_name,\n",
    "                'Best Hyperparameters': params\n",
    "            })\n",
    "    all_model_hyperparameters_df = pd.DataFrame(all_model_hyperparameters)\n",
    "    all_model_hyperparameters_df.to_csv('../artifacts/ds1/models/all_model_hyperparameters.csv', index=False)\n",
    "\n",
    "    # Show All Model Hyperparameters for all samplers\n",
    "    display(all_model_hyperparameters_df)\n",
    "else:\n",
    "    print(\"Skipping model storage (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # Save Every Best Meta Model for each Tuning Method as .pkl\n",
    "    for sampler, models in all_models.items():\n",
    "        folder = sampler.lower().replace(\"-\", \"\")\n",
    "        for model_name, model in models.items():\n",
    "            filename = f'../artifacts/ds1/models/{folder}/{model_name.replace(\" \", \"_\").lower()}_best_model.pkl'\n",
    "            joblib.dump(model, filename)\n",
    "            print(f'Saved {model_name} model tuned with {sampler} to {filename}')\n",
    "else:\n",
    "    print(\"Skipping model saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # SAVE TRAIN TIME FOR EACH SAMPLER TYPE (BASE + META) IN A FILE\n",
    "    train_times = {\n",
    "        'Sampler': ['TPE', 'GP', 'CMA-ES', 'QMC'],\n",
    "        'Base Models Training Time (seconds)': [\n",
    "            tpe_base_models_training_time,\n",
    "            gp_base_models_training_time,\n",
    "            cmaes_base_models_training_time,\n",
    "            qmc_base_models_training_time\n",
    "        ],\n",
    "        'Meta Model Training Time (seconds)': [\n",
    "            tpe_meta_model_training_time,\n",
    "            gp_meta_model_training_time,\n",
    "            cmaes_meta_model_training_time,\n",
    "            qmc_meta_model_training_time\n",
    "        ],\n",
    "        'Total Training Time (seconds)': [\n",
    "            tpe_base_models_training_time + tpe_meta_model_training_time,\n",
    "            gp_base_models_training_time + gp_meta_model_training_time,\n",
    "            cmaes_base_models_training_time + cmaes_meta_model_training_time,\n",
    "            qmc_base_models_training_time + qmc_meta_model_training_time\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    train_times_df = pd.DataFrame(train_times)\n",
    "    train_times_df.to_csv('../artifacts/ds1/models/training_times.csv', index=False)\n",
    "    display(train_times_df)\n",
    "else:\n",
    "    print(\"Skipping training times saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip step 4 and load every best model for each tuning method if SKIP_TRAINING is True\n",
    "if SKIP_TRAINING:\n",
    "    print(\"Loading pre-existing models...\")\n",
    "    all_models = {sampler: {\n",
    "            'Logistic Regression': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/logistic_regression_best_model.pkl'),\n",
    "            'Decision Tree': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/decision_tree_best_model.pkl'),\n",
    "            'Random Forest': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/random_forest_best_model.pkl'),\n",
    "            'K-Nearest Neighbors': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/k-nearest_neighbors_best_model.pkl'),\n",
    "            'Support Vector Machine': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/support_vector_machine_best_model.pkl'),\n",
    "            'AdaBoost': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/adaboost_best_model.pkl'),\n",
    "            'Gradient Boosting': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/gradient_boosting_best_model.pkl'),\n",
    "            'SEL-NNML': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/sel-nnml_best_model.pkl')\n",
    "        } for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']}\n",
    "    print(\"All models loaded successfully!\")\n",
    "    \n",
    "    # Load training times\n",
    "    print(\"Loading training times...\")\n",
    "    train_times_df = pd.read_csv('../artifacts/ds1/models/training_times.csv')\n",
    "    \n",
    "    # Extract individual training times for each sampler\n",
    "    for idx, row in train_times_df.iterrows():\n",
    "        sampler = row['Sampler']\n",
    "        if sampler == 'TPE':\n",
    "            tpe_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            tpe_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'GP':\n",
    "            gp_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            gp_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'CMA-ES':\n",
    "            cmaes_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            cmaes_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'QMC':\n",
    "            qmc_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            qmc_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "    \n",
    "    print(\"Training times loaded successfully!\")\n",
    "    display(train_times_df)\n",
    "else:\n",
    "    print(\"SKIP_TRAINING is False. Models should be trained in steps 4 and 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage contains model evaluation on the test set, with details as follows:\n",
    "- `plot_evaluation_metrics()`: Shows the confusion matrix graph & scores for accuracy, precision, recall, and F1-Score\n",
    "- `Model Performance Comparison Plot`: Displays accuracy, precision, recall, F1-Score, and ROC AUC scores\n",
    "- `overfitting_index_plot()`: Shows the percentage of the difference between model scores on test data versus training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Model Evaluation Dashboard\n",
    "def evaluation_metrics_plot(y_true, y_pred):\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "    }\n",
    "    metric_order = ['F1-Score', 'Recall', 'Precision', 'Accuracy']\n",
    "    values = [metrics[name] for name in metric_order]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    cm_pos = [0.08, 0.15, 0.53, 0.7]\n",
    "    metrics_pos = [0.75, 0.15, 0.21, 0.7]\n",
    "\n",
    "    # Confusion Matrix\n",
    "    ax_cm = fig.add_axes(cm_pos)\n",
    "    im = ax_cm.imshow(cm, cmap='Blues', interpolation='nearest', aspect='equal')\n",
    "    cbar_ax = fig.add_axes([cm_pos[0] + cm_pos[2] + 0.02, cm_pos[1], 0.02, cm_pos[3]])\n",
    "    fig.colorbar(im, cax=cbar_ax).ax.tick_params(labelsize=16)\n",
    "\n",
    "    cm_pct = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            count, pct = int(cm[i, j]), cm_pct[i, j]\n",
    "            color = 'white' if count > cm.max() / 2 else 'black'\n",
    "            ax_cm.text(j, i, f'{count}\\n({pct:.1f}%)', ha='center', va='center',\n",
    "                    color=color, fontsize=18, fontweight='bold', linespacing=1.1)\n",
    "\n",
    "    ax_cm.set_xticks([0, 1])\n",
    "    ax_cm.set_yticks([0, 1])\n",
    "    ax_cm.set_xticklabels(['No\\n(0)', 'Disease\\n(1)'], fontsize=16)\n",
    "    ax_cm.set_yticklabels(['No (0)', 'Disease (1)'], fontsize=16, rotation=90, va='center')\n",
    "    ax_cm.set_xlabel('Predicted', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_ylabel('Actual', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_title('Confusion Matrix', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_cm.set_ylim(1.5, -0.5)\n",
    "\n",
    "    # Metrics Bar\n",
    "    ax_metrics = fig.add_axes(metrics_pos)\n",
    "    y_positions = np.arange(len(metric_order)) * 2\n",
    "    bars = ax_metrics.barh(y_positions, values, height=0.8, color='#31688E', alpha=0.8)\n",
    "\n",
    "    for bar, value in zip(bars, values):\n",
    "        color = 'white' if value > 0.5 else 'black'\n",
    "        x_pos = value - 0.02 if value > 0.5 else value + 0.02\n",
    "        ha = 'right' if value > 0.5 else 'left'\n",
    "        ax_metrics.text(x_pos, bar.get_y() + bar.get_height()/2, f'{value:.3f}',\n",
    "                        ha=ha, va='center', fontsize=18, fontweight='bold', color=color)\n",
    "\n",
    "    ax_metrics.set_xlim(-0.05, 1.05)\n",
    "    ax_metrics.set_ylim(-0.8, len(metric_order) * 2 - 0.2)\n",
    "    ax_metrics.set_xticks([0, 0.5, 1.0])\n",
    "    ax_metrics.set_xticklabels(['0.0', '0.5', '1.0'], fontsize=16)\n",
    "    ax_metrics.set_yticks(y_positions)\n",
    "    ax_metrics.set_yticklabels(metric_order, fontsize=16, rotation=90, ha='left', va='center')\n",
    "    ax_metrics.tick_params(axis='y', pad=15)\n",
    "    ax_metrics.tick_params(axis='x', pad=8)\n",
    "    ax_metrics.set_xlabel('Score', fontsize=16, fontweight='bold')\n",
    "    ax_metrics.set_title('Performance Metrics', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_metrics.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    for spine in ['top', 'right', 'left']:\n",
    "        ax_metrics.spines[spine].set_visible(False)\n",
    "    ax_metrics.spines['bottom'].set_alpha(0.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Model Comparison Dashboard (for comparing all models)\n",
    "def model_comparison_plot(models, x_test, y_test):\n",
    "    metrics = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'F1-Score': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "    \n",
    "    # Map full names to short names\n",
    "    short_names = {\n",
    "        'Logistic Regression': 'LR',\n",
    "        'Decision Tree': 'DT',\n",
    "        'Random Forest': 'RF',\n",
    "        'K-Nearest Neighbors': 'KNN',\n",
    "        'Support Vector Machine': 'SVM',\n",
    "        'AdaBoost': 'AdaBoost',\n",
    "        'Gradient Boosting': 'Gradient Boosting',\n",
    "        'SEL-NNML': 'SEL-NNML'\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics for each model\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(x_test)\n",
    "        metrics['Model'].append(short_names[model_name])\n",
    "        metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        metrics['F1-Score'].append(f1_score(y_test, y_pred))\n",
    "        metrics['Precision'].append(precision_score(y_test, y_pred))\n",
    "        metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "        \n",
    "        # Calculate AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        metrics['AUC'].append(roc_auc)\n",
    "    \n",
    "    # Convert metrics to DataFrame for sorting\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "    fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold') \n",
    "    \n",
    "    # Helper function to plot sorted bar charts\n",
    "    def plot_sorted_bar_chart(ax, metric_name):\n",
    "        sorted_df = metrics_df.sort_values(by=metric_name, ascending=False)\n",
    "        colors = ['tab:orange' if model == 'SEL-NNML' else 'tab:blue' for model in sorted_df['Model']]\n",
    "        ax.bar(sorted_df['Model'], sorted_df[metric_name], color=colors)\n",
    "        ax.set_title(metric_name)\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_xticks(range(len(sorted_df['Model'])))\n",
    "        ax.set_xticklabels(sorted_df['Model'], rotation=30, ha='center')\n",
    "        for i, v in enumerate(sorted_df[metric_name]):\n",
    "            ax.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "    # Plot each metric\n",
    "    plot_sorted_bar_chart(axes[0, 0], 'Accuracy')\n",
    "    plot_sorted_bar_chart(axes[0, 1], 'F1-Score')\n",
    "    plot_sorted_bar_chart(axes[1, 0], 'Precision')\n",
    "    plot_sorted_bar_chart(axes[1, 1], 'Recall')\n",
    "    \n",
    "    # ROC Curve\n",
    "    ax_roc = axes[2, 0]\n",
    "    for model_name, model in models.items():\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax_roc.plot(fpr, tpr, lw=2, label=f'{short_names[model_name]} (AUC = {roc_auc:.3f})')\n",
    "    ax_roc.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_title('Receiver Operating Characteristic')\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Bar chart for AUC\n",
    "    plot_sorted_bar_chart(axes[2, 1], 'AUC')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfitting_index_plot(all_models, x_train, y_train, x_test, y_test):\n",
    "    metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "    overfitting_indices = {metric: [] for metric in metrics}\n",
    "\n",
    "    for _, model in all_models.items():\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "        overfitting_indices['Accuracy'].append(abs(accuracy_score(y_train, y_train_pred) - accuracy_score(y_test, y_test_pred)) / accuracy_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['F1-Score'].append(abs(f1_score(y_train, y_train_pred) - f1_score(y_test, y_test_pred)) / f1_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Precision'].append(abs(precision_score(y_train, y_train_pred) - precision_score(y_test, y_test_pred)) / precision_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Recall'].append(abs(recall_score(y_train, y_train_pred) - recall_score(y_test, y_test_pred)) / recall_score(y_train, y_train_pred) * 100)\n",
    "\n",
    "    overfitting_df = pd.DataFrame(overfitting_indices, index=all_models.keys())\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Overfitting Index for All Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "    def get_bar_colors(models, highlight_model='SEL-NNML', default_color='tab:blue', highlight_color='tab:orange'):\n",
    "        return [highlight_color if model == highlight_model else default_color for model in models]\n",
    "\n",
    "    # Accuracy\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Accuracy', ascending=False)\n",
    "    axes[0, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Accuracy'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 0].set_title('Accuracy Overfitting Index')\n",
    "    axes[0, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 0].set_ylim([0, 100])\n",
    "    axes[0, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Accuracy']):\n",
    "        axes[0, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # F1-Score\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='F1-Score', ascending=False)\n",
    "    axes[0, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['F1-Score'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 1].set_title('F1-Score Overfitting Index')\n",
    "    axes[0, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 1].set_ylim([0, 100])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['F1-Score']):\n",
    "        axes[0, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Precision\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Precision', ascending=False)\n",
    "    axes[1, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Precision'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 0].set_title('Precision Overfitting Index')\n",
    "    axes[1, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 0].set_ylim([0, 100])\n",
    "    axes[1, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Precision']):\n",
    "        axes[1, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Recall\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Recall', ascending=False)\n",
    "    axes[1, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['Recall'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 1].set_title('Recall Overfitting Index')\n",
    "    axes[1, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 1].set_ylim([0, 100])\n",
    "    axes[1, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Recall']):\n",
    "        axes[1, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 Single Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show SEL-NNML Evaluation Metrics\n",
    "y_pred_stack = sel_nnml.predict(X_test)\n",
    "evaluation_metrics_plot(y_test, y_pred_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show SEL-NNM: all fold scores with mean and std \n",
    "sel_nnml_cv_scores = cross_val_score(sel_nnml, X_train, y_train, cv=CV_FOLDS, scoring='accuracy', n_jobs=N_JOBS)\n",
    "print(f'SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: {sel_nnml_cv_scores}')\n",
    "print(f'Mean: {sel_nnml_cv_scores.mean():.4f}')\n",
    "print(f'Standard Deviation: {sel_nnml_cv_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show SELL-NNML Training Time\n",
    "Total_training_time = base_models_training_time + meta_model_training_time\n",
    "print(f'Base Models Tuning & Training Time: {base_models_training_time:.2f} seconds')\n",
    "print(f'Meta Model Tuning & Training Time: {meta_model_training_time:.2f} seconds')\n",
    "print(f'Total SEL-NNML Tuning & Training Time: {Total_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Multiple Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_plot(all_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitting_index_plot(all_models, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
