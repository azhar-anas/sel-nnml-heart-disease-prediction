{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SEL-NNML Tuning - UCI Heart Disease Dataset**\n",
    "\n",
    "This notebook implements several tuning methods on the `Stacking Ensemble Learning with a Neural Network Meta-Learner (SEL-NNML)` model using the `UCI Heart Disease Dataset (UCHDD)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Global Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global configuration loaded successfully!\n",
      "Random State: 42\n",
      "Test Size: 0.2\n",
      "CV Folds: 5\n",
      "Optimization Iterations: 100\n",
      "Optimization Metric: accuracy\n",
      "Optimization Direction: maximize\n",
      "Skip Training: False\n"
     ]
    }
   ],
   "source": [
    "# Random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Data splitting configuration\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Cross-validation configuration\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Hyperparameter tuning configuration\n",
    "OPTIMIZATION_ITERATIONS = 100\n",
    "OPTIMIZATION_METRIC = 'accuracy'\n",
    "OPTIMIZATION_DIRECTION='maximize'\n",
    "\n",
    "# Parallel processing configuration\n",
    "N_JOBS = -1 \n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_PATH = '../datasets/processed/ds2_uci_heart_clean.csv'\n",
    "TARGET_COLUMN = 'num'\n",
    "\n",
    "# Training configuration\n",
    "SKIP_TRAINING = True  # Set to True to load pre-existing models instead of training\n",
    "\n",
    "print('Global configuration loaded successfully!')\n",
    "print(f'Random State: {RANDOM_STATE}')\n",
    "print(f'Test Size: {TEST_SIZE}')\n",
    "print(f'CV Folds: {CV_FOLDS}')\n",
    "print(f'Optimization Iterations: {OPTIMIZATION_ITERATIONS}')\n",
    "print(f'Optimization Metric: {OPTIMIZATION_METRIC}')\n",
    "print(f'Optimization Direction: {OPTIMIZATION_DIRECTION}')\n",
    "print(f'Skip Training: {SKIP_TRAINING}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src import base_model_tuning, meta_model_tuning\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 297 entries, 0 to 296\n",
      "Data columns (total 26 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        297 non-null    int64  \n",
      " 1   sex        297 non-null    bool   \n",
      " 2   trestbps   297 non-null    int64  \n",
      " 3   chol       297 non-null    int64  \n",
      " 4   fbs        297 non-null    bool   \n",
      " 5   thalach    297 non-null    int64  \n",
      " 6   exang      297 non-null    bool   \n",
      " 7   oldpeak    297 non-null    float64\n",
      " 8   num        297 non-null    bool   \n",
      " 9   cp_1       297 non-null    bool   \n",
      " 10  cp_2       297 non-null    bool   \n",
      " 11  cp_3       297 non-null    bool   \n",
      " 12  cp_4       297 non-null    bool   \n",
      " 13  restecg_0  297 non-null    bool   \n",
      " 14  restecg_1  297 non-null    bool   \n",
      " 15  restecg_2  297 non-null    bool   \n",
      " 16  slope_1    297 non-null    bool   \n",
      " 17  slope_2    297 non-null    bool   \n",
      " 18  slope_3    297 non-null    bool   \n",
      " 19  ca_0.0     297 non-null    bool   \n",
      " 20  ca_1.0     297 non-null    bool   \n",
      " 21  ca_2.0     297 non-null    bool   \n",
      " 22  ca_3.0     297 non-null    bool   \n",
      " 23  thal_3.0   297 non-null    bool   \n",
      " 24  thal_6.0   297 non-null    bool   \n",
      " 25  thal_7.0   297 non-null    bool   \n",
      "dtypes: bool(21), float64(1), int64(4)\n",
      "memory usage: 17.8 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "trestbps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chol",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fbs",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "thalach",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exang",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "oldpeak",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "cp_1",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "cp_2",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "cp_3",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "cp_4",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "restecg_0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "restecg_1",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "restecg_2",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "slope_1",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "slope_2",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "slope_3",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ca_0.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ca_1.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ca_2.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ca_3.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "thal_3.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "thal_6.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "thal_7.0",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "eac65aa4-4223-40fd-89f1-e1a44185454e",
       "rows": [
        [
         "0",
         "63",
         "True",
         "145",
         "233",
         "True",
         "150",
         "False",
         "2.3",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "1",
         "67",
         "True",
         "160",
         "286",
         "False",
         "108",
         "True",
         "1.5",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False"
        ],
        [
         "2",
         "67",
         "True",
         "120",
         "229",
         "False",
         "129",
         "True",
         "2.6",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "3",
         "37",
         "True",
         "130",
         "250",
         "False",
         "187",
         "False",
         "3.5",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "4",
         "41",
         "False",
         "130",
         "204",
         "False",
         "172",
         "False",
         "1.4",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "5",
         "56",
         "True",
         "120",
         "236",
         "False",
         "178",
         "False",
         "0.8",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "6",
         "62",
         "False",
         "140",
         "268",
         "False",
         "160",
         "False",
         "3.6",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "7",
         "57",
         "False",
         "120",
         "354",
         "False",
         "163",
         "True",
         "0.6",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "8",
         "63",
         "True",
         "130",
         "254",
         "False",
         "147",
         "False",
         "1.4",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "9",
         "53",
         "True",
         "140",
         "203",
         "True",
         "155",
         "True",
         "3.1",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "10",
         "57",
         "True",
         "140",
         "192",
         "False",
         "148",
         "False",
         "0.4",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "11",
         "56",
         "False",
         "140",
         "294",
         "False",
         "153",
         "False",
         "1.3",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "12",
         "56",
         "True",
         "130",
         "256",
         "True",
         "142",
         "True",
         "0.6",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "13",
         "44",
         "True",
         "120",
         "263",
         "False",
         "173",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "14",
         "52",
         "True",
         "172",
         "199",
         "True",
         "162",
         "False",
         "0.5",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "15",
         "57",
         "True",
         "150",
         "168",
         "False",
         "174",
         "False",
         "1.6",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "16",
         "48",
         "True",
         "110",
         "229",
         "False",
         "168",
         "False",
         "1.0",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "17",
         "54",
         "True",
         "140",
         "239",
         "False",
         "160",
         "False",
         "1.2",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "18",
         "48",
         "False",
         "130",
         "275",
         "False",
         "139",
         "False",
         "0.2",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "19",
         "49",
         "True",
         "130",
         "266",
         "False",
         "171",
         "False",
         "0.6",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "20",
         "64",
         "True",
         "110",
         "211",
         "False",
         "144",
         "True",
         "1.8",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "21",
         "58",
         "False",
         "150",
         "283",
         "True",
         "162",
         "False",
         "1.0",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "22",
         "58",
         "True",
         "120",
         "284",
         "False",
         "160",
         "False",
         "1.8",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "23",
         "58",
         "True",
         "132",
         "224",
         "False",
         "173",
         "False",
         "3.2",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "24",
         "60",
         "True",
         "130",
         "206",
         "False",
         "132",
         "True",
         "2.4",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "25",
         "50",
         "False",
         "120",
         "219",
         "False",
         "158",
         "False",
         "1.6",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "26",
         "58",
         "False",
         "120",
         "340",
         "False",
         "172",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "27",
         "66",
         "False",
         "150",
         "226",
         "False",
         "114",
         "False",
         "2.6",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "28",
         "43",
         "True",
         "150",
         "247",
         "False",
         "171",
         "False",
         "1.5",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "29",
         "40",
         "True",
         "110",
         "167",
         "False",
         "114",
         "True",
         "2.0",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "30",
         "69",
         "False",
         "140",
         "239",
         "False",
         "151",
         "False",
         "1.8",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "31",
         "60",
         "True",
         "117",
         "230",
         "True",
         "160",
         "True",
         "1.4",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "32",
         "64",
         "True",
         "140",
         "335",
         "False",
         "158",
         "False",
         "0.0",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "33",
         "59",
         "True",
         "135",
         "234",
         "False",
         "161",
         "False",
         "0.5",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "34",
         "44",
         "True",
         "130",
         "233",
         "False",
         "179",
         "True",
         "0.4",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "35",
         "42",
         "True",
         "140",
         "226",
         "False",
         "178",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "36",
         "43",
         "True",
         "120",
         "177",
         "False",
         "120",
         "True",
         "2.5",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "37",
         "57",
         "True",
         "150",
         "276",
         "False",
         "112",
         "True",
         "0.6",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "38",
         "55",
         "True",
         "132",
         "353",
         "False",
         "132",
         "True",
         "1.2",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "39",
         "61",
         "True",
         "150",
         "243",
         "True",
         "137",
         "True",
         "1.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "40",
         "65",
         "False",
         "150",
         "225",
         "False",
         "114",
         "False",
         "1.0",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "41",
         "40",
         "True",
         "140",
         "199",
         "False",
         "178",
         "True",
         "1.4",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "42",
         "71",
         "False",
         "160",
         "302",
         "False",
         "162",
         "False",
         "0.4",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "43",
         "59",
         "True",
         "150",
         "212",
         "True",
         "157",
         "False",
         "1.6",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "44",
         "61",
         "False",
         "130",
         "330",
         "False",
         "169",
         "False",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "45",
         "58",
         "True",
         "112",
         "230",
         "False",
         "165",
         "False",
         "2.5",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "46",
         "51",
         "True",
         "110",
         "175",
         "False",
         "123",
         "False",
         "0.6",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "47",
         "50",
         "True",
         "150",
         "243",
         "False",
         "128",
         "False",
         "2.6",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "48",
         "65",
         "False",
         "140",
         "417",
         "True",
         "157",
         "False",
         "0.8",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "49",
         "53",
         "True",
         "130",
         "197",
         "True",
         "152",
         "False",
         "1.2",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 26,
        "rows": 297
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>num</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "      <th>slope_3</th>\n",
       "      <th>ca_0.0</th>\n",
       "      <th>ca_1.0</th>\n",
       "      <th>ca_2.0</th>\n",
       "      <th>ca_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>False</td>\n",
       "      <td>108</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "      <td>129</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>187</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>False</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>123</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>False</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>True</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "      <td>3.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>False</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age    sex  trestbps  chol    fbs  thalach  exang  oldpeak    num   cp_1  \\\n",
       "0     63   True       145   233   True      150  False      2.3  False   True   \n",
       "1     67   True       160   286  False      108   True      1.5   True  False   \n",
       "2     67   True       120   229  False      129   True      2.6   True  False   \n",
       "3     37   True       130   250  False      187  False      3.5  False  False   \n",
       "4     41  False       130   204  False      172  False      1.4  False  False   \n",
       "..   ...    ...       ...   ...    ...      ...    ...      ...    ...    ...   \n",
       "292   57  False       140   241  False      123   True      0.2   True  False   \n",
       "293   45   True       110   264  False      132  False      1.2   True   True   \n",
       "294   68   True       144   193   True      141  False      3.4   True  False   \n",
       "295   57   True       130   131  False      115   True      1.2   True  False   \n",
       "296   57  False       130   236  False      174  False      0.0   True  False   \n",
       "\n",
       "     ...  slope_1  slope_2  slope_3  ca_0.0  ca_1.0  ca_2.0  ca_3.0  thal_3.0  \\\n",
       "0    ...    False    False     True    True   False   False   False     False   \n",
       "1    ...    False     True    False   False   False   False    True      True   \n",
       "2    ...    False     True    False   False   False    True   False     False   \n",
       "3    ...    False    False     True    True   False   False   False      True   \n",
       "4    ...     True    False    False    True   False   False   False      True   \n",
       "..   ...      ...      ...      ...     ...     ...     ...     ...       ...   \n",
       "292  ...    False     True    False    True   False   False   False     False   \n",
       "293  ...    False     True    False    True   False   False   False     False   \n",
       "294  ...    False     True    False   False   False    True   False     False   \n",
       "295  ...    False     True    False   False    True   False   False     False   \n",
       "296  ...    False     True    False   False    True   False   False      True   \n",
       "\n",
       "     thal_6.0  thal_7.0  \n",
       "0        True     False  \n",
       "1       False     False  \n",
       "2       False      True  \n",
       "3       False     False  \n",
       "4       False     False  \n",
       "..        ...       ...  \n",
       "292     False      True  \n",
       "293     False      True  \n",
       "294     False      True  \n",
       "295     False      True  \n",
       "296     False     False  \n",
       "\n",
       "[297 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into desired training and testing\n",
    "- After that, Scaling the data using Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Min-Max Scaler function for this dataset to ../artifacts/ds2/models/min_max_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "# Separate numeric and boolean columns\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "bool_cols = X_train.select_dtypes(include=['bool', 'uint8']).columns  # includes one-hot from get_dummies\n",
    "\n",
    "# Initialize scaler and fit_transform only on numeric data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=num_cols, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=num_cols, index=X_test.index)\n",
    "\n",
    "# Concatenate back with boolean features (without modification)\n",
    "X_train = pd.concat([X_train_scaled, X_train[bool_cols]], axis=1)\n",
    "X_test = pd.concat([X_test_scaled, X_test[bool_cols]], axis=1)\n",
    "\n",
    "# Save Min-Max Scaler\n",
    "scaler_filename = '../artifacts/ds2/models/min_max_scaler.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f'Saved Min-Max Scaler function for this dataset to {scaler_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trestbps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "thalach",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oldpeak",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sex",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "fbs",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "exang",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "cp_1",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "cp_2",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "cp_3",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "cp_4",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "restecg_0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "restecg_1",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "restecg_2",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "slope_1",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "slope_2",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "slope_3",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ca_0.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ca_1.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ca_2.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ca_3.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "thal_3.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "thal_6.0",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "thal_7.0",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "6a823032-e0c1-4d60-b502-f9dc1c177cbd",
       "rows": [
        [
         "273",
         "0.20833333333333337",
         "0.41509433962264153",
         "0.2146118721461187",
         "0.6183206106870228",
         "0.0",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "259",
         "0.6458333333333334",
         "0.5283018867924528",
         "0.2602739726027397",
         "0.763358778625954",
         "0.16071428571428573",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "30",
         "0.8333333333333334",
         "0.4339622641509434",
         "0.2579908675799087",
         "0.6106870229007634",
         "0.32142857142857145",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "22",
         "0.6041666666666666",
         "0.24528301886792458",
         "0.3607305936073059",
         "0.6793893129770993",
         "0.32142857142857145",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "277",
         "0.375",
         "0.339622641509434",
         "0.28995433789954334",
         "0.8244274809160305",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "56",
         "0.4374999999999999",
         "0.4339622641509434",
         "0.24429223744292233",
         "0.7022900763358778",
         "0.10714285714285714",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "109",
         "0.6666666666666666",
         "0.48113207547169823",
         "0.4132420091324201",
         "0.5725190839694655",
         "0.17857142857142858",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "246",
         "0.6874999999999999",
         "0.3207547169811321",
         "0.1872146118721461",
         "0.5267175572519084",
         "0.0",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "168",
         "0.8541666666666666",
         "0.6226415094339622",
         "0.32648401826484014",
         "0.3129770992366412",
         "0.5178571428571429",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "226",
         "0.7708333333333334",
         "0.16981132075471705",
         "0.1963470319634703",
         "0.46564885496183195",
         "0.01785714285714286",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "280",
         "0.6666666666666666",
         "0.5094339622641509",
         "0.17579908675799089",
         "0.6870229007633587",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "125",
         "0.5624999999999999",
         "1.0",
         "0.3698630136986301",
         "0.4732824427480916",
         "0.7142857142857143",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "157",
         "0.6458333333333334",
         "0.4339622641509434",
         "0.38127853881278534",
         "0.7557251908396946",
         "0.21428571428571427",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "223",
         "0.375",
         "0.16981132075471705",
         "0.1780821917808219",
         "0.5496183206106869",
         "0.01785714285714286",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "76",
         "0.6458333333333334",
         "0.2924528301886792",
         "0.30136986301369856",
         "0.5343511450381678",
         "0.5",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "66",
         "0.6458333333333334",
         "0.4339622641509434",
         "0.13470319634703193",
         "0.6412213740458014",
         "0.5357142857142857",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "104",
         "0.5208333333333334",
         "0.1320754716981133",
         "0.41780821917808214",
         "0.648854961832061",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "159",
         "0.35416666666666663",
         "0.0660377358490567",
         "0.16210045662100453",
         "0.648854961832061",
         "0.0",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "146",
         "0.25",
         "0.16981132075471705",
         "0.28310502283105016",
         "0.8244274809160305",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "19",
         "0.41666666666666663",
         "0.339622641509434",
         "0.31963470319634696",
         "0.763358778625954",
         "0.10714285714285714",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "289",
         "0.7083333333333334",
         "0.28301886792452835",
         "0.16210045662100453",
         "0.49618320610687017",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "79",
         "0.6041666666666666",
         "0.5283018867924528",
         "0.32876712328767127",
         "0.30534351145038163",
         "0.14285714285714288",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "210",
         "0.7708333333333334",
         "0.7924528301886792",
         "0.2328767123287671",
         "0.7175572519083969",
         "0.17857142857142858",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "137",
         "0.125",
         "0.24528301886792458",
         "0.1643835616438356",
         "0.45038167938931295",
         "0.28571428571428575",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "72",
         "0.6874999999999999",
         "0.24528301886792458",
         "0.3219178082191781",
         "0.2137404580152671",
         "0.32142857142857145",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "15",
         "0.5833333333333334",
         "0.5283018867924528",
         "0.0958904109589041",
         "0.7862595419847328",
         "0.28571428571428575",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "10",
         "0.5833333333333334",
         "0.4339622641509434",
         "0.1506849315068493",
         "0.5877862595419846",
         "0.07142857142857144",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "228",
         "0.5416666666666666",
         "0.8113207547169811",
         "0.4589041095890411",
         "0.35114503816793885",
         "0.6071428571428571",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "184",
         "0.27083333333333337",
         "0.24528301886792458",
         "0.2602739726027397",
         "0.9389312977099237",
         "0.14285714285714288",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "68",
         "0.6249999999999999",
         "0.7169811320754716",
         "0.4566210045662101",
         "0.5267175572519084",
         "0.6071428571428571",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "266",
         "0.6666666666666666",
         "0.4339622641509434",
         "0.18493150684931509",
         "0.5114503816793893",
         "0.3392857142857143",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "37",
         "0.5833333333333334",
         "0.5283018867924528",
         "0.3424657534246575",
         "0.3129770992366412",
         "0.10714285714285714",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "16",
         "0.39583333333333337",
         "0.15094339622641517",
         "0.23515981735159813",
         "0.7404580152671755",
         "0.17857142857142858",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "253",
         "0.7916666666666666",
         "0.1132075471698114",
         "0.2214611872146119",
         "0.5419847328244275",
         "0.05357142857142857",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "144",
         "0.375",
         "0.1320754716981133",
         "0.2671232876712329",
         "0.6183206106870228",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "267",
         "0.7708333333333334",
         "0.6226415094339622",
         "0.2328767123287671",
         "0.5114503816793893",
         "0.4107142857142857",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "67",
         "0.5208333333333334",
         "0.5283018867924528",
         "0.2420091324200913",
         "0.7175572519083969",
         "0.28571428571428575",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "286",
         "0.5416666666666666",
         "0.3584905660377359",
         "0.4931506849315069",
         "0.7251908396946564",
         "0.21428571428571427",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "69",
         "0.35416666666666663",
         "0.5283018867924528",
         "0.2397260273972603",
         "0.5801526717557252",
         "0.6428571428571429",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "31",
         "0.6458333333333334",
         "0.21698113207547165",
         "0.23744292237442927",
         "0.6793893129770993",
         "0.25",
         "True",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "170",
         "0.6249999999999999",
         "0.7547169811320754",
         "0.28082191780821913",
         "0.5496183206106869",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "147",
         "0.33333333333333337",
         "0.3207547169811321",
         "0.4155251141552511",
         "0.7557251908396946",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "221",
         "0.7083333333333334",
         "0.1320754716981133",
         "0.32648401826484014",
         "0.7480916030534351",
         "0.32142857142857145",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "114",
         "0.25",
         "0.3867924528301888",
         "0.17579908675799089",
         "0.46564885496183195",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "18",
         "0.39583333333333337",
         "0.339622641509434",
         "0.3401826484018265",
         "0.5190839694656487",
         "0.03571428571428572",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "177",
         "0.4999999999999999",
         "0.339622641509434",
         "0.27397260273972607",
         "0.7786259541984731",
         "0.0",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False"
        ],
        [
         "96",
         "0.6458333333333334",
         "0.5283018867924528",
         "0.30136986301369856",
         "0.6564885496183205",
         "0.4642857142857143",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "178",
         "0.39583333333333337",
         "0.28301886792452835",
         "0.33789954337899536",
         "0.7251908396946564",
         "0.08928571428571429",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "119",
         "0.39583333333333337",
         "0.339622641509434",
         "0.2968036529680365",
         "0.6030534351145037",
         "0.0",
         "True",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "86",
         "0.375",
         "0.41509433962264153",
         "0.29908675799086754",
         "0.648854961832061",
         "0.0",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 25,
        "rows": 237
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex</th>\n",
       "      <th>fbs</th>\n",
       "      <th>exang</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "      <th>slope_3</th>\n",
       "      <th>ca_0.0</th>\n",
       "      <th>ca_1.0</th>\n",
       "      <th>ca_2.0</th>\n",
       "      <th>ca_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.618321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.260274</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.257991</td>\n",
       "      <td>0.610687</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.360731</td>\n",
       "      <td>0.679389</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.159817</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.292237</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.694656</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.317352</td>\n",
       "      <td>0.450382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  trestbps      chol   thalach   oldpeak    sex    fbs  exang  \\\n",
       "273  0.208333  0.415094  0.214612  0.618321  0.000000  False  False  False   \n",
       "259  0.645833  0.528302  0.260274  0.763359  0.160714  False  False  False   \n",
       "30   0.833333  0.433962  0.257991  0.610687  0.321429  False  False  False   \n",
       "22   0.604167  0.245283  0.360731  0.679389  0.321429   True  False  False   \n",
       "277  0.375000  0.339623  0.289954  0.824427  0.000000   True  False  False   \n",
       "..        ...       ...       ...       ...       ...    ...    ...    ...   \n",
       "188  0.437500  0.330189  0.159817  0.702290  0.000000   True  False  False   \n",
       "71   0.791667  0.292453  0.292237  0.702290  0.035714   True   True  False   \n",
       "106  0.583333  0.320755  0.235160  0.603053  0.071429   True  False  False   \n",
       "270  0.625000  0.377358  0.178082  0.694656  0.142857   True  False  False   \n",
       "102  0.875000  0.150943  0.317352  0.450382  0.000000  False   True  False   \n",
       "\n",
       "      cp_1   cp_2  ...  slope_1  slope_2  slope_3  ca_0.0  ca_1.0  ca_2.0  \\\n",
       "273  False  False  ...    False     True    False    True   False   False   \n",
       "259   True  False  ...     True    False    False    True   False   False   \n",
       "30    True  False  ...     True    False    False   False   False    True   \n",
       "22   False   True  ...    False     True    False    True   False   False   \n",
       "277  False  False  ...     True    False    False    True   False   False   \n",
       "..     ...    ...  ...      ...      ...      ...     ...     ...     ...   \n",
       "188  False  False  ...     True    False    False    True   False   False   \n",
       "71   False  False  ...    False     True    False   False   False    True   \n",
       "106  False  False  ...    False     True    False   False    True   False   \n",
       "270   True  False  ...     True    False    False   False   False    True   \n",
       "102  False  False  ...     True    False    False   False    True   False   \n",
       "\n",
       "     ca_3.0  thal_3.0  thal_6.0  thal_7.0  \n",
       "273   False      True     False     False  \n",
       "259   False      True     False     False  \n",
       "30    False      True     False     False  \n",
       "22    False      True     False     False  \n",
       "277   False      True     False     False  \n",
       "..      ...       ...       ...       ...  \n",
       "188   False      True     False     False  \n",
       "71    False     False     False      True  \n",
       "106   False     False     False      True  \n",
       "270   False      True     False     False  \n",
       "102   False      True     False     False  \n",
       "\n",
       "[237 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Default Base Models (Baseline)**\n",
    "\n",
    "Create base models with default parameters as a baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training default base models...\n",
      "Default Base Models Training Time: 0.33 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    default_models_training_start = time.time()\n",
    "    \n",
    "    # Initialize base models with default parameters\n",
    "    default_logistic_regression = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    default_decision_tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    default_random_forest = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "    default_knn = KNeighborsClassifier(n_jobs=N_JOBS)\n",
    "    default_svc = SVC(random_state=RANDOM_STATE, probability=True)  # probability=True for predict_proba\n",
    "    default_adaboost = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "    default_gradient_boosting = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Fit all default models\n",
    "    print(\"Training default base models...\")\n",
    "    default_logistic_regression.fit(X_train, y_train)\n",
    "    default_decision_tree.fit(X_train, y_train)\n",
    "    default_random_forest.fit(X_train, y_train)\n",
    "    default_knn.fit(X_train, y_train)\n",
    "    default_svc.fit(X_train, y_train)\n",
    "    default_adaboost.fit(X_train, y_train)\n",
    "    default_gradient_boosting.fit(X_train, y_train)\n",
    "    \n",
    "    default_models_training_end = time.time()\n",
    "    default_models_training_time = default_models_training_end - default_models_training_start\n",
    "    \n",
    "    print(f'Default Base Models Training Time: {default_models_training_time:.2f} seconds')\n",
    "    \n",
    "    # Store in dictionary\n",
    "    default_base_models = {\n",
    "        'Logistic Regression': default_logistic_regression,\n",
    "        'Decision Tree': default_decision_tree,\n",
    "        'Random Forest': default_random_forest,\n",
    "        'K-Nearest Neighbors': default_knn,\n",
    "        'Support Vector Machine': default_svc,\n",
    "        'AdaBoost': default_adaboost,\n",
    "        'Gradient Boosting': default_gradient_boosting\n",
    "    }\n",
    "else:\n",
    "    print(\"Skipping default base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Stacking with Default Base Models + Linear Regression**\n",
    "\n",
    "Create a stacking ensemble using default base learners with Linear Regression as the meta-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking model with Linear Regression meta-learner...\n",
      "Stacking + Linear Regression Training Time: 5.25 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    stack_lr_training_start = time.time()\n",
    "    \n",
    "    # Create stacking ensemble with Linear Regression as meta-learner\n",
    "    base_estimators = [\n",
    "        ('Logistic Regression', default_logistic_regression),\n",
    "        ('Decision Tree', default_decision_tree),\n",
    "        ('Random Forest', default_random_forest),\n",
    "        ('K-Nearest Neighbors', default_knn),\n",
    "        ('Support Vector Machine', default_svc),\n",
    "        ('AdaBoost', default_adaboost),\n",
    "        ('Gradient Boosting', default_gradient_boosting)\n",
    "    ]\n",
    "    \n",
    "    # Linear Regression meta-learner (using LogisticRegression for classification)\n",
    "    meta_lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    \n",
    "    stacking_lr = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=meta_lr,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "    \n",
    "    print(\"Training Stacking model with Linear Regression meta-learner...\")\n",
    "    stacking_lr.fit(X_train, y_train)\n",
    "    \n",
    "    stack_lr_training_end = time.time()\n",
    "    stack_lr_training_time = stack_lr_training_end - stack_lr_training_start\n",
    "    \n",
    "    print(f'Stacking + Linear Regression Training Time: {stack_lr_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping Stacking + LR training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 Stacking with Default Base Models + Default MLP**\n",
    "\n",
    "Create a stacking ensemble using default base learners with a default MLP (Multi-Layer Perceptron) as the meta-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking model with default MLP meta-learner...\n",
      "Stacking + Default MLP Training Time: 2.65 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    stack_mlp_training_start = time.time()\n",
    "    \n",
    "    # Create stacking ensemble with default MLP as meta-learner\n",
    "    # Using default MLP with just random_state for reproducibility\n",
    "    meta_mlp = MLPClassifier(random_state=RANDOM_STATE, max_iter=300)\n",
    "    \n",
    "    stacking_mlp = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=meta_mlp,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "    \n",
    "    print(\"Training Stacking model with default MLP meta-learner...\")\n",
    "    stacking_mlp.fit(X_train, y_train)\n",
    "    \n",
    "    stack_mlp_training_end = time.time()\n",
    "    stack_mlp_training_time = stack_mlp_training_end - stack_mlp_training_start\n",
    "    \n",
    "    print(f'Stacking + Default MLP Training Time: {stack_mlp_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping Stacking + MLP training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Base Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Set `SKIP_TRAINING = True` in the global configuration to skip steps 4 and 5 and load pre-existing models instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:10,857] A new study created in memory with name: Logistic Regression Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9414448b4bda40e4b83b132211c8826f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:10,914] Trial 0 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:10,976] Trial 1 finished with value: 0.8313829787234042 and parameters: {'solver': 'newton-cholesky', 'C': 0.3470266988650412}. Best is trial 1 with value: 0.8313829787234042.\n",
      "[I 2025-12-28 19:41:11,026] Trial 2 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0008111941985431928}. Best is trial 1 with value: 0.8313829787234042.\n",
      "[I 2025-12-28 19:41:11,072] Trial 3 finished with value: 0.8015070921985815 and parameters: {'solver': 'newton-cholesky', 'C': 0.0028585493941961923}. Best is trial 1 with value: 0.8313829787234042.\n",
      "[I 2025-12-28 19:41:11,109] Trial 4 finished with value: 0.839627659574468 and parameters: {'solver': 'lbfgs', 'C': 0.019069966103000432}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,149] Trial 5 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00017070728830306665}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,185] Trial 6 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 6.732248920775331}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,222] Trial 7 finished with value: 0.835372340425532 and parameters: {'solver': 'lbfgs', 'C': 0.015876781526923997}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,261] Trial 8 finished with value: 0.7340425531914894 and parameters: {'solver': 'sag', 'C': 0.0019674328025306126}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,297] Trial 9 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.0008399864445957502}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,336] Trial 10 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.23114272501983435}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,377] Trial 11 finished with value: 0.839627659574468 and parameters: {'solver': 'lbfgs', 'C': 0.022212906398276673}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,414] Trial 12 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.03127454434877546}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,453] Trial 13 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.23547164170627424}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,493] Trial 14 finished with value: 0.8182624113475179 and parameters: {'solver': 'lbfgs', 'C': 0.00790717256900017}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,530] Trial 15 finished with value: 0.8356382978723405 and parameters: {'solver': 'lbfgs', 'C': 0.06203312414676465}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,568] Trial 16 finished with value: 0.8101063829787234 and parameters: {'solver': 'newton-cg', 'C': 2.8359603155870414}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,609] Trial 17 finished with value: 0.8356382978723405 and parameters: {'solver': 'sag', 'C': 0.053955285200606204}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,657] Trial 18 finished with value: 0.8186170212765959 and parameters: {'solver': 'newton-cholesky', 'C': 0.7133775108174092}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,695] Trial 19 finished with value: 0.8140070921985816 and parameters: {'solver': 'lbfgs', 'C': 0.00866904026900546}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:41:11,735] Trial 20 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.10511058777298}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:11,773] Trial 21 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.09579478382298531}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:11,814] Trial 22 finished with value: 0.8185283687943261 and parameters: {'solver': 'lbfgs', 'C': 0.9021282386939767}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:11,856] Trial 23 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.12349417486709256}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:11,894] Trial 24 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.10253916297490513}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:11,933] Trial 25 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08885514862395398}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:11,983] Trial 26 finished with value: 0.8185283687943261 and parameters: {'solver': 'newton-cholesky', 'C': 1.2297547457155955}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,021] Trial 27 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cg', 'C': 0.16725088571097357}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,060] Trial 28 finished with value: 0.8144503546099291 and parameters: {'solver': 'sag', 'C': 0.473647030468632}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,101] Trial 29 finished with value: 0.81427304964539 and parameters: {'solver': 'newton-cg', 'C': 2.500746292622828}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,138] Trial 30 finished with value: 0.8356382978723405 and parameters: {'solver': 'lbfgs', 'C': 0.05935443244214272}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,176] Trial 31 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.10515624420505762}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,216] Trial 32 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08518448699621496}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,253] Trial 33 finished with value: 0.8144503546099291 and parameters: {'solver': 'lbfgs', 'C': 0.43788841152586483}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,302] Trial 34 finished with value: 0.8312943262411346 and parameters: {'solver': 'newton-cholesky', 'C': 0.041968693930132236}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,341] Trial 35 finished with value: 0.8310283687943262 and parameters: {'solver': 'lbfgs', 'C': 0.011162708528043243}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,378] Trial 36 finished with value: 0.8355496453900708 and parameters: {'solver': 'lbfgs', 'C': 0.27469060941296386}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,417] Trial 37 finished with value: 0.8182624113475176 and parameters: {'solver': 'newton-cg', 'C': 0.005126053594044327}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,456] Trial 38 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.027084699256165714}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,494] Trial 39 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cholesky', 'C': 0.13920172098641317}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,533] Trial 40 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 1.770905390465969}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,573] Trial 41 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08251966742856091}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,610] Trial 42 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.10564361374841384}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,648] Trial 43 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.16214702578114584}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,689] Trial 44 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.038416950386432606}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,726] Trial 45 finished with value: 0.8144503546099291 and parameters: {'solver': 'lbfgs', 'C': 0.425124712208641}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,766] Trial 46 finished with value: 0.835372340425532 and parameters: {'solver': 'lbfgs', 'C': 0.01639831490785207}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,806] Trial 47 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.31585692799539056}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,842] Trial 48 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00030963608898612485}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,881] Trial 49 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.19395834496761943}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,922] Trial 50 finished with value: 0.7847517730496454 and parameters: {'solver': 'sag', 'C': 0.002328144608186507}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:12,960] Trial 51 finished with value: 0.8355496453900709 and parameters: {'solver': 'lbfgs', 'C': 0.07418023078509615}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,000] Trial 52 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.10511491633211649}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,040] Trial 53 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.02487223947535763}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,078] Trial 54 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08231440702905402}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,116] Trial 55 finished with value: 0.8312943262411346 and parameters: {'solver': 'lbfgs', 'C': 0.048682948432294246}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,156] Trial 56 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.21863439681562882}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,193] Trial 57 finished with value: 0.8186170212765959 and parameters: {'solver': 'newton-cg', 'C': 0.6295030042778785}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,233] Trial 58 finished with value: 0.8184397163120568 and parameters: {'solver': 'lbfgs', 'C': 8.064276941408508}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,272] Trial 59 finished with value: 0.8310283687943262 and parameters: {'solver': 'lbfgs', 'C': 0.012316932035532682}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,310] Trial 60 finished with value: 0.8354609929078014 and parameters: {'solver': 'newton-cholesky', 'C': 0.03092528921252613}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,348] Trial 61 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.0885363242773496}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,388] Trial 62 finished with value: 0.8355496453900709 and parameters: {'solver': 'lbfgs', 'C': 0.06778170846312445}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,426] Trial 63 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.15362378697035195}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,467] Trial 64 finished with value: 0.8355496453900709 and parameters: {'solver': 'lbfgs', 'C': 0.04506818984856132}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,507] Trial 65 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.11408313720173278}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,545] Trial 66 finished with value: 0.8355496453900708 and parameters: {'solver': 'sag', 'C': 0.2811644110744442}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,583] Trial 67 finished with value: 0.839627659574468 and parameters: {'solver': 'lbfgs', 'C': 0.018040988043418284}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,623] Trial 68 finished with value: 0.8356382978723405 and parameters: {'solver': 'newton-cg', 'C': 0.059201552891107706}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,660] Trial 69 finished with value: 0.8312943262411346 and parameters: {'solver': 'lbfgs', 'C': 0.03938446360995749}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,701] Trial 70 finished with value: 0.8140070921985816 and parameters: {'solver': 'lbfgs', 'C': 0.005840857482550606}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,740] Trial 71 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.14355530900596972}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,777] Trial 72 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.10698375278383007}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,816] Trial 73 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.07729600991825956}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,856] Trial 74 finished with value: 0.8313829787234042 and parameters: {'solver': 'newton-cholesky', 'C': 0.19790476722000647}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,893] Trial 75 finished with value: 0.8228723404255319 and parameters: {'solver': 'lbfgs', 'C': 0.38121090968269494}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,933] Trial 76 finished with value: 0.8144503546099291 and parameters: {'solver': 'lbfgs', 'C': 0.5897039046263632}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:13,974] Trial 77 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08729253481392706}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,011] Trial 78 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.03367243833605013}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,052] Trial 79 finished with value: 0.8356382978723405 and parameters: {'solver': 'sag', 'C': 0.05675130393345647}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,093] Trial 80 finished with value: 0.8355496453900708 and parameters: {'solver': 'lbfgs', 'C': 0.2720741578493304}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,131] Trial 81 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.09121340995989048}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,170] Trial 82 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.10186383447078869}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,210] Trial 83 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.12491460559278368}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,248] Trial 84 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.18536731439158965}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,286] Trial 85 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.12652424834137088}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,327] Trial 86 finished with value: 0.8353723404255318 and parameters: {'solver': 'newton-cg', 'C': 0.02157442376777269}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,364] Trial 87 finished with value: 0.8356382978723405 and parameters: {'solver': 'lbfgs', 'C': 0.054043970065939737}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,404] Trial 88 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00011100251313161746}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,444] Trial 89 finished with value: 0.8313829787234042 and parameters: {'solver': 'newton-cholesky', 'C': 0.2340918627120444}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,482] Trial 90 finished with value: 0.8355496453900709 and parameters: {'solver': 'lbfgs', 'C': 0.06995355100445558}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,521] Trial 91 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08687696799818942}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,562] Trial 92 finished with value: 0.8355496453900709 and parameters: {'solver': 'lbfgs', 'C': 0.04637444561012601}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,601] Trial 93 finished with value: 0.8355496453900708 and parameters: {'solver': 'lbfgs', 'C': 0.17061586020492692}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,640] Trial 94 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.11550804113529424}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,680] Trial 95 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.027539687732221235}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,717] Trial 96 finished with value: 0.8355496453900709 and parameters: {'solver': 'lbfgs', 'C': 0.07224124204935563}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,756] Trial 97 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.03766650614533106}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,797] Trial 98 finished with value: 0.8313829787234042 and parameters: {'solver': 'sag', 'C': 0.3384830621544235}. Best is trial 20 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:41:14,835] Trial 99 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.1362236226056684}. Best is trial 20 with value: 0.8439716312056736.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:14,839] A new study created in memory with name: Decision Tree Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Logistic Regression Using TPESampler: {'solver': 'lbfgs', 'C': 0.10511058777298}\n",
      "Best accuracy: 0.8440, at trial: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb0cce660954beaa3f3c27a8f5d06e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:14,881] Trial 0 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:14,910] Trial 1 finished with value: 0.7296099290780143 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:14,928] Trial 2 finished with value: 0.7087765957446808 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:14,944] Trial 3 finished with value: 0.725886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:14,962] Trial 4 finished with value: 0.7469858156028369 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:14,977] Trial 5 finished with value: 0.7257092198581561 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:14,994] Trial 6 finished with value: 0.7383865248226951 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,010] Trial 7 finished with value: 0.7044326241134753 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,027] Trial 8 finished with value: 0.7467198581560284 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,054] Trial 9 finished with value: 0.713209219858156 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,090] Trial 10 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,111] Trial 11 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,144] Trial 12 finished with value: 0.7422872340425533 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,166] Trial 13 finished with value: 0.7425531914893617 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,188] Trial 14 finished with value: 0.763918439716312 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,211] Trial 15 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,231] Trial 16 finished with value: 0.6960106382978724 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,252] Trial 17 finished with value: 0.699822695035461 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,275] Trial 18 finished with value: 0.7091312056737589 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,299] Trial 19 finished with value: 0.7553191489361702 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,323] Trial 20 finished with value: 0.7045212765957447 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,342] Trial 21 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,363] Trial 22 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,384] Trial 23 finished with value: 0.7425531914893617 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,418] Trial 24 finished with value: 0.7426418439716311 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,442] Trial 25 finished with value: 0.7764184397163121 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,462] Trial 26 finished with value: 0.7260638297872339 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,483] Trial 27 finished with value: 0.7465425531914894 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,506] Trial 28 finished with value: 0.7422872340425533 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,528] Trial 29 finished with value: 0.7551418439716311 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,553] Trial 30 finished with value: 0.7422872340425533 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,573] Trial 31 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,595] Trial 32 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,615] Trial 33 finished with value: 0.7382978723404255 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,637] Trial 34 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,660] Trial 35 finished with value: 0.7256205673758865 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,680] Trial 36 finished with value: 0.7465425531914894 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,702] Trial 37 finished with value: 0.7766843971631205 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,723] Trial 38 finished with value: 0.7300531914893617 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,745] Trial 39 finished with value: 0.7382978723404255 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,768] Trial 40 finished with value: 0.7553191489361702 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,789] Trial 41 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,810] Trial 42 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,832] Trial 43 finished with value: 0.7296099290780143 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,854] Trial 44 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,877] Trial 45 finished with value: 0.7382978723404255 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,898] Trial 46 finished with value: 0.7764184397163121 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,922] Trial 47 finished with value: 0.7764184397163121 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,944] Trial 48 finished with value: 0.7766843971631205 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:41:15,967] Trial 49 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:15,991] Trial 50 finished with value: 0.7424645390070923 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,011] Trial 51 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,033] Trial 52 finished with value: 0.7969858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,068] Trial 53 finished with value: 0.7969858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,091] Trial 54 finished with value: 0.7969858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,114] Trial 55 finished with value: 0.7424645390070922 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,146] Trial 56 finished with value: 0.7510638297872341 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,168] Trial 57 finished with value: 0.7130319148936171 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,189] Trial 58 finished with value: 0.7421985815602838 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,211] Trial 59 finished with value: 0.7257978723404255 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,234] Trial 60 finished with value: 0.7969858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,255] Trial 61 finished with value: 0.7969858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,277] Trial 62 finished with value: 0.7969858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,298] Trial 63 finished with value: 0.7510638297872341 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,320] Trial 64 finished with value: 0.7089539007092197 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,342] Trial 65 finished with value: 0.7969858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,363] Trial 66 finished with value: 0.7130319148936171 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,385] Trial 67 finished with value: 0.7510638297872341 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,406] Trial 68 finished with value: 0.7969858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,429] Trial 69 finished with value: 0.763563829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,452] Trial 70 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,472] Trial 71 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,494] Trial 72 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,516] Trial 73 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,538] Trial 74 finished with value: 0.763563829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,560] Trial 75 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,581] Trial 76 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,603] Trial 77 finished with value: 0.763563829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,626] Trial 78 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,647] Trial 79 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,674] Trial 80 finished with value: 0.7425531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,696] Trial 81 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,718] Trial 82 finished with value: 0.7716312056737589 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,740] Trial 83 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,762] Trial 84 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,784] Trial 85 finished with value: 0.7425531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,804] Trial 86 finished with value: 0.7422872340425533 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,826] Trial 87 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,848] Trial 88 finished with value: 0.7174645390070922 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,870] Trial 89 finished with value: 0.7716312056737589 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,893] Trial 90 finished with value: 0.7257978723404255 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,914] Trial 91 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,936] Trial 92 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:16,958] Trial 93 finished with value: 0.7716312056737589 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 49 with value: 0.8011524822695035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:17,107] A new study created in memory with name: Random Forest Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:16,981] Trial 94 finished with value: 0.763563829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:17,006] Trial 95 finished with value: 0.7174645390070922 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:17,026] Trial 96 finished with value: 0.7425531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:17,048] Trial 97 finished with value: 0.7379432624113476 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:17,081] Trial 98 finished with value: 0.7424645390070923 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 49 with value: 0.8011524822695035.\n",
      "[I 2025-12-28 19:41:17,104] Trial 99 finished with value: 0.8011524822695035 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 49 with value: 0.8011524822695035.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using TPESampler: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6}\n",
      "Best accuracy: 0.8012, at trial: 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71056e001d4403a82bc15c62b359cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:17,204] Trial 0 finished with value: 0.7849290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7849290780141844.\n",
      "[I 2025-12-28 19:41:17,314] Trial 1 finished with value: 0.797340425531915 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.797340425531915.\n",
      "[I 2025-12-28 19:41:17,446] Trial 2 finished with value: 0.7762411347517729 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.797340425531915.\n",
      "[I 2025-12-28 19:41:17,586] Trial 3 finished with value: 0.8016843971631206 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8016843971631206.\n",
      "[I 2025-12-28 19:41:17,696] Trial 4 finished with value: 0.7930851063829787 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8016843971631206.\n",
      "[I 2025-12-28 19:41:17,775] Trial 5 finished with value: 0.788918439716312 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8016843971631206.\n",
      "[I 2025-12-28 19:41:17,864] Trial 6 finished with value: 0.7847517730496454 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 22, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8016843971631206.\n",
      "[I 2025-12-28 19:41:18,026] Trial 7 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:18,178] Trial 8 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:18,309] Trial 9 finished with value: 0.801595744680851 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:18,498] Trial 10 finished with value: 0.810017730496454 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 98, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:18,679] Trial 11 finished with value: 0.810017730496454 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 97, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:18,880] Trial 12 finished with value: 0.8057624113475178 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:19,049] Trial 13 finished with value: 0.7972517730496455 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 82, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:19,228] Trial 14 finished with value: 0.7718971631205674 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:19,390] Trial 15 finished with value: 0.7930851063829787 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:19,578] Trial 16 finished with value: 0.8101063829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 90, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:19,763] Trial 17 finished with value: 0.8101063829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:19,910] Trial 18 finished with value: 0.7847517730496454 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:20,089] Trial 19 finished with value: 0.8056737588652483 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:20,237] Trial 20 finished with value: 0.814095744680851 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:20,408] Trial 21 finished with value: 0.797340425531915 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:20,546] Trial 22 finished with value: 0.8060283687943264 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:20,737] Trial 23 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 90, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:41:20,887] Trial 24 finished with value: 0.8228723404255319 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:41:21,048] Trial 25 finished with value: 0.8186170212765956 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:41:21,187] Trial 26 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:41:21,304] Trial 27 finished with value: 0.8186170212765956 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 47, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 24 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:41:21,421] Trial 28 finished with value: 0.7764184397163121 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 24 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:41:21,581] Trial 29 finished with value: 0.81427304964539 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 24 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:41:21,710] Trial 30 finished with value: 0.7975177304964538 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 47, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:41:21,839] Trial 31 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 24 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:41:21,969] Trial 32 finished with value: 0.8271276595744681 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:22,097] Trial 33 finished with value: 0.8018617021276595 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 42, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:22,207] Trial 34 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 31, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:22,324] Trial 35 finished with value: 0.7931737588652482 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 32, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:22,473] Trial 36 finished with value: 0.7976063829787232 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 59, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:22,592] Trial 37 finished with value: 0.7932624113475177 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:22,730] Trial 38 finished with value: 0.7848404255319149 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:22,807] Trial 39 finished with value: 0.7551418439716311 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 11, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:22,923] Trial 40 finished with value: 0.8018617021276595 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:23,073] Trial 41 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:23,169] Trial 42 finished with value: 0.7976063829787233 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 25, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:23,326] Trial 43 finished with value: 0.788918439716312 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 74, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:23,453] Trial 44 finished with value: 0.8187056737588652 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 42, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:23,622] Trial 45 finished with value: 0.8058510638297871 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:23,749] Trial 46 finished with value: 0.7804964539007092 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 33, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:23,924] Trial 47 finished with value: 0.797340425531915 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:24,121] Trial 48 finished with value: 0.801595744680851 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:24,297] Trial 49 finished with value: 0.7890957446808511 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 44, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:24,481] Trial 50 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:24,625] Trial 51 finished with value: 0.8059397163120566 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 35, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:24,787] Trial 52 finished with value: 0.8017730496453901 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 62, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:24,918] Trial 53 finished with value: 0.7931737588652481 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 39, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:25,119] Trial 54 finished with value: 0.7974290780141844 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:25,230] Trial 55 finished with value: 0.8017730496453901 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 26, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:25,391] Trial 56 finished with value: 0.8060283687943262 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 55, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:25,495] Trial 57 finished with value: 0.7930851063829787 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 21, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:25,718] Trial 58 finished with value: 0.7931737588652482 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 95, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:25,858] Trial 59 finished with value: 0.7932624113475178 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:26,037] Trial 60 finished with value: 0.8058510638297871 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 79, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:26,218] Trial 61 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:26,415] Trial 62 finished with value: 0.8102836879432624 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:26,594] Trial 63 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 86, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:26,784] Trial 64 finished with value: 0.81427304964539 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 95, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:26,901] Trial 65 finished with value: 0.7934397163120568 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:27,070] Trial 66 finished with value: 0.7975177304964539 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:27,229] Trial 67 finished with value: 0.7890070921985816 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:27,345] Trial 68 finished with value: 0.7723404255319148 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 52, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:27,492] Trial 69 finished with value: 0.8060283687943264 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:27,632] Trial 70 finished with value: 0.8187943262411348 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:27,776] Trial 71 finished with value: 0.8187056737588652 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 42, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:27,906] Trial 72 finished with value: 0.8187943262411348 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:28,046] Trial 73 finished with value: 0.8187943262411348 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:28,174] Trial 74 finished with value: 0.8187943262411348 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:28,294] Trial 75 finished with value: 0.8144503546099291 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 40, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:28,412] Trial 76 finished with value: 0.8017730496453901 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 35, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:28,520] Trial 77 finished with value: 0.8101950354609929 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 30, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:28,663] Trial 78 finished with value: 0.8187056737588652 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 42, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:28,792] Trial 79 finished with value: 0.7718971631205674 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:28,974] Trial 80 finished with value: 0.7933510638297872 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:29,133] Trial 81 finished with value: 0.8102836879432624 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 44, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:29,240] Trial 82 finished with value: 0.8017730496453901 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 35, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:29,367] Trial 83 finished with value: 0.8187056737588652 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 42, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:29,484] Trial 84 finished with value: 0.8101950354609929 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:29,611] Trial 85 finished with value: 0.8060283687943264 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:29,719] Trial 86 finished with value: 0.8059397163120566 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 28, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:29,847] Trial 87 finished with value: 0.7975177304964538 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:29,966] Trial 88 finished with value: 0.7848404255319149 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 42, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,075] Trial 89 finished with value: 0.8101950354609929 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,173] Trial 90 finished with value: 0.7890070921985816 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 33, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,289] Trial 91 finished with value: 0.8102836879432624 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 44, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,396] Trial 92 finished with value: 0.8187056737588652 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 42, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,502] Trial 93 finished with value: 0.8187056737588654 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 39, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,608] Trial 94 finished with value: 0.8057624113475178 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 48, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,724] Trial 95 finished with value: 0.8101950354609929 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 53, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,819] Trial 96 finished with value: 0.8059397163120569 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:30,924] Trial 97 finished with value: 0.8102836879432624 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 39, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:31,031] Trial 98 finished with value: 0.7891843971631206 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8271276595744681.\n",
      "[I 2025-12-28 19:41:31,117] Trial 99 finished with value: 0.7891843971631205 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 30, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8271276595744681.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:31,119] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Random Forest Using TPESampler: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}\n",
      "Best accuracy: 0.8271, at trial: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d4bf7dc5ba4ac089e59825a03e88ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:31,171] Trial 0 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:41:31,300] Trial 1 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:41:31,350] Trial 2 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:41:31,479] Trial 3 finished with value: 0.8356382978723402 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:41:31,528] Trial 4 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:41:31,564] Trial 5 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:41:31,602] Trial 6 finished with value: 0.835372340425532 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:41:31,639] Trial 7 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:41:31,675] Trial 8 finished with value: 0.8437056737588653 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:31,723] Trial 9 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:31,781] Trial 10 finished with value: 0.835372340425532 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:31,831] Trial 11 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:31,881] Trial 12 finished with value: 0.8186170212765956 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:31,934] Trial 13 finished with value: 0.835372340425532 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:31,984] Trial 14 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:32,026] Trial 15 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:32,065] Trial 16 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:41:32,167] Trial 17 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,272] Trial 18 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,364] Trial 19 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,397] Trial 20 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,428] Trial 21 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,457] Trial 22 finished with value: 0.8186170212765959 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,489] Trial 23 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,524] Trial 24 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,553] Trial 25 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,585] Trial 26 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,617] Trial 27 finished with value: 0.8315602836879433 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,651] Trial 28 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,681] Trial 29 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,713] Trial 30 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,743] Trial 31 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,775] Trial 32 finished with value: 0.839627659574468 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,809] Trial 33 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,843] Trial 34 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,877] Trial 35 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,907] Trial 36 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,938] Trial 37 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 28, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:32,968] Trial 38 finished with value: 0.8101063829787234 and parameters: {'algorithm': 'brute', 'n_neighbors': 6, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,022] Trial 39 finished with value: 0.835372340425532 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,051] Trial 40 finished with value: 0.8187056737588654 and parameters: {'algorithm': 'brute', 'n_neighbors': 13, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,082] Trial 41 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,116] Trial 42 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,145] Trial 43 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,196] Trial 44 finished with value: 0.835372340425532 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,229] Trial 45 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,258] Trial 46 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,289] Trial 47 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,341] Trial 48 finished with value: 0.839627659574468 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,375] Trial 49 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,405] Trial 50 finished with value: 0.835372340425532 and parameters: {'algorithm': 'brute', 'n_neighbors': 48, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,436] Trial 51 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,466] Trial 52 finished with value: 0.7972517730496453 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,498] Trial 53 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,528] Trial 54 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,559] Trial 55 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,613] Trial 56 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,665] Trial 57 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,696] Trial 58 finished with value: 0.835372340425532 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,732] Trial 59 finished with value: 0.839982269503546 and parameters: {'algorithm': 'brute', 'n_neighbors': 21, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,764] Trial 60 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,793] Trial 61 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,824] Trial 62 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,856] Trial 63 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,889] Trial 64 finished with value: 0.835372340425532 and parameters: {'algorithm': 'brute', 'n_neighbors': 48, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,938] Trial 65 finished with value: 0.8186170212765959 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:33,972] Trial 66 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,004] Trial 67 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,034] Trial 68 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,066] Trial 69 finished with value: 0.839627659574468 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,097] Trial 70 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,128] Trial 71 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,159] Trial 72 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,191] Trial 73 finished with value: 0.835372340425532 and parameters: {'algorithm': 'brute', 'n_neighbors': 49, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,211] Trial 74 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,242] Trial 75 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,281] Trial 76 finished with value: 0.835372340425532 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,322] Trial 77 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,341] Trial 78 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,363] Trial 79 finished with value: 0.8312943262411349 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 1}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,392] Trial 80 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,432] Trial 81 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,472] Trial 82 finished with value: 0.835372340425532 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,515] Trial 83 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,555] Trial 84 finished with value: 0.839627659574468 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,597] Trial 85 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,628] Trial 86 finished with value: 0.835372340425532 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,660] Trial 87 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,689] Trial 88 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,730] Trial 89 finished with value: 0.835372340425532 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,772] Trial 90 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,801] Trial 91 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,832] Trial 92 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,863] Trial 93 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,892] Trial 94 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,911] Trial 95 finished with value: 0.8187056737588654 and parameters: {'algorithm': 'brute', 'n_neighbors': 13, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,942] Trial 96 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:34,974] Trial 97 finished with value: 0.835372340425532 and parameters: {'algorithm': 'brute', 'n_neighbors': 49, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:35,004] Trial 98 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:41:35,034] Trial 99 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 17 with value: 0.8437943262411348.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:35,037] A new study created in memory with name: Support Vector Machine Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using TPESampler: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}\n",
      "Best accuracy: 0.8438, at trial: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27c6352e771470cbaa33056cdcde724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:35,069] Trial 0 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,085] Trial 1 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.005399484409787433}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,112] Trial 2 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.008706020878304856}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,138] Trial 3 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00023270677083837802}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,155] Trial 4 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0003823475224675188}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,170] Trial 5 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0005404103854647331}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,186] Trial 6 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0010677482709481358}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,212] Trial 7 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00021930485556643703, 'degree': 2}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,228] Trial 8 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0004066563313514797}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,254] Trial 9 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00017541893487450815}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,276] Trial 10 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0021291805287692966, 'degree': 5}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,303] Trial 11 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00461735794844261}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,321] Trial 12 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0025603761492914456}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,349] Trial 13 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0013838713864867114}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:41:35,368] Trial 14 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009698829035069871, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,389] Trial 15 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009243135778676024, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,408] Trial 16 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009591652681969536, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,426] Trial 17 finished with value: 0.5823581560283687 and parameters: {'kernel': 'poly', 'C': 0.0038978191279307036, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,446] Trial 18 finished with value: 0.7299645390070921 and parameters: {'kernel': 'poly', 'C': 0.007009652753801009, 'degree': 4}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,465] Trial 19 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0032095843081439003, 'degree': 4}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,496] Trial 20 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.005334614573162788, 'degree': 3}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,527] Trial 21 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009164010871969922, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,544] Trial 22 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009906571221598617, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,563] Trial 23 finished with value: 0.6665780141843971 and parameters: {'kernel': 'poly', 'C': 0.006314160024729558, 'degree': 4}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,582] Trial 24 finished with value: 0.5738475177304965 and parameters: {'kernel': 'poly', 'C': 0.0035927186383067837, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,612] Trial 25 finished with value: 0.7088652482269503 and parameters: {'kernel': 'poly', 'C': 0.006745334021762559, 'degree': 4}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,632] Trial 26 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009946059445623757, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,650] Trial 27 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0025285626060545944, 'degree': 3}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,669] Trial 28 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00010740407619157729, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,687] Trial 29 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0017112566505466196, 'degree': 4}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,706] Trial 30 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0009029245888295053, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,724] Trial 31 finished with value: 0.7593971631205674 and parameters: {'kernel': 'poly', 'C': 0.007611148779217139, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,744] Trial 32 finished with value: 0.7171099290780141 and parameters: {'kernel': 'poly', 'C': 0.005511324751284086, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,771] Trial 33 finished with value: 0.7593971631205674 and parameters: {'kernel': 'poly', 'C': 0.007378825990834327, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,790] Trial 34 finished with value: 0.552836879432624 and parameters: {'kernel': 'poly', 'C': 0.0045072119355838835, 'degree': 4}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,821] Trial 35 finished with value: 0.7678191489361701 and parameters: {'kernel': 'poly', 'C': 0.008684621403197049, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,841] Trial 36 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.005325928898424262}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,872] Trial 37 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009799041159431013, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,889] Trial 38 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0029602963537663533}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,909] Trial 39 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0042029592864566345, 'degree': 2}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,926] Trial 40 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.007387402107120954}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,944] Trial 41 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009980486980480482, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,965] Trial 42 finished with value: 0.7129432624113475 and parameters: {'kernel': 'poly', 'C': 0.005622660874494249, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:35,982] Trial 43 finished with value: 0.7677304964539008 and parameters: {'kernel': 'poly', 'C': 0.008288750841815545, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,001] Trial 44 finished with value: 0.7382978723404255 and parameters: {'kernel': 'poly', 'C': 0.006394345026452608, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,018] Trial 45 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00839262259028964}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,037] Trial 46 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0007137245092957818}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,056] Trial 47 finished with value: 0.5653368794326241 and parameters: {'kernel': 'poly', 'C': 0.004570247386545836, 'degree': 4}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,076] Trial 48 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009869548994934009, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,105] Trial 49 finished with value: 0.7340425531914894 and parameters: {'kernel': 'poly', 'C': 0.006068258294314838, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,123] Trial 50 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0003922476286345663}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,141] Trial 51 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009884157497089997, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,159] Trial 52 finished with value: 0.7593971631205674 and parameters: {'kernel': 'poly', 'C': 0.007844316302537855, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,191] Trial 53 finished with value: 0.7678191489361701 and parameters: {'kernel': 'poly', 'C': 0.008492331697270946, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,209] Trial 54 finished with value: 0.7467198581560284 and parameters: {'kernel': 'poly', 'C': 0.006583704695440834, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,228] Trial 55 finished with value: 0.6960992907801419 and parameters: {'kernel': 'poly', 'C': 0.005187418641052477, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,248] Trial 56 finished with value: 0.5653368794326241 and parameters: {'kernel': 'poly', 'C': 0.003453388574706885, 'degree': 5}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,276] Trial 57 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0066088570623544915}. Best is trial 14 with value: 0.7720744680851064.\n",
      "[I 2025-12-28 19:41:36,297] Trial 58 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.009989167941012688, 'degree': 4}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,315] Trial 59 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0005041470618034526, 'degree': 3}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,336] Trial 60 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0002848573994502198, 'degree': 4}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,354] Trial 61 finished with value: 0.7593971631205674 and parameters: {'kernel': 'poly', 'C': 0.00883611292767846, 'degree': 4}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,373] Trial 62 finished with value: 0.7593971631205674 and parameters: {'kernel': 'poly', 'C': 0.007709267051214847, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,403] Trial 63 finished with value: 0.5653368794326241 and parameters: {'kernel': 'poly', 'C': 0.00888417047007655, 'degree': 2}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,425] Trial 64 finished with value: 0.5781028368794325 and parameters: {'kernel': 'poly', 'C': 0.005080332824539498, 'degree': 4}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,443] Trial 65 finished with value: 0.7509751773049645 and parameters: {'kernel': 'poly', 'C': 0.007111556012346714, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,463] Trial 66 finished with value: 0.552836879432624 and parameters: {'kernel': 'poly', 'C': 0.0061361462325649815, 'degree': 3}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,481] Trial 67 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.009067194013281014}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,511] Trial 68 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0017204252816481742, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,531] Trial 69 finished with value: 0.7509751773049645 and parameters: {'kernel': 'poly', 'C': 0.007296865381998785, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,549] Trial 70 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.004044424511846331}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,567] Trial 71 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009823519228937632, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,586] Trial 72 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009917388098986568, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,605] Trial 73 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.008201291214172289, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,624] Trial 74 finished with value: 0.7171099290780141 and parameters: {'kernel': 'poly', 'C': 0.00580741362777212, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,645] Trial 75 finished with value: 0.7552304964539008 and parameters: {'kernel': 'poly', 'C': 0.0073348067734200426, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,662] Trial 76 finished with value: 0.7636524822695036 and parameters: {'kernel': 'poly', 'C': 0.008953535956241704, 'degree': 4}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,682] Trial 77 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0012157325452700546, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,700] Trial 78 finished with value: 0.675 and parameters: {'kernel': 'poly', 'C': 0.004964120314395361, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,729] Trial 79 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.006646196996158061}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,750] Trial 80 finished with value: 0.7593971631205674 and parameters: {'kernel': 'poly', 'C': 0.007959604801718805, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,780] Trial 81 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009819347568563916, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,811] Trial 82 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009976259197570982, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,841] Trial 83 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.008040070921701982, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,873] Trial 84 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.000143158121694863, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,905] Trial 85 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009098731081847916, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,936] Trial 86 finished with value: 0.7171099290780141 and parameters: {'kernel': 'poly', 'C': 0.005811153369173605, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,967] Trial 87 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.006946454051150582}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:36,987] Trial 88 finished with value: 0.7678191489361701 and parameters: {'kernel': 'poly', 'C': 0.008365936830933252, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,006] Trial 89 finished with value: 0.6243794326241134 and parameters: {'kernel': 'poly', 'C': 0.007546349027734385, 'degree': 3}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,028] Trial 90 finished with value: 0.675 and parameters: {'kernel': 'poly', 'C': 0.006366956512934784, 'degree': 4}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,056] Trial 91 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.0099806714739453, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,076] Trial 92 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009033994765054421, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,106] Trial 93 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009068488339371345, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,126] Trial 94 finished with value: 0.7593971631205674 and parameters: {'kernel': 'poly', 'C': 0.007863922859009345, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,148] Trial 95 finished with value: 0.7509751773049645 and parameters: {'kernel': 'poly', 'C': 0.006991524672776781, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,166] Trial 96 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.009967073889316488, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:37,236] A new study created in memory with name: AdaBoost Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:37,195] Trial 97 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.008551132455844943}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,215] Trial 98 finished with value: 0.7340425531914894 and parameters: {'kernel': 'poly', 'C': 0.006092327908453386, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:41:37,233] Trial 99 finished with value: 0.7593971631205674 and parameters: {'kernel': 'poly', 'C': 0.007588155560844567, 'degree': 5}. Best is trial 58 with value: 0.7762411347517731.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using TPESampler: {'kernel': 'poly', 'C': 0.009989167941012688, 'degree': 4}\n",
      "Best accuracy: 0.7762, at trial: 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbeb8fe29a7541599f22e87ea6fc42b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:37,320] Trial 0 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:41:37,451] Trial 1 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 76, 'learning_rate': 0.06251373574521749}. Best is trial 1 with value: 0.8059397163120569.\n",
      "[I 2025-12-28 19:41:37,512] Trial 2 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029375384576328283}. Best is trial 1 with value: 0.8059397163120569.\n",
      "[I 2025-12-28 19:41:37,549] Trial 3 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 15, 'learning_rate': 0.39676050770529875}. Best is trial 1 with value: 0.8059397163120569.\n",
      "[I 2025-12-28 19:41:37,668] Trial 4 finished with value: 0.8311170212765957 and parameters: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:37,717] Trial 5 finished with value: 0.7929964539007092 and parameters: {'n_estimators': 11, 'learning_rate': 0.8123245085588685}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:37,878] Trial 6 finished with value: 0.725531914893617 and parameters: {'n_estimators': 85, 'learning_rate': 0.004335281794951566}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:37,970] Trial 7 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 26, 'learning_rate': 0.0035498788321965025}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,059] Trial 8 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 37, 'learning_rate': 0.03752055855124281}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,149] Trial 9 finished with value: 0.725531914893617 and parameters: {'n_estimators': 49, 'learning_rate': 0.007476312062252299}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,251] Trial 10 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 67, 'learning_rate': 0.14171731252095018}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,366] Trial 11 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 63, 'learning_rate': 0.14519765494874043}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,478] Trial 12 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 62, 'learning_rate': 0.158341601515545}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,631] Trial 13 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 94, 'learning_rate': 0.01504383897839578}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,743] Trial 14 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 59, 'learning_rate': 0.0010952927106776854}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,869] Trial 15 finished with value: 0.810017730496454 and parameters: {'n_estimators': 75, 'learning_rate': 0.1535429802579226}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:38,994] Trial 16 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 73, 'learning_rate': 0.06363660047282137}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:39,159] Trial 17 finished with value: 0.810017730496454 and parameters: {'n_estimators': 99, 'learning_rate': 0.27765180871683454}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:39,251] Trial 18 finished with value: 0.7976063829787232 and parameters: {'n_estimators': 48, 'learning_rate': 0.023612893083708977}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:39,416] Trial 19 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 84, 'learning_rate': 0.07478858887592477}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:39,519] Trial 20 finished with value: 0.7931737588652482 and parameters: {'n_estimators': 54, 'learning_rate': 0.3366038653393071}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:39,633] Trial 21 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 63, 'learning_rate': 0.1432915406984101}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:39,758] Trial 22 finished with value: 0.7930851063829787 and parameters: {'n_estimators': 67, 'learning_rate': 0.20514799847290124}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:39,860] Trial 23 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 56, 'learning_rate': 0.0859772614854437}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:39,944] Trial 24 finished with value: 0.8015070921985815 and parameters: {'n_estimators': 42, 'learning_rate': 0.45859747702732295}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:40,116] Trial 25 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 82, 'learning_rate': 0.03577667363195622}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:40,294] Trial 26 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 85, 'learning_rate': 0.03423239265392781}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:40,485] Trial 27 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 86, 'learning_rate': 0.014477862347217946}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:40,665] Trial 28 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 91, 'learning_rate': 0.024954580018812945}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:40,790] Trial 29 finished with value: 0.810017730496454 and parameters: {'n_estimators': 79, 'learning_rate': 0.041084724358396274}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:40,986] Trial 30 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 100, 'learning_rate': 0.014006232991181785}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:41,143] Trial 31 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 81, 'learning_rate': 0.10278011585338233}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:41,265] Trial 32 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 70, 'learning_rate': 0.053750832362115995}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:41,402] Trial 33 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 77, 'learning_rate': 0.022486792316804758}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:41,547] Trial 34 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 88, 'learning_rate': 0.046688223454718444}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:41,671] Trial 35 finished with value: 0.810017730496454 and parameters: {'n_estimators': 70, 'learning_rate': 0.5275559662447786}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:41,835] Trial 36 finished with value: 0.7676418439716312 and parameters: {'n_estimators': 94, 'learning_rate': 0.007895535275576068}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:41,968] Trial 37 finished with value: 0.801595744680851 and parameters: {'n_estimators': 81, 'learning_rate': 0.2577778651316338}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,040] Trial 38 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 36, 'learning_rate': 0.10202358084256205}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,140] Trial 39 finished with value: 0.8184397163120568 and parameters: {'n_estimators': 53, 'learning_rate': 0.6438413712993004}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,253] Trial 40 finished with value: 0.7468085106382979 and parameters: {'n_estimators': 64, 'learning_rate': 0.009939353720090359}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,356] Trial 41 finished with value: 0.810017730496454 and parameters: {'n_estimators': 61, 'learning_rate': 0.1987861767393076}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,489] Trial 42 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 71, 'learning_rate': 0.03254532337454712}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,591] Trial 43 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 59, 'learning_rate': 0.11705523033366984}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,683] Trial 44 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 49, 'learning_rate': 0.05968916427489038}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,754] Trial 45 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 30, 'learning_rate': 0.06299415671179272}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,837] Trial 46 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 47, 'learning_rate': 0.029471945364329673}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,930] Trial 47 finished with value: 0.7676418439716312 and parameters: {'n_estimators': 43, 'learning_rate': 0.018325350753580914}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:42,991] Trial 48 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 20, 'learning_rate': 0.07110669744068661}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,083] Trial 49 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 51, 'learning_rate': 0.05380884249380706}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,165] Trial 50 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 38, 'learning_rate': 0.040130535081308746}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,256] Trial 51 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 50, 'learning_rate': 0.05246265177258021}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,370] Trial 52 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 50, 'learning_rate': 0.051542212587787975}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,482] Trial 53 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 52, 'learning_rate': 0.08564273352310818}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,607] Trial 54 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 57, 'learning_rate': 0.03402508956322437}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,689] Trial 55 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 40, 'learning_rate': 0.054594505730072684}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,752] Trial 56 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 31, 'learning_rate': 0.03097650244697758}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,843] Trial 57 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 46, 'learning_rate': 0.020122609081300716}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:43,970] Trial 58 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 66, 'learning_rate': 0.001717788084031656}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,062] Trial 59 finished with value: 0.801595744680851 and parameters: {'n_estimators': 45, 'learning_rate': 0.11107578728681904}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,156] Trial 60 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 50, 'learning_rate': 0.07990082418655116}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,259] Trial 61 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 50, 'learning_rate': 0.04944260349820245}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,362] Trial 62 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 56, 'learning_rate': 0.04470391531451044}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,454] Trial 63 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 52, 'learning_rate': 0.056484086689320936}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,548] Trial 64 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 34, 'learning_rate': 0.026472286489505868}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,651] Trial 65 finished with value: 0.81427304964539 and parameters: {'n_estimators': 41, 'learning_rate': 0.19624920724733758}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,779] Trial 66 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 48, 'learning_rate': 0.03700174187344634}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:44,934] Trial 67 finished with value: 0.7930851063829787 and parameters: {'n_estimators': 91, 'learning_rate': 0.9826740452177564}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:45,070] Trial 68 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 84, 'learning_rate': 0.011688794748653412}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:45,236] Trial 69 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 96, 'learning_rate': 0.06776335136575971}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:45,373] Trial 70 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 58, 'learning_rate': 0.017029071154169313}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:45,476] Trial 71 finished with value: 0.8227836879432624 and parameters: {'n_estimators': 52, 'learning_rate': 0.12352811983175202}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:45,579] Trial 72 finished with value: 0.8186170212765956 and parameters: {'n_estimators': 55, 'learning_rate': 0.13171133143615316}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:45,674] Trial 73 finished with value: 0.81427304964539 and parameters: {'n_estimators': 56, 'learning_rate': 0.15164521951105145}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:45,784] Trial 74 finished with value: 0.810017730496454 and parameters: {'n_estimators': 61, 'learning_rate': 0.27561047502479646}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:45,878] Trial 75 finished with value: 0.8144503546099291 and parameters: {'n_estimators': 53, 'learning_rate': 0.133515442329162}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,020] Trial 76 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 75, 'learning_rate': 0.09361595983120265}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,127] Trial 77 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 45, 'learning_rate': 0.34124758171191627}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,230] Trial 78 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 60, 'learning_rate': 0.12368287736792341}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,362] Trial 79 finished with value: 0.8141843971631205 and parameters: {'n_estimators': 82, 'learning_rate': 0.16678768027260643}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,506] Trial 80 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 66, 'learning_rate': 0.08382309177567226}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,634] Trial 81 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 51, 'learning_rate': 0.06078280038642739}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,758] Trial 82 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 54, 'learning_rate': 0.04307740149797831}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,850] Trial 83 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 43, 'learning_rate': 0.026196896045297836}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:46,941] Trial 84 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 49, 'learning_rate': 0.07176687208876109}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,076] Trial 85 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 87, 'learning_rate': 0.09938399669753342}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,168] Trial 86 finished with value: 0.8226950354609928 and parameters: {'n_estimators': 55, 'learning_rate': 0.17573692831755328}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,290] Trial 87 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 78, 'learning_rate': 0.21575698497819887}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,394] Trial 88 finished with value: 0.7973404255319149 and parameters: {'n_estimators': 63, 'learning_rate': 0.33479980245908453}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,486] Trial 89 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 54, 'learning_rate': 0.1672367574674028}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,628] Trial 90 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 90, 'learning_rate': 0.036456895278097486}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,722] Trial 91 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 46, 'learning_rate': 0.04930223725244157}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,813] Trial 92 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 49, 'learning_rate': 0.12000598453902568}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:47,926] Trial 93 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 58, 'learning_rate': 0.23931712497474403}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:48,019] Trial 94 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 55, 'learning_rate': 0.05692725271703608}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:48,120] Trial 95 finished with value: 0.81427304964539 and parameters: {'n_estimators': 51, 'learning_rate': 0.18078992478511313}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:48,216] Trial 96 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 39, 'learning_rate': 0.07445608825578834}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:48,317] Trial 97 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 48, 'learning_rate': 0.021848820247940652}. Best is trial 4 with value: 0.8311170212765957.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:48,513] A new study created in memory with name: Gradient Boosting Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:48,431] Trial 98 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 68, 'learning_rate': 0.08848938565487179}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:41:48,513] Trial 99 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 44, 'learning_rate': 0.02967313787308324}. Best is trial 4 with value: 0.8311170212765957.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using TPESampler: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}\n",
      "Best accuracy: 0.8311, at trial: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc88040756784854b8910dc02e85a5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:41:48,634] Trial 0 finished with value: 0.788741134751773 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.788741134751773.\n",
      "[I 2025-12-28 19:41:48,766] Trial 1 finished with value: 0.7975177304964538 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.0026587543983272706, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.762378215816119}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:41:48,815] Trial 2 finished with value: 0.7295212765957447 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.00383962929980417, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.5998368910791798}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:41:48,893] Trial 3 finished with value: 0.788918439716312 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.002193048555664369, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9041986740582306}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:41:48,963] Trial 4 finished with value: 0.6957446808510639 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.0017541893487450805, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6293899908000085}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:41:49,041] Trial 5 finished with value: 0.7929964539007093 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.0023426581058204046, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.9474136752138245}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:41:49,100] Trial 6 finished with value: 0.52322695035461 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.0012315571723666018, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9143687545759647}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:41:49,137] Trial 7 finished with value: 0.7805851063829786 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.040215545266902894, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.5993578407670862}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:41:49,218] Trial 8 finished with value: 0.7888297872340425 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.034877126245459314, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9315517129377968}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:41:49,277] Trial 9 finished with value: 0.8015070921985815 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.004470608546778492, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7361074625809747}. Best is trial 9 with value: 0.8015070921985815.\n",
      "[I 2025-12-28 19:41:49,343] Trial 10 finished with value: 0.797340425531915 and parameters: {'max_features': 'sqrt', 'n_estimators': 43, 'learning_rate': 0.009879112890178472, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.5077973998292282}. Best is trial 9 with value: 0.8015070921985815.\n",
      "[I 2025-12-28 19:41:49,493] Trial 11 finished with value: 0.810017730496454 and parameters: {'max_features': 'sqrt', 'n_estimators': 98, 'learning_rate': 0.0057439213796957695, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7592692723198686}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:49,633] Trial 12 finished with value: 0.8099290780141845 and parameters: {'max_features': 'sqrt', 'n_estimators': 95, 'learning_rate': 0.007452376220377403, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.6859059745865284}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:49,795] Trial 13 finished with value: 0.7975177304964538 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.011334227303984852, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.676815533613015}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:49,987] Trial 14 finished with value: 0.801595744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.012486080101915624, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.8441147559750997}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:50,151] Trial 15 finished with value: 0.7889184397163121 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.0852463694895217, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.6858365802969703}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:50,528] Trial 16 finished with value: 0.7972517730496453 and parameters: {'max_features': 'sqrt', 'n_estimators': 89, 'learning_rate': 0.008028836717487805, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.837993597256527}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:50,629] Trial 17 finished with value: 0.7848404255319149 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.018818674226775734, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.5295487890571599}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:50,800] Trial 18 finished with value: 0.810017730496454 and parameters: {'max_features': 'sqrt', 'n_estimators': 94, 'learning_rate': 0.0052234452800069215, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7168133062655662}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:50,849] Trial 19 finished with value: 0.6328014184397163 and parameters: {'max_features': 'sqrt', 'n_estimators': 11, 'learning_rate': 0.005121929484914879, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7533881284358336}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:51,028] Trial 20 finished with value: 0.7931737588652482 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.018989349451529167, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.8572932346769414}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:51,211] Trial 21 finished with value: 0.810017730496454 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.005749656201278859, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.6953241085155935}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:51,366] Trial 22 finished with value: 0.8016843971631206 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.006133035263714935, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7200854705201467}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:51,589] Trial 23 finished with value: 0.784663120567376 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.003626380707135968, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.9906565433791467}. Best is trial 11 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:41:51,750] Trial 24 finished with value: 0.8101063829787234 and parameters: {'max_features': 'sqrt', 'n_estimators': 98, 'learning_rate': 0.0036531236053328267, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.8013780098162571}. Best is trial 24 with value: 0.8101063829787234.\n",
      "[I 2025-12-28 19:41:51,922] Trial 25 finished with value: 0.7676418439716313 and parameters: {'max_features': 'sqrt', 'n_estimators': 96, 'learning_rate': 0.0011167905775588418, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.794720067400805}. Best is trial 24 with value: 0.8101063829787234.\n",
      "[I 2025-12-28 19:41:52,030] Trial 26 finished with value: 0.8311170212765958 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.003029810889904899, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7985914751742912}. Best is trial 26 with value: 0.8311170212765958.\n",
      "[I 2025-12-28 19:41:52,138] Trial 27 finished with value: 0.822695035460993 and parameters: {'max_features': 'sqrt', 'n_estimators': 68, 'learning_rate': 0.0033138649781134255, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.7822143811182183}. Best is trial 26 with value: 0.8311170212765958.\n",
      "[I 2025-12-28 19:41:52,250] Trial 28 finished with value: 0.7549645390070923 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.001555091246806653, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8033697677550173}. Best is trial 26 with value: 0.8311170212765958.\n",
      "[I 2025-12-28 19:41:52,370] Trial 29 finished with value: 0.7892730496453899 and parameters: {'max_features': None, 'n_estimators': 56, 'learning_rate': 0.0037722559687227188, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8820525278120188}. Best is trial 26 with value: 0.8311170212765958.\n",
      "[I 2025-12-28 19:41:52,481] Trial 30 finished with value: 0.8056737588652482 and parameters: {'max_features': 'log2', 'n_estimators': 68, 'learning_rate': 0.002783225727128141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.794627915045579}. Best is trial 26 with value: 0.8311170212765958.\n",
      "[I 2025-12-28 19:41:52,600] Trial 31 finished with value: 0.8312056737588651 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.0031766373787891163, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7774219392909123}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:52,711] Trial 32 finished with value: 0.8141843971631205 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.003072028243683875, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.8082455970727049}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:52,822] Trial 33 finished with value: 0.8310283687943263 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.002937271180323077, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.7857169184260695}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:52,935] Trial 34 finished with value: 0.7338652482269504 and parameters: {'max_features': None, 'n_estimators': 61, 'learning_rate': 0.001642470279951591, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.7747820126914404}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,023] Trial 35 finished with value: 0.7718085106382978 and parameters: {'max_features': 'sqrt', 'n_estimators': 50, 'learning_rate': 0.0023145118339246407, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.8311969023798921}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,132] Trial 36 finished with value: 0.7844858156028369 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.0019048645573406316, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8705117921498238}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,252] Trial 37 finished with value: 0.7339539007092197 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.0013724463116101824, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.7738993837545108}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,362] Trial 38 finished with value: 0.814095744680851 and parameters: {'max_features': 'log2', 'n_estimators': 80, 'learning_rate': 0.0028948446752593967, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.6292059316299597}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,451] Trial 39 finished with value: 0.624290780141844 and parameters: {'max_features': 'sqrt', 'n_estimators': 60, 'learning_rate': 0.0010254562839234968, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.8877323639787018}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,549] Trial 40 finished with value: 0.7971631205673759 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.00223593532828918, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.7307230964571557}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,669] Trial 41 finished with value: 0.822695035460993 and parameters: {'max_features': 'sqrt', 'n_estimators': 78, 'learning_rate': 0.00311075347578454, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8183663340071613}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,788] Trial 42 finished with value: 0.8228723404255319 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.0045419843928161795, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8236391927928678}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:53,928] Trial 43 finished with value: 0.810017730496454 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.004290748272823158, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.7773233829052376}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,027] Trial 44 finished with value: 0.7844858156028369 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.002047070040413673, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.7462154906520283}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,178] Trial 45 finished with value: 0.7849290780141843 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.006940235338009642, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.855666312258134}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,259] Trial 46 finished with value: 0.8098404255319149 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.004536871324513378, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10, 'subsample': 0.9119581278260335}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,355] Trial 47 finished with value: 0.8184397163120567 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.002626214546419166, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.7083660714587177}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,425] Trial 48 finished with value: 0.7929964539007093 and parameters: {'max_features': 'sqrt', 'n_estimators': 40, 'learning_rate': 0.009024184638385236, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.8201847711757244}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,512] Trial 49 finished with value: 0.8098404255319147 and parameters: {'max_features': 'sqrt', 'n_estimators': 56, 'learning_rate': 0.003382337416910836, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.7787147975203743}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,632] Trial 50 finished with value: 0.8184397163120567 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.004361893224794207, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.667124604621604}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,751] Trial 51 finished with value: 0.8056737588652483 and parameters: {'max_features': 'sqrt', 'n_estimators': 78, 'learning_rate': 0.0025238304658055646, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8184556451798713}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,863] Trial 52 finished with value: 0.8184397163120568 and parameters: {'max_features': 'sqrt', 'n_estimators': 73, 'learning_rate': 0.003273102294638807, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.8325338902447958}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:54,983] Trial 53 finished with value: 0.788741134751773 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.0018551320160783483, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.7568185926614055}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:55,093] Trial 54 finished with value: 0.763386524822695 and parameters: {'max_features': 'sqrt', 'n_estimators': 76, 'learning_rate': 0.0014065192670290186, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8555042006370881}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:55,202] Trial 55 finished with value: 0.8142730496453903 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.004966085194398547, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.7389928657682999}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:55,321] Trial 56 finished with value: 0.810017730496454 and parameters: {'max_features': 'sqrt', 'n_estimators': 89, 'learning_rate': 0.006373400870829545, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7814645673071606}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:55,420] Trial 57 finished with value: 0.8098404255319147 and parameters: {'max_features': 'sqrt', 'n_estimators': 63, 'learning_rate': 0.002888476404339962, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.8192726329113791}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:55,529] Trial 58 finished with value: 0.801595744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 73, 'learning_rate': 0.01419006346152466, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.7605693856312317}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:55,649] Trial 59 finished with value: 0.7931737588652482 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.004027195885310274, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.9384741066763407}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:55,781] Trial 60 finished with value: 0.7975177304964539 and parameters: {'max_features': None, 'n_estimators': 88, 'learning_rate': 0.002233225122127672, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.8418648398079169}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:55,891] Trial 61 finished with value: 0.8268617021276595 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.0033932183469045723, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.8248411050413912}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,010] Trial 62 finished with value: 0.8312056737588651 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.003615792070004177, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.7932109499406075}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,140] Trial 63 finished with value: 0.8141843971631205 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.005368853058858619, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7978981009290143}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,260] Trial 64 finished with value: 0.7844858156028369 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.0879862938600457, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8714221405957865}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,400] Trial 65 finished with value: 0.8142730496453903 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.0038214497763170182, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.7884350651578226}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,511] Trial 66 finished with value: 0.8057624113475178 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.061837204675819483, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7609363198730732}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,631] Trial 67 finished with value: 0.8059397163120569 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.00770925181784956, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7286711020440231}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,740] Trial 68 finished with value: 0.8310283687943263 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.0025588605236329188, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.8043101073628698}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,870] Trial 69 finished with value: 0.8098404255319147 and parameters: {'max_features': 'sqrt', 'n_estimators': 94, 'learning_rate': 0.002539763288326749, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.8120831671494495}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:56,989] Trial 70 finished with value: 0.8099290780141845 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.0017975187616836134, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.8963374167322086}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,120] Trial 71 finished with value: 0.8184397163120568 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.003216891834104784, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.83485628575305}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,219] Trial 72 finished with value: 0.7932624113475176 and parameters: {'max_features': 'sqrt', 'n_estimators': 76, 'learning_rate': 0.0047924693569654, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.7935847013828263}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,317] Trial 73 finished with value: 0.82677304964539 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.003847237104327214, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.5582786511961941}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,428] Trial 74 finished with value: 0.8099290780141845 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.003931419171424159, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.6593083294197704}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,518] Trial 75 finished with value: 0.8141843971631205 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.002500638605396971, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 9, 'subsample': 0.5812420008922072}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,638] Trial 76 finished with value: 0.801418439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 87, 'learning_rate': 0.00356150679255086, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.7676798300782298}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,802] Trial 77 finished with value: 0.7849290780141844 and parameters: {'max_features': None, 'n_estimators': 91, 'learning_rate': 0.0020198515887057383, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.8460101197124791}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,850] Trial 78 finished with value: 0.7676418439716312 and parameters: {'max_features': 'log2', 'n_estimators': 26, 'learning_rate': 0.005532807738587144, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.5499475745876025}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,959] Trial 79 finished with value: 0.8015070921985815 and parameters: {'max_features': 'sqrt', 'n_estimators': 70, 'learning_rate': 0.0027442266322631513, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.8687876877091983}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:57,996] Trial 80 finished with value: 0.6875886524822694 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.0064836170972903, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7500524506232632}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,105] Trial 81 finished with value: 0.8099290780141845 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.0029509067172661667, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8068372295133656}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,236] Trial 82 finished with value: 0.8184397163120568 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.003502957358877266, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8273765544739883}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,335] Trial 83 finished with value: 0.8184397163120568 and parameters: {'max_features': 'sqrt', 'n_estimators': 62, 'learning_rate': 0.004215907407249325, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7805970073628006}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,445] Trial 84 finished with value: 0.7970744680851064 and parameters: {'max_features': 'sqrt', 'n_estimators': 58, 'learning_rate': 0.0022900914544315585, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.7088892558998846}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,555] Trial 85 finished with value: 0.8183510638297872 and parameters: {'max_features': 'sqrt', 'n_estimators': 78, 'learning_rate': 0.0031357008956538236, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.807363377101235}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,645] Trial 86 finished with value: 0.763386524822695 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.0015367439882395674, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.7905292138718599}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,753] Trial 87 finished with value: 0.8057624113475178 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.004672303558606162, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7721448279506606}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,865] Trial 88 finished with value: 0.8099290780141845 and parameters: {'max_features': 'sqrt', 'n_estimators': 93, 'learning_rate': 0.0020653149124330375, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.5148084917146959}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:58,985] Trial 89 finished with value: 0.822695035460993 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.00347216916535301, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.7483693815888826}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:59,129] Trial 90 finished with value: 0.7933510638297873 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.002685000625924291, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8525076565673748}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:59,251] Trial 91 finished with value: 0.8268617021276595 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.0030360510393520578, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8207854905098814}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:59,381] Trial 92 finished with value: 0.8099290780141845 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.0024405379404035714, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8266399151240222}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:59,491] Trial 93 finished with value: 0.8311170212765958 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.004138617348962102, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.800609085359539}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:59,602] Trial 94 finished with value: 0.8311170212765958 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.003993692646189386, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.8038919375785775}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:59,715] Trial 95 finished with value: 0.8226063829787235 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.003992401200484707, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7999184617123769}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:59,836] Trial 96 finished with value: 0.7974290780141844 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.02888665104441038, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.8114343423898674}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:41:59,977] Trial 97 finished with value: 0.8270390070921986 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.0029201370231885086, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.7900152610386063}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:42:00,109] Trial 98 finished with value: 0.8099290780141842 and parameters: {'max_features': 'log2', 'n_estimators': 73, 'learning_rate': 0.002894298695954807, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7906857801161071}. Best is trial 31 with value: 0.8312056737588651.\n",
      "[I 2025-12-28 19:42:00,220] Trial 99 finished with value: 0.8014184397163122 and parameters: {'max_features': 'log2', 'n_estimators': 70, 'learning_rate': 0.0020902222096604926, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.7670704967034385}. Best is trial 31 with value: 0.8312056737588651.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using TPESampler: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.0031766373787891163, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7774219392909123}\n",
      "Best accuracy: 0.8312, at trial: 31\n",
      "TPE Base Models Training Time: 49.63 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    tpe_base_models_training_start = time.time()\n",
    "\n",
    "    # TPE Hyperparameter Tuning with Cross Validation\n",
    "    tpe_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    tpe_logistic_regression.fit(X_train, y_train)\n",
    "    tpe_decision_tree.fit(X_train, y_train)\n",
    "    tpe_random_forest.fit(X_train, y_train)\n",
    "    tpe_knn.fit(X_train, y_train)\n",
    "    tpe_svc.fit(X_train, y_train)\n",
    "    tpe_adaboost.fit(X_train, y_train)\n",
    "    tpe_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    tpe_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for TPE base models training\n",
    "    tpe_base_models_training_time = tpe_base_models_training_end - tpe_base_models_training_start\n",
    "    print(f'TPE Base Models Training Time: {tpe_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping TPE base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:42:00,508] A new study created in memory with name: Logistic Regression Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a71922ddfc54d72a4eb94eee1011fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:42:00,550] Trial 0 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:42:00,586] Trial 1 finished with value: 0.8313829787234042 and parameters: {'solver': 'newton-cholesky', 'C': 0.3470266988650412}. Best is trial 1 with value: 0.8313829787234042.\n",
      "[I 2025-12-28 19:42:00,623] Trial 2 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0008111941985431928}. Best is trial 1 with value: 0.8313829787234042.\n",
      "[I 2025-12-28 19:42:00,662] Trial 3 finished with value: 0.8015070921985815 and parameters: {'solver': 'newton-cholesky', 'C': 0.0028585493941961923}. Best is trial 1 with value: 0.8313829787234042.\n",
      "[I 2025-12-28 19:42:00,698] Trial 4 finished with value: 0.839627659574468 and parameters: {'solver': 'lbfgs', 'C': 0.019069966103000432}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:42:00,735] Trial 5 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00017070728830306665}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:42:00,772] Trial 6 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 6.732248920775331}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:42:00,808] Trial 7 finished with value: 0.835372340425532 and parameters: {'solver': 'lbfgs', 'C': 0.015876781526923997}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:42:00,844] Trial 8 finished with value: 0.7340425531914894 and parameters: {'solver': 'sag', 'C': 0.0019674328025306126}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:42:00,881] Trial 9 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.0008399864445957502}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:42:04,907] Trial 10 finished with value: 0.8354609929078014 and parameters: {'solver': 'newton-cholesky', 'C': 0.025697362618501956}. Best is trial 4 with value: 0.839627659574468.\n",
      "[I 2025-12-28 19:42:06,993] Trial 11 finished with value: 0.8397163120567376 and parameters: {'solver': 'sag', 'C': 0.1163811905199968}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:09,088] Trial 12 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.2959164819035333}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:10,977] Trial 13 finished with value: 0.81427304964539 and parameters: {'solver': 'newton-cg', 'C': 1.7970570815702642}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:11,091] Trial 14 finished with value: 0.839627659574468 and parameters: {'solver': 'sag', 'C': 0.022447811804778308}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:11,204] Trial 15 finished with value: 0.8226063829787235 and parameters: {'solver': 'newton-cholesky', 'C': 9.999999999999993}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:11,331] Trial 16 finished with value: 0.8226063829787235 and parameters: {'solver': 'lbfgs', 'C': 9.999999999999975}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:11,470] Trial 17 finished with value: 0.8356382978723405 and parameters: {'solver': 'lbfgs', 'C': 0.05282130571352251}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:11,617] Trial 18 finished with value: 0.8143617021276596 and parameters: {'solver': 'sag', 'C': 0.7556584128036078}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:11,756] Trial 19 finished with value: 0.8226063829787235 and parameters: {'solver': 'newton-cg', 'C': 9.999999999999993}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:11,892] Trial 20 finished with value: 0.8310283687943262 and parameters: {'solver': 'newton-cholesky', 'C': 0.009990183372376366}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:12,024] Trial 21 finished with value: 0.81427304964539 and parameters: {'solver': 'lbfgs', 'C': 1.755805430410138}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:12,160] Trial 22 finished with value: 0.8271276595744681 and parameters: {'solver': 'sag', 'C': 0.04921720214986952}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:12,307] Trial 23 finished with value: 0.8313829787234042 and parameters: {'solver': 'newton-cg', 'C': 0.18456570239198883}. Best is trial 11 with value: 0.8397163120567376.\n",
      "[I 2025-12-28 19:42:12,448] Trial 24 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10971272926314876}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:12,584] Trial 25 finished with value: 0.8310283687943262 and parameters: {'solver': 'sag', 'C': 0.011648425461085864}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:12,722] Trial 26 finished with value: 0.8313829787234042 and parameters: {'solver': 'sag', 'C': 0.2181540011225414}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:12,849] Trial 27 finished with value: 0.8271276595744681 and parameters: {'solver': 'newton-cg', 'C': 0.05046797316327007}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:12,998] Trial 28 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08090789514947372}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:13,143] Trial 29 finished with value: 0.81427304964539 and parameters: {'solver': 'newton-cholesky', 'C': 2.304237471575022}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:13,308] Trial 30 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cholesky', 'C': 0.12375935846424825}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:13,453] Trial 31 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.027775829199234183}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:13,590] Trial 32 finished with value: 0.8355496453900709 and parameters: {'solver': 'newton-cholesky', 'C': 0.06574425332967197}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:13,770] Trial 33 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.12544389057723937}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:13,922] Trial 34 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cholesky', 'C': 0.1478032516068963}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:14,085] Trial 35 finished with value: 0.8144503546099291 and parameters: {'solver': 'newton-cg', 'C': 0.4772615039946587}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:14,228] Trial 36 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.10008654672175231}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:14,390] Trial 37 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.10013180294903816}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:14,557] Trial 38 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.09935593533274602}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:14,701] Trial 39 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.09874779406048208}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:14,866] Trial 40 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.09850923979818486}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:15,026] Trial 41 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.09949830978281679}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:15,233] Trial 42 finished with value: 0.8182624113475176 and parameters: {'solver': 'sag', 'C': 0.005079035381987818}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:15,450] Trial 43 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.09125591644103541}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:15,624] Trial 44 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.09457170513610857}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:15,820] Trial 45 finished with value: 0.839627659574468 and parameters: {'solver': 'newton-cg', 'C': 0.01895226189218878}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:15,995] Trial 46 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.07725177760408397}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:16,193] Trial 47 finished with value: 0.839627659574468 and parameters: {'solver': 'newton-cholesky', 'C': 0.01762894839630887}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:16,403] Trial 48 finished with value: 0.8313829787234042 and parameters: {'solver': 'newton-cholesky', 'C': 0.20730105296038964}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:16,596] Trial 49 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10358978241420634}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:16,807] Trial 50 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.0830980870910909}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:17,113] Trial 51 finished with value: 0.81427304964539 and parameters: {'solver': 'newton-cg', 'C': 3.891461110975679}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:17,352] Trial 52 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08225998718773651}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:17,548] Trial 53 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08255091822145581}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:17,753] Trial 54 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08588572083816637}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:17,973] Trial 55 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.1027325592423173}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:18,240] Trial 56 finished with value: 0.8182624113475179 and parameters: {'solver': 'newton-cg', 'C': 0.007631662394477799}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:18,527] Trial 57 finished with value: 0.8185283687943261 and parameters: {'solver': 'newton-cholesky', 'C': 1.1553619016153902}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:18,784] Trial 58 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08863074017984264}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:19,077] Trial 59 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10572312006751632}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:19,404] Trial 60 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.09020001722573576}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:19,696] Trial 61 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.0857910913936491}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:20,038] Trial 62 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.0977004393813173}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:20,224] Trial 63 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.1681394947344599}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:20,595] Trial 64 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.07987478570801686}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:20,886] Trial 65 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10586692415615877}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:21,075] Trial 66 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08361807332451009}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:21,358] Trial 67 finished with value: 0.839627659574468 and parameters: {'solver': 'sag', 'C': 0.01809386668283683}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:21,640] Trial 68 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10592931748492783}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:22,146] Trial 69 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.09431933026992742}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:22,380] Trial 70 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08517517806333043}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:22,667] Trial 71 finished with value: 0.8271276595744681 and parameters: {'solver': 'sag', 'C': 0.36521625780176553}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:23,165] Trial 72 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10597421082607858}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:23,609] Trial 73 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08352502698524703}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:24,169] Trial 74 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.07963970139516437}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:24,601] Trial 75 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08566435375535426}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:25,103] Trial 76 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.09931673009998908}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:25,520] Trial 77 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10607005597900891}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:26,002] Trial 78 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.0901823012226533}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:26,595] Trial 79 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08353605089948204}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:27,092] Trial 80 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10614326849254467}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:27,639] Trial 81 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.0794664891553643}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:28,046] Trial 82 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.09571107576549541}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:28,548] Trial 83 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.0948353954823465}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:28,987] Trial 84 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08486027816822812}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:29,426] Trial 85 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08583780297745912}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:29,798] Trial 86 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.10625553906579863}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:30,179] Trial 87 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.07988327360421747}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:30,653] Trial 88 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08194861492617288}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:31,064] Trial 89 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.0791144048057077}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:31,557] Trial 90 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08127437181707252}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:31,941] Trial 91 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08782969930603773}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:32,430] Trial 92 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.0947055576054154}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:32,804] Trial 93 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.09172102489379538}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:33,142] Trial 94 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08138358219840991}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:33,569] Trial 95 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.09181601390297223}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:33,944] Trial 96 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.10030645228369982}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:34,396] Trial 97 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08188734747823395}. Best is trial 24 with value: 0.8439716312056736.\n",
      "[I 2025-12-28 19:42:34,865] Trial 98 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08335785934461451}. Best is trial 24 with value: 0.8439716312056736.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:42:35,212] A new study created in memory with name: Decision Tree Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:42:35,210] Trial 99 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.09166428253837378}. Best is trial 24 with value: 0.8439716312056736.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using GPSampler: {'solver': 'newton-cholesky', 'C': 0.10971272926314876}\n",
      "Best accuracy: 0.8440, at trial: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18269e5053b43f2817834595f0adb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:42:35,236] Trial 0 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,263] Trial 1 finished with value: 0.7296099290780143 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,280] Trial 2 finished with value: 0.7087765957446808 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,298] Trial 3 finished with value: 0.725886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,314] Trial 4 finished with value: 0.7469858156028369 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,331] Trial 5 finished with value: 0.7257092198581561 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,347] Trial 6 finished with value: 0.7383865248226951 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,363] Trial 7 finished with value: 0.7044326241134753 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,380] Trial 8 finished with value: 0.7467198581560284 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,396] Trial 9 finished with value: 0.713209219858156 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,484] Trial 10 finished with value: 0.7382978723404255 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,563] Trial 11 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,662] Trial 12 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,757] Trial 13 finished with value: 0.7297872340425531 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,854] Trial 14 finished with value: 0.7296099290780143 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:35,938] Trial 15 finished with value: 0.7680851063829788 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:36,020] Trial 16 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:36,097] Trial 17 finished with value: 0.7766843971631205 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:36,178] Trial 18 finished with value: 0.7766843971631205 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:36,251] Trial 19 finished with value: 0.7725177304964539 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[I 2025-12-28 19:42:36,342] Trial 20 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:36,418] Trial 21 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:36,503] Trial 22 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:36,581] Trial 23 finished with value: 0.7766843971631205 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:36,664] Trial 24 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:36,743] Trial 25 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:36,829] Trial 26 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:36,908] Trial 27 finished with value: 0.7725177304964539 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:36,986] Trial 28 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,062] Trial 29 finished with value: 0.763918439716312 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,143] Trial 30 finished with value: 0.7085992907801418 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,223] Trial 31 finished with value: 0.7722517730496454 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,305] Trial 32 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,388] Trial 33 finished with value: 0.7297872340425531 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,470] Trial 34 finished with value: 0.7214539007092198 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,544] Trial 35 finished with value: 0.7722517730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,636] Trial 36 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,725] Trial 37 finished with value: 0.7597517730496455 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,817] Trial 38 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,908] Trial 39 finished with value: 0.7805851063829786 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:37,994] Trial 40 finished with value: 0.7722517730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,072] Trial 41 finished with value: 0.7683510638297871 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,160] Trial 42 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,258] Trial 43 finished with value: 0.700531914893617 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,341] Trial 44 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,436] Trial 45 finished with value: 0.7675531914893616 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,517] Trial 46 finished with value: 0.7500886524822695 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,600] Trial 47 finished with value: 0.7427304964539008 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,688] Trial 48 finished with value: 0.7805851063829786 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,772] Trial 49 finished with value: 0.7468971631205674 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,851] Trial 50 finished with value: 0.7045212765957447 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:38,947] Trial 51 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,051] Trial 52 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,129] Trial 53 finished with value: 0.7085992907801418 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,244] Trial 54 finished with value: 0.7554964539007092 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,327] Trial 55 finished with value: 0.7425531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,424] Trial 56 finished with value: 0.750709219858156 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,509] Trial 57 finished with value: 0.7598404255319149 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,607] Trial 58 finished with value: 0.7722517730496454 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,688] Trial 59 finished with value: 0.7805851063829786 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,804] Trial 60 finished with value: 0.750709219858156 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,886] Trial 61 finished with value: 0.7675531914893616 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:39,995] Trial 62 finished with value: 0.750709219858156 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,081] Trial 63 finished with value: 0.7679964539007094 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,194] Trial 64 finished with value: 0.7382978723404255 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,277] Trial 65 finished with value: 0.763918439716312 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,389] Trial 66 finished with value: 0.7762411347517731 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,473] Trial 67 finished with value: 0.7550531914893617 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,584] Trial 68 finished with value: 0.7553191489361702 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,667] Trial 69 finished with value: 0.7171099290780141 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,779] Trial 70 finished with value: 0.7550531914893617 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,864] Trial 71 finished with value: 0.7597517730496455 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:40,984] Trial 72 finished with value: 0.7425531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,077] Trial 73 finished with value: 0.7469858156028369 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,197] Trial 74 finished with value: 0.7469858156028369 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,286] Trial 75 finished with value: 0.7675531914893616 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,396] Trial 76 finished with value: 0.7675531914893616 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,483] Trial 77 finished with value: 0.7766843971631205 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,600] Trial 78 finished with value: 0.750709219858156 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,700] Trial 79 finished with value: 0.7382978723404255 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,833] Trial 80 finished with value: 0.763918439716312 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:41,919] Trial 81 finished with value: 0.7598404255319149 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:42,034] Trial 82 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:42,144] Trial 83 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:42,268] Trial 84 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:42,412] Trial 85 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:42,540] Trial 86 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:42,681] Trial 87 finished with value: 0.7511524822695035 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:42,815] Trial 88 finished with value: 0.7597517730496455 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:42,939] Trial 89 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:43,061] Trial 90 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:43,180] Trial 91 finished with value: 0.7764184397163121 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:43,331] Trial 92 finished with value: 0.7764184397163121 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:43,466] Trial 93 finished with value: 0.7851950354609929 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:43,601] Trial 94 finished with value: 0.7766843971631205 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:43,754] Trial 95 finished with value: 0.763918439716312 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:43,883] Trial 96 finished with value: 0.7255319148936169 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:44,025] Trial 97 finished with value: 0.7635638297872339 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.7851950354609929.\n",
      "[I 2025-12-28 19:42:44,158] Trial 98 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:42:44,303] A new study created in memory with name: Random Forest Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:42:44,300] Trial 99 finished with value: 0.7725177304964539 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.7851950354609929.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using GPSampler: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
      "Best accuracy: 0.7852, at trial: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df655fedf0894d188acab87b19a64214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:42:44,391] Trial 0 finished with value: 0.7849290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7849290780141844.\n",
      "[I 2025-12-28 19:42:44,511] Trial 1 finished with value: 0.797340425531915 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.797340425531915.\n",
      "[I 2025-12-28 19:42:44,602] Trial 2 finished with value: 0.7762411347517729 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.797340425531915.\n",
      "[I 2025-12-28 19:42:44,721] Trial 3 finished with value: 0.8016843971631206 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8016843971631206.\n",
      "[I 2025-12-28 19:42:44,820] Trial 4 finished with value: 0.7930851063829787 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8016843971631206.\n",
      "[I 2025-12-28 19:42:44,888] Trial 5 finished with value: 0.788918439716312 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8016843971631206.\n",
      "[I 2025-12-28 19:42:44,968] Trial 6 finished with value: 0.7847517730496454 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 22, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8016843971631206.\n",
      "[I 2025-12-28 19:42:45,117] Trial 7 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:45,268] Trial 8 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:45,399] Trial 9 finished with value: 0.801595744680851 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:45,805] Trial 10 finished with value: 0.8057624113475177 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 87, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:46,181] Trial 11 finished with value: 0.8058510638297871 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 94, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:46,540] Trial 12 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:46,948] Trial 13 finished with value: 0.810017730496454 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:47,347] Trial 14 finished with value: 0.8059397163120569 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 84, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:47,750] Trial 15 finished with value: 0.8059397163120569 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 88, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:48,105] Trial 16 finished with value: 0.8015070921985815 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:48,497] Trial 17 finished with value: 0.788918439716312 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:42:48,868] Trial 18 finished with value: 0.8228723404255319 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:42:49,219] Trial 19 finished with value: 0.7804964539007093 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 18 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:42:49,572] Trial 20 finished with value: 0.8144503546099291 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 91, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:42:49,948] Trial 21 finished with value: 0.8186170212765956 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 91, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:42:50,306] Trial 22 finished with value: 0.8144503546099291 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 74, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:42:50,678] Trial 23 finished with value: 0.8228723404255319 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:42:51,030] Trial 24 finished with value: 0.8016843971631206 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.8228723404255319.\n",
      "[I 2025-12-28 19:42:51,400] Trial 25 finished with value: 0.826950354609929 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:51,802] Trial 26 finished with value: 0.7931737588652482 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:52,188] Trial 27 finished with value: 0.8016843971631206 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:52,605] Trial 28 finished with value: 0.8186170212765956 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:52,968] Trial 29 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:53,337] Trial 30 finished with value: 0.8016843971631206 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:53,566] Trial 31 finished with value: 0.7674645390070921 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:53,970] Trial 32 finished with value: 0.7931737588652481 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:54,394] Trial 33 finished with value: 0.8015070921985815 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:54,829] Trial 34 finished with value: 0.7931737588652481 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:55,206] Trial 35 finished with value: 0.7890070921985816 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:55,500] Trial 36 finished with value: 0.8101063829787234 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:55,793] Trial 37 finished with value: 0.8058510638297871 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 49, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:56,073] Trial 38 finished with value: 0.8101063829787234 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:56,364] Trial 39 finished with value: 0.7975177304964538 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:56,579] Trial 40 finished with value: 0.7634751773049645 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:56,903] Trial 41 finished with value: 0.7934397163120567 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 47, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:57,223] Trial 42 finished with value: 0.8101063829787234 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:57,636] Trial 43 finished with value: 0.7933510638297872 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:58,052] Trial 44 finished with value: 0.8145390070921987 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 73, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:58,411] Trial 45 finished with value: 0.8101063829787234 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 67, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.826950354609929.\n",
      "[I 2025-12-28 19:42:58,836] Trial 46 finished with value: 0.8312056737588653 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:42:59,171] Trial 47 finished with value: 0.8270390070921986 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:42:59,551] Trial 48 finished with value: 0.8144503546099291 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:42:59,894] Trial 49 finished with value: 0.8144503546099291 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 77, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:00,218] Trial 50 finished with value: 0.8059397163120566 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 77, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:00,547] Trial 51 finished with value: 0.7804964539007092 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:00,912] Trial 52 finished with value: 0.8016843971631206 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 78, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:01,246] Trial 53 finished with value: 0.7974290780141843 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:01,612] Trial 54 finished with value: 0.7720744680851064 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:01,908] Trial 55 finished with value: 0.810017730496454 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:02,278] Trial 56 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:02,640] Trial 57 finished with value: 0.789095744680851 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 40, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:03,026] Trial 58 finished with value: 0.8015070921985815 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 73, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:03,417] Trial 59 finished with value: 0.7890070921985816 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:03,742] Trial 60 finished with value: 0.8101063829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:04,015] Trial 61 finished with value: 0.8059397163120569 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 44, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:04,354] Trial 62 finished with value: 0.7807624113475178 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 55, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:04,710] Trial 63 finished with value: 0.81427304964539 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:04,999] Trial 64 finished with value: 0.8099290780141845 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:05,331] Trial 65 finished with value: 0.8017730496453901 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 74, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:05,621] Trial 66 finished with value: 0.7932624113475176 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:05,962] Trial 67 finished with value: 0.8017730496453901 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 42, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:06,319] Trial 68 finished with value: 0.797340425531915 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:06,533] Trial 69 finished with value: 0.7592198581560282 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:06,863] Trial 70 finished with value: 0.81427304964539 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:07,156] Trial 71 finished with value: 0.7931737588652481 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:07,429] Trial 72 finished with value: 0.7974290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:07,732] Trial 73 finished with value: 0.81427304964539 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:08,068] Trial 74 finished with value: 0.8016843971631207 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:08,356] Trial 75 finished with value: 0.8057624113475178 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 55, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:08,666] Trial 76 finished with value: 0.7848404255319149 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:08,954] Trial 77 finished with value: 0.7933510638297872 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:09,313] Trial 78 finished with value: 0.7974290780141843 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:09,598] Trial 79 finished with value: 0.801595744680851 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:09,984] Trial 80 finished with value: 0.8101950354609929 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 80, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:10,221] Trial 81 finished with value: 0.7759751773049646 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:10,494] Trial 82 finished with value: 0.8186170212765956 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:10,785] Trial 83 finished with value: 0.8101063829787234 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:11,078] Trial 84 finished with value: 0.8187056737588652 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 47, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:11,453] Trial 85 finished with value: 0.8101063829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:11,768] Trial 86 finished with value: 0.8101063829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:12,111] Trial 87 finished with value: 0.8186170212765956 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 47, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:12,551] Trial 88 finished with value: 0.7849290780141844 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:12,931] Trial 89 finished with value: 0.8015070921985815 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:13,232] Trial 90 finished with value: 0.8229609929078014 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:13,524] Trial 91 finished with value: 0.8143617021276596 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 39, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:13,860] Trial 92 finished with value: 0.8101063829787233 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 42, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:14,187] Trial 93 finished with value: 0.7930851063829787 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:14,544] Trial 94 finished with value: 0.8101063829787233 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 59, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:14,912] Trial 95 finished with value: 0.810017730496454 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:15,256] Trial 96 finished with value: 0.8101063829787233 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:15,511] Trial 97 finished with value: 0.7929964539007093 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n",
      "[I 2025-12-28 19:43:15,965] Trial 98 finished with value: 0.8101063829787234 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.8312056737588653.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:43:16,312] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:43:16,309] Trial 99 finished with value: 0.7890070921985816 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 46 with value: 0.8312056737588653.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using GPSampler: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}\n",
      "Best accuracy: 0.8312, at trial: 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd35e308b5624232992fd7109ff7c2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:43:16,370] Trial 0 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:43:16,399] Trial 1 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:43:16,448] Trial 2 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:43:16,477] Trial 3 finished with value: 0.8356382978723402 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:43:16,513] Trial 4 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:43:16,551] Trial 5 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:43:16,601] Trial 6 finished with value: 0.835372340425532 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:43:16,636] Trial 7 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[I 2025-12-28 19:43:16,673] Trial 8 finished with value: 0.8437056737588653 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:43:16,711] Trial 9 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:43:16,884] Trial 10 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 1}. Best is trial 8 with value: 0.8437056737588653.\n",
      "[I 2025-12-28 19:43:17,023] Trial 11 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:17,173] Trial 12 finished with value: 0.8270390070921987 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:17,346] Trial 13 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:17,526] Trial 14 finished with value: 0.835372340425532 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:17,684] Trial 15 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:17,848] Trial 16 finished with value: 0.7972517730496453 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:17,991] Trial 17 finished with value: 0.8314716312056737 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 22, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:18,133] Trial 18 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:18,269] Trial 19 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:18,417] Trial 20 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:18,540] Trial 21 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'brute', 'n_neighbors': 16, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:18,674] Trial 22 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:18,847] Trial 23 finished with value: 0.8314716312056738 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 24, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:18,977] Trial 24 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:19,127] Trial 25 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:19,243] Trial 26 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:19,391] Trial 27 finished with value: 0.8312943262411349 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:19,522] Trial 28 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:19,621] Trial 29 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:19,759] Trial 30 finished with value: 0.8437056737588653 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:19,913] Trial 31 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:20,047] Trial 32 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:20,226] Trial 33 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 11, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:20,350] Trial 34 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:20,484] Trial 35 finished with value: 0.8312056737588653 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:20,643] Trial 36 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:20,795] Trial 37 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 18, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:20,958] Trial 38 finished with value: 0.8312056737588653 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:21,101] Trial 39 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:21,288] Trial 40 finished with value: 0.8312943262411349 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:21,466] Trial 41 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:21,611] Trial 42 finished with value: 0.8312943262411346 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:21,781] Trial 43 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:21,938] Trial 44 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 27, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:22,104] Trial 45 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:22,268] Trial 46 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:22,398] Trial 47 finished with value: 0.8437056737588653 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 1}. Best is trial 11 with value: 0.8437943262411348.\n",
      "[I 2025-12-28 19:43:22,540] Trial 48 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:22,704] Trial 49 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:22,867] Trial 50 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:23,023] Trial 51 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:23,202] Trial 52 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 7, 'p': 1}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:23,357] Trial 53 finished with value: 0.8312056737588651 and parameters: {'algorithm': 'brute', 'n_neighbors': 8, 'p': 2}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:23,528] Trial 54 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:23,662] Trial 55 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'brute', 'n_neighbors': 21, 'p': 1}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:23,820] Trial 56 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 48 with value: 0.8440602836879432.\n",
      "[I 2025-12-28 19:43:24,067] Trial 57 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:24,215] Trial 58 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:24,344] Trial 59 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:24,515] Trial 60 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:24,658] Trial 61 finished with value: 0.8101063829787234 and parameters: {'algorithm': 'brute', 'n_neighbors': 5, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:24,848] Trial 62 finished with value: 0.839982269503546 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:24,993] Trial 63 finished with value: 0.826950354609929 and parameters: {'algorithm': 'brute', 'n_neighbors': 8, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:25,164] Trial 64 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:25,330] Trial 65 finished with value: 0.8186170212765956 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 7, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:25,488] Trial 66 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:25,638] Trial 67 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 19, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:25,786] Trial 68 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 16, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:25,936] Trial 69 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:26,078] Trial 70 finished with value: 0.8312943262411349 and parameters: {'algorithm': 'brute', 'n_neighbors': 12, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:26,239] Trial 71 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 9, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:26,413] Trial 72 finished with value: 0.835372340425532 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:26,574] Trial 73 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:26,720] Trial 74 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:26,854] Trial 75 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'brute', 'n_neighbors': 21, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:27,008] Trial 76 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:27,141] Trial 77 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:27,292] Trial 78 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:27,438] Trial 79 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:27,589] Trial 80 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:27,754] Trial 81 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:27,904] Trial 82 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:28,045] Trial 83 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:28,190] Trial 84 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:28,345] Trial 85 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:28,530] Trial 86 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:28,673] Trial 87 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:28,811] Trial 88 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'brute', 'n_neighbors': 21, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:28,957] Trial 89 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:29,092] Trial 90 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:29,268] Trial 91 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:29,454] Trial 92 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:29,627] Trial 93 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 14, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:29,794] Trial 94 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:29,953] Trial 95 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:30,097] Trial 96 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 22, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:30,266] Trial 97 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n",
      "[I 2025-12-28 19:43:30,467] Trial 98 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 57 with value: 0.8440602836879434.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:43:30,677] A new study created in memory with name: Support Vector Machine Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:43:30,675] Trial 99 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 57 with value: 0.8440602836879434.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using GPSampler: {'algorithm': 'ball_tree', 'n_neighbors': 22, 'p': 1}\n",
      "Best accuracy: 0.8441, at trial: 57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93f32b38dfb471094a0677c75fd2e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:43:30,714] Trial 0 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,741] Trial 1 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.005399484409787433}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,768] Trial 2 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.008706020878304856}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,796] Trial 3 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00023270677083837802}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,826] Trial 4 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0003823475224675188}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,853] Trial 5 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0005404103854647331}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,881] Trial 6 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0010677482709481358}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,908] Trial 7 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00021930485556643703, 'degree': 2}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,936] Trial 8 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0004066563313514797}. Best is trial 0 with value: 0.52322695035461.\n",
      "[I 2025-12-28 19:43:30,962] Trial 9 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00017541893487450815}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:43:31,050] The parameter `degree` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,075] Trial 10 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 10 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:43:31,218] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,244] Trial 11 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 10 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:43:31,340] The parameter `degree` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,370] Trial 12 finished with value: 0.5570035460992908 and parameters: {'kernel': 'poly', 'C': 0.0032684768594823284, 'degree': 5}. Best is trial 10 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:43:31,419] The parameter `degree` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,448] Trial 13 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 10 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:43:31,485] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,508] Trial 14 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:31,556] The parameter `degree` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,581] Trial 15 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:31,624] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,651] Trial 16 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:31,699] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,725] Trial 17 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:31,767] The parameter `degree` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,782] Trial 18 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:31,830] The parameter `degree` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,855] Trial 19 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:31,898] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,924] Trial 20 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:31,967] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:31,992] Trial 21 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,035] The parameter `degree` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:32,062] Trial 22 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,115] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:32,147] Trial 23 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,196] The parameter `degree` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:32,223] Trial 24 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,277] The parameter `degree` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:32,304] Trial 25 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,366] The parameter `degree` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:32,392] Trial 26 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:32,479] Trial 27 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.01}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:32,550] Trial 28 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00010000000000000009}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,604] The parameter `degree` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:32,630] Trial 29 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,709] The parameter `degree` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:32,734] Trial 30 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00010000000000000009, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,825] The parameter `degree` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:32,851] Trial 31 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0026139520089209006, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:32,932] Trial 32 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00010000000000000009}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:32,992] The parameter `degree` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,017] Trial 33 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,073] The parameter `degree` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,099] Trial 34 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,160] The parameter `degree` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,185] Trial 35 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,239] The parameter `degree` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,265] Trial 36 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,328] The parameter `degree` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,342] Trial 37 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,397] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,414] Trial 38 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:33,490] Trial 39 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.01}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,561] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,588] Trial 40 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,643] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,657] Trial 41 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,734] The parameter `degree` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,760] Trial 42 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,826] The parameter `degree` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,852] Trial 43 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:33,922] The parameter `degree` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:33,949] Trial 44 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,023] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,049] Trial 45 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,125] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,152] Trial 46 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0008117644534618327, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:34,238] Trial 47 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0016874336574758159}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,288] The parameter `degree` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,315] Trial 48 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,365] The parameter `degree` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,390] Trial 49 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,435] The parameter `degree` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,460] Trial 50 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,525] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,550] Trial 51 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:34,637] Trial 52 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.01}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:34,720] Trial 53 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00010000000000000009}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,773] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,799] Trial 54 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,847] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,861] Trial 55 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:34,917] The parameter `degree` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:34,943] Trial 56 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00010000000000000009, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,021] The parameter `degree` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,045] Trial 57 finished with value: 0.5695035460992908 and parameters: {'kernel': 'poly', 'C': 0.004762855726018487, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:35,127] Trial 58 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00010000000000000009}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,190] The parameter `degree` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,216] Trial 59 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,272] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,298] Trial 60 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:35,399] Trial 61 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.01}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,472] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,499] Trial 62 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,577] The parameter `degree` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,602] Trial 63 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,662] The parameter `degree` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,692] Trial 64 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,753] The parameter `degree` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,779] Trial 65 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,839] The parameter `degree` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,866] Trial 66 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:35,930] The parameter `degree` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:35,956] Trial 67 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,030] The parameter `degree` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,057] Trial 68 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,140] The parameter `degree` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,171] Trial 69 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,233] The parameter `degree` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,261] Trial 70 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,336] The parameter `degree` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,363] Trial 71 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,447] The parameter `degree` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,476] Trial 72 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,548] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,573] Trial 73 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,648] The parameter `degree` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,676] Trial 74 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,755] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,784] Trial 75 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:36,892] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:36,919] Trial 76 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:37,015] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:37,042] Trial 77 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:37,170] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:37,197] Trial 78 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.005218224583901275, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:37,319] The parameter `degree` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:37,344] Trial 79 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0004636859025988989, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:37,481] Trial 80 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0010242917843538688}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:37,635] Trial 81 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.003193410182570083}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:37,720] The parameter `degree` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:37,747] Trial 82 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:37,813] The parameter `degree` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:37,839] Trial 83 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:37,906] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:37,933] Trial 84 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:38,003] The parameter `degree` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:38,028] Trial 85 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:38,130] Trial 86 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.01}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:38,198] The parameter `degree` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:38,224] Trial 87 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:38,297] The parameter `degree` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:38,324] Trial 88 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:38,394] The parameter `degree` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:38,420] Trial 89 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[I 2025-12-28 19:43:38,520] Trial 90 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00010000000000000009}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:38,618] The parameter `degree` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:38,643] Trial 91 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00010000000000000009, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:38,736] The parameter `degree` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:38,763] Trial 92 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:38,842] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:38,868] Trial 93 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:38,987] The parameter `degree` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:39,013] Trial 94 finished with value: 0.7129432624113475 and parameters: {'kernel': 'poly', 'C': 0.005737265903265418, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:39,110] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:39,136] Trial 95 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:39,235] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:39,260] Trial 96 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:39,347] The parameter `degree` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:39,374] Trial 97 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:43:39,466] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:39,492] Trial 98 finished with value: 0.7720744680851064 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 14 with value: 0.7762411347517731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:43:39,614] A new study created in memory with name: AdaBoost Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:43:39,585] The parameter `degree` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:43:39,611] Trial 99 finished with value: 0.6159574468085107 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 14 with value: 0.7762411347517731.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using GPSampler: {'kernel': 'poly', 'C': 0.01, 'degree': 4}\n",
      "Best accuracy: 0.7762, at trial: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a545c4ebc7fd4399b0cb44cb1084207b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:43:39,734] Trial 0 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:43:39,910] Trial 1 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 76, 'learning_rate': 0.06251373574521749}. Best is trial 1 with value: 0.8059397163120569.\n",
      "[I 2025-12-28 19:43:39,968] Trial 2 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029375384576328283}. Best is trial 1 with value: 0.8059397163120569.\n",
      "[I 2025-12-28 19:43:40,003] Trial 3 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 15, 'learning_rate': 0.39676050770529875}. Best is trial 1 with value: 0.8059397163120569.\n",
      "[I 2025-12-28 19:43:40,111] Trial 4 finished with value: 0.8311170212765957 and parameters: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:40,159] Trial 5 finished with value: 0.7929964539007092 and parameters: {'n_estimators': 11, 'learning_rate': 0.8123245085588685}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:40,298] Trial 6 finished with value: 0.725531914893617 and parameters: {'n_estimators': 85, 'learning_rate': 0.004335281794951566}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:40,356] Trial 7 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 26, 'learning_rate': 0.0035498788321965025}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:40,423] Trial 8 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 37, 'learning_rate': 0.03752055855124281}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:40,513] Trial 9 finished with value: 0.725531914893617 and parameters: {'n_estimators': 49, 'learning_rate': 0.007476312062252299}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:41,135] Trial 10 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 100, 'learning_rate': 0.26262617952635375}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:41,490] Trial 11 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 53, 'learning_rate': 0.16323916918874673}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:41,796] Trial 12 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 10, 'learning_rate': 0.11961451636972045}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:42,141] Trial 13 finished with value: 0.801418439716312 and parameters: {'n_estimators': 100, 'learning_rate': 1.0}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:42,467] Trial 14 finished with value: 0.801595744680851 and parameters: {'n_estimators': 60, 'learning_rate': 0.21322154243485236}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:42,808] Trial 15 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 100, 'learning_rate': 0.10336929648213487}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:43,152] Trial 16 finished with value: 0.8227836879432624 and parameters: {'n_estimators': 100, 'learning_rate': 0.10533121994695412}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:43,502] Trial 17 finished with value: 0.822695035460993 and parameters: {'n_estimators': 100, 'learning_rate': 0.10588157575680225}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:43,862] Trial 18 finished with value: 0.8227836879432624 and parameters: {'n_estimators': 100, 'learning_rate': 0.08359258529761782}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:44,216] Trial 19 finished with value: 0.8099290780141845 and parameters: {'n_estimators': 100, 'learning_rate': 0.1345490420940566}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:44,552] Trial 20 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 100, 'learning_rate': 0.05775391353319875}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:44,950] Trial 21 finished with value: 0.8056737588652482 and parameters: {'n_estimators': 100, 'learning_rate': 0.1651851476944245}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:45,211] Trial 22 finished with value: 0.7510638297872341 and parameters: {'n_estimators': 10, 'learning_rate': 0.09121783098225819}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:45,461] Trial 23 finished with value: 0.801418439716312 and parameters: {'n_estimators': 64, 'learning_rate': 1.0}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:45,881] Trial 24 finished with value: 0.8183510638297872 and parameters: {'n_estimators': 72, 'learning_rate': 0.21956845176416087}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:46,261] Trial 25 finished with value: 0.8227836879432624 and parameters: {'n_estimators': 72, 'learning_rate': 0.119811051061987}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:46,621] Trial 26 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 72, 'learning_rate': 0.11376780541689088}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:47,047] Trial 27 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 100, 'learning_rate': 0.047105797164525634}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:47,404] Trial 28 finished with value: 0.8141843971631205 and parameters: {'n_estimators': 68, 'learning_rate': 0.2926571330487692}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:47,777] Trial 29 finished with value: 0.8101063829787233 and parameters: {'n_estimators': 72, 'learning_rate': 0.10819593345364764}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:48,202] Trial 30 finished with value: 0.8141843971631205 and parameters: {'n_estimators': 100, 'learning_rate': 0.339249622336703}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:48,587] Trial 31 finished with value: 0.801418439716312 and parameters: {'n_estimators': 100, 'learning_rate': 1.0}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:48,846] Trial 32 finished with value: 0.784663120567376 and parameters: {'n_estimators': 10, 'learning_rate': 1.0}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:49,212] Trial 33 finished with value: 0.81427304964539 and parameters: {'n_estimators': 100, 'learning_rate': 0.19067833968765036}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:49,551] Trial 34 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 61, 'learning_rate': 0.31183699490033034}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:49,942] Trial 35 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 100, 'learning_rate': 0.0010038061494749985}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:50,355] Trial 36 finished with value: 0.8056737588652482 and parameters: {'n_estimators': 100, 'learning_rate': 0.16457850732037757}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:50,825] Trial 37 finished with value: 0.81427304964539 and parameters: {'n_estimators': 71, 'learning_rate': 0.10283706597391473}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:51,254] Trial 38 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 100, 'learning_rate': 0.04580162167645396}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:51,713] Trial 39 finished with value: 0.8101063829787233 and parameters: {'n_estimators': 70, 'learning_rate': 0.10536288962035764}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:52,235] Trial 40 finished with value: 0.8015070921985817 and parameters: {'n_estimators': 100, 'learning_rate': 0.37306068316981206}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:52,573] Trial 41 finished with value: 0.801595744680851 and parameters: {'n_estimators': 49, 'learning_rate': 0.284612974010012}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:52,895] Trial 42 finished with value: 0.8226950354609928 and parameters: {'n_estimators': 100, 'learning_rate': 0.09672812944619501}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:53,258] Trial 43 finished with value: 0.8226950354609928 and parameters: {'n_estimators': 100, 'learning_rate': 0.09636327991637166}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:53,571] Trial 44 finished with value: 0.826950354609929 and parameters: {'n_estimators': 100, 'learning_rate': 0.09560479834090718}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:53,891] Trial 45 finished with value: 0.8226950354609928 and parameters: {'n_estimators': 100, 'learning_rate': 0.09482797985108408}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:54,221] Trial 46 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 100, 'learning_rate': 0.087339928433521}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:54,536] Trial 47 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 100, 'learning_rate': 0.035748362409380764}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:54,838] Trial 48 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 74, 'learning_rate': 0.08183389715255278}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:55,151] Trial 49 finished with value: 0.801418439716312 and parameters: {'n_estimators': 100, 'learning_rate': 1.0}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:55,464] Trial 50 finished with value: 0.8099290780141845 and parameters: {'n_estimators': 100, 'learning_rate': 0.1367212261309633}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:55,738] Trial 51 finished with value: 0.8015070921985815 and parameters: {'n_estimators': 57, 'learning_rate': 1.0}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:56,088] Trial 52 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 100, 'learning_rate': 0.06688105222340003}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:56,513] Trial 53 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 100, 'learning_rate': 0.029560367765679503}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:56,932] Trial 54 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 100, 'learning_rate': 0.029140615332453955}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:57,311] Trial 55 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 100, 'learning_rate': 0.023856243548328503}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:57,626] Trial 56 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 10, 'learning_rate': 0.18307133769657338}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:57,949] Trial 57 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 10, 'learning_rate': 0.02000618116583757}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:58,329] Trial 58 finished with value: 0.8101950354609929 and parameters: {'n_estimators': 74, 'learning_rate': 0.03075155737211156}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:58,563] Trial 59 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 10, 'learning_rate': 0.0010000000000000002}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:58,997] Trial 60 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 100, 'learning_rate': 0.013785931465786492}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:59,422] Trial 61 finished with value: 0.8184397163120567 and parameters: {'n_estimators': 100, 'learning_rate': 0.6328323757862663}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:43:59,785] Trial 62 finished with value: 0.8015070921985815 and parameters: {'n_estimators': 65, 'learning_rate': 0.5064869167781394}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:00,074] Trial 63 finished with value: 0.81427304964539 and parameters: {'n_estimators': 49, 'learning_rate': 0.1376196757028194}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:00,397] Trial 64 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 70, 'learning_rate': 0.14744213313494198}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:00,755] Trial 65 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 100, 'learning_rate': 0.7108073487659531}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:01,007] Trial 66 finished with value: 0.8101950354609929 and parameters: {'n_estimators': 10, 'learning_rate': 0.5364675615369613}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:01,370] Trial 67 finished with value: 0.801595744680851 and parameters: {'n_estimators': 80, 'learning_rate': 0.7328173683464593}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:01,755] Trial 68 finished with value: 0.8184397163120568 and parameters: {'n_estimators': 100, 'learning_rate': 0.5300884678404638}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:02,123] Trial 69 finished with value: 0.8101950354609929 and parameters: {'n_estimators': 100, 'learning_rate': 0.020536992893819765}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:02,471] Trial 70 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 71, 'learning_rate': 0.04101150749001438}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:02,897] Trial 71 finished with value: 0.8226950354609928 and parameters: {'n_estimators': 72, 'learning_rate': 0.14834774539657258}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:03,265] Trial 72 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 100, 'learning_rate': 0.00833679285252577}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:03,579] Trial 73 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 33, 'learning_rate': 0.4917519512346823}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:03,925] Trial 74 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 75, 'learning_rate': 0.022828320300371876}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:04,356] Trial 75 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 74, 'learning_rate': 0.1431224730072478}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:04,623] Trial 76 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 10, 'learning_rate': 0.2983942023297566}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:05,022] Trial 77 finished with value: 0.8184397163120568 and parameters: {'n_estimators': 100, 'learning_rate': 0.5297652490146568}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:05,351] Trial 78 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 42, 'learning_rate': 0.14467339338109156}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:05,698] Trial 79 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 78, 'learning_rate': 0.03436566067038881}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:06,148] Trial 80 finished with value: 0.8184397163120567 and parameters: {'n_estimators': 100, 'learning_rate': 0.5989663359057441}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:06,685] Trial 81 finished with value: 0.8056737588652482 and parameters: {'n_estimators': 100, 'learning_rate': 0.4832933155654534}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:07,052] Trial 82 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 100, 'learning_rate': 0.02719684137961456}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:07,446] Trial 83 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 62, 'learning_rate': 0.0467002473117176}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:07,751] Trial 84 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 51, 'learning_rate': 0.07477338646896331}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:08,080] Trial 85 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 57, 'learning_rate': 0.03372832408257081}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:08,549] Trial 86 finished with value: 0.8141843971631205 and parameters: {'n_estimators': 83, 'learning_rate': 0.38740620699003625}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:08,911] Trial 87 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 53, 'learning_rate': 0.10155721547268791}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:09,279] Trial 88 finished with value: 0.81427304964539 and parameters: {'n_estimators': 80, 'learning_rate': 0.19424928756690307}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:09,616] Trial 89 finished with value: 0.8101063829787233 and parameters: {'n_estimators': 30, 'learning_rate': 0.21918458274026176}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:10,092] Trial 90 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 88, 'learning_rate': 0.11218359171588489}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:10,457] Trial 91 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 55, 'learning_rate': 0.05385735836732577}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:10,764] Trial 92 finished with value: 0.810017730496454 and parameters: {'n_estimators': 36, 'learning_rate': 0.9992181585951669}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:11,228] Trial 93 finished with value: 0.801595744680851 and parameters: {'n_estimators': 82, 'learning_rate': 0.26919277869794894}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:11,589] Trial 94 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 88, 'learning_rate': 0.11135918398948236}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:12,004] Trial 95 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 53, 'learning_rate': 0.055309036739883397}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:12,346] Trial 96 finished with value: 0.8184397163120568 and parameters: {'n_estimators': 86, 'learning_rate': 0.5409617180389219}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:12,709] Trial 97 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 61, 'learning_rate': 0.15733058918459847}. Best is trial 4 with value: 0.8311170212765957.\n",
      "[I 2025-12-28 19:44:13,064] Trial 98 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 87, 'learning_rate': 0.03101881069509192}. Best is trial 4 with value: 0.8311170212765957.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:44:13,316] A new study created in memory with name: Gradient Boosting Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:44:13,314] Trial 99 finished with value: 0.8058510638297873 and parameters: {'n_estimators': 10, 'learning_rate': 0.31252299899830943}. Best is trial 4 with value: 0.8311170212765957.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using GPSampler: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}\n",
      "Best accuracy: 0.8311, at trial: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b42ac1e4974bf18dd304addf93db2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:44:13,421] Trial 0 finished with value: 0.788741134751773 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.788741134751773.\n",
      "[I 2025-12-28 19:44:13,559] Trial 1 finished with value: 0.7975177304964538 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.0026587543983272706, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.762378215816119}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:44:13,619] Trial 2 finished with value: 0.7295212765957447 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.00383962929980417, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.5998368910791798}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:44:13,687] Trial 3 finished with value: 0.788918439716312 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.002193048555664369, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9041986740582306}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:44:13,756] Trial 4 finished with value: 0.6957446808510639 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.0017541893487450805, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6293899908000085}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:44:13,836] Trial 5 finished with value: 0.7929964539007093 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.0023426581058204046, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.9474136752138245}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:44:13,896] Trial 6 finished with value: 0.52322695035461 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.0012315571723666018, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9143687545759647}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:44:13,933] Trial 7 finished with value: 0.7805851063829786 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.040215545266902894, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.5993578407670862}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:44:14,022] Trial 8 finished with value: 0.7888297872340425 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.034877126245459314, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9315517129377968}. Best is trial 1 with value: 0.7975177304964538.\n",
      "[I 2025-12-28 19:44:14,083] Trial 9 finished with value: 0.8015070921985815 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.004470608546778492, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7361074625809747}. Best is trial 9 with value: 0.8015070921985815.\n",
      "[I 2025-12-28 19:44:14,558] Trial 10 finished with value: 0.7849290780141844 and parameters: {'max_features': 'log2', 'n_estimators': 95, 'learning_rate': 0.01908775097571146, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.8018504341254866}. Best is trial 9 with value: 0.8015070921985815.\n",
      "[I 2025-12-28 19:44:15,003] Trial 11 finished with value: 0.7932624113475178 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.6752345464768064}. Best is trial 9 with value: 0.8015070921985815.\n",
      "[I 2025-12-28 19:44:15,464] Trial 12 finished with value: 0.7549645390070922 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 9 with value: 0.8015070921985815.\n",
      "[I 2025-12-28 19:44:15,835] Trial 13 finished with value: 0.6789893617021276 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.0010000000000000002, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.6028755909254956}. Best is trial 9 with value: 0.8015070921985815.\n",
      "[I 2025-12-28 19:44:16,198] Trial 14 finished with value: 0.7971631205673758 and parameters: {'max_features': 'sqrt', 'n_estimators': 43, 'learning_rate': 0.09999999999999998, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 9 with value: 0.8015070921985815.\n",
      "[I 2025-12-28 19:44:16,628] Trial 15 finished with value: 0.8055851063829786 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.002124010049437027, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 15 with value: 0.8055851063829786.\n",
      "[I 2025-12-28 19:44:16,952] Trial 16 finished with value: 0.7804964539007092 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.1, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 15 with value: 0.8055851063829786.\n",
      "[I 2025-12-28 19:44:17,276] Trial 17 finished with value: 0.6622340425531915 and parameters: {'max_features': 'log2', 'n_estimators': 79, 'learning_rate': 0.0010000000000000002, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 15 with value: 0.8055851063829786.\n",
      "[I 2025-12-28 19:44:17,794] Trial 18 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 77, 'learning_rate': 0.0038708799149862793, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10, 'subsample': 0.8059175911927354}. Best is trial 18 with value: 0.810017730496454.\n",
      "[I 2025-12-28 19:44:18,657] Trial 19 finished with value: 0.814095744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.0031098776659299132, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.8713351295434495}. Best is trial 19 with value: 0.814095744680851.\n",
      "[I 2025-12-28 19:44:19,121] Trial 20 finished with value: 0.8187056737588652 and parameters: {'max_features': 'sqrt', 'n_estimators': 48, 'learning_rate': 0.009890861301226753, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 20 with value: 0.8187056737588652.\n",
      "[I 2025-12-28 19:44:19,623] Trial 21 finished with value: 0.788918439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 62, 'learning_rate': 0.0066463389695551, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 20 with value: 0.8187056737588652.\n",
      "[I 2025-12-28 19:44:20,054] Trial 22 finished with value: 0.7805851063829787 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.012387227285374312, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 20 with value: 0.8187056737588652.\n",
      "[I 2025-12-28 19:44:20,680] Trial 23 finished with value: 0.8185283687943263 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.005690458364416876, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 20 with value: 0.8187056737588652.\n",
      "[I 2025-12-28 19:44:21,156] Trial 24 finished with value: 0.7973404255319148 and parameters: {'max_features': 'log2', 'n_estimators': 72, 'learning_rate': 0.003059464258668756, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 20 with value: 0.8187056737588652.\n",
      "[I 2025-12-28 19:44:21,716] Trial 25 finished with value: 0.801595744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 48, 'learning_rate': 0.006658429584360672, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 20 with value: 0.8187056737588652.\n",
      "[I 2025-12-28 19:44:22,173] Trial 26 finished with value: 0.8186170212765959 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.00457176665104494, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 20 with value: 0.8187056737588652.\n",
      "[I 2025-12-28 19:44:22,549] Trial 27 finished with value: 0.7680851063829787 and parameters: {'max_features': 'log2', 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 20 with value: 0.8187056737588652.\n",
      "[I 2025-12-28 19:44:23,087] Trial 28 finished with value: 0.8225177304964539 and parameters: {'max_features': 'log2', 'n_estimators': 70, 'learning_rate': 0.002935053369823518, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:23,527] Trial 29 finished with value: 0.7848404255319148 and parameters: {'max_features': 'sqrt', 'n_estimators': 60, 'learning_rate': 0.025631139805163242, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:23,930] Trial 30 finished with value: 0.7590425531914893 and parameters: {'max_features': 'log2', 'n_estimators': 10, 'learning_rate': 0.0113195842908718, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:24,373] Trial 31 finished with value: 0.8059397163120566 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.010087119733600255, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:24,930] Trial 32 finished with value: 0.8185283687943261 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.002794899008881236, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:25,407] Trial 33 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.0026597381421297013, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:26,091] Trial 34 finished with value: 0.8099290780141845 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.003456293150084524, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:26,658] Trial 35 finished with value: 0.7766843971631204 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.0034540297234202134, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:27,205] Trial 36 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.0028428733640719203, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:27,670] Trial 37 finished with value: 0.7974290780141844 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.002847805216637531, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:28,133] Trial 38 finished with value: 0.8055851063829789 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.003548184607190427, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:28,586] Trial 39 finished with value: 0.8186170212765959 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.006030067013185296, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:28,963] Trial 40 finished with value: 0.7638297872340425 and parameters: {'max_features': None, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:29,528] Trial 41 finished with value: 0.8099290780141845 and parameters: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.05888249397128182, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:30,325] Trial 42 finished with value: 0.8142730496453903 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.038612771221807986, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:30,895] Trial 43 finished with value: 0.8141843971631205 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.04783005401737618, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:31,415] Trial 44 finished with value: 0.7973404255319149 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.03644326251798938, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:31,904] Trial 45 finished with value: 0.801595744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 60, 'learning_rate': 0.05961445440193741, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:32,513] Trial 46 finished with value: 0.7970744680851063 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.05021853003843441, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:32,972] Trial 47 finished with value: 0.8060283687943264 and parameters: {'max_features': 'sqrt', 'n_estimators': 48, 'learning_rate': 0.007090927356694643, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:33,470] Trial 48 finished with value: 0.7973404255319149 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.04184890132051399, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:34,221] Trial 49 finished with value: 0.8097517730496454 and parameters: {'max_features': None, 'n_estimators': 77, 'learning_rate': 0.03616376511952599, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:34,986] Trial 50 finished with value: 0.7848404255319149 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.021746244620407782, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:35,452] Trial 51 finished with value: 0.8141843971631205 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.0033300797419179864, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:36,243] Trial 52 finished with value: 0.8017730496453901 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.04690950506069833, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:36,728] Trial 53 finished with value: 0.7803191489361702 and parameters: {'max_features': None, 'n_estimators': 54, 'learning_rate': 0.05702482312888743, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:37,215] Trial 54 finished with value: 0.7549645390070922 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.04016132640144974, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:37,925] Trial 55 finished with value: 0.7590425531914893 and parameters: {'max_features': 'sqrt', 'n_estimators': 60, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:38,393] Trial 56 finished with value: 0.7973404255319148 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.04097492943818115, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:38,887] Trial 57 finished with value: 0.8016843971631206 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.007132591742841706, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:39,443] Trial 58 finished with value: 0.8054964539007091 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.002428762349879516, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:40,118] Trial 59 finished with value: 0.8144503546099291 and parameters: {'max_features': 'sqrt', 'n_estimators': 56, 'learning_rate': 0.004308647419515402, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:40,715] Trial 60 finished with value: 0.7933510638297873 and parameters: {'max_features': 'sqrt', 'n_estimators': 58, 'learning_rate': 0.04068791533571814, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:41,677] Trial 61 finished with value: 0.801418439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0024280340072084655, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:42,132] Trial 62 finished with value: 0.7932624113475178 and parameters: {'max_features': 'sqrt', 'n_estimators': 34, 'learning_rate': 0.06506384622886446, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:42,688] Trial 63 finished with value: 0.801595744680851 and parameters: {'max_features': 'log2', 'n_estimators': 79, 'learning_rate': 0.003162414635754354, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:43,235] Trial 64 finished with value: 0.7725177304964539 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.009014134634591924, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:43,798] Trial 65 finished with value: 0.7931737588652481 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.00933733611524934, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:44,416] Trial 66 finished with value: 0.8099290780141845 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.002431279449774055, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.6146628556107336}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:44,918] Trial 67 finished with value: 0.8184397163120568 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.07094621912453704, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:45,438] Trial 68 finished with value: 0.8058510638297871 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:46,048] Trial 69 finished with value: 0.8101063829787234 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0037284036200515335, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:46,743] Trial 70 finished with value: 0.8183510638297872 and parameters: {'max_features': 'sqrt', 'n_estimators': 95, 'learning_rate': 0.0028982748957592872, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:47,373] Trial 71 finished with value: 0.7929964539007093 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.06855134923683028, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:48,055] Trial 72 finished with value: 0.8056737588652482 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0571369012060548, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:48,569] Trial 73 finished with value: 0.8141843971631205 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.002926321627037201, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.6035725815871087}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:49,425] Trial 74 finished with value: 0.8055851063829786 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.03890802704416964, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 28 with value: 0.8225177304964539.\n",
      "[I 2025-12-28 19:44:50,090] Trial 75 finished with value: 0.8226063829787235 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.0027719599525022017, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:50,630] Trial 76 finished with value: 0.8183510638297872 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.0030798403311770996, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:51,250] Trial 77 finished with value: 0.8185283687943261 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.002526841048740613, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:51,788] Trial 78 finished with value: 0.8185283687943261 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.0027063870575107507, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:52,281] Trial 79 finished with value: 0.8183510638297872 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0024237085192759557, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:52,915] Trial 80 finished with value: 0.8226063829787235 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0029903621872492776, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:53,585] Trial 81 finished with value: 0.788918439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 92, 'learning_rate': 0.0028731296909935435, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:54,122] Trial 82 finished with value: 0.8183510638297872 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.002592013345878615, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:54,598] Trial 83 finished with value: 0.8183510638297872 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.002745753830715734, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:55,112] Trial 84 finished with value: 0.8142730496453903 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.003574221385443811, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:55,597] Trial 85 finished with value: 0.8059397163120569 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.006384317116572792, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:56,143] Trial 86 finished with value: 0.8185283687943263 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.0056631116863877255, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 75 with value: 0.8226063829787235.\n",
      "[I 2025-12-28 19:44:56,642] Trial 87 finished with value: 0.822695035460993 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.0053601954809141235, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:44:57,110] Trial 88 finished with value: 0.81427304964539 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.004466909531190437, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:44:57,560] Trial 89 finished with value: 0.81427304964539 and parameters: {'max_features': 'log2', 'n_estimators': 80, 'learning_rate': 0.006832477034724218, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:44:58,054] Trial 90 finished with value: 0.801595744680851 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.005785531952499813, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:44:58,519] Trial 91 finished with value: 0.8101063829787234 and parameters: {'max_features': 'log2', 'n_estimators': 72, 'learning_rate': 0.005924151039596092, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:44:59,079] Trial 92 finished with value: 0.8099290780141845 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:44:59,586] Trial 93 finished with value: 0.7973404255319149 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.0052865372725197715, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:45:00,128] Trial 94 finished with value: 0.8185283687943261 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.0033602222951281046, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:45:00,731] Trial 95 finished with value: 0.8016843971631206 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.010276515107246972, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:45:01,299] Trial 96 finished with value: 0.7975177304964539 and parameters: {'max_features': 'log2', 'n_estimators': 60, 'learning_rate': 0.026658676094035192, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:45:01,742] Trial 97 finished with value: 0.8183510638297872 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.002559368542354524, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:45:02,252] Trial 98 finished with value: 0.8099290780141845 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.003220362838859776, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 87 with value: 0.822695035460993.\n",
      "[I 2025-12-28 19:45:02,784] Trial 99 finished with value: 0.8058510638297871 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 87 with value: 0.822695035460993.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using GPSampler: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.0053601954809141235, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}\n",
      "Best accuracy: 0.8227, at trial: 87\n",
      "GP Base Models Training Time: 182.54 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    gp_base_models_training_start = time.time()\n",
    "\n",
    "    # GP Hyperparameter Tuning with Cross Validation\n",
    "    gp_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    gp_logistic_regression.fit(X_train, y_train)\n",
    "    gp_decision_tree.fit(X_train, y_train)\n",
    "    gp_random_forest.fit(X_train, y_train)\n",
    "    gp_knn.fit(X_train, y_train)\n",
    "    gp_svc.fit(X_train, y_train)\n",
    "    gp_adaboost.fit(X_train, y_train)\n",
    "    gp_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    gp_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for GP base models training\n",
    "    gp_base_models_training_time = gp_base_models_training_end - gp_base_models_training_start\n",
    "    print(f'GP Base Models Training Time: {gp_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping GP base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:03,067] A new study created in memory with name: Logistic Regression Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517e73bf6227478682c5e6a0d84ea1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:03,111] Trial 0 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:03,126] The parameter `solver` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,162] Trial 1 finished with value: 0.839627659574468 and parameters: {'solver': 'newton-cholesky', 'C': 0.02205741280502818}. Best is trial 1 with value: 0.839627659574468.\n",
      "[W 2025-12-28 19:45:03,165] The parameter `solver` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,201] Trial 2 finished with value: 0.8354609929078014 and parameters: {'solver': 'newton-cholesky', 'C': 0.02802913837564577}. Best is trial 1 with value: 0.839627659574468.\n",
      "[W 2025-12-28 19:45:03,204] The parameter `solver` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,239] Trial 3 finished with value: 0.8271276595744681 and parameters: {'solver': 'sag', 'C': 0.36204298853974154}. Best is trial 1 with value: 0.839627659574468.\n",
      "[W 2025-12-28 19:45:03,241] The parameter `solver` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,277] Trial 4 finished with value: 0.52322695035461 and parameters: {'solver': 'sag', 'C': 0.00011850115518950796}. Best is trial 1 with value: 0.839627659574468.\n",
      "[W 2025-12-28 19:45:03,279] The parameter `solver` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,315] Trial 5 finished with value: 0.8355496453900709 and parameters: {'solver': 'sag', 'C': 0.06882028019479247}. Best is trial 1 with value: 0.839627659574468.\n",
      "[W 2025-12-28 19:45:03,317] The parameter `solver` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,353] Trial 6 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.02961528545783935}. Best is trial 1 with value: 0.839627659574468.\n",
      "[W 2025-12-28 19:45:03,355] The parameter `solver` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,392] Trial 7 finished with value: 0.7931737588652482 and parameters: {'solver': 'newton-cg', 'C': 0.0023806795788514994}. Best is trial 1 with value: 0.839627659574468.\n",
      "[W 2025-12-28 19:45:03,394] The parameter `solver` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,430] Trial 8 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cg', 'C': 0.1160198820749854}. Best is trial 8 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:03,433] The parameter `solver` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,468] Trial 9 finished with value: 0.8228723404255319 and parameters: {'solver': 'newton-cg', 'C': 0.3880328417753178}. Best is trial 8 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:03,470] The parameter `solver` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,506] Trial 10 finished with value: 0.8144503546099291 and parameters: {'solver': 'newton-cholesky', 'C': 0.5851440087459954}. Best is trial 8 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:03,508] The parameter `solver` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,543] Trial 11 finished with value: 0.8353723404255318 and parameters: {'solver': 'lbfgs', 'C': 0.019710753538043992}. Best is trial 8 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:03,546] The parameter `solver` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,581] Trial 12 finished with value: 0.8313829787234042 and parameters: {'solver': 'newton-cg', 'C': 0.20938187085340448}. Best is trial 8 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:03,583] The parameter `solver` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,618] Trial 13 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cholesky', 'C': 0.15213106517903918}. Best is trial 8 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:03,620] The parameter `solver` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,655] Trial 14 finished with value: 0.8355496453900709 and parameters: {'solver': 'sag', 'C': 0.044526626984624035}. Best is trial 8 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:03,658] The parameter `solver` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,693] Trial 15 finished with value: 0.8354609929078014 and parameters: {'solver': 'newton-cg', 'C': 0.02777650341087946}. Best is trial 8 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:03,694] The parameter `solver` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,732] Trial 16 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.084423328736445}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:03,735] The parameter `solver` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,772] Trial 17 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.03717088460887574}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:03,774] The parameter `solver` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,810] Trial 18 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.1555295464389249}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:03,812] The parameter `solver` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,848] Trial 19 finished with value: 0.8397163120567376 and parameters: {'solver': 'sag', 'C': 0.1413238181401341}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:03,849] The parameter `solver` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,885] Trial 20 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.037676905712243136}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:03,888] The parameter `solver` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,924] Trial 21 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 1.6094133887915294}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:03,926] The parameter `solver` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:03,962] Trial 22 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.11249906237968472}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:03,964] The parameter `solver` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,000] Trial 23 finished with value: 0.8144503546099291 and parameters: {'solver': 'newton-cg', 'C': 0.42558767309255124}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,002] The parameter `solver` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,038] Trial 24 finished with value: 0.8353723404255318 and parameters: {'solver': 'lbfgs', 'C': 0.02124891145963997}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,040] The parameter `solver` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,074] Trial 25 finished with value: 0.8354609929078014 and parameters: {'solver': 'sag', 'C': 0.036824245226642384}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,076] The parameter `solver` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,111] Trial 26 finished with value: 0.8312943262411346 and parameters: {'solver': 'newton-cholesky', 'C': 0.0482767499078503}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,113] The parameter `solver` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,149] Trial 27 finished with value: 0.835372340425532 and parameters: {'solver': 'sag', 'C': 0.016177438761679555}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,150] The parameter `solver` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,188] Trial 28 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.0909662753993412}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,191] The parameter `solver` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,227] Trial 29 finished with value: 0.8355496453900709 and parameters: {'solver': 'newton-cg', 'C': 0.06596173752498014}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,229] The parameter `solver` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,265] Trial 30 finished with value: 0.8397163120567376 and parameters: {'solver': 'lbfgs', 'C': 0.1361538327922896}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,266] The parameter `solver` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,302] Trial 31 finished with value: 0.8312943262411346 and parameters: {'solver': 'newton-cholesky', 'C': 0.047948966965416506}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,304] The parameter `solver` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,339] Trial 32 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.07915167313888147}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,342] The parameter `solver` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,377] Trial 33 finished with value: 0.8312943262411346 and parameters: {'solver': 'newton-cg', 'C': 0.04886253217869538}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,379] The parameter `solver` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,415] Trial 34 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.07890091109637816}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,417] The parameter `solver` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,452] Trial 35 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cg', 'C': 0.15163763833320315}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,454] The parameter `solver` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,489] Trial 36 finished with value: 0.8356382978723405 and parameters: {'solver': 'newton-cg', 'C': 0.05516984690505451}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,491] The parameter `solver` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,527] Trial 37 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08064934216181419}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,529] The parameter `solver` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,565] Trial 38 finished with value: 0.8356382978723405 and parameters: {'solver': 'newton-cg', 'C': 0.06108530189918081}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,567] The parameter `solver` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,602] Trial 39 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08674866322929618}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,604] The parameter `solver` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,640] Trial 40 finished with value: 0.8355496453900709 and parameters: {'solver': 'newton-cg', 'C': 0.07207998090995199}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,642] The parameter `solver` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,677] Trial 41 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.07863336331849552}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,679] The parameter `solver` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,715] Trial 42 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08422781776206695}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,716] The parameter `solver` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,752] Trial 43 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.07693521275272606}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,754] The parameter `solver` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,790] Trial 44 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.09245462527212954}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,792] The parameter `solver` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,827] Trial 45 finished with value: 0.8355496453900709 and parameters: {'solver': 'newton-cg', 'C': 0.07240517851952617}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,829] The parameter `solver` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,865] Trial 46 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08678269868018823}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,867] The parameter `solver` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,903] Trial 47 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.07807095533080712}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,905] The parameter `solver` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,941] Trial 48 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.09346690688661936}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,943] The parameter `solver` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:04,980] Trial 49 finished with value: 0.8355496453900709 and parameters: {'solver': 'lbfgs', 'C': 0.07444486722445255}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:04,981] The parameter `solver` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,017] Trial 50 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.086457063121424}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,020] The parameter `solver` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,055] Trial 51 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08076861242257236}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,057] The parameter `solver` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,092] Trial 52 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08640084315885185}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,095] The parameter `solver` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,131] Trial 53 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08887017633692537}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,134] The parameter `solver` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,168] Trial 54 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.0793673413428965}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,170] The parameter `solver` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,206] Trial 55 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08101186172350333}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,208] The parameter `solver` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,244] Trial 56 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.085538421888607}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,246] The parameter `solver` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,282] Trial 57 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08742353591407073}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,284] The parameter `solver` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,319] Trial 58 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08229253048992824}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,321] The parameter `solver` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,357] Trial 59 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.09199287303478582}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,359] The parameter `solver` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,394] Trial 60 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08264947654339606}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,396] The parameter `solver` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,431] Trial 61 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08131684974877348}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,433] The parameter `solver` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,551] Trial 62 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.0845978714129355}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,551] The parameter `solver` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,590] Trial 63 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.09109451227591706}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,592] The parameter `solver` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,627] Trial 64 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08567536443505055}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,630] The parameter `solver` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,665] Trial 65 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08873499325932102}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,665] The parameter `solver` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,703] Trial 66 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08665272374895099}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,703] The parameter `solver` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,739] Trial 67 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08168412552883708}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,741] The parameter `solver` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,778] Trial 68 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.083314230851279}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,780] The parameter `solver` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,815] Trial 69 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08400217741987494}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,817] The parameter `solver` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,852] Trial 70 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08599169880969515}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,852] The parameter `solver` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,889] Trial 71 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08182230739216981}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,890] The parameter `solver` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,927] Trial 72 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08050760753040123}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,927] The parameter `solver` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:05,965] Trial 73 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08666132220576862}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:05,967] The parameter `solver` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,002] Trial 74 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08375994621324041}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,004] The parameter `solver` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,039] Trial 75 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.07871543887076377}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,040] The parameter `solver` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,077] Trial 76 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08305966143351519}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,080] The parameter `solver` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,116] Trial 77 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08396188905791392}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,116] The parameter `solver` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,154] Trial 78 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.0846890424601729}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,155] The parameter `solver` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,193] Trial 79 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08744309608040758}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,195] The parameter `solver` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,230] Trial 80 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08575969230432749}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,233] The parameter `solver` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,268] Trial 81 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08677397879983839}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,268] The parameter `solver` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,305] Trial 82 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08234672296133376}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,305] The parameter `solver` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,342] Trial 83 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08227028080154972}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,344] The parameter `solver` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,380] Trial 84 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08392494967099264}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,382] The parameter `solver` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,418] Trial 85 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08560657697831835}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,418] The parameter `solver` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,456] Trial 86 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08363621723805063}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,456] The parameter `solver` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,493] Trial 87 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08510215988411493}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,495] The parameter `solver` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,531] Trial 88 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.0879265989422816}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,533] The parameter `solver` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,569] Trial 89 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08373283304613448}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,569] The parameter `solver` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,606] Trial 90 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08469042037747362}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,606] The parameter `solver` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,644] Trial 91 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08707009427709089}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,644] The parameter `solver` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,680] Trial 92 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08544878084105745}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,683] The parameter `solver` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,718] Trial 93 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08526924696368893}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,720] The parameter `solver` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,839] Trial 94 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08440953804266085}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,841] The parameter `solver` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,877] Trial 95 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08501344834058681}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,879] The parameter `solver` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,914] Trial 96 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.08634963388336815}. Best is trial 16 with value: 0.8439716312056736.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:07,027] A new study created in memory with name: Decision Tree Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:45:06,916] The parameter `solver` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,952] Trial 97 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cg', 'C': 0.08590944314256077}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,952] The parameter `solver` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:06,989] Trial 98 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.08741969043597624}. Best is trial 16 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:06,989] The parameter `solver` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,026] Trial 99 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.0864677648916376}. Best is trial 16 with value: 0.8439716312056736.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using CmaEsSampler: {'solver': 'newton-cholesky', 'C': 0.084423328736445}\n",
      "Best accuracy: 0.8440, at trial: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419c05d4540843f6a1c1fb35069b9415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:07,061] Trial 0 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,063] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,066] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,081] Trial 1 finished with value: 0.7382978723404255 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,083] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,084] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,110] Trial 2 finished with value: 0.7047872340425532 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,113] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,115] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,131] Trial 3 finished with value: 0.7635638297872339 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,134] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,135] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,150] Trial 4 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,153] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,154] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,168] Trial 5 finished with value: 0.7257092198581561 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,169] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,169] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,186] Trial 6 finished with value: 0.674822695035461 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,187] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,187] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,203] Trial 7 finished with value: 0.7089539007092199 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,205] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,205] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,220] Trial 8 finished with value: 0.7500886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,222] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,223] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,238] Trial 9 finished with value: 0.7340425531914893 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,240] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,240] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,256] Trial 10 finished with value: 0.7252659574468084 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,258] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,260] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,273] Trial 11 finished with value: 0.750886524822695 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,275] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,276] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,291] Trial 12 finished with value: 0.7299645390070921 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,293] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,294] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,308] Trial 13 finished with value: 0.6879432624113476 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,310] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,310] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,326] Trial 14 finished with value: 0.7171985815602838 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,327] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,327] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,343] Trial 15 finished with value: 0.7422872340425533 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,345] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,347] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,361] Trial 16 finished with value: 0.7300531914893617 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,363] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,363] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,379] Trial 17 finished with value: 0.7382978723404255 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,381] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,381] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,396] Trial 18 finished with value: 0.7547872340425531 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,398] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,399] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,413] Trial 19 finished with value: 0.7500886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,415] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,416] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,430] Trial 20 finished with value: 0.7341312056737589 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,432] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,433] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,448] Trial 21 finished with value: 0.7598404255319149 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,452] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,452] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,467] Trial 22 finished with value: 0.7464539007092197 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,469] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,470] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,485] Trial 23 finished with value: 0.7425531914893616 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,487] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,488] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,503] Trial 24 finished with value: 0.7087765957446809 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,505] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,506] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,521] Trial 25 finished with value: 0.699822695035461 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,523] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,524] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,539] Trial 26 finished with value: 0.7549645390070923 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,541] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,542] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,556] Trial 27 finished with value: 0.7555851063829786 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,559] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,560] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,574] Trial 28 finished with value: 0.7426418439716312 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,576] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,577] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,591] Trial 29 finished with value: 0.7682624113475176 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,593] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,594] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,608] Trial 30 finished with value: 0.7468085106382979 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,610] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,610] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,626] Trial 31 finished with value: 0.763918439716312 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,628] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,629] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,644] Trial 32 finished with value: 0.7508865248226949 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,646] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,647] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,661] Trial 33 finished with value: 0.7762411347517731 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,664] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,664] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,679] Trial 34 finished with value: 0.7174645390070922 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,681] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,682] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,707] Trial 35 finished with value: 0.7170212765957447 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,711] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,712] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,726] Trial 36 finished with value: 0.7425531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,728] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,729] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,743] Trial 37 finished with value: 0.7762411347517731 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,745] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,747] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,761] Trial 38 finished with value: 0.7422872340425533 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,763] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,764] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,779] Trial 39 finished with value: 0.7292553191489362 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,781] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,781] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,796] Trial 40 finished with value: 0.7547872340425531 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,798] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,799] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,813] Trial 41 finished with value: 0.7549645390070923 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,815] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,816] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,831] Trial 42 finished with value: 0.7682624113475176 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,833] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,834] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,849] Trial 43 finished with value: 0.7549645390070923 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,851] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,852] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,866] Trial 44 finished with value: 0.7257092198581561 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,869] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,870] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,885] Trial 45 finished with value: 0.7171099290780141 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,887] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,888] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,902] Trial 46 finished with value: 0.7382978723404255 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,904] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,905] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,919] Trial 47 finished with value: 0.7500886524822695 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,921] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,922] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,936] Trial 48 finished with value: 0.7426418439716311 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,937] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,939] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,953] Trial 49 finished with value: 0.7426418439716312 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,955] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,956] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,970] Trial 50 finished with value: 0.7426418439716312 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,972] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,973] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:07,987] Trial 51 finished with value: 0.7500886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:07,990] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:07,991] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,005] Trial 52 finished with value: 0.7469858156028369 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,007] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,009] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,022] Trial 53 finished with value: 0.7087765957446809 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,025] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,026] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,040] Trial 54 finished with value: 0.7424645390070923 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,042] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,044] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,058] Trial 55 finished with value: 0.750709219858156 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,060] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,061] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,075] Trial 56 finished with value: 0.7500886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,078] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,079] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,093] Trial 57 finished with value: 0.7500886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,095] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,096] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,111] Trial 58 finished with value: 0.7716312056737589 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,113] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,114] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,129] Trial 59 finished with value: 0.7500886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,131] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,132] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,146] Trial 60 finished with value: 0.7762411347517731 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,148] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,149] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,163] Trial 61 finished with value: 0.7464539007092197 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,166] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,167] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,181] Trial 62 finished with value: 0.7550531914893617 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,183] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,184] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,197] Trial 63 finished with value: 0.7292553191489362 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,200] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,200] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,215] Trial 64 finished with value: 0.7762411347517731 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,217] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,218] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,233] Trial 65 finished with value: 0.7679964539007094 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,235] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,236] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,249] Trial 66 finished with value: 0.7085992907801418 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,252] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,253] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,267] Trial 67 finished with value: 0.750709219858156 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,269] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,270] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,294] Trial 68 finished with value: 0.725886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,296] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,297] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,323] Trial 69 finished with value: 0.7762411347517731 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,326] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,326] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,341] Trial 70 finished with value: 0.7292553191489362 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,343] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,344] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,359] Trial 71 finished with value: 0.7762411347517731 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,360] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,361] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,375] Trial 72 finished with value: 0.7762411347517731 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,377] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,378] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,393] Trial 73 finished with value: 0.7469858156028369 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,395] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,396] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,411] Trial 74 finished with value: 0.7002659574468085 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,413] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,414] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,429] Trial 75 finished with value: 0.7295212765957446 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,431] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,432] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,447] Trial 76 finished with value: 0.7383865248226951 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,448] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,450] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,464] Trial 77 finished with value: 0.7500886524822695 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,467] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,468] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,482] Trial 78 finished with value: 0.7295212765957446 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,483] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,484] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,499] Trial 79 finished with value: 0.7464539007092197 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,501] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,502] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,517] Trial 80 finished with value: 0.7426418439716312 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,518] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,519] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,534] Trial 81 finished with value: 0.7598404255319149 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,537] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,538] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,552] Trial 82 finished with value: 0.7341312056737588 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,554] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,555] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,569] Trial 83 finished with value: 0.7469858156028369 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,571] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,572] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,587] Trial 84 finished with value: 0.7382978723404255 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,590] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,591] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,616] Trial 85 finished with value: 0.7428191489361702 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,618] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,620] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,634] Trial 86 finished with value: 0.7762411347517731 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,636] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,637] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,652] Trial 87 finished with value: 0.7507978723404255 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,654] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,655] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,670] Trial 88 finished with value: 0.7550531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,672] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,673] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,687] Trial 89 finished with value: 0.725886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,689] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,690] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,704] Trial 90 finished with value: 0.7174645390070922 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,706] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,707] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,722] Trial 91 finished with value: 0.7469858156028369 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:08,725] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,726] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,740] Trial 92 finished with value: 0.7888297872340425 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 92 with value: 0.7888297872340425.\n",
      "[W 2025-12-28 19:45:08,742] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,743] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,757] Trial 93 finished with value: 0.7295212765957446 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 92 with value: 0.7888297872340425.\n",
      "[W 2025-12-28 19:45:08,760] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,761] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,775] Trial 94 finished with value: 0.7506205673758866 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 92 with value: 0.7888297872340425.\n",
      "[W 2025-12-28 19:45:08,777] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,778] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,802] Trial 95 finished with value: 0.7170212765957447 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 92 with value: 0.7888297872340425.\n",
      "[W 2025-12-28 19:45:08,804] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:08,876] A new study created in memory with name: Random Forest Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:45:08,805] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,821] Trial 96 finished with value: 0.7383865248226951 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 92 with value: 0.7888297872340425.\n",
      "[W 2025-12-28 19:45:08,823] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,824] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,838] Trial 97 finished with value: 0.7550531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 92 with value: 0.7888297872340425.\n",
      "[W 2025-12-28 19:45:08,840] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,841] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,855] Trial 98 finished with value: 0.7087765957446809 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 92 with value: 0.7888297872340425.\n",
      "[W 2025-12-28 19:45:08,857] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,858] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:08,873] Trial 99 finished with value: 0.7464539007092197 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 92 with value: 0.7888297872340425.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using CmaEsSampler: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
      "Best accuracy: 0.7888, at trial: 92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415abbb036c9472e8a583016c3f54711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:08,950] Trial 0 finished with value: 0.7849290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7849290780141844.\n",
      "[W 2025-12-28 19:45:08,952] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:08,953] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:09,070] Trial 1 finished with value: 0.7803191489361702 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7849290780141844.\n",
      "[W 2025-12-28 19:45:09,072] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:09,073] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:09,212] Trial 2 finished with value: 0.7974290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7974290780141844.\n",
      "[W 2025-12-28 19:45:09,214] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:09,215] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:09,312] Trial 3 finished with value: 0.7847517730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7974290780141844.\n",
      "[W 2025-12-28 19:45:09,315] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:09,316] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:09,444] Trial 4 finished with value: 0.7891843971631205 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 51, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7974290780141844.\n",
      "[W 2025-12-28 19:45:09,447] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:09,448] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:09,691] Trial 5 finished with value: 0.7803191489361702 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 79, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7974290780141844.\n",
      "[W 2025-12-28 19:45:09,694] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:09,694] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:09,771] Trial 6 finished with value: 0.7718085106382979 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 29, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7974290780141844.\n",
      "[W 2025-12-28 19:45:09,773] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:09,774] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:09,872] Trial 7 finished with value: 0.771985815602837 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7974290780141844.\n",
      "[W 2025-12-28 19:45:09,874] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:09,875] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:10,003] Trial 8 finished with value: 0.822695035460993 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:10,008] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:10,008] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:10,135] Trial 9 finished with value: 0.8058510638297873 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:10,138] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:10,139] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:10,267] Trial 10 finished with value: 0.7765070921985815 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 52, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:10,269] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:10,270] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:10,409] Trial 11 finished with value: 0.8057624113475177 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:10,411] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:10,412] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:10,521] Trial 12 finished with value: 0.801595744680851 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:10,523] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:10,524] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:10,652] Trial 13 finished with value: 0.8058510638297871 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:10,655] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:10,656] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:10,784] Trial 14 finished with value: 0.8184397163120567 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:10,786] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:10,787] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:10,904] Trial 15 finished with value: 0.7974290780141844 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:10,906] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:10,907] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:11,138] Trial 16 finished with value: 0.8141843971631205 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 80, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:11,143] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:11,144] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:11,354] Trial 17 finished with value: 0.7975177304964538 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:11,356] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:11,357] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:11,588] Trial 18 finished with value: 0.8099290780141845 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:11,592] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:11,592] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:11,731] Trial 19 finished with value: 0.7974290780141844 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:11,734] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:11,734] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:11,861] Trial 20 finished with value: 0.801595744680851 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:11,864] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:11,865] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:11,993] Trial 21 finished with value: 0.8058510638297871 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:11,996] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:11,997] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:12,114] Trial 22 finished with value: 0.7849290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:12,116] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:12,117] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:12,265] Trial 23 finished with value: 0.810017730496454 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:12,268] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:12,268] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:12,470] Trial 24 finished with value: 0.784663120567376 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 44, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:12,474] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:12,475] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:12,707] Trial 25 finished with value: 0.801595744680851 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:12,710] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:12,710] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:12,837] Trial 26 finished with value: 0.789095744680851 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 62, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:12,839] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:12,840] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:12,998] Trial 27 finished with value: 0.8057624113475178 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:13,001] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:13,001] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:13,171] Trial 28 finished with value: 0.7932624113475177 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 78, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:13,174] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:13,175] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:13,315] Trial 29 finished with value: 0.7931737588652481 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:13,317] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:13,318] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:13,457] Trial 30 finished with value: 0.7848404255319149 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 77, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:13,460] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:13,460] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:13,578] Trial 31 finished with value: 0.7890070921985817 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:13,579] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:13,579] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:13,761] Trial 32 finished with value: 0.7888297872340425 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 94, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:13,764] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:13,764] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:13,933] Trial 33 finished with value: 0.7932624113475176 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 94, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:13,937] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:13,937] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:14,085] Trial 34 finished with value: 0.7804964539007091 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:14,086] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:14,089] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:14,256] Trial 35 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 89, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:14,259] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:14,260] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:14,500] Trial 36 finished with value: 0.7932624113475176 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 72, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:14,501] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:14,501] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:14,641] Trial 37 finished with value: 0.8101063829787233 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:14,642] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:14,642] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:14,834] Trial 38 finished with value: 0.7974290780141844 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:14,835] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:14,837] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:14,976] Trial 39 finished with value: 0.7974290780141843 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:14,979] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:14,979] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:15,252] Trial 40 finished with value: 0.8015070921985815 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:15,256] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:15,257] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:15,415] Trial 41 finished with value: 0.7933510638297873 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 79, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:15,417] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:15,418] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:15,671] Trial 42 finished with value: 0.7848404255319148 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 72, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:15,673] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:15,675] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:15,834] Trial 43 finished with value: 0.8015070921985815 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:15,836] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:15,837] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:15,956] Trial 44 finished with value: 0.785017730496454 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 53, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:15,959] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:15,959] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:16,191] Trial 45 finished with value: 0.7806737588652481 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 69, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:16,194] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:16,194] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:16,344] Trial 46 finished with value: 0.8056737588652483 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 78, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:16,347] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:16,348] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:16,506] Trial 47 finished with value: 0.801418439716312 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:16,509] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:16,510] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:16,658] Trial 48 finished with value: 0.8057624113475178 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:16,662] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:16,663] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:16,810] Trial 49 finished with value: 0.8016843971631206 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 69, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:16,813] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:16,813] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:16,952] Trial 50 finished with value: 0.8016843971631206 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:16,955] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:16,955] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:17,104] Trial 51 finished with value: 0.7932624113475176 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:17,107] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:17,108] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:17,267] Trial 52 finished with value: 0.7763297872340424 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 78, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:17,270] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:17,270] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:17,439] Trial 53 finished with value: 0.810017730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 95, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:17,442] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:17,443] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:17,684] Trial 54 finished with value: 0.8059397163120569 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:17,684] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:17,688] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:17,837] Trial 55 finished with value: 0.7888297872340425 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:17,840] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:17,841] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:18,083] Trial 56 finished with value: 0.7848404255319149 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:18,086] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:18,087] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:18,216] Trial 57 finished with value: 0.7847517730496454 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 61, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:18,218] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:18,218] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:18,366] Trial 58 finished with value: 0.8016843971631206 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 79, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:18,369] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:18,369] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:18,519] Trial 59 finished with value: 0.8016843971631206 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:18,519] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:18,519] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:18,691] Trial 60 finished with value: 0.7931737588652481 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:18,691] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:18,695] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:18,855] Trial 61 finished with value: 0.8058510638297871 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 79, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:18,855] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:18,855] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:19,050] Trial 62 finished with value: 0.788918439716312 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 91, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:19,053] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:19,053] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:19,203] Trial 63 finished with value: 0.7931737588652481 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:19,205] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:19,206] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:19,395] Trial 64 finished with value: 0.7975177304964539 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 96, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:19,399] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:19,400] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:19,549] Trial 65 finished with value: 0.7976063829787233 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 74, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:19,552] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:19,552] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:19,681] Trial 66 finished with value: 0.785017730496454 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 53, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:19,682] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:19,685] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:19,844] Trial 67 finished with value: 0.7848404255319148 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 72, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:19,844] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:19,844] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:19,996] Trial 68 finished with value: 0.7890070921985817 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 75, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:20,000] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:20,001] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:20,180] Trial 69 finished with value: 0.7931737588652481 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 90, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:20,182] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:20,184] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:20,353] Trial 70 finished with value: 0.81427304964539 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:20,356] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:20,357] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:20,506] Trial 71 finished with value: 0.7890070921985816 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 71, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:20,509] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:20,510] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:20,679] Trial 72 finished with value: 0.7848404255319148 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 76, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:20,682] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:20,685] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:20,834] Trial 73 finished with value: 0.788918439716312 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:20,836] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:20,838] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:21,018] Trial 74 finished with value: 0.7890957446808511 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 95, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:21,021] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:21,022] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:21,191] Trial 75 finished with value: 0.7931737588652481 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:21,191] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:21,191] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:21,354] Trial 76 finished with value: 0.8015070921985817 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:21,356] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:21,357] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:21,517] Trial 77 finished with value: 0.7933510638297873 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 79, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:21,520] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:21,520] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:21,670] Trial 78 finished with value: 0.7804964539007091 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:21,672] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:21,673] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:21,833] Trial 79 finished with value: 0.7931737588652481 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 85, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:21,836] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:21,837] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:21,987] Trial 80 finished with value: 0.8057624113475177 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:21,992] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:21,992] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:22,151] Trial 81 finished with value: 0.810017730496454 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:22,153] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:22,154] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:22,314] Trial 82 finished with value: 0.7804964539007091 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:22,317] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:22,318] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:22,487] Trial 83 finished with value: 0.8016843971631206 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 73, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:22,490] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:22,491] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:22,638] Trial 84 finished with value: 0.8144503546099291 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 77, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:22,641] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:22,642] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:22,801] Trial 85 finished with value: 0.7932624113475177 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:22,803] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:22,804] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:22,964] Trial 86 finished with value: 0.7929964539007093 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 84, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:22,966] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:22,968] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:23,117] Trial 87 finished with value: 0.7932624113475178 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 74, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:23,120] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:23,121] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:23,301] Trial 88 finished with value: 0.797340425531915 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 88, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:23,304] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:23,305] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:23,453] Trial 89 finished with value: 0.8017730496453901 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 73, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:23,456] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:23,457] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:23,595] Trial 90 finished with value: 0.7763297872340426 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 69, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:23,595] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:23,600] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:23,747] Trial 91 finished with value: 0.7972517730496455 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:23,747] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:23,747] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:23,889] Trial 92 finished with value: 0.8057624113475177 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 73, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:23,891] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:23,892] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:24,030] Trial 93 finished with value: 0.8015070921985815 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:24,033] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:24,034] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:24,183] Trial 94 finished with value: 0.7930851063829787 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:24,185] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:24,187] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:24,335] Trial 95 finished with value: 0.7931737588652481 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:24,336] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:24,336] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:24,487] Trial 96 finished with value: 0.801595744680851 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 86, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:24,490] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:24,491] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:24,619] Trial 97 finished with value: 0.7890957446808511 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:24,620] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:24,620] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:24,904] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:24,770] Trial 98 finished with value: 0.8099290780141845 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "[W 2025-12-28 19:45:24,773] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:24,774] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:24,902] Trial 99 finished with value: 0.7890070921985817 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.822695035460993.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using CmaEsSampler: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
      "Best accuracy: 0.8227, at trial: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fa598d90444629817210995c535754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:24,957] Trial 0 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:24,960] The parameter `algorithm` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:24,987] Trial 1 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:24,990] The parameter `algorithm` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,036] Trial 2 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,040] The parameter `algorithm` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,074] Trial 3 finished with value: 0.8186170212765959 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,076] The parameter `algorithm` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,102] Trial 4 finished with value: 0.7972517730496453 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,104] The parameter `algorithm` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,140] Trial 5 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,142] The parameter `algorithm` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,178] Trial 6 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,180] The parameter `algorithm` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,205] Trial 7 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,207] The parameter `algorithm` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,223] Trial 8 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 26, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,225] The parameter `algorithm` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,259] Trial 9 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,259] The parameter `algorithm` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,277] Trial 10 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,279] The parameter `algorithm` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,314] Trial 11 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,314] The parameter `algorithm` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,350] Trial 12 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,350] The parameter `algorithm` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,378] Trial 13 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,380] The parameter `algorithm` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,416] Trial 14 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 33, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,416] The parameter `algorithm` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,453] Trial 15 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 25, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,453] The parameter `algorithm` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,490] Trial 16 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,490] The parameter `algorithm` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,517] Trial 17 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,519] The parameter `algorithm` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,554] Trial 18 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,557] The parameter `algorithm` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,591] Trial 19 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 34, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,592] The parameter `algorithm` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,629] Trial 20 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,631] The parameter `algorithm` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,656] Trial 21 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 26, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,659] The parameter `algorithm` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,694] Trial 22 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,695] The parameter `algorithm` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,711] Trial 23 finished with value: 0.8356382978723402 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,713] The parameter `algorithm` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,738] Trial 24 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'brute', 'n_neighbors': 28, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,740] The parameter `algorithm` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,776] Trial 25 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 34, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,778] The parameter `algorithm` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,814] Trial 26 finished with value: 0.8314716312056738 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 24, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,815] The parameter `algorithm` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,831] Trial 27 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 32, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,832] The parameter `algorithm` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,847] Trial 28 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,849] The parameter `algorithm` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,875] Trial 29 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,877] The parameter `algorithm` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,892] Trial 30 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 29, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,895] The parameter `algorithm` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,929] Trial 31 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,932] The parameter `algorithm` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:25,968] Trial 32 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:25,970] The parameter `algorithm` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,006] Trial 33 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,008] The parameter `algorithm` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,055] Trial 34 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,057] The parameter `algorithm` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,092] Trial 35 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,094] The parameter `algorithm` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,119] Trial 36 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 27, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,121] The parameter `algorithm` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,147] Trial 37 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,150] The parameter `algorithm` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,175] Trial 38 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,177] The parameter `algorithm` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,202] Trial 39 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,204] The parameter `algorithm` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,250] Trial 40 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,252] The parameter `algorithm` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,277] Trial 41 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 32, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,279] The parameter `algorithm` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,315] Trial 42 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 33, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,317] The parameter `algorithm` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,342] Trial 43 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 32, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,344] The parameter `algorithm` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,380] Trial 44 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,382] The parameter `algorithm` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,406] Trial 45 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'brute', 'n_neighbors': 28, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,408] The parameter `algorithm` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,443] Trial 46 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,445] The parameter `algorithm` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,481] Trial 47 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,484] The parameter `algorithm` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,519] Trial 48 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,522] The parameter `algorithm` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,558] Trial 49 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 32, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,560] The parameter `algorithm` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,575] Trial 50 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,578] The parameter `algorithm` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,592] Trial 51 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,594] The parameter `algorithm` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,630] Trial 52 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,631] The parameter `algorithm` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,667] Trial 53 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,669] The parameter `algorithm` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,705] Trial 54 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,707] The parameter `algorithm` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,722] Trial 55 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 32, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,723] The parameter `algorithm` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,759] Trial 56 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,762] The parameter `algorithm` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,797] Trial 57 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,799] The parameter `algorithm` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,824] Trial 58 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,827] The parameter `algorithm` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,862] Trial 59 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,864] The parameter `algorithm` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,898] Trial 60 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,900] The parameter `algorithm` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,937] Trial 61 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,939] The parameter `algorithm` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:26,975] Trial 62 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:26,977] The parameter `algorithm` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,013] Trial 63 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 30, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,014] The parameter `algorithm` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,040] Trial 64 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,043] The parameter `algorithm` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,088] Trial 65 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,090] The parameter `algorithm` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,127] Trial 66 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,129] The parameter `algorithm` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,164] Trial 67 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,165] The parameter `algorithm` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,201] Trial 68 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,202] The parameter `algorithm` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,228] Trial 69 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,230] The parameter `algorithm` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,255] Trial 70 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 32, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,257] The parameter `algorithm` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,282] Trial 71 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,285] The parameter `algorithm` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,320] Trial 72 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,322] The parameter `algorithm` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,358] Trial 73 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,361] The parameter `algorithm` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,386] Trial 74 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,388] The parameter `algorithm` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,423] Trial 75 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,425] The parameter `algorithm` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,461] Trial 76 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,463] The parameter `algorithm` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,478] Trial 77 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,479] The parameter `algorithm` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,494] Trial 78 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,497] The parameter `algorithm` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,522] Trial 79 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,523] The parameter `algorithm` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,559] Trial 80 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,561] The parameter `algorithm` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,586] Trial 81 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,588] The parameter `algorithm` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,623] Trial 82 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,625] The parameter `algorithm` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,660] Trial 83 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,663] The parameter `algorithm` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,678] Trial 84 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,680] The parameter `algorithm` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,716] Trial 85 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,718] The parameter `algorithm` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,753] Trial 86 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,755] The parameter `algorithm` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,790] Trial 87 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,793] The parameter `algorithm` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,827] Trial 88 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,829] The parameter `algorithm` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,854] Trial 89 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,857] The parameter `algorithm` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,892] Trial 90 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,894] The parameter `algorithm` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,929] Trial 91 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,932] The parameter `algorithm` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,957] Trial 92 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,959] The parameter `algorithm` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:27,994] Trial 93 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:27,996] The parameter `algorithm` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,032] Trial 94 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:28,034] The parameter `algorithm` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,059] Trial 95 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:28,060] The parameter `algorithm` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,076] Trial 96 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:28,078] The parameter `algorithm` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,104] Trial 97 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:28,106] The parameter `algorithm` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:28,181] A new study created in memory with name: Support Vector Machine Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:28,152] Trial 98 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:45:28,154] The parameter `algorithm` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,179] Trial 99 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using CmaEsSampler: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}\n",
      "Best accuracy: 0.8357, at trial: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50f2a09e34f4737b4928bd90de6e034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:28,213] Trial 0 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,215] The parameter `kernel` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,240] Trial 1 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.000865808466690932}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,242] The parameter `kernel` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,267] Trial 2 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0009528924787594206}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,269] The parameter `kernel` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,294] Trial 3 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.002651575859618515}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,297] The parameter `kernel` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,324] Trial 4 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00010702593573937491}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,326] The parameter `kernel` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,341] Trial 5 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0013648551870204498}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,342] The parameter `kernel` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,358] Trial 6 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0009741063383591005}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,359] The parameter `kernel` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,361] The parameter `degree` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,386] Trial 7 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00035536968608811256, 'degree': 5}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,388] The parameter `kernel` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,388] The parameter `degree` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,403] Trial 8 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0016819495611083031, 'degree': 2}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,405] The parameter `kernel` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,420] Trial 9 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0018375880092626332}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,420] The parameter `kernel` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,446] Trial 10 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0020594834365669262}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,448] The parameter `kernel` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,449] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,464] Trial 11 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0008036660590116804, 'degree': 3}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,466] The parameter `kernel` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,479] Trial 12 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0015484212122073447}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,481] The parameter `kernel` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,496] Trial 13 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.004325242884695832}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,497] The parameter `kernel` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,499] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,513] Trial 14 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0022625707493004244, 'degree': 2}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,515] The parameter `kernel` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,530] Trial 15 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0017640869367327792}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,532] The parameter `kernel` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,532] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,547] Trial 16 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0031705200615514424, 'degree': 2}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,549] The parameter `kernel` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,550] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,565] Trial 17 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0018222396077369667, 'degree': 3}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,566] The parameter `kernel` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,581] Trial 18 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.005630905467192243}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,583] The parameter `kernel` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,598] Trial 19 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.005221433262262516}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,599] The parameter `kernel` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,600] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,615] Trial 20 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0018417651052045892, 'degree': 5}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:28,617] The parameter `kernel` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,619] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,633] Trial 21 finished with value: 0.7762411347517731 and parameters: {'kernel': 'poly', 'C': 0.00977884880613245, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,635] The parameter `kernel` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,650] Trial 22 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.001881345134481074}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,651] The parameter `kernel` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,653] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,668] Trial 23 finished with value: 0.5400709219858155 and parameters: {'kernel': 'poly', 'C': 0.004289712110500326, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,670] The parameter `kernel` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,694] Trial 24 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0006700114198355781}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,697] The parameter `kernel` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,711] Trial 25 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0022011963612600803}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,713] The parameter `kernel` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,728] Trial 26 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00347159088889355}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,730] The parameter `kernel` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,745] Trial 27 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0005516035072493659}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,747] The parameter `kernel` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,772] Trial 28 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.006411980890096533}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,773] The parameter `kernel` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,789] Trial 29 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0017669886523862552}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,791] The parameter `kernel` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,806] Trial 30 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.008337555412880511}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,808] The parameter `kernel` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,823] Trial 31 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0008926869494284906}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,824] The parameter `kernel` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,840] Trial 32 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.002610479245482267}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,842] The parameter `kernel` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,857] Trial 33 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0007345913043414656}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,858] The parameter `kernel` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,873] Trial 34 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0019222601662566329}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,875] The parameter `kernel` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,901] Trial 35 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.007134790353855902}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,902] The parameter `kernel` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,928] Trial 36 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0009373271488059397}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,930] The parameter `kernel` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,946] Trial 37 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0004866789149311413}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,948] The parameter `kernel` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,949] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,963] Trial 38 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00010098985429115987, 'degree': 5}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,965] The parameter `kernel` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,980] Trial 39 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0007352766888107413}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:28,982] The parameter `kernel` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:28,983] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:28,998] Trial 40 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0002576976289668745, 'degree': 5}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,000] The parameter `kernel` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,001] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,015] Trial 41 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00022138338183089304, 'degree': 3}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,017] The parameter `kernel` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,042] Trial 42 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0005091240060677448}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,045] The parameter `kernel` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,059] Trial 43 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0001699240086906067}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,061] The parameter `kernel` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,076] Trial 44 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0015748479325861423}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,079] The parameter `kernel` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,080] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,094] Trial 45 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.002003612787076449, 'degree': 2}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,096] The parameter `kernel` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,097] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,111] Trial 46 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.001068819027227903, 'degree': 2}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,112] The parameter `kernel` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,127] Trial 47 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00018510697789798032}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,129] The parameter `kernel` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,154] Trial 48 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.003655986115552493}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,156] The parameter `kernel` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,181] Trial 49 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00012555687033385937}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,183] The parameter `kernel` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,198] Trial 50 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.002485109424475313}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,200] The parameter `kernel` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,201] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,216] Trial 51 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0006389495448329528, 'degree': 2}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,217] The parameter `kernel` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,218] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,232] Trial 52 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0024530577322078623, 'degree': 2}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,235] The parameter `kernel` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,236] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,250] Trial 53 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0008999429951358952, 'degree': 2}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,252] The parameter `kernel` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,253] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,266] Trial 54 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0004786724936007807, 'degree': 5}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,267] The parameter `kernel` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,269] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,293] Trial 55 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0019784233221958507, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,295] The parameter `kernel` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,321] Trial 56 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0002464344680732743}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,324] The parameter `kernel` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,338] Trial 57 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0009402589589636685}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,339] The parameter `kernel` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,341] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,365] Trial 58 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0001607860394788972, 'degree': 5}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,367] The parameter `kernel` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,382] Trial 59 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.004161981943558554}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,384] The parameter `kernel` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,385] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,399] Trial 60 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0001824456458648311, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,401] The parameter `kernel` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,402] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,416] Trial 61 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00011771115480324992, 'degree': 2}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,418] The parameter `kernel` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,418] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,433] Trial 62 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0003648337606463508, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,436] The parameter `kernel` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,459] Trial 63 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.003027051524595439}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,460] The parameter `kernel` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,475] Trial 64 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0005239419727829307}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,478] The parameter `kernel` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,492] Trial 65 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0015650364479781525}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,494] The parameter `kernel` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,519] Trial 66 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0007723813843091386}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,519] The parameter `kernel` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,549] Trial 67 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00013340755434197805}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,551] The parameter `kernel` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,566] Trial 68 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0002400982918157693}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,568] The parameter `kernel` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,593] Trial 69 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00031646856601587087}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,595] The parameter `kernel` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,620] Trial 70 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.000625535421358509}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,622] The parameter `kernel` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,648] Trial 71 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00014721107777528573}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,648] The parameter `kernel` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,675] Trial 72 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00017555527548028494}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,677] The parameter `kernel` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,677] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,693] Trial 73 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.000790905271427972, 'degree': 3}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,696] The parameter `kernel` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,721] Trial 74 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0002902366344568955}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,721] The parameter `kernel` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,721] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,738] Trial 75 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.001525574947951835, 'degree': 3}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,739] The parameter `kernel` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,741] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,755] Trial 76 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00022667857497116252, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,755] The parameter `kernel` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,755] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,773] Trial 77 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0003129414601705034, 'degree': 5}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,773] The parameter `kernel` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,773] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,790] Trial 78 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0004027625659108397, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,791] The parameter `kernel` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,817] Trial 79 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0010273968258567678}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,817] The parameter `kernel` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,817] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,834] Trial 80 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0005817027703087252, 'degree': 5}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,837] The parameter `kernel` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,851] Trial 81 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0008230179675202893}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,852] The parameter `kernel` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,878] Trial 82 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0001769064226933906}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,881] The parameter `kernel` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,906] Trial 83 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00017214833292186193}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,907] The parameter `kernel` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:29,909] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,923] Trial 84 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.000308875208697199, 'degree': 2}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,926] The parameter `kernel` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,941] Trial 85 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0005530884888319468}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,943] The parameter `kernel` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,968] Trial 86 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0002795324715597837}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,968] The parameter `kernel` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:29,985] Trial 87 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00046513584113641615}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:29,986] The parameter `kernel` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,001] Trial 88 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0012109527756871481}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,003] The parameter `kernel` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,019] Trial 89 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00028901350021244755}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,021] The parameter `kernel` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:30,022] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,036] Trial 90 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00040344069089381663, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,038] The parameter `kernel` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,054] Trial 91 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0009094847879345241}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,054] The parameter `kernel` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,081] Trial 92 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.000524016760083747}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,083] The parameter `kernel` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:30,085] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,099] Trial 93 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0004927793710650633, 'degree': 5}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,100] The parameter `kernel` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:30,204] A new study created in memory with name: AdaBoost Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:30,117] Trial 94 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0003660125322836225}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,118] The parameter `kernel` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:30,119] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,134] Trial 95 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0004511902847172314, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,135] The parameter `kernel` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:30,136] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,150] Trial 96 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0007130632691174076, 'degree': 4}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,152] The parameter `kernel` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,167] Trial 97 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0006136993637982659}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,168] The parameter `kernel` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:30,168] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,184] Trial 98 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0010233176985283434, 'degree': 2}. Best is trial 21 with value: 0.7762411347517731.\n",
      "[W 2025-12-28 19:45:30,186] The parameter `kernel` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:30,201] Trial 99 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.000742161498824266}. Best is trial 21 with value: 0.7762411347517731.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using CmaEsSampler: {'kernel': 'poly', 'C': 0.00977884880613245, 'degree': 4}\n",
      "Best accuracy: 0.7762, at trial: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b96e7cc8f4479285f0676566c97aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:30,309] Trial 0 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:45:30,387] Trial 1 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 43, 'learning_rate': 0.025476088134515826}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:45:30,464] Trial 2 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 41, 'learning_rate': 0.029414796527869724}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:45:30,575] Trial 3 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 60, 'learning_rate': 0.13653880096488336}. Best is trial 3 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:45:30,662] Trial 4 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 57, 'learning_rate': 0.0011072190527544395}. Best is trial 3 with value: 0.8143617021276596.\n",
      "[I 2025-12-28 19:45:30,731] Trial 5 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 36, 'learning_rate': 0.08721915368491258}. Best is trial 5 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:45:30,799] Trial 6 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 39, 'learning_rate': 0.11322743764742889}. Best is trial 5 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:45:30,848] Trial 7 finished with value: 0.801595744680851 and parameters: {'n_estimators': 19, 'learning_rate': 0.19954026122594948}. Best is trial 5 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:45:30,926] Trial 8 finished with value: 0.810017730496454 and parameters: {'n_estimators': 45, 'learning_rate': 0.07240897655300367}. Best is trial 5 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:45:31,005] Trial 9 finished with value: 0.81427304964539 and parameters: {'n_estimators': 49, 'learning_rate': 0.13878531436424396}. Best is trial 5 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:45:31,113] Trial 10 finished with value: 0.8186170212765956 and parameters: {'n_estimators': 65, 'learning_rate': 0.12930336354417177}. Best is trial 10 with value: 0.8186170212765956.\n",
      "[I 2025-12-28 19:45:31,203] Trial 11 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 57, 'learning_rate': 0.05697947131264073}. Best is trial 10 with value: 0.8186170212765956.\n",
      "[I 2025-12-28 19:45:31,280] Trial 12 finished with value: 0.810017730496454 and parameters: {'n_estimators': 47, 'learning_rate': 0.1389907895174507}. Best is trial 10 with value: 0.8186170212765956.\n",
      "[I 2025-12-28 19:45:31,380] Trial 13 finished with value: 0.8226950354609928 and parameters: {'n_estimators': 63, 'learning_rate': 0.15495768689883024}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:31,489] Trial 14 finished with value: 0.8015070921985817 and parameters: {'n_estimators': 67, 'learning_rate': 0.16289956132669542}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:31,579] Trial 15 finished with value: 0.8184397163120568 and parameters: {'n_estimators': 54, 'learning_rate': 0.8250848775175008}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:31,699] Trial 16 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 81, 'learning_rate': 0.08102796151068065}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:31,800] Trial 17 finished with value: 0.8184397163120567 and parameters: {'n_estimators': 62, 'learning_rate': 0.7895030194384841}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:31,899] Trial 18 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 60, 'learning_rate': 0.10568995665739332}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,009] Trial 19 finished with value: 0.7931737588652482 and parameters: {'n_estimators': 71, 'learning_rate': 0.35731147191657675}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,107] Trial 20 finished with value: 0.8141843971631205 and parameters: {'n_estimators': 61, 'learning_rate': 0.5481506149431028}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,188] Trial 21 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 45, 'learning_rate': 0.6910450014834031}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,286] Trial 22 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 61, 'learning_rate': 0.05251135886725196}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,355] Trial 23 finished with value: 0.81427304964539 and parameters: {'n_estimators': 37, 'learning_rate': 0.21499414520298635}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,443] Trial 24 finished with value: 0.801595744680851 and parameters: {'n_estimators': 59, 'learning_rate': 0.06401734434632904}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,514] Trial 25 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 42, 'learning_rate': 0.03618567066766231}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,580] Trial 26 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 38, 'learning_rate': 0.027728946674603953}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,679] Trial 27 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 60, 'learning_rate': 0.3355003101088986}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,727] Trial 28 finished with value: 0.801595744680851 and parameters: {'n_estimators': 20, 'learning_rate': 0.6303480127390058}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,838] Trial 29 finished with value: 0.810017730496454 and parameters: {'n_estimators': 71, 'learning_rate': 0.20329971264703486}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:32,916] Trial 30 finished with value: 0.81427304964539 and parameters: {'n_estimators': 48, 'learning_rate': 0.22007769246148243}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,019] Trial 31 finished with value: 0.81427304964539 and parameters: {'n_estimators': 63, 'learning_rate': 0.4190299139745699}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,096] Trial 32 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 47, 'learning_rate': 0.19689267993752638}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,198] Trial 33 finished with value: 0.810017730496454 and parameters: {'n_estimators': 61, 'learning_rate': 0.2708736674829924}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,285] Trial 34 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 54, 'learning_rate': 0.11443809637533259}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,366] Trial 35 finished with value: 0.81427304964539 and parameters: {'n_estimators': 48, 'learning_rate': 0.24664172558452369}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,464] Trial 36 finished with value: 0.81427304964539 and parameters: {'n_estimators': 60, 'learning_rate': 0.05430485620938505}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,565] Trial 37 finished with value: 0.8098404255319149 and parameters: {'n_estimators': 55, 'learning_rate': 0.41690264800951493}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,652] Trial 38 finished with value: 0.801595744680851 and parameters: {'n_estimators': 57, 'learning_rate': 0.528113046602069}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,742] Trial 39 finished with value: 0.8014184397163122 and parameters: {'n_estimators': 58, 'learning_rate': 0.4847038442088924}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,820] Trial 40 finished with value: 0.7973404255319149 and parameters: {'n_estimators': 48, 'learning_rate': 0.5028374529547955}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:33,920] Trial 41 finished with value: 0.7930851063829787 and parameters: {'n_estimators': 64, 'learning_rate': 0.5131466574035061}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,018] Trial 42 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 65, 'learning_rate': 0.959084709369695}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,119] Trial 43 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 65, 'learning_rate': 0.3813293562370776}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,206] Trial 44 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 59, 'learning_rate': 0.39604745882445286}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,285] Trial 45 finished with value: 0.801595744680851 and parameters: {'n_estimators': 48, 'learning_rate': 0.37226551480651343}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,373] Trial 46 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 55, 'learning_rate': 0.2499547154190399}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,474] Trial 47 finished with value: 0.8098404255319149 and parameters: {'n_estimators': 63, 'learning_rate': 0.4109675039853497}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,571] Trial 48 finished with value: 0.81427304964539 and parameters: {'n_estimators': 66, 'learning_rate': 0.2872315479002801}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,682] Trial 49 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 70, 'learning_rate': 0.34468881470385276}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,779] Trial 50 finished with value: 0.8184397163120568 and parameters: {'n_estimators': 62, 'learning_rate': 0.6125827288443784}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,890] Trial 51 finished with value: 0.81427304964539 and parameters: {'n_estimators': 70, 'learning_rate': 0.22907120360085562}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:34,989] Trial 52 finished with value: 0.8183510638297873 and parameters: {'n_estimators': 63, 'learning_rate': 0.5803967289184502}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,088] Trial 53 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 63, 'learning_rate': 0.7491409484111382}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,186] Trial 54 finished with value: 0.8182624113475179 and parameters: {'n_estimators': 62, 'learning_rate': 0.5823351685378945}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,275] Trial 55 finished with value: 0.8099290780141845 and parameters: {'n_estimators': 58, 'learning_rate': 0.5574806736148288}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,374] Trial 56 finished with value: 0.7973404255319149 and parameters: {'n_estimators': 61, 'learning_rate': 0.4994060123547848}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,462] Trial 57 finished with value: 0.8056737588652482 and parameters: {'n_estimators': 55, 'learning_rate': 0.4324482741100626}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,549] Trial 58 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 58, 'learning_rate': 0.28496744264851637}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,650] Trial 59 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 63, 'learning_rate': 0.2656916177869112}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,740] Trial 60 finished with value: 0.810017730496454 and parameters: {'n_estimators': 58, 'learning_rate': 0.24354998758525195}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,842] Trial 61 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 63, 'learning_rate': 0.10094945132764681}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:35,939] Trial 62 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 62, 'learning_rate': 0.07934638459189447}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:36,040] Trial 63 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 55, 'learning_rate': 0.09270183267049399}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:36,139] Trial 64 finished with value: 0.801595744680851 and parameters: {'n_estimators': 64, 'learning_rate': 0.26161880047826996}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:36,241] Trial 65 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 62, 'learning_rate': 0.40131426276020904}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:36,330] Trial 66 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 60, 'learning_rate': 0.4941877998612038}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:36,421] Trial 67 finished with value: 0.8141843971631205 and parameters: {'n_estimators': 58, 'learning_rate': 0.4629433127280133}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:36,520] Trial 68 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 66, 'learning_rate': 0.23218236690163616}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:36,622] Trial 69 finished with value: 0.81427304964539 and parameters: {'n_estimators': 59, 'learning_rate': 0.10937714203577135}. Best is trial 13 with value: 0.8226950354609928.\n",
      "[I 2025-12-28 19:45:36,731] Trial 70 finished with value: 0.8268617021276595 and parameters: {'n_estimators': 72, 'learning_rate': 0.5602864813134}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:36,822] Trial 71 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 58, 'learning_rate': 0.02304558752307114}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:36,920] Trial 72 finished with value: 0.725531914893617 and parameters: {'n_estimators': 63, 'learning_rate': 0.007282904450320345}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,021] Trial 73 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 63, 'learning_rate': 0.28329639942326323}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,130] Trial 74 finished with value: 0.810017730496454 and parameters: {'n_estimators': 67, 'learning_rate': 0.16419872126120272}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,220] Trial 75 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 58, 'learning_rate': 0.6640692429030672}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,329] Trial 76 finished with value: 0.8141843971631207 and parameters: {'n_estimators': 66, 'learning_rate': 0.3934544899899819}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,432] Trial 77 finished with value: 0.7974290780141843 and parameters: {'n_estimators': 64, 'learning_rate': 0.9714912649423385}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,529] Trial 78 finished with value: 0.8141843971631205 and parameters: {'n_estimators': 65, 'learning_rate': 0.183278777976456}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,632] Trial 79 finished with value: 0.8184397163120567 and parameters: {'n_estimators': 63, 'learning_rate': 0.7804310115175468}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,741] Trial 80 finished with value: 0.810017730496454 and parameters: {'n_estimators': 68, 'learning_rate': 0.20887695936400283}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,852] Trial 81 finished with value: 0.8226950354609928 and parameters: {'n_estimators': 66, 'learning_rate': 0.14782253245627963}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:37,952] Trial 82 finished with value: 0.8184397163120568 and parameters: {'n_estimators': 65, 'learning_rate': 0.2958491166411213}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:38,062] Trial 83 finished with value: 0.8227836879432624 and parameters: {'n_estimators': 72, 'learning_rate': 0.13492687866579095}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:38,163] Trial 84 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 65, 'learning_rate': 0.2691610676563794}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:38,275] Trial 85 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 77, 'learning_rate': 0.0739108707875402}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:38,397] Trial 86 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 82, 'learning_rate': 0.028816363388350145}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:38,516] Trial 87 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 85, 'learning_rate': 0.01850736981997407}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:38,617] Trial 88 finished with value: 0.810017730496454 and parameters: {'n_estimators': 67, 'learning_rate': 0.7051820457200599}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:38,762] Trial 89 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 85, 'learning_rate': 0.016419127549471824}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:38,884] Trial 90 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 81, 'learning_rate': 0.03761078735160979}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:39,005] Trial 91 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 81, 'learning_rate': 0.070939154409377}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:39,134] Trial 92 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 84, 'learning_rate': 0.04526457787339213}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:39,254] Trial 93 finished with value: 0.7252659574468086 and parameters: {'n_estimators': 74, 'learning_rate': 0.004079108268831968}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:39,354] Trial 94 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 67, 'learning_rate': 0.0686800302192512}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:39,485] Trial 95 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 84, 'learning_rate': 0.01918936637680413}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:39,615] Trial 96 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 89, 'learning_rate': 0.031199944787663483}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:39,715] Trial 97 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 63, 'learning_rate': 0.01961468197958464}. Best is trial 70 with value: 0.8268617021276595.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:39,977] A new study created in memory with name: Gradient Boosting Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:39,844] Trial 98 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 87, 'learning_rate': 0.05555255063706087}. Best is trial 70 with value: 0.8268617021276595.\n",
      "[I 2025-12-28 19:45:39,975] Trial 99 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 94, 'learning_rate': 0.016547992120549405}. Best is trial 70 with value: 0.8268617021276595.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using CmaEsSampler: {'n_estimators': 72, 'learning_rate': 0.5602864813134}\n",
      "Best accuracy: 0.8269, at trial: 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5172031ffcec46efbd6ded46c91fccbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:40,083] Trial 0 finished with value: 0.788741134751773 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.788741134751773.\n",
      "[W 2025-12-28 19:45:40,085] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,195] Trial 1 finished with value: 0.7677304964539008 and parameters: {'max_features': None, 'n_estimators': 57, 'learning_rate': 0.008658084666909323, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8397600270730616}. Best is trial 0 with value: 0.788741134751773.\n",
      "[W 2025-12-28 19:45:40,198] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,296] Trial 2 finished with value: 0.788741134751773 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.009528924787594208, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.8029297907760695}. Best is trial 0 with value: 0.788741134751773.\n",
      "[W 2025-12-28 19:45:40,299] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,367] Trial 3 finished with value: 0.7678191489361701 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.026515758596185147, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7269530336476903}. Best is trial 0 with value: 0.788741134751773.\n",
      "[W 2025-12-28 19:45:40,369] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,426] Trial 4 finished with value: 0.52322695035461 and parameters: {'max_features': None, 'n_estimators': 24, 'learning_rate': 0.0010702593573937475, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7677248753915946}. Best is trial 0 with value: 0.788741134751773.\n",
      "[W 2025-12-28 19:45:40,428] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,515] Trial 5 finished with value: 0.785017730496454 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.019667141639294356, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.7115398922202714}. Best is trial 0 with value: 0.788741134751773.\n",
      "[W 2025-12-28 19:45:40,517] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,596] Trial 6 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 47, 'learning_rate': 0.02340459441539314, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.7681058459555117}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:40,599] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,668] Trial 7 finished with value: 0.7932624113475176 and parameters: {'max_features': 'log2', 'n_estimators': 35, 'learning_rate': 0.01959654330798669, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7131820938134579}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:40,670] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,737] Trial 8 finished with value: 0.7846631205673759 and parameters: {'max_features': 'sqrt', 'n_estimators': 29, 'learning_rate': 0.028171880519557702, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.8047109221769}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:40,740] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,838] Trial 9 finished with value: 0.8057624113475178 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.011695860437734951, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.757470058328777}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:40,841] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,898] Trial 10 finished with value: 0.801595744680851 and parameters: {'max_features': None, 'n_estimators': 36, 'learning_rate': 0.010748731396537764, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 8, 'subsample': 0.6619730323140252}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:40,901] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:40,969] Trial 11 finished with value: 0.7805851063829787 and parameters: {'max_features': None, 'n_estimators': 35, 'learning_rate': 0.015441036213472214, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7831514021152561}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:40,971] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,091] Trial 12 finished with value: 0.7848404255319148 and parameters: {'max_features': 'log2', 'n_estimators': 83, 'learning_rate': 0.016347783786097, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.6980034325781809}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,095] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,183] Trial 13 finished with value: 0.7847517730496454 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.04658111962761048, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.9630823902967601}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,185] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,339] Trial 14 finished with value: 0.7510638297872341 and parameters: {'max_features': None, 'n_estimators': 64, 'learning_rate': 0.005411394463324009, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.9969077215942912}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,341] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,440] Trial 15 finished with value: 0.8058510638297871 and parameters: {'max_features': 'log2', 'n_estimators': 63, 'learning_rate': 0.016822321634372642, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 2, 'subsample': 0.7514588676665623}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,442] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,509] Trial 16 finished with value: 0.8058510638297871 and parameters: {'max_features': 'log2', 'n_estimators': 36, 'learning_rate': 0.013337777790822574, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.8470221945621772}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,513] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,609] Trial 17 finished with value: 0.7679078014184396 and parameters: {'max_features': None, 'n_estimators': 47, 'learning_rate': 0.03435729514577486, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.8146238512290335}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,609] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,709] Trial 18 finished with value: 0.776241134751773 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.0311389878449006, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.8030761245490746}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,713] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,832] Trial 19 finished with value: 0.7848404255319149 and parameters: {'max_features': None, 'n_estimators': 74, 'learning_rate': 0.008972470499904014, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7467800278701251}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,834] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:41,943] Trial 20 finished with value: 0.8055851063829786 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.003212345145578249, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.7802196860466954}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:41,943] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,033] Trial 21 finished with value: 0.801595744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 68, 'learning_rate': 0.016275822900170284, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.8587549781695702}. Best is trial 6 with value: 0.810017730496454.\n",
      "[W 2025-12-28 19:45:42,035] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,113] Trial 22 finished with value: 0.8184397163120568 and parameters: {'max_features': 'log2', 'n_estimators': 50, 'learning_rate': 0.05520392313997818, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.799816101953481}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,115] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,193] Trial 23 finished with value: 0.801595744680851 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.02290422833005936, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.6994528079608591}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,195] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,303] Trial 24 finished with value: 0.7721631205673759 and parameters: {'max_features': None, 'n_estimators': 56, 'learning_rate': 0.014080431946699045, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.815766351729212}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,305] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,371] Trial 25 finished with value: 0.8143617021276596 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.00982550178028511, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7331051504315822}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,373] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,484] Trial 26 finished with value: 0.7761524822695035 and parameters: {'max_features': None, 'n_estimators': 60, 'learning_rate': 0.014973089219732, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.7218568917136452}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,486] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,563] Trial 27 finished with value: 0.8059397163120569 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.011738082000522714, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.7484352312442488}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,565] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,674] Trial 28 finished with value: 0.7763297872340426 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.014174431757605424, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.8116102222719072}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,676] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,732] Trial 29 finished with value: 0.7933510638297872 and parameters: {'max_features': 'log2', 'n_estimators': 42, 'learning_rate': 0.02316912336265272, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2, 'subsample': 0.7598086759080382}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,732] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,811] Trial 30 finished with value: 0.8015070921985815 and parameters: {'max_features': 'sqrt', 'n_estimators': 48, 'learning_rate': 0.03442286846557137, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.7568034754666061}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,813] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:42,962] Trial 31 finished with value: 0.776063829787234 and parameters: {'max_features': None, 'n_estimators': 65, 'learning_rate': 0.055571729449209614, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.68632120576383}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:42,962] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,052] Trial 32 finished with value: 0.7930851063829787 and parameters: {'max_features': None, 'n_estimators': 60, 'learning_rate': 0.012044179334163845, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6346087680862642}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,056] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,133] Trial 33 finished with value: 0.7848404255319148 and parameters: {'max_features': None, 'n_estimators': 42, 'learning_rate': 0.021266464777045937, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.8088556630127541}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,133] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,212] Trial 34 finished with value: 0.7764184397163121 and parameters: {'max_features': None, 'n_estimators': 52, 'learning_rate': 0.026703050824327175, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.8470123207342295}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,214] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,260] Trial 35 finished with value: 0.7976063829787234 and parameters: {'max_features': 'log2', 'n_estimators': 32, 'learning_rate': 0.01758875329980893, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.78449166257416}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,260] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,352] Trial 36 finished with value: 0.8017730496453901 and parameters: {'max_features': 'log2', 'n_estimators': 60, 'learning_rate': 0.011665480635233384, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.773619941912819}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,354] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,401] Trial 37 finished with value: 0.8098404255319149 and parameters: {'max_features': 'log2', 'n_estimators': 38, 'learning_rate': 0.005813912630941533, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.720169867777923}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,401] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,489] Trial 38 finished with value: 0.8015070921985817 and parameters: {'max_features': 'log2', 'n_estimators': 59, 'learning_rate': 0.015913316057814826, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.6675222596396508}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,492] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,599] Trial 39 finished with value: 0.7678191489361702 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.006903417532148276, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7731037902163043}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,601] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,691] Trial 40 finished with value: 0.814095744680851 and parameters: {'max_features': 'log2', 'n_estimators': 60, 'learning_rate': 0.008658763565369692, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.7970467043388061}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,694] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,750] Trial 41 finished with value: 0.7974290780141844 and parameters: {'max_features': 'sqrt', 'n_estimators': 42, 'learning_rate': 0.013978026852222202, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.7380667341763819}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,752] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,861] Trial 42 finished with value: 0.763563829787234 and parameters: {'max_features': None, 'n_estimators': 54, 'learning_rate': 0.007788432486331105, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.7801826013376045}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,864] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:43,963] Trial 43 finished with value: 0.7847517730496454 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.04015127443037732, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.789995385213615}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:43,966] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,075] Trial 44 finished with value: 0.8182624113475179 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.01073678935151566, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.7003606189376475}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:44,078] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,154] Trial 45 finished with value: 0.801595744680851 and parameters: {'max_features': 'log2', 'n_estimators': 58, 'learning_rate': 0.01790186906262893, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7703290737846953}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:44,157] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,257] Trial 46 finished with value: 0.7634751773049646 and parameters: {'max_features': None, 'n_estimators': 52, 'learning_rate': 0.017687007875882656, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7292788286748904}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:44,260] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,359] Trial 47 finished with value: 0.7975177304964539 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.007128674146064242, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.730700175435856}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:44,361] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,429] Trial 48 finished with value: 0.788741134751773 and parameters: {'max_features': 'sqrt', 'n_estimators': 48, 'learning_rate': 0.012034105457474312, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.7618125236206088}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:44,432] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,541] Trial 49 finished with value: 0.7969858156028369 and parameters: {'max_features': 'log2', 'n_estimators': 55, 'learning_rate': 0.005725517519533638, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 1, 'subsample': 0.7745687526767641}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:44,544] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,633] Trial 50 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.0033837330532693628, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.7219615115761713}. Best is trial 22 with value: 0.8184397163120568.\n",
      "[W 2025-12-28 19:45:44,635] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,735] Trial 51 finished with value: 0.8227836879432623 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.005235902569264692, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.6862618218190607}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:44,738] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,837] Trial 52 finished with value: 0.7973404255319149 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.010711146211016275, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9036029430781675}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:44,840] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:44,919] Trial 53 finished with value: 0.810017730496454 and parameters: {'max_features': 'sqrt', 'n_estimators': 62, 'learning_rate': 0.0052455022718266055, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.7973010892881898}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:44,922] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,054] Trial 54 finished with value: 0.771985815602837 and parameters: {'max_features': None, 'n_estimators': 73, 'learning_rate': 0.009074100635215344, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7985150663502554}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,058] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,136] Trial 55 finished with value: 0.8016843971631206 and parameters: {'max_features': 'log2', 'n_estimators': 59, 'learning_rate': 0.009543989845664562, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.7168122715014262}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,138] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,253] Trial 56 finished with value: 0.7718971631205673 and parameters: {'max_features': None, 'n_estimators': 52, 'learning_rate': 0.0024553466631647976, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.6862290546980205}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,255] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,333] Trial 57 finished with value: 0.8101950354609929 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.012092056758881715, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.6868003286976568}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,336] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,435] Trial 58 finished with value: 0.7762411347517731 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.006265800123895016, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7330295444784037}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,438] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,516] Trial 59 finished with value: 0.814095744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.003394201509077508, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6490863984643414}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,516] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,615] Trial 60 finished with value: 0.801418439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 46, 'learning_rate': 0.007981985846669482, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7987510282525273}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,616] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,695] Trial 61 finished with value: 0.776063829787234 and parameters: {'max_features': None, 'n_estimators': 48, 'learning_rate': 0.0029530167869503397, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.6835050627230155}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,697] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,838] Trial 62 finished with value: 0.7971631205673758 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.0028010000083593797, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2, 'subsample': 0.6589406667236145}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,841] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:45,959] Trial 63 finished with value: 0.7677304964539007 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.017496087753177333, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8559671763244256}. Best is trial 51 with value: 0.8227836879432623.\n",
      "[W 2025-12-28 19:45:45,962] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,071] Trial 64 finished with value: 0.8228723404255318 and parameters: {'max_features': 'sqrt', 'n_estimators': 61, 'learning_rate': 0.004843258306892117, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7027116044528738}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,074] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,162] Trial 65 finished with value: 0.7930851063829787 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.003234703744750534, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.652269946431523}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,162] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,230] Trial 66 finished with value: 0.8098404255319149 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.005427839943028157, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.678871904396366}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,230] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,320] Trial 67 finished with value: 0.7802304964539009 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.0025870463073388735, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6704300878993432}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,321] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,421] Trial 68 finished with value: 0.8101950354609929 and parameters: {'max_features': 'log2', 'n_estimators': 55, 'learning_rate': 0.008686037110618276, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.7582285529424904}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,423] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,491] Trial 69 finished with value: 0.8101063829787234 and parameters: {'max_features': 'log2', 'n_estimators': 36, 'learning_rate': 0.007013814085785641, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 1, 'subsample': 0.7179073204336892}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,491] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,570] Trial 70 finished with value: 0.8014184397163122 and parameters: {'max_features': 'log2', 'n_estimators': 57, 'learning_rate': 0.002965011927957733, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.5772691140656214}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,570] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,641] Trial 71 finished with value: 0.7973404255319148 and parameters: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.012066828205683697, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1, 'subsample': 0.6002370308219505}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,642] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,700] Trial 72 finished with value: 0.8097517730496454 and parameters: {'max_features': 'log2', 'n_estimators': 44, 'learning_rate': 0.009712379740243575, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.6644066771071249}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,702] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,813] Trial 73 finished with value: 0.7971631205673759 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.0069854495025956165, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.6678274111066054}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,813] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:46,923] Trial 74 finished with value: 0.8015070921985815 and parameters: {'max_features': 'sqrt', 'n_estimators': 58, 'learning_rate': 0.008857649512456088, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7299120151351555}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:46,923] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,022] Trial 75 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 56, 'learning_rate': 0.00818301938206445, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.6789649529236776}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,025] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,104] Trial 76 finished with value: 0.822695035460993 and parameters: {'max_features': 'log2', 'n_estimators': 50, 'learning_rate': 0.00884724397451278, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.7517257171483263}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,107] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,184] Trial 77 finished with value: 0.8056737588652482 and parameters: {'max_features': 'log2', 'n_estimators': 57, 'learning_rate': 0.0035216081172682713, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.690248112161781}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,184] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,293] Trial 78 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.0031023992743642193, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.6552994177677638}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,297] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,405] Trial 79 finished with value: 0.775886524822695 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.002227606501243069, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.6204038725967918}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,408] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,505] Trial 80 finished with value: 0.7929964539007093 and parameters: {'max_features': 'log2', 'n_estimators': 59, 'learning_rate': 0.0026528987073857323, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.6652747055138898}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,507] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,575] Trial 81 finished with value: 0.8186170212765959 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.013309237765878836, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.7777837118913675}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,578] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,647] Trial 82 finished with value: 0.7974290780141844 and parameters: {'max_features': 'sqrt', 'n_estimators': 46, 'learning_rate': 0.012641608109274241, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.7275170916277915}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,650] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,707] Trial 83 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.011536724473128989, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7179088961578761}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,709] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,808] Trial 84 finished with value: 0.7803191489361703 and parameters: {'max_features': None, 'n_estimators': 53, 'learning_rate': 0.02066668693237781, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.6431190498957928}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,811] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,890] Trial 85 finished with value: 0.7930851063829787 and parameters: {'max_features': 'sqrt', 'n_estimators': 58, 'learning_rate': 0.010401105668156418, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.83898832159702}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,892] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:47,991] Trial 86 finished with value: 0.7890070921985816 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.007963295741888192, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.6576341990863528}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:47,995] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,083] Trial 87 finished with value: 0.7974290780141844 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.008267363587195965, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7044084144247893}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:48,086] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,164] Trial 88 finished with value: 0.7765070921985816 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.013098921309577063, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7757920322472243}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:48,167] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,246] Trial 89 finished with value: 0.8057624113475177 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.008338225844919224, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.7489993218324127}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:48,248] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,358] Trial 90 finished with value: 0.8058510638297873 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.008588293029656996, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7422478751899332}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:48,363] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,429] Trial 91 finished with value: 0.8015070921985815 and parameters: {'max_features': 'log2', 'n_estimators': 40, 'learning_rate': 0.007704388464900342, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.8082618856756826}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:48,432] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,556] Trial 92 finished with value: 0.7678191489361701 and parameters: {'max_features': None, 'n_estimators': 43, 'learning_rate': 0.018353862120137763, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.8001162450538908}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:48,560] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,646] Trial 93 finished with value: 0.7761524822695035 and parameters: {'max_features': None, 'n_estimators': 44, 'learning_rate': 0.015211497867958012, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7525243591383245}. Best is trial 64 with value: 0.8228723404255318.\n",
      "[W 2025-12-28 19:45:48,648] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,747] Trial 94 finished with value: 0.82677304964539 and parameters: {'max_features': 'log2', 'n_estimators': 57, 'learning_rate': 0.009210476518456951, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6999388305477132}. Best is trial 94 with value: 0.82677304964539.\n",
      "[W 2025-12-28 19:45:48,750] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,850] Trial 95 finished with value: 0.814095744680851 and parameters: {'max_features': 'log2', 'n_estimators': 54, 'learning_rate': 0.006701338463848853, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.682706715329727}. Best is trial 94 with value: 0.82677304964539.\n",
      "[W 2025-12-28 19:45:48,852] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:48,941] Trial 96 finished with value: 0.7549645390070923 and parameters: {'max_features': None, 'n_estimators': 41, 'learning_rate': 0.012419538211655414, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.731337285544524}. Best is trial 94 with value: 0.82677304964539.\n",
      "[W 2025-12-28 19:45:48,944] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,047] Trial 97 finished with value: 0.8228723404255319 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.013658860565524903, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.6902281904966955}. Best is trial 94 with value: 0.82677304964539.\n",
      "[W 2025-12-28 19:45:49,049] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,127] Trial 98 finished with value: 0.763563829787234 and parameters: {'max_features': None, 'n_estimators': 38, 'learning_rate': 0.03426627655006743, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7255510779139377}. Best is trial 94 with value: 0.82677304964539.\n",
      "[W 2025-12-28 19:45:49,130] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,219] Trial 99 finished with value: 0.7679078014184397 and parameters: {'max_features': None, 'n_estimators': 52, 'learning_rate': 0.013262370442438354, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.7295316754982364}. Best is trial 94 with value: 0.82677304964539.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using CmaEsSampler: {'max_features': 'log2', 'n_estimators': 57, 'learning_rate': 0.009210476518456951, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6999388305477132}\n",
      "Best accuracy: 0.8268, at trial: 94\n",
      "CMA-ES Base Models Training Time: 46.42 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    cmaes_base_models_training_start = time.time()\n",
    "\n",
    "    # CMA-ES Hyperparameter Tuning with Cross Validation\n",
    "    cmaes_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    cmaes_logistic_regression.fit(X_train, y_train)\n",
    "    cmaes_decision_tree.fit(X_train, y_train)\n",
    "    cmaes_random_forest.fit(X_train, y_train)\n",
    "    cmaes_knn.fit(X_train, y_train)\n",
    "    cmaes_svc.fit(X_train, y_train)\n",
    "    cmaes_adaboost.fit(X_train, y_train)\n",
    "    cmaes_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    cmaes_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for CMA-ES base models training\n",
    "    cmaes_base_models_training_time = cmaes_base_models_training_end - cmaes_base_models_training_start\n",
    "    print(f'CMA-ES Base Models Training Time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping CMA-ES base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:45:49,514] A new study created in memory with name: Logistic Regression Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f365b37ee5b44db49474e44041f0d6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:49,566] Trial 0 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:49,569] The parameter `solver` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,606] Trial 1 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cholesky', 'C': 0.00010000000000000009}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:45:49,607] The parameter `solver` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,643] Trial 2 finished with value: 0.8354609929078014 and parameters: {'solver': 'newton-cholesky', 'C': 0.0316227766016838}. Best is trial 2 with value: 0.8354609929078014.\n",
      "[W 2025-12-28 19:45:49,646] The parameter `solver` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,681] Trial 3 finished with value: 0.8144503546099291 and parameters: {'solver': 'sag', 'C': 0.5623413251903494}. Best is trial 2 with value: 0.8354609929078014.\n",
      "[W 2025-12-28 19:45:49,682] The parameter `solver` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,718] Trial 4 finished with value: 0.7045212765957446 and parameters: {'solver': 'sag', 'C': 0.0017782794100389236}. Best is trial 2 with value: 0.8354609929078014.\n",
      "[W 2025-12-28 19:45:49,718] The parameter `solver` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,754] Trial 5 finished with value: 0.8182624113475179 and parameters: {'solver': 'sag', 'C': 0.007498942093324564}. Best is trial 2 with value: 0.8354609929078014.\n",
      "[W 2025-12-28 19:45:49,756] The parameter `solver` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,792] Trial 6 finished with value: 0.81427304964539 and parameters: {'solver': 'lbfgs', 'C': 2.371373705661655}. Best is trial 2 with value: 0.8354609929078014.\n",
      "[W 2025-12-28 19:45:49,792] The parameter `solver` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,829] Trial 7 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cg', 'C': 0.13335214321633232}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:49,830] The parameter `solver` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,866] Trial 8 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.00042169650342858235}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:49,866] The parameter `solver` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,903] Trial 9 finished with value: 0.527482269503546 and parameters: {'solver': 'newton-cg', 'C': 0.000865964323360066}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:49,903] The parameter `solver` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,940] Trial 10 finished with value: 0.8355496453900708 and parameters: {'solver': 'newton-cholesky', 'C': 0.27384196342643613}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:49,940] The parameter `solver` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:49,977] Trial 11 finished with value: 0.81427304964539 and parameters: {'solver': 'lbfgs', 'C': 4.8696752516586255}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:49,979] The parameter `solver` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,013] Trial 12 finished with value: 0.8395390070921985 and parameters: {'solver': 'newton-cg', 'C': 0.015399265260594926}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:50,013] The parameter `solver` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,050] Trial 13 finished with value: 0.8015070921985815 and parameters: {'solver': 'newton-cholesky', 'C': 0.0036517412725483775}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:50,050] The parameter `solver` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,224] Trial 14 finished with value: 0.8185283687943261 and parameters: {'solver': 'sag', 'C': 1.1547819846894576}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:50,224] The parameter `solver` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,260] Trial 15 finished with value: 0.8355496453900709 and parameters: {'solver': 'newton-cg', 'C': 0.06493816315762112}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:50,260] The parameter `solver` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,297] Trial 16 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cholesky', 'C': 0.0002053525026457149}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:50,297] The parameter `solver` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,334] Trial 17 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.0002942727176209287}. Best is trial 7 with value: 0.8397163120567376.\n",
      "[W 2025-12-28 19:45:50,334] The parameter `solver` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,370] Trial 18 finished with value: 0.8439716312056736 and parameters: {'solver': 'lbfgs', 'C': 0.0930572040929699}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,370] The parameter `solver` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,407] Trial 19 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 1.6548170999431808}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,407] The parameter `solver` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,445] Trial 20 finished with value: 0.8182624113475176 and parameters: {'solver': 'lbfgs', 'C': 0.005232991146814949}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,447] The parameter `solver` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,482] Trial 21 finished with value: 0.839627659574468 and parameters: {'solver': 'sag', 'C': 0.022067340690845896}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,484] The parameter `solver` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,519] Trial 22 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 6.978305848598657}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,521] The parameter `solver` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,556] Trial 23 finished with value: 0.8228723404255319 and parameters: {'solver': 'newton-cg', 'C': 0.3924189758484537}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,558] The parameter `solver` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,595] Trial 24 finished with value: 0.6159574468085106 and parameters: {'solver': 'lbfgs', 'C': 0.0012409377607517208}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,595] The parameter `solver` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,633] Trial 25 finished with value: 0.52322695035461 and parameters: {'solver': 'sag', 'C': 0.0006042963902381332}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,633] The parameter `solver` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,671] Trial 26 finished with value: 0.8313829787234042 and parameters: {'solver': 'newton-cholesky', 'C': 0.19109529749704401}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,671] The parameter `solver` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,708] Trial 27 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 3.39820832894256}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,708] The parameter `solver` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,745] Trial 28 finished with value: 0.8310283687943262 and parameters: {'solver': 'newton-cholesky', 'C': 0.010746078283213176}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,745] The parameter `solver` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,782] Trial 29 finished with value: 0.7931737588652482 and parameters: {'solver': 'newton-cg', 'C': 0.0025482967479793462}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,782] The parameter `solver` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,819] Trial 30 finished with value: 0.8185283687943261 and parameters: {'solver': 'lbfgs', 'C': 0.8058421877614811}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,819] The parameter `solver` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,855] Trial 31 finished with value: 0.8355496453900709 and parameters: {'solver': 'newton-cholesky', 'C': 0.045315836376008195}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,856] The parameter `solver` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,893] Trial 32 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00014330125702369644}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,893] The parameter `solver` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,930] Trial 33 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.00017154378963428796}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,930] The parameter `solver` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:50,966] Trial 34 finished with value: 0.8356382978723405 and parameters: {'solver': 'newton-cholesky', 'C': 0.05424690937011324}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:50,966] The parameter `solver` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,003] Trial 35 finished with value: 0.8185283687943261 and parameters: {'solver': 'newton-cg', 'C': 0.9646616199111994}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,005] The parameter `solver` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,040] Trial 36 finished with value: 0.8056737588652482 and parameters: {'solver': 'newton-cg', 'C': 0.0030505278902670284}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,042] The parameter `solver` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,076] Trial 37 finished with value: 0.8310283687943262 and parameters: {'solver': 'newton-cg', 'C': 0.01286396944936975}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,077] The parameter `solver` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,113] Trial 38 finished with value: 0.81427304964539 and parameters: {'solver': 'newton-cg', 'C': 4.067944321083045}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,114] The parameter `solver` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,150] Trial 39 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.22875732003183954}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,152] The parameter `solver` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,188] Trial 40 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0007233941627366753}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,188] The parameter `solver` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,225] Trial 41 finished with value: 0.6624113475177305 and parameters: {'solver': 'lbfgs', 'C': 0.0014855080171727755}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,225] The parameter `solver` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,262] Trial 42 finished with value: 0.8144503546099291 and parameters: {'solver': 'newton-cg', 'C': 0.469758881670649}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,262] The parameter `solver` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,298] Trial 43 finished with value: 0.8184397163120568 and parameters: {'solver': 'sag', 'C': 8.353625469578262}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,298] The parameter `solver` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,335] Trial 44 finished with value: 0.8354609929078014 and parameters: {'solver': 'newton-cg', 'C': 0.026416483203860926}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,335] The parameter `solver` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,372] Trial 45 finished with value: 0.8225177304964539 and parameters: {'solver': 'newton-cg', 'C': 0.00626433536656886}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,372] The parameter `solver` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,408] Trial 46 finished with value: 0.81427304964539 and parameters: {'solver': 'newton-cg', 'C': 1.9809567785503366}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,408] The parameter `solver` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,445] Trial 47 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.11139738599948026}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,445] The parameter `solver` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,483] Trial 48 finished with value: 0.52322695035461 and parameters: {'solver': 'sag', 'C': 0.0003522694651473105}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,485] The parameter `solver` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,520] Trial 49 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.0002458244068920199}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,521] The parameter `solver` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,557] Trial 50 finished with value: 0.8439716312056736 and parameters: {'solver': 'newton-cholesky', 'C': 0.07773650302387758}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,558] The parameter `solver` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,594] Trial 51 finished with value: 0.8185283687943261 and parameters: {'solver': 'newton-cholesky', 'C': 1.3823722273579002}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,595] The parameter `solver` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,631] Trial 52 finished with value: 0.814095744680851 and parameters: {'solver': 'newton-cholesky', 'C': 0.004371444812611091}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,632] The parameter `solver` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,667] Trial 53 finished with value: 0.839627659574468 and parameters: {'solver': 'newton-cg', 'C': 0.018434229924091116}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,669] The parameter `solver` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,704] Trial 54 finished with value: 0.81427304964539 and parameters: {'solver': 'newton-cholesky', 'C': 5.829415347136073}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,705] The parameter `solver` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,741] Trial 55 finished with value: 0.8313829787234042 and parameters: {'solver': 'lbfgs', 'C': 0.32781211513934566}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,742] The parameter `solver` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,778] Trial 56 finished with value: 0.5653368794326241 and parameters: {'solver': 'newton-cg', 'C': 0.001036632928437698}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,780] The parameter `solver` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,816] Trial 57 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0005048065716667473}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,817] The parameter `solver` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,852] Trial 58 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cholesky', 'C': 0.15963385442879416}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,854] The parameter `solver` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,889] Trial 59 finished with value: 0.8101063829787234 and parameters: {'solver': 'sag', 'C': 2.8387359647587527}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,891] The parameter `solver` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,927] Trial 60 finished with value: 0.8310283687943262 and parameters: {'solver': 'lbfgs', 'C': 0.008976871324473142}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,928] The parameter `solver` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:51,964] Trial 61 finished with value: 0.7551418439716312 and parameters: {'solver': 'newton-cholesky', 'C': 0.002128751661796374}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:51,966] The parameter `solver` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,001] Trial 62 finished with value: 0.8186170212765959 and parameters: {'solver': 'lbfgs', 'C': 0.6731703824144981}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,003] The parameter `solver` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,038] Trial 63 finished with value: 0.8354609929078014 and parameters: {'solver': 'sag', 'C': 0.03785515249258631}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,039] The parameter `solver` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,075] Trial 64 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00011970850304957301}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,077] The parameter `solver` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,114] Trial 65 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00013097472643005907}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,116] The parameter `solver` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,151] Trial 66 finished with value: 0.8312943262411346 and parameters: {'solver': 'lbfgs', 'C': 0.04141784514364404}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,153] The parameter `solver` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,189] Trial 67 finished with value: 0.8143617021276596 and parameters: {'solver': 'sag', 'C': 0.7365250122712284}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,190] The parameter `solver` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,225] Trial 68 finished with value: 0.7847517730496454 and parameters: {'solver': 'lbfgs', 'C': 0.0023290965924605465}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,227] The parameter `solver` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,263] Trial 69 finished with value: 0.8310283687943262 and parameters: {'solver': 'sag', 'C': 0.009821718891880384}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,264] The parameter `solver` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,300] Trial 70 finished with value: 0.8101063829787234 and parameters: {'solver': 'sag', 'C': 3.105900223624704}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,301] The parameter `solver` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,336] Trial 71 finished with value: 0.8355496453900708 and parameters: {'solver': 'newton-cholesky', 'C': 0.17465760476621184}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,338] The parameter `solver` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,374] Trial 72 finished with value: 0.52322695035461 and parameters: {'solver': 'sag', 'C': 0.0005523158417307104}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,375] The parameter `solver` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,411] Trial 73 finished with value: 0.573758865248227 and parameters: {'solver': 'sag', 'C': 0.0011341944035027575}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,412] The parameter `solver` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,448] Trial 74 finished with value: 0.8271276595744681 and parameters: {'solver': 'newton-cg', 'C': 0.3586637624484768}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,450] The parameter `solver` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,484] Trial 75 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 6.378043838892169}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,485] The parameter `solver` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,521] Trial 76 finished with value: 0.8353723404255318 and parameters: {'solver': 'lbfgs', 'C': 0.02016914554730331}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,523] The parameter `solver` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,558] Trial 77 finished with value: 0.8140070921985816 and parameters: {'solver': 'newton-cg', 'C': 0.004782858141653791}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,560] The parameter `solver` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,595] Trial 78 finished with value: 0.8185283687943261 and parameters: {'solver': 'lbfgs', 'C': 1.512472545310622}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,596] The parameter `solver` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,632] Trial 79 finished with value: 0.8439716312056736 and parameters: {'solver': 'sag', 'C': 0.08505258154439958}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,633] The parameter `solver` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,668] Trial 80 finished with value: 0.52322695035461 and parameters: {'solver': 'sag', 'C': 0.00026895987855750467}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,670] The parameter `solver` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,705] Trial 81 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00038542288686231087}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,707] The parameter `solver` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,742] Trial 82 finished with value: 0.8397163120567376 and parameters: {'solver': 'newton-cholesky', 'C': 0.12188141848422895}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,743] The parameter `solver` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,779] Trial 83 finished with value: 0.81427304964539 and parameters: {'solver': 'sag', 'C': 2.167392169568416}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,781] The parameter `solver` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,816] Trial 84 finished with value: 0.8182624113475179 and parameters: {'solver': 'lbfgs', 'C': 0.006853895838650084}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,817] The parameter `solver` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,854] Trial 85 finished with value: 0.8354609929078014 and parameters: {'solver': 'lbfgs', 'C': 0.028902639100224517}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,855] The parameter `solver` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,890] Trial 86 finished with value: 0.8226063829787235 and parameters: {'solver': 'newton-cg', 'C': 9.139816994654893}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,892] The parameter `solver` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,927] Trial 87 finished with value: 0.8144503546099291 and parameters: {'solver': 'newton-cholesky', 'C': 0.5139696800771514}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,928] The parameter `solver` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:52,963] Trial 88 finished with value: 0.6960992907801419 and parameters: {'solver': 'newton-cholesky', 'C': 0.001625314837311866}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:52,965] The parameter `solver` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,001] Trial 89 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.0007914755439411164}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,003] The parameter `solver` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,038] Trial 90 finished with value: 0.8313829787234042 and parameters: {'solver': 'sag', 'C': 0.2502865431174607}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,039] The parameter `solver` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,075] Trial 91 finished with value: 0.81427304964539 and parameters: {'solver': 'newton-cg', 'C': 4.450794062355996}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,076] The parameter `solver` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,111] Trial 92 finished with value: 0.8352836879432625 and parameters: {'solver': 'newton-cg', 'C': 0.014074646633398432}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,113] The parameter `solver` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,148] Trial 93 finished with value: 0.8056737588652482 and parameters: {'solver': 'sag', 'C': 0.0033376246942920405}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,150] The parameter `solver` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,186] Trial 94 finished with value: 0.8185283687943261 and parameters: {'solver': 'newton-cg', 'C': 1.0554496008786018}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,187] The parameter `solver` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,222] Trial 95 finished with value: 0.8356382978723405 and parameters: {'solver': 'newton-cholesky', 'C': 0.05935229272296987}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,224] The parameter `solver` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,259] Trial 96 finished with value: 0.52322695035461 and parameters: {'solver': 'lbfgs', 'C': 0.00018768842935762206}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,260] The parameter `solver` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,296] Trial 97 finished with value: 0.52322695035461 and parameters: {'solver': 'newton-cg', 'C': 0.00015678788438269704}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,297] The parameter `solver` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,332] Trial 98 finished with value: 0.8271276595744681 and parameters: {'solver': 'newton-cholesky', 'C': 0.04958068241684656}. Best is trial 18 with value: 0.8439716312056736.\n",
      "[W 2025-12-28 19:45:53,334] The parameter `solver` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:45:53,371] A new study created in memory with name: Decision Tree Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:53,369] Trial 99 finished with value: 0.8185283687943261 and parameters: {'solver': 'newton-cholesky', 'C': 0.8816830667755706}. Best is trial 18 with value: 0.8439716312056736.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using QMCSampler: {'solver': 'lbfgs', 'C': 0.0930572040929699}\n",
      "Best accuracy: 0.8440, at trial: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04894cb06c00412d817aff4574d00bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:53,405] Trial 0 finished with value: 0.7805851063829786 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,407] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,408] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,424] Trial 1 finished with value: 0.7722517730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,426] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,427] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,442] Trial 2 finished with value: 0.7257978723404255 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,443] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,444] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,460] Trial 3 finished with value: 0.7085992907801417 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,462] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,463] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,478] Trial 4 finished with value: 0.7508865248226949 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,480] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,481] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,496] Trial 5 finished with value: 0.7640070921985815 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,497] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,498] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,513] Trial 6 finished with value: 0.6877659574468085 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,514] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,515] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,530] Trial 7 finished with value: 0.7257092198581561 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,531] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,532] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,546] Trial 8 finished with value: 0.7214539007092198 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,547] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,548] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,563] Trial 9 finished with value: 0.763918439716312 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,565] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,565] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,580] Trial 10 finished with value: 0.738031914893617 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,582] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,582] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,597] Trial 11 finished with value: 0.7425531914893617 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,599] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,600] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,614] Trial 12 finished with value: 0.7130319148936171 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,615] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,617] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,630] Trial 13 finished with value: 0.6879432624113475 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,631] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,632] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,647] Trial 14 finished with value: 0.7383865248226951 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,648] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,649] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,663] Trial 15 finished with value: 0.7383865248226951 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7805851063829786.\n",
      "[W 2025-12-28 19:45:53,664] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,666] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,680] Trial 16 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,682] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,683] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,697] Trial 17 finished with value: 0.7851950354609929 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,699] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,700] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,715] Trial 18 finished with value: 0.7085992907801418 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,716] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,717] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,731] Trial 19 finished with value: 0.7085992907801417 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,732] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,733] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,747] Trial 20 finished with value: 0.699822695035461 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,748] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,750] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,765] Trial 21 finished with value: 0.7257092198581561 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,766] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,768] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,781] Trial 22 finished with value: 0.674822695035461 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,782] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,783] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,799] Trial 23 finished with value: 0.7382978723404255 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,800] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,801] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,815] Trial 24 finished with value: 0.7345744680851063 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,816] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,818] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,832] Trial 25 finished with value: 0.7379432624113476 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,834] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,835] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,850] Trial 26 finished with value: 0.6918439716312056 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,851] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,853] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,877] Trial 27 finished with value: 0.7469858156028369 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,879] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,880] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,895] Trial 28 finished with value: 0.7257978723404255 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,896] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,897] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,911] Trial 29 finished with value: 0.7424645390070923 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,913] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,913] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,928] Trial 30 finished with value: 0.7171099290780141 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,929] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,930] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,945] Trial 31 finished with value: 0.7763297872340426 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,946] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,947] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,962] Trial 32 finished with value: 0.7382978723404255 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,964] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,965] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,978] Trial 33 finished with value: 0.7465425531914894 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,980] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,981] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:53,995] Trial 34 finished with value: 0.751241134751773 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:53,996] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:53,998] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,012] Trial 35 finished with value: 0.7085992907801418 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,014] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,015] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,028] Trial 36 finished with value: 0.7130319148936171 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,029] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,031] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,045] Trial 37 finished with value: 0.7386524822695036 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,046] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,048] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,062] Trial 38 finished with value: 0.7635638297872339 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,063] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,065] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,078] Trial 39 finished with value: 0.674822695035461 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,079] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,080] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,095] Trial 40 finished with value: 0.7170212765957447 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,096] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,097] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,111] Trial 41 finished with value: 0.7217198581560285 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,112] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,114] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,128] Trial 42 finished with value: 0.7426418439716312 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,130] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,131] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,145] Trial 43 finished with value: 0.750709219858156 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,146] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,148] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,163] Trial 44 finished with value: 0.7343085106382978 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,165] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,166] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,179] Trial 45 finished with value: 0.7171099290780141 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,180] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,182] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,196] Trial 46 finished with value: 0.713209219858156 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,197] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,199] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,213] Trial 47 finished with value: 0.7547872340425531 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,214] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,215] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,229] Trial 48 finished with value: 0.7469858156028369 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,231] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,232] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,246] Trial 49 finished with value: 0.7766843971631205 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,248] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,249] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,263] Trial 50 finished with value: 0.7257092198581561 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,264] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,265] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,279] Trial 51 finished with value: 0.7635638297872339 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,280] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,281] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,296] Trial 52 finished with value: 0.7170212765957447 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,297] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,298] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,312] Trial 53 finished with value: 0.7551418439716311 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,314] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,315] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,330] Trial 54 finished with value: 0.7675531914893616 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,331] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,333] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,346] Trial 55 finished with value: 0.7468085106382978 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,348] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,349] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,364] Trial 56 finished with value: 0.7296099290780143 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,365] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,366] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,381] Trial 57 finished with value: 0.700531914893617 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,382] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,384] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,399] Trial 58 finished with value: 0.7295212765957446 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,400] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,401] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,417] Trial 59 finished with value: 0.738031914893617 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,419] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,420] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,434] Trial 60 finished with value: 0.7550531914893617 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,435] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,436] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,451] Trial 61 finished with value: 0.7506205673758866 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,453] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,453] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,467] Trial 62 finished with value: 0.7253546099290781 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,468] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,469] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,484] Trial 63 finished with value: 0.7292553191489362 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,485] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,487] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,501] Trial 64 finished with value: 0.7722517730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,502] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,503] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,518] Trial 65 finished with value: 0.7425531914893616 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,519] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,521] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,535] Trial 66 finished with value: 0.7169326241134752 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,536] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,537] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,552] Trial 67 finished with value: 0.7845744680851063 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,555] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,556] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,569] Trial 68 finished with value: 0.7423758865248227 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,571] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,572] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,587] Trial 69 finished with value: 0.7381205673758865 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,588] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,589] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,603] Trial 70 finished with value: 0.7085992907801418 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,604] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,605] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,620] Trial 71 finished with value: 0.738209219858156 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,621] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,622] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,637] Trial 72 finished with value: 0.7422872340425533 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,638] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,639] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,653] Trial 73 finished with value: 0.700177304964539 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,654] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,655] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,669] Trial 74 finished with value: 0.7171099290780141 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,670] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,671] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,686] Trial 75 finished with value: 0.7469858156028369 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,687] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,689] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,703] Trial 76 finished with value: 0.7383865248226951 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,704] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,705] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,718] Trial 77 finished with value: 0.7422872340425533 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,721] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,722] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,736] Trial 78 finished with value: 0.7261524822695036 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,737] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,738] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,753] Trial 79 finished with value: 0.7500886524822695 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,754] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,755] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,769] Trial 80 finished with value: 0.7469858156028369 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,771] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,772] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,786] Trial 81 finished with value: 0.7725177304964539 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,787] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,788] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,803] Trial 82 finished with value: 0.7131205673758865 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,804] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,805] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,820] Trial 83 finished with value: 0.7468971631205674 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,821] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,822] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,837] Trial 84 finished with value: 0.7299645390070921 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,837] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,839] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,853] Trial 85 finished with value: 0.7253546099290781 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,854] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,855] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,869] Trial 86 finished with value: 0.7679964539007094 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,871] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,871] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,886] Trial 87 finished with value: 0.7637411347517731 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,888] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,889] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,903] Trial 88 finished with value: 0.7676418439716312 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,905] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,906] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,920] Trial 89 finished with value: 0.7425531914893617 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,921] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,923] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,936] Trial 90 finished with value: 0.7716312056737589 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,937] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,938] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,953] Trial 91 finished with value: 0.7130319148936171 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,954] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,955] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,970] Trial 92 finished with value: 0.7171099290780141 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,972] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,972] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:54,986] Trial 93 finished with value: 0.7675531914893616 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:54,987] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:54,988] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,002] Trial 94 finished with value: 0.738031914893617 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:55,004] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,006] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,019] Trial 95 finished with value: 0.7500886524822695 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:55,021] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,022] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,036] Trial 96 finished with value: 0.7469858156028369 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:55,037] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,038] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,063] Trial 97 finished with value: 0.7049645390070922 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:55,064] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,067] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,081] Trial 98 finished with value: 0.7087765957446809 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.7851950354609929.\n",
      "[W 2025-12-28 19:45:55,083] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,084] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,098] Trial 99 finished with value: 0.746631205673759 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7851950354609929.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:45:55,100] A new study created in memory with name: Random Forest Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Decision Tree Using QMCSampler: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}\n",
      "Best accuracy: 0.7852, at trial: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cfc3230d21479b92509b57a71f5b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:45:55,174] Trial 0 finished with value: 0.7849290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7849290780141844.\n",
      "[W 2025-12-28 19:45:55,176] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,177] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,233] Trial 1 finished with value: 0.7594858156028368 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7849290780141844.\n",
      "[W 2025-12-28 19:45:55,235] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,236] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,353] Trial 2 finished with value: 0.7974290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7974290780141844.\n",
      "[W 2025-12-28 19:45:55,355] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,356] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,504] Trial 3 finished with value: 0.801595744680851 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.801595744680851.\n",
      "[W 2025-12-28 19:45:55,507] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,507] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,595] Trial 4 finished with value: 0.7849290780141843 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 32, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.801595744680851.\n",
      "[W 2025-12-28 19:45:55,596] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,597] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,694] Trial 5 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.801595744680851.\n",
      "[W 2025-12-28 19:45:55,696] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,697] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,856] Trial 6 finished with value: 0.7970744680851064 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.801595744680851.\n",
      "[W 2025-12-28 19:45:55,857] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,858] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:55,988] Trial 7 finished with value: 0.8059397163120566 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 7 with value: 0.8059397163120566.\n",
      "[W 2025-12-28 19:45:55,990] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:55,991] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:56,068] Trial 8 finished with value: 0.7763297872340426 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 21, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8059397163120566.\n",
      "[W 2025-12-28 19:45:56,069] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:56,070] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:56,158] Trial 9 finished with value: 0.7844858156028369 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 27, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 7 with value: 0.8059397163120566.\n",
      "[W 2025-12-28 19:45:56,160] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:56,161] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:56,291] Trial 10 finished with value: 0.7890957446808511 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 72, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 7 with value: 0.8059397163120566.\n",
      "[W 2025-12-28 19:45:56,292] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:56,293] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:56,462] Trial 11 finished with value: 0.801595744680851 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 95, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8059397163120566.\n",
      "[W 2025-12-28 19:45:56,464] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:56,465] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:56,583] Trial 12 finished with value: 0.801595744680851 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 7 with value: 0.8059397163120566.\n",
      "[W 2025-12-28 19:45:56,585] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:56,586] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:56,695] Trial 13 finished with value: 0.8102836879432624 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.8102836879432624.\n",
      "[W 2025-12-28 19:45:56,697] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:56,698] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:56,846] Trial 14 finished with value: 0.7930851063829787 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.8102836879432624.\n",
      "[W 2025-12-28 19:45:56,848] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:56,849] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:56,977] Trial 15 finished with value: 0.7932624113475176 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.8102836879432624.\n",
      "[W 2025-12-28 19:45:56,979] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:56,980] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:57,047] Trial 16 finished with value: 0.7848404255319148 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 15, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.8102836879432624.\n",
      "[W 2025-12-28 19:45:57,048] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:57,049] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:57,117] Trial 17 finished with value: 0.7675531914893616 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 18, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.8102836879432624.\n",
      "[W 2025-12-28 19:45:57,119] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:57,120] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:57,248] Trial 18 finished with value: 0.8060283687943262 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8102836879432624.\n",
      "[W 2025-12-28 19:45:57,250] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:57,251] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:57,409] Trial 19 finished with value: 0.797340425531915 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 13 with value: 0.8102836879432624.\n",
      "[W 2025-12-28 19:45:57,411] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:57,412] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:57,519] Trial 20 finished with value: 0.7764184397163121 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.8102836879432624.\n",
      "[W 2025-12-28 19:45:57,521] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:57,521] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:57,640] Trial 21 finished with value: 0.8143617021276596 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:57,641] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:57,643] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:57,812] Trial 22 finished with value: 0.7930851063829787 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 98, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:57,812] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:57,815] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:57,954] Trial 23 finished with value: 0.7887411347517731 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:57,955] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:57,955] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:58,043] Trial 24 finished with value: 0.7763297872340426 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 29, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:58,043] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:58,046] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:58,133] Trial 25 finished with value: 0.7806737588652483 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 24, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:58,133] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:58,137] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:58,275] Trial 26 finished with value: 0.7890070921985817 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 69, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:58,277] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:58,277] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:58,446] Trial 27 finished with value: 0.810017730496454 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:58,448] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:58,448] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:58,557] Trial 28 finished with value: 0.7804078014184397 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:58,559] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:58,559] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:58,657] Trial 29 finished with value: 0.801950354609929 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 35, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:58,659] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:58,659] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:58,808] Trial 30 finished with value: 0.7930851063829787 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:58,810] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:58,811] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:58,939] Trial 31 finished with value: 0.8058510638297873 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:58,939] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:58,939] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,008] Trial 32 finished with value: 0.7849290780141844 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 12, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:59,008] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,011] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,077] Trial 33 finished with value: 0.7890070921985816 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 14, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:59,078] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,078] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,197] Trial 34 finished with value: 0.7847517730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:59,199] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,199] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,348] Trial 35 finished with value: 0.7890070921985816 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:59,348] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,351] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,448] Trial 36 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8143617021276596.\n",
      "[W 2025-12-28 19:45:59,448] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,448] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,569] Trial 37 finished with value: 0.8272163120567375 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:45:59,571] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,572] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,731] Trial 38 finished with value: 0.7888297872340425 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:45:59,732] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,733] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,862] Trial 39 finished with value: 0.8058510638297871 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:45:59,864] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,865] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:45:59,941] Trial 40 finished with value: 0.7805851063829787 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 25, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:45:59,942] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:45:59,943] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,030] Trial 41 finished with value: 0.7764184397163121 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 31, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,032] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,033] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,170] Trial 42 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,172] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,173] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,342] Trial 43 finished with value: 0.7930851063829787 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,345] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,345] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,462] Trial 44 finished with value: 0.7848404255319149 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 54, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,465] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,466] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,564] Trial 45 finished with value: 0.7764184397163121 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 42, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,566] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,567] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,715] Trial 46 finished with value: 0.801595744680851 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,717] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,717] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,846] Trial 47 finished with value: 0.7763297872340426 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,848] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,848] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,924] Trial 48 finished with value: 0.763386524822695 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 19, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,926] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,927] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:00,994] Trial 49 finished with value: 0.7847517730496454 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 17, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:00,996] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:00,996] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:01,124] Trial 50 finished with value: 0.8101063829787234 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:01,127] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:01,127] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:01,277] Trial 51 finished with value: 0.7890070921985816 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 85, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:01,279] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:01,280] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:01,377] Trial 52 finished with value: 0.7765070921985816 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 39, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:01,379] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:01,380] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:01,486] Trial 53 finished with value: 0.7847517730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:01,488] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:01,489] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:01,658] Trial 54 finished with value: 0.8058510638297873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:01,660] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:01,661] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:01,789] Trial 55 finished with value: 0.8057624113475177 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:01,791] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:01,792] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:01,879] Trial 56 finished with value: 0.7720744680851063 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:01,880] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:01,881] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:01,957] Trial 57 finished with value: 0.7761524822695035 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 22, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:01,959] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:01,959] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,087] Trial 58 finished with value: 0.7974290780141844 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,088] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,089] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,249] Trial 59 finished with value: 0.7890070921985816 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,251] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,252] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,349] Trial 60 finished with value: 0.7847517730496454 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,351] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,352] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,438] Trial 61 finished with value: 0.7890070921985816 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,440] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,441] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,591] Trial 62 finished with value: 0.7930851063829787 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 79, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,593] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,594] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,712] Trial 63 finished with value: 0.7890070921985816 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,714] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,715] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,780] Trial 64 finished with value: 0.7890070921985816 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 11, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,781] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,783] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,849] Trial 65 finished with value: 0.7890070921985815 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 12, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,851] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,851] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:02,969] Trial 66 finished with value: 0.7890070921985817 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:02,970] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:02,972] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:03,120] Trial 67 finished with value: 0.7975177304964538 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 80, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:03,122] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:03,123] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:03,222] Trial 68 finished with value: 0.7720744680851064 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:03,223] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:03,224] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:03,320] Trial 69 finished with value: 0.7931737588652481 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:03,321] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:03,323] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:03,481] Trial 70 finished with value: 0.7930851063829787 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:03,483] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:03,483] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:03,621] Trial 71 finished with value: 0.7848404255319148 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 69, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:03,623] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:03,624] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:03,700] Trial 72 finished with value: 0.7804964539007093 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 23, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:03,701] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:03,702] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:03,789] Trial 73 finished with value: 0.7932624113475178 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 29, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:03,791] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:03,791] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:03,930] Trial 74 finished with value: 0.7890957446808511 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 74, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:03,932] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:03,933] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:04,101] Trial 75 finished with value: 0.7972517730496455 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 97, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:04,103] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:04,103] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:04,211] Trial 76 finished with value: 0.7890070921985816 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:04,213] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:04,214] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:04,311] Trial 77 finished with value: 0.7848404255319148 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 40, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:04,312] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:04,313] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:04,462] Trial 78 finished with value: 0.7930851063829787 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:04,464] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:04,464] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:04,582] Trial 79 finished with value: 0.7975177304964539 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:04,584] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:04,585] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:04,651] Trial 80 finished with value: 0.7761524822695035 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 17, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:04,654] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:04,654] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:04,720] Trial 81 finished with value: 0.7804964539007092 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 20, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:04,722] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:04,723] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:04,850] Trial 82 finished with value: 0.7974290780141844 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:04,851] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:04,852] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:05,011] Trial 83 finished with value: 0.7931737588652482 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:05,013] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:05,014] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:05,110] Trial 84 finished with value: 0.8059397163120566 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:05,112] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:05,113] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:05,232] Trial 85 finished with value: 0.7975177304964538 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:05,234] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:05,235] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:05,403] Trial 86 finished with value: 0.7890070921985816 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:05,405] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:05,406] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:05,545] Trial 87 finished with value: 0.7933510638297873 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 77, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:05,545] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:05,548] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:05,635] Trial 88 finished with value: 0.7677304964539007 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 32, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:05,637] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:05,638] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:05,714] Trial 89 finished with value: 0.7848404255319148 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 26, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:05,716] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:05,716] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:05,866] Trial 90 finished with value: 0.7763297872340426 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:05,868] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:05,868] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,028] Trial 91 finished with value: 0.7932624113475178 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 94, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:06,030] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:06,030] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,138] Trial 92 finished with value: 0.8058510638297871 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:06,138] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:06,138] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,238] Trial 93 finished with value: 0.7763297872340426 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:06,240] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:06,240] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,389] Trial 94 finished with value: 0.8016843971631206 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:06,391] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:06,392] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,519] Trial 95 finished with value: 0.8015070921985815 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:06,520] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:06,520] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,588] Trial 96 finished with value: 0.763386524822695 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 14, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:06,590] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:06,591] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,656] Trial 97 finished with value: 0.7973404255319148 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 13, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8272163120567375.\n",
      "[W 2025-12-28 19:46:06,659] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:06,659] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,777] Trial 98 finished with value: 0.801595744680851 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.8272163120567375.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:46:06,930] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:46:06,779] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:06,780] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:06,928] Trial 99 finished with value: 0.7720744680851064 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8272163120567375.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using QMCSampler: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}\n",
      "Best accuracy: 0.8272, at trial: 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea6efade8c64bc59b55e4b1fd836a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:06,973] Trial 0 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:46:06,975] The parameter `algorithm` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,000] Trial 1 finished with value: 0.7930851063829787 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:46:07,000] The parameter `algorithm` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,037] Trial 2 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:46:07,037] The parameter `algorithm` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,073] Trial 3 finished with value: 0.8312943262411349 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:46:07,074] The parameter `algorithm` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,089] Trial 4 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 15, 'p': 2}. Best is trial 0 with value: 0.83572695035461.\n",
      "[W 2025-12-28 19:46:07,090] The parameter `algorithm` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,127] Trial 5 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,128] The parameter `algorithm` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,174] Trial 6 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,176] The parameter `algorithm` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,201] Trial 7 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,201] The parameter `algorithm` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,217] Trial 8 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 9, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,217] The parameter `algorithm` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,255] Trial 9 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 11, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,256] The parameter `algorithm` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,271] Trial 10 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,272] The parameter `algorithm` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,308] Trial 11 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,309] The parameter `algorithm` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,345] Trial 12 finished with value: 0.8314716312056737 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 23, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,346] The parameter `algorithm` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,361] Trial 13 finished with value: 0.8145390070921987 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,363] The parameter `algorithm` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,398] Trial 14 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,399] The parameter `algorithm` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,435] Trial 15 finished with value: 0.83572695035461 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,435] The parameter `algorithm` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,471] Trial 16 finished with value: 0.8142730496453903 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,472] The parameter `algorithm` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,487] Trial 17 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 7, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,488] The parameter `algorithm` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,524] Trial 18 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,524] The parameter `algorithm` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,560] Trial 19 finished with value: 0.8270390070921987 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,560] The parameter `algorithm` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,597] Trial 20 finished with value: 0.83572695035461 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 19, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,598] The parameter `algorithm` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,624] Trial 21 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,625] The parameter `algorithm` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,661] Trial 22 finished with value: 0.835372340425532 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,661] The parameter `algorithm` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,677] Trial 23 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,678] The parameter `algorithm` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,704] Trial 24 finished with value: 0.8187056737588654 and parameters: {'algorithm': 'brute', 'n_neighbors': 13, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,705] The parameter `algorithm` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,742] Trial 25 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,742] The parameter `algorithm` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,778] Trial 26 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,778] The parameter `algorithm` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,795] Trial 27 finished with value: 0.8437056737588653 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,796] The parameter `algorithm` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,811] Trial 28 finished with value: 0.8314716312056737 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,813] The parameter `algorithm` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,838] Trial 29 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'brute', 'n_neighbors': 16, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,838] The parameter `algorithm` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,854] Trial 30 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,854] The parameter `algorithm` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,890] Trial 31 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 28, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,891] The parameter `algorithm` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,927] Trial 32 finished with value: 0.801595744680851 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 4, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,928] The parameter `algorithm` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:07,963] Trial 33 finished with value: 0.8101063829787234 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:07,965] The parameter `algorithm` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,001] Trial 34 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,001] The parameter `algorithm` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,038] Trial 35 finished with value: 0.835372340425532 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,038] The parameter `algorithm` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,064] Trial 36 finished with value: 0.8315602836879433 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,064] The parameter `algorithm` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,091] Trial 37 finished with value: 0.8356382978723402 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,092] The parameter `algorithm` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,117] Trial 38 finished with value: 0.835372340425532 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,119] The parameter `algorithm` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,133] Trial 39 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,134] The parameter `algorithm` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,170] Trial 40 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 11, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,171] The parameter `algorithm` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,186] Trial 41 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 14, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,186] The parameter `algorithm` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,222] Trial 42 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,222] The parameter `algorithm` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,249] Trial 43 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,249] The parameter `algorithm` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,286] Trial 44 finished with value: 0.8312943262411349 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,289] The parameter `algorithm` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,303] Trial 45 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,304] The parameter `algorithm` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,340] Trial 46 finished with value: 0.8437943262411348 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,342] The parameter `algorithm` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,377] Trial 47 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,378] The parameter `algorithm` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,413] Trial 48 finished with value: 0.8312056737588651 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 8, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,415] The parameter `algorithm` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,451] Trial 49 finished with value: 0.8186170212765956 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,452] The parameter `algorithm` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,467] Trial 50 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,467] The parameter `algorithm` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,493] Trial 51 finished with value: 0.8312943262411349 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,493] The parameter `algorithm` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,530] Trial 52 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 18, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,531] The parameter `algorithm` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,566] Trial 53 finished with value: 0.8314716312056738 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 24, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,567] The parameter `algorithm` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,603] Trial 54 finished with value: 0.835372340425532 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,603] The parameter `algorithm` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,619] Trial 55 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,620] The parameter `algorithm` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,655] Trial 56 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 12, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,658] The parameter `algorithm` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,693] Trial 57 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 9, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,694] The parameter `algorithm` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,708] Trial 58 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,710] The parameter `algorithm` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,746] Trial 59 finished with value: 0.8312056737588653 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,747] The parameter `algorithm` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,783] Trial 60 finished with value: 0.839982269503546 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,785] The parameter `algorithm` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,820] Trial 61 finished with value: 0.8314716312056738 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 15, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,820] The parameter `algorithm` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,856] Trial 62 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,858] The parameter `algorithm` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,893] Trial 63 finished with value: 0.8229609929078014 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,895] The parameter `algorithm` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,909] Trial 64 finished with value: 0.7972517730496453 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,911] The parameter `algorithm` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,946] Trial 65 finished with value: 0.7972517730496455 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 4, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,948] The parameter `algorithm` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:08,983] Trial 66 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:08,985] The parameter `algorithm` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,020] Trial 67 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:09,020] The parameter `algorithm` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,057] Trial 68 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 16, 'p': 2}. Best is trial 5 with value: 0.8440602836879432.\n",
      "[W 2025-12-28 19:46:09,057] The parameter `algorithm` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,084] Trial 69 finished with value: 0.8440602836879434 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,084] The parameter `algorithm` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,101] Trial 70 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,101] The parameter `algorithm` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,117] Trial 71 finished with value: 0.8228723404255319 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,117] The parameter `algorithm` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,153] Trial 72 finished with value: 0.8355496453900709 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,155] The parameter `algorithm` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,190] Trial 73 finished with value: 0.8356382978723405 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,191] The parameter `algorithm` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,206] Trial 74 finished with value: 0.8186170212765959 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,206] The parameter `algorithm` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,243] Trial 75 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,244] The parameter `algorithm` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,279] Trial 76 finished with value: 0.8272163120567375 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,279] The parameter `algorithm` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,305] Trial 77 finished with value: 0.8314716312056737 and parameters: {'algorithm': 'brute', 'n_neighbors': 19, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,307] The parameter `algorithm` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,322] Trial 78 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,323] The parameter `algorithm` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,338] Trial 79 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,338] The parameter `algorithm` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,374] Trial 80 finished with value: 0.8186170212765956 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,375] The parameter `algorithm` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,390] Trial 81 finished with value: 0.826950354609929 and parameters: {'algorithm': 'brute', 'n_neighbors': 8, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,391] The parameter `algorithm` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,426] Trial 82 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,429] The parameter `algorithm` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,464] Trial 83 finished with value: 0.839627659574468 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,465] The parameter `algorithm` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,490] Trial 84 finished with value: 0.8440602836879432 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,491] The parameter `algorithm` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,526] Trial 85 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,527] The parameter `algorithm` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,562] Trial 86 finished with value: 0.8395390070921988 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,563] The parameter `algorithm` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,599] Trial 87 finished with value: 0.8312943262411346 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,600] The parameter `algorithm` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,636] Trial 88 finished with value: 0.8312943262411349 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,637] The parameter `algorithm` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,663] Trial 89 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'brute', 'n_neighbors': 11, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,664] The parameter `algorithm` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,700] Trial 90 finished with value: 0.8271276595744681 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,702] The parameter `algorithm` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,738] Trial 91 finished with value: 0.8395390070921985 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,739] The parameter `algorithm` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,754] Trial 92 finished with value: 0.8314716312056737 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,755] The parameter `algorithm` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,790] Trial 93 finished with value: 0.8145390070921987 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 17, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,792] The parameter `algorithm` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,828] Trial 94 finished with value: 0.8270390070921986 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,830] The parameter `algorithm` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,844] Trial 95 finished with value: 0.83572695035461 and parameters: {'algorithm': 'brute', 'n_neighbors': 29, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,845] The parameter `algorithm` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,860] Trial 96 finished with value: 0.8142730496453903 and parameters: {'algorithm': 'brute', 'n_neighbors': 5, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,862] The parameter `algorithm` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,876] Trial 97 finished with value: 0.7972517730496455 and parameters: {'algorithm': 'brute', 'n_neighbors': 4, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,877] The parameter `algorithm` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:09,913] Trial 98 finished with value: 0.8313829787234042 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 69 with value: 0.8440602836879434.\n",
      "[W 2025-12-28 19:46:09,914] The parameter `algorithm` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:46:09,944] A new study created in memory with name: Support Vector Machine Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:09,941] Trial 99 finished with value: 0.8354609929078014 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 69 with value: 0.8440602836879434.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using QMCSampler: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}\n",
      "Best accuracy: 0.8441, at trial: 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23e2d3bf82343139d214d510e5eab38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:09,977] Trial 0 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:09,978] The parameter `kernel` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,003] Trial 1 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00010000000000000009}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,005] The parameter `kernel` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,019] Trial 2 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0010000000000000002}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,020] The parameter `kernel` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,036] Trial 3 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.003162277660168382}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,038] The parameter `kernel` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,053] Trial 4 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0003162277660168384}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,055] The parameter `kernel` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,069] Trial 5 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0005623413251903495}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,071] The parameter `kernel` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,085] Trial 6 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.005623413251903492}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,086] The parameter `kernel` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,087] The parameter `degree` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,101] Trial 7 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0017782794100389236, 'degree': 5}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,102] The parameter `kernel` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,104] The parameter `degree` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,118] Trial 8 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00017782794100389232, 'degree': 2}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,119] The parameter `kernel` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,134] Trial 9 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00023713737056616573}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,135] The parameter `kernel` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,150] Trial 10 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.002371373705661656}. Best is trial 0 with value: 0.52322695035461.\n",
      "[W 2025-12-28 19:46:10,151] The parameter `kernel` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,152] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,167] Trial 11 finished with value: 0.6243794326241134 and parameters: {'kernel': 'poly', 'C': 0.007498942093324564, 'degree': 3}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,169] The parameter `kernel` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,184] Trial 12 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0007498942093324562}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,185] The parameter `kernel` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,200] Trial 13 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00042169650342858235}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,201] The parameter `kernel` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,202] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,217] Trial 14 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.004216965034285825, 'degree': 2}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,218] The parameter `kernel` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,234] Trial 15 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0013335214321633251}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,235] The parameter `kernel` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,236] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,251] Trial 16 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0001333521432163326, 'degree': 2}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,252] The parameter `kernel` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,254] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,268] Trial 17 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00015399265260594933, 'degree': 3}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,268] The parameter `kernel` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,283] Trial 18 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0015399265260594922}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,285] The parameter `kernel` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,300] Trial 19 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.004869675251658635}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,300] The parameter `kernel` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,303] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,316] Trial 20 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00048696752516586337, 'degree': 5}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,317] The parameter `kernel` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,319] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,334] Trial 21 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.000865964323360066, 'degree': 4}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,335] The parameter `kernel` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,349] Trial 22 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.008659643233600654}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,351] The parameter `kernel` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,352] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,366] Trial 23 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0027384196342643626, 'degree': 4}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,367] The parameter `kernel` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,383] Trial 24 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0002738419634264362}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,384] The parameter `kernel` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,398] Trial 25 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0002053525026457149}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,401] The parameter `kernel` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,415] Trial 26 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0020535250264571477}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,416] The parameter `kernel` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,431] Trial 27 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0064938163157621165}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,432] The parameter `kernel` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,447] Trial 28 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0006493816315762115}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,448] The parameter `kernel` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,463] Trial 29 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.000365174127254838}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,464] The parameter `kernel` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,479] Trial 30 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0036517412725483775}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,480] The parameter `kernel` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,495] Trial 31 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0011547819846894588}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,497] The parameter `kernel` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,522] Trial 32 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00011547819846894585}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,524] The parameter `kernel` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,548] Trial 33 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00012409377607517218}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,549] The parameter `kernel` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,575] Trial 34 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0012409377607517208}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,576] The parameter `kernel` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,591] Trial 35 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.003924189758484535}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,592] The parameter `kernel` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,607] Trial 36 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0003924189758484538}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,609] The parameter `kernel` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,623] Trial 37 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0006978305848598669}. Best is trial 11 with value: 0.6243794326241134.\n",
      "[W 2025-12-28 19:46:10,624] The parameter `kernel` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,625] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,640] Trial 38 finished with value: 0.7509751773049645 and parameters: {'kernel': 'poly', 'C': 0.006978305848598664, 'degree': 5}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,642] The parameter `kernel` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,656] Trial 39 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.002206734069084591}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,657] The parameter `kernel` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,659] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,673] Trial 40 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00022067340690845924, 'degree': 5}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,674] The parameter `kernel` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,675] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,690] Trial 41 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0002942727176209287, 'degree': 3}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,691] The parameter `kernel` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,706] Trial 42 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.002942727176209285}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,707] The parameter `kernel` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,723] Trial 43 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.009305720409296997}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,724] The parameter `kernel` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,750] Trial 44 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0009305720409296995}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,751] The parameter `kernel` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,752] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,767] Trial 45 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0005232991146814953, 'degree': 2}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,768] The parameter `kernel` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,769] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,783] Trial 46 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.005232991146814949, 'degree': 2}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,785] The parameter `kernel` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,800] Trial 47 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0016548170999431827}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,801] The parameter `kernel` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,816] Trial 48 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00016548170999431823}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,817] The parameter `kernel` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,833] Trial 49 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00014330125702369644}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,834] The parameter `kernel` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,849] Trial 50 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0014330125702369636}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,849] The parameter `kernel` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,850] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,865] Trial 51 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0045315836376008225, 'degree': 2}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,866] The parameter `kernel` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,867] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,882] Trial 52 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00045315836376008217, 'degree': 2}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,884] The parameter `kernel` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,885] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,899] Trial 53 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0008058421877614828, 'degree': 2}. Best is trial 38 with value: 0.7509751773049645.\n",
      "[W 2025-12-28 19:46:10,900] The parameter `kernel` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,902] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,916] Trial 54 finished with value: 0.763563829787234 and parameters: {'kernel': 'poly', 'C': 0.008058421877614822, 'degree': 5}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:10,918] The parameter `kernel` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,919] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,933] Trial 55 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0025482967479793484, 'degree': 4}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:10,934] The parameter `kernel` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,949] Trial 56 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0002548296747979348}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:10,951] The parameter `kernel` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,975] Trial 57 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00019109529749704405}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:10,977] The parameter `kernel` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:10,977] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:10,992] Trial 58 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0019109529749704425, 'degree': 5}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:10,994] The parameter `kernel` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,009] Trial 59 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.006042963902381333}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,010] The parameter `kernel` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,011] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,025] Trial 60 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0006042963902381332, 'degree': 4}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,026] The parameter `kernel` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,028] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,042] Trial 61 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00033982083289425634, 'degree': 2}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,043] The parameter `kernel` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,044] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,068] Trial 62 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.003398208328942561, 'degree': 4}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,069] The parameter `kernel` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,095] Trial 63 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0010746078283213184}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,097] The parameter `kernel` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,112] Trial 64 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00010746078283213182}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,113] The parameter `kernel` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,128] Trial 65 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0001113973859994803}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,129] The parameter `kernel` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,144] Trial 66 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.001113973859994803}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,145] The parameter `kernel` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,170] Trial 67 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0035226946514731027}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,171] The parameter `kernel` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,186] Trial 68 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0003522694651473105}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,187] The parameter `kernel` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,203] Trial 69 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0006264335366568858}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,205] The parameter `kernel` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,229] Trial 70 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00626433536656886}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,230] The parameter `kernel` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,245] Trial 71 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.001980956778550341}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,247] The parameter `kernel` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,262] Trial 72 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0001980956778550342}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,263] The parameter `kernel` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,264] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,279] Trial 73 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00026416483203860934, 'degree': 3}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,280] The parameter `kernel` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,295] Trial 74 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0026416483203860943}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,296] The parameter `kernel` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,298] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,312] Trial 75 finished with value: 0.6835992907801419 and parameters: {'kernel': 'poly', 'C': 0.008353625469578265, 'degree': 3}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,314] The parameter `kernel` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,315] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,329] Trial 76 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.000835362546957827, 'degree': 4}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,330] The parameter `kernel` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,331] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,345] Trial 77 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0004697588816706495, 'degree': 5}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,346] The parameter `kernel` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,347] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,361] Trial 78 finished with value: 0.5695035460992908 and parameters: {'kernel': 'poly', 'C': 0.004697588816706496, 'degree': 4}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,363] The parameter `kernel` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,377] Trial 79 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0014855080171727755}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,378] The parameter `kernel` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,379] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,394] Trial 80 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00014855080171727767, 'degree': 5}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,396] The parameter `kernel` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,410] Trial 81 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00017154378963428796}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,412] The parameter `kernel` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,426] Trial 82 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0017154378963428801}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,428] The parameter `kernel` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,442] Trial 83 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.005424690937011328}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,444] The parameter `kernel` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,445] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,459] Trial 84 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0005424690937011332, 'degree': 2}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,460] The parameter `kernel` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,476] Trial 85 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.0009646616199111995}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,477] The parameter `kernel` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,492] Trial 86 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.009646616199111998}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,493] The parameter `kernel` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,509] Trial 87 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0030505278902670284}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,510] The parameter `kernel` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,535] Trial 88 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00030505278902670253}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,537] The parameter `kernel` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,551] Trial 89 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0002287573200318398}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,552] The parameter `kernel` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,554] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,567] Trial 90 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0022875732003183966, 'degree': 4}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,568] The parameter `kernel` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,583] Trial 91 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.007233941627366754}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,585] The parameter `kernel` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,599] Trial 92 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0007233941627366753}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,600] The parameter `kernel` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,602] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,616] Trial 93 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0004067944321083049, 'degree': 5}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,616] The parameter `kernel` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,632] Trial 94 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.0040679443210830495}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,633] The parameter `kernel` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,634] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,648] Trial 95 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0012863969449369757, 'degree': 4}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,650] The parameter `kernel` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,650] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,665] Trial 96 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.00012863969449369766, 'degree': 4}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,666] The parameter `kernel` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,692] Trial 97 finished with value: 0.52322695035461 and parameters: {'kernel': 'sigmoid', 'C': 0.00011970850304957301}. Best is trial 54 with value: 0.763563829787234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:46:11,748] A new study created in memory with name: AdaBoost Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:46:11,693] The parameter `kernel` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:46:11,694] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,720] Trial 98 finished with value: 0.52322695035461 and parameters: {'kernel': 'poly', 'C': 0.0011970850304957315, 'degree': 2}. Best is trial 54 with value: 0.763563829787234.\n",
      "[W 2025-12-28 19:46:11,721] The parameter `kernel` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:11,746] Trial 99 finished with value: 0.52322695035461 and parameters: {'kernel': 'rbf', 'C': 0.00378551524925863}. Best is trial 54 with value: 0.763563829787234.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using QMCSampler: {'kernel': 'poly', 'C': 0.008058421877614822, 'degree': 5}\n",
      "Best accuracy: 0.7636, at trial: 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d469b1221d4f43971347a348772a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:11,832] Trial 0 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:11,857] Trial 1 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 10, 'learning_rate': 0.0010000000000000002}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:11,948] Trial 2 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 55, 'learning_rate': 0.0316227766016838}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:12,065] Trial 3 finished with value: 0.725531914893617 and parameters: {'n_estimators': 78, 'learning_rate': 0.005623413251903492}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:12,123] Trial 4 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 32, 'learning_rate': 0.1778279410038923}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:12,190] Trial 5 finished with value: 0.7468085106382979 and parameters: {'n_estimators': 44, 'learning_rate': 0.013335214321633242}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:12,319] Trial 6 finished with value: 0.8056737588652482 and parameters: {'n_estimators': 89, 'learning_rate': 0.4216965034285823}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:12,416] Trial 7 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 66, 'learning_rate': 0.002371373705661656}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:12,464] Trial 8 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 21, 'learning_rate': 0.07498942093324559}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:12,510] Trial 9 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 27, 'learning_rate': 0.008659643233600654}. Best is trial 0 with value: 0.8058510638297871.\n",
      "[I 2025-12-28 19:46:12,621] Trial 10 finished with value: 0.8185283687943263 and parameters: {'n_estimators': 72, 'learning_rate': 0.27384196342643613}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:12,764] Trial 11 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 95, 'learning_rate': 0.0015399265260594922}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:12,842] Trial 12 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 49, 'learning_rate': 0.04869675251658632}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:12,911] Trial 13 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 38, 'learning_rate': 0.0036517412725483775}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,029] Trial 14 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 83, 'learning_rate': 0.11547819846894583}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,140] Trial 15 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 61, 'learning_rate': 0.020535250264571463}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,175] Trial 16 finished with value: 0.7972517730496455 and parameters: {'n_estimators': 15, 'learning_rate': 0.6493816315762113}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,214] Trial 17 finished with value: 0.7297872340425531 and parameters: {'n_estimators': 18, 'learning_rate': 0.025482967479793468}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,314] Trial 18 finished with value: 0.801418439716312 and parameters: {'n_estimators': 64, 'learning_rate': 0.8058421877614819}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,435] Trial 19 finished with value: 0.725531914893617 and parameters: {'n_estimators': 86, 'learning_rate': 0.004531583637600819}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,502] Trial 20 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 41, 'learning_rate': 0.14330125702369628}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,591] Trial 21 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 52, 'learning_rate': 0.001910952974970441}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,731] Trial 22 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 98, 'learning_rate': 0.060429639023813285}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,853] Trial 23 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 75, 'learning_rate': 0.010746078283213176}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,910] Trial 24 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 29, 'learning_rate': 0.33982083289425596}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:13,959] Trial 25 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029427271762092824}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,078] Trial 26 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 69, 'learning_rate': 0.0930572040929699}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,210] Trial 27 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 92, 'learning_rate': 0.016548170999431816}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,288] Trial 28 finished with value: 0.81427304964539 and parameters: {'n_estimators': 46, 'learning_rate': 0.5232991146814947}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,358] Trial 29 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 35, 'learning_rate': 0.006978305848598664}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,478] Trial 30 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 81, 'learning_rate': 0.220673406908459}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,569] Trial 31 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 58, 'learning_rate': 0.0012409377607517198}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,605] Trial 32 finished with value: 0.7422872340425531 and parameters: {'n_estimators': 12, 'learning_rate': 0.039241897584845364}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,641] Trial 33 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 14, 'learning_rate': 0.006264335366568854}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,740] Trial 34 finished with value: 0.8099290780141845 and parameters: {'n_estimators': 59, 'learning_rate': 0.1980956778550338}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,872] Trial 35 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 82, 'learning_rate': 0.0011139738599948022}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:14,940] Trial 36 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 37, 'learning_rate': 0.03522694651473102}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,019] Trial 37 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 48, 'learning_rate': 0.0026416483203860917}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,148] Trial 38 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 93, 'learning_rate': 0.08353625469578259}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,270] Trial 39 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 71, 'learning_rate': 0.014855080171727746}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,327] Trial 40 finished with value: 0.8015070921985817 and parameters: {'n_estimators': 25, 'learning_rate': 0.469758881670649}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,396] Trial 41 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 31, 'learning_rate': 0.0017154378963428786}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,506] Trial 42 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 76, 'learning_rate': 0.05424690937011326}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,649] Trial 43 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 99, 'learning_rate': 0.00964661619911199}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,737] Trial 44 finished with value: 0.8101950354609929 and parameters: {'n_estimators': 54, 'learning_rate': 0.3050527890267024}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,814] Trial 45 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 42, 'learning_rate': 0.02287573200318396}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:15,945] Trial 46 finished with value: 0.8100177304964538 and parameters: {'n_estimators': 88, 'learning_rate': 0.7233941627366745}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,046] Trial 47 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 65, 'learning_rate': 0.004067944321083046}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,093] Trial 48 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 19, 'learning_rate': 0.12863969449369742}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,131] Trial 49 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 17, 'learning_rate': 0.005048065716667474}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,228] Trial 50 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 62, 'learning_rate': 0.1596338544287943}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,360] Trial 51 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 85, 'learning_rate': 0.02838735964758755}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,426] Trial 52 finished with value: 0.8060283687943262 and parameters: {'n_estimators': 39, 'learning_rate': 0.8976871324473146}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,516] Trial 53 finished with value: 0.7468085106382979 and parameters: {'n_estimators': 51, 'learning_rate': 0.011970850304957308}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,677] Trial 54 finished with value: 0.7973404255319149 and parameters: {'n_estimators': 96, 'learning_rate': 0.3785515249258632}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,809] Trial 55 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 73, 'learning_rate': 0.002128751661796374}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,878] Trial 56 finished with value: 0.8101950354609929 and parameters: {'n_estimators': 28, 'learning_rate': 0.06731703824144986}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:16,926] Trial 57 finished with value: 0.7422872340425531 and parameters: {'n_estimators': 22, 'learning_rate': 0.018434229924091106}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,046] Trial 58 finished with value: 0.8184397163120567 and parameters: {'n_estimators': 68, 'learning_rate': 0.5829415347136077}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,188] Trial 59 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 91, 'learning_rate': 0.003278121151393461}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,266] Trial 60 finished with value: 0.801595744680851 and parameters: {'n_estimators': 45, 'learning_rate': 0.10366329284376985}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,336] Trial 61 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 34, 'learning_rate': 0.0013823722273579005}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,456] Trial 62 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 79, 'learning_rate': 0.0437144481261109}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,556] Trial 63 finished with value: 0.725531914893617 and parameters: {'n_estimators': 56, 'learning_rate': 0.007773650302387762}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,592] Trial 64 finished with value: 0.801595744680851 and parameters: {'n_estimators': 11, 'learning_rate': 0.24582440689201987}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,640] Trial 65 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 12, 'learning_rate': 0.01567878843826971}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,727] Trial 66 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 57, 'learning_rate': 0.4958068241684657}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,871] Trial 67 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 80, 'learning_rate': 0.0027881266654131345}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:17,927] Trial 68 finished with value: 0.8142730496453903 and parameters: {'n_estimators': 34, 'learning_rate': 0.08816830667755711}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,016] Trial 69 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 46, 'learning_rate': 0.0011757432659207114}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,164] Trial 70 finished with value: 0.810017730496454 and parameters: {'n_estimators': 91, 'learning_rate': 0.037180266639144754}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,274] Trial 71 finished with value: 0.725531914893617 and parameters: {'n_estimators': 69, 'learning_rate': 0.006611690262414818}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,320] Trial 72 finished with value: 0.8058510638297871 and parameters: {'n_estimators': 23, 'learning_rate': 0.20908000412787187}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,377] Trial 73 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 29, 'learning_rate': 0.004293510210083484}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,505] Trial 74 finished with value: 0.81427304964539 and parameters: {'n_estimators': 74, 'learning_rate': 0.13577271421051842}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,657] Trial 75 finished with value: 0.8143617021276596 and parameters: {'n_estimators': 97, 'learning_rate': 0.024144182212566402}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,735] Trial 76 finished with value: 0.81427304964539 and parameters: {'n_estimators': 51, 'learning_rate': 0.7635060803383348}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,803] Trial 77 finished with value: 0.7297872340425531 and parameters: {'n_estimators': 40, 'learning_rate': 0.010181517217181822}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:18,932] Trial 78 finished with value: 0.81427304964539 and parameters: {'n_estimators': 86, 'learning_rate': 0.321967844425138}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,031] Trial 79 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 63, 'learning_rate': 0.0018105582430271226}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,076] Trial 80 finished with value: 0.7933510638297872 and parameters: {'n_estimators': 17, 'learning_rate': 0.05725487884358381}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,124] Trial 81 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 20, 'learning_rate': 0.0022467900918126454}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,222] Trial 82 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 66, 'learning_rate': 0.07104974114426789}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,352] Trial 83 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 88, 'learning_rate': 0.01263462917654469}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,428] Trial 84 finished with value: 0.8056737588652483 and parameters: {'n_estimators': 43, 'learning_rate': 0.39954205589498876}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,527] Trial 85 finished with value: 0.8016843971631206 and parameters: {'n_estimators': 54, 'learning_rate': 0.029961427410043647}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,678] Trial 86 finished with value: 0.7973404255319149 and parameters: {'n_estimators': 100, 'learning_rate': 0.9474635256553756}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,799] Trial 87 finished with value: 0.725531914893617 and parameters: {'n_estimators': 77, 'learning_rate': 0.005327978945865643}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,858] Trial 88 finished with value: 0.8101063829787234 and parameters: {'n_estimators': 32, 'learning_rate': 0.16848548794358392}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:19,906] Trial 89 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 26, 'learning_rate': 0.008204696109024995}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,016] Trial 90 finished with value: 0.8057624113475178 and parameters: {'n_estimators': 71, 'learning_rate': 0.2594552721404016}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,158] Trial 91 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 94, 'learning_rate': 0.0014590242156305613}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,236] Trial 92 finished with value: 0.8059397163120569 and parameters: {'n_estimators': 49, 'learning_rate': 0.04613839682733216}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,306] Trial 93 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 37, 'learning_rate': 0.003459891660869934}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,435] Trial 94 finished with value: 0.8185283687943261 and parameters: {'n_estimators': 83, 'learning_rate': 0.10941138105771861}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,526] Trial 95 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 60, 'learning_rate': 0.019456400615886365}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,561] Trial 96 finished with value: 0.801595744680851 and parameters: {'n_estimators': 14, 'learning_rate': 0.6152654101490374}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,611] Trial 97 finished with value: 0.7127659574468085 and parameters: {'n_estimators': 13, 'learning_rate': 0.0025028654311746077}. Best is trial 10 with value: 0.8185283687943263.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:46:20,836] A new study created in memory with name: Gradient Boosting Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:20,710] Trial 98 finished with value: 0.7974290780141844 and parameters: {'n_estimators': 59, 'learning_rate': 0.0791475543941116}. Best is trial 10 with value: 0.8185283687943263.\n",
      "[I 2025-12-28 19:46:20,832] Trial 99 finished with value: 0.8059397163120566 and parameters: {'n_estimators': 81, 'learning_rate': 0.014074646633398432}. Best is trial 10 with value: 0.8185283687943263.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using QMCSampler: {'n_estimators': 72, 'learning_rate': 0.27384196342643613}\n",
      "Best accuracy: 0.8185, at trial: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9f745b13a34d4590cdb202bf79c8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:20,920] Trial 0 finished with value: 0.788741134751773 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.788741134751773.\n",
      "[W 2025-12-28 19:46:20,922] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:20,948] Trial 1 finished with value: 0.52322695035461 and parameters: {'max_features': None, 'n_estimators': 10, 'learning_rate': 0.0010000000000000002, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 0 with value: 0.788741134751773.\n",
      "[W 2025-12-28 19:46:20,951] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,050] Trial 2 finished with value: 0.788918439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.010000000000000004, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.75}. Best is trial 2 with value: 0.788918439716312.\n",
      "[W 2025-12-28 19:46:21,053] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,164] Trial 3 finished with value: 0.7934397163120567 and parameters: {'max_features': None, 'n_estimators': 78, 'learning_rate': 0.003162277660168382, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.875}. Best is trial 3 with value: 0.7934397163120567.\n",
      "[W 2025-12-28 19:46:21,166] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,234] Trial 4 finished with value: 0.7845744680851062 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.03162277660168381, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.625}. Best is trial 3 with value: 0.7934397163120567.\n",
      "[W 2025-12-28 19:46:21,235] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,314] Trial 5 finished with value: 0.7846631205673759 and parameters: {'max_features': None, 'n_estimators': 44, 'learning_rate': 0.005623413251903492, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.5625}. Best is trial 3 with value: 0.7934397163120567.\n",
      "[W 2025-12-28 19:46:21,316] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,394] Trial 6 finished with value: 0.797340425531915 and parameters: {'max_features': 'log2', 'n_estimators': 89, 'learning_rate': 0.05623413251903493, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.8125}. Best is trial 6 with value: 0.797340425531915.\n",
      "[W 2025-12-28 19:46:21,396] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,485] Trial 7 finished with value: 0.7803191489361702 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.0017782794100389236, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.9375}. Best is trial 6 with value: 0.797340425531915.\n",
      "[W 2025-12-28 19:46:21,487] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,532] Trial 8 finished with value: 0.7804078014184397 and parameters: {'max_features': 'sqrt', 'n_estimators': 21, 'learning_rate': 0.01778279410038924, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.6875}. Best is trial 6 with value: 0.797340425531915.\n",
      "[W 2025-12-28 19:46:21,533] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,580] Trial 9 finished with value: 0.763209219858156 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.004216965034285825, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.65625}. Best is trial 6 with value: 0.797340425531915.\n",
      "[W 2025-12-28 19:46:21,580] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,712] Trial 10 finished with value: 0.750709219858156 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.04216965034285825, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.90625}. Best is trial 6 with value: 0.797340425531915.\n",
      "[W 2025-12-28 19:46:21,713] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,893] Trial 11 finished with value: 0.7804964539007093 and parameters: {'max_features': None, 'n_estimators': 95, 'learning_rate': 0.0013335214321633238, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.78125}. Best is trial 6 with value: 0.797340425531915.\n",
      "[W 2025-12-28 19:46:21,895] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:21,973] Trial 12 finished with value: 0.8228723404255319 and parameters: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.013335214321633242, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.53125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:21,975] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,021] Trial 13 finished with value: 0.7127659574468085 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.002371373705661656, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.71875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,022] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,194] Trial 14 finished with value: 0.7507978723404254 and parameters: {'max_features': None, 'n_estimators': 83, 'learning_rate': 0.023713737056616564, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.96875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,196] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,273] Trial 15 finished with value: 0.8143617021276596 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.007498942093324564, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.84375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,274] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,321] Trial 16 finished with value: 0.801595744680851 and parameters: {'max_features': 'log2', 'n_estimators': 15, 'learning_rate': 0.07498942093324566, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.59375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,321] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,369] Trial 17 finished with value: 0.7427304964539008 and parameters: {'max_features': None, 'n_estimators': 18, 'learning_rate': 0.008659643233600654, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.984375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,371] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,480] Trial 18 finished with value: 0.771985815602837 and parameters: {'max_features': None, 'n_estimators': 64, 'learning_rate': 0.08659643233600657, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.734375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,480] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,591] Trial 19 finished with value: 0.7931737588652482 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.0027384196342643626, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.609375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,592] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,699] Trial 20 finished with value: 0.7971631205673759 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.027384196342643632, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.859375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,699] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,881] Trial 21 finished with value: 0.712677304964539 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.0015399265260594922, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.921875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,883] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:22,992] Trial 22 finished with value: 0.7975177304964539 and parameters: {'max_features': 'log2', 'n_estimators': 98, 'learning_rate': 0.015399265260594926, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.671875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:22,995] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,072] Trial 23 finished with value: 0.8059397163120566 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.004869675251658635, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.546875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,074] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,120] Trial 24 finished with value: 0.7847517730496454 and parameters: {'max_features': None, 'n_estimators': 29, 'learning_rate': 0.04869675251658634, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.796875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,122] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,168] Trial 25 finished with value: 0.5570921985815602 and parameters: {'max_features': 'sqrt', 'n_estimators': 24, 'learning_rate': 0.0020535250264571477, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.828125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,169] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,248] Trial 26 finished with value: 0.7719858156028367 and parameters: {'max_features': None, 'n_estimators': 69, 'learning_rate': 0.020535250264571474, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.578125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,248] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,430] Trial 27 finished with value: 0.8015070921985815 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.0064938163157621165, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'subsample': 0.703125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,432] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,509] Trial 28 finished with value: 0.7890070921985816 and parameters: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.06493816315762117, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.953125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,509] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,556] Trial 29 finished with value: 0.763386524822695 and parameters: {'max_features': 'log2', 'n_estimators': 35, 'learning_rate': 0.0036517412725483775, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.765625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,557] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,668] Trial 30 finished with value: 0.788918439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.03651741272548378, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.515625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,670] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,757] Trial 31 finished with value: 0.6916666666666667 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.0011547819846894588, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.640625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,759] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,795] Trial 32 finished with value: 0.7679964539007093 and parameters: {'max_features': None, 'n_estimators': 12, 'learning_rate': 0.01154781984689459, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.890625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,797] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,844] Trial 33 finished with value: 0.6201241134751772 and parameters: {'max_features': None, 'n_estimators': 14, 'learning_rate': 0.003398208328942561, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.9609375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,846] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:23,924] Trial 34 finished with value: 0.7889184397163119 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.03398208328942562, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.7109375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:23,926] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,004] Trial 35 finished with value: 0.6875 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.0010746078283213173, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.5859375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,006] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,073] Trial 36 finished with value: 0.7930851063829787 and parameters: {'max_features': 'log2', 'n_estimators': 37, 'learning_rate': 0.010746078283213186, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.8359375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,075] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,132] Trial 37 finished with value: 0.712854609929078 and parameters: {'max_features': 'log2', 'n_estimators': 48, 'learning_rate': 0.001910952974970441, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8984375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,134] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,231] Trial 38 finished with value: 0.8060283687943264 and parameters: {'max_features': 'log2', 'n_estimators': 93, 'learning_rate': 0.019109529749704413, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.6484375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,233] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,319] Trial 39 finished with value: 0.7972517730496452 and parameters: {'max_features': None, 'n_estimators': 71, 'learning_rate': 0.006042963902381328, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.5234375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,321] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,379] Trial 40 finished with value: 0.814095744680851 and parameters: {'max_features': 'log2', 'n_estimators': 25, 'learning_rate': 0.06042963902381334, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.7734375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,381] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,427] Trial 41 finished with value: 0.527482269503546 and parameters: {'max_features': 'sqrt', 'n_estimators': 31, 'learning_rate': 0.0014330125702369636, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.8671875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,429] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,590] Trial 42 finished with value: 0.7803191489361702 and parameters: {'max_features': None, 'n_estimators': 76, 'learning_rate': 0.014330125702369625, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.6171875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,593] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,690] Trial 43 finished with value: 0.7806737588652483 and parameters: {'max_features': None, 'n_estimators': 99, 'learning_rate': 0.004531583637600819, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7421875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,691] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,759] Trial 44 finished with value: 0.8017730496453901 and parameters: {'max_features': 'log2', 'n_estimators': 54, 'learning_rate': 0.045315836376008195, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.9921875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,761] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,817] Trial 45 finished with value: 0.810017730496454 and parameters: {'max_features': 'log2', 'n_estimators': 42, 'learning_rate': 0.008058421877614822, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8046875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,819] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:24,950] Trial 46 finished with value: 0.7804964539007091 and parameters: {'max_features': None, 'n_estimators': 88, 'learning_rate': 0.08058421877614824, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.5546875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:24,952] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,100] Trial 47 finished with value: 0.801418439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.0025482967479793462, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.6796875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,102] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,138] Trial 48 finished with value: 0.7934397163120567 and parameters: {'max_features': 'sqrt', 'n_estimators': 19, 'learning_rate': 0.02548296747979348, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.9296875}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,140] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,176] Trial 49 finished with value: 0.573936170212766 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.0029427271762092824, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.5390625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,177] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,244] Trial 50 finished with value: 0.8016843971631206 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.02942727176209283, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.7890625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,246] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,355] Trial 51 finished with value: 0.7932624113475176 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.009305720409296989, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.9140625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,356] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,403] Trial 52 finished with value: 0.7931737588652481 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.09305720409296998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.6640625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,406] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,482] Trial 53 finished with value: 0.8015070921985815 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.005232991146814949, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.6015625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,483] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,643] Trial 54 finished with value: 0.7930851063829787 and parameters: {'max_features': None, 'n_estimators': 96, 'learning_rate': 0.052329911468149505, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.8515625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,645] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,731] Trial 55 finished with value: 0.776063829787234 and parameters: {'max_features': 'log2', 'n_estimators': 73, 'learning_rate': 0.0016548170999431814, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.9765625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,733] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,799] Trial 56 finished with value: 0.7844858156028369 and parameters: {'max_features': None, 'n_estimators': 28, 'learning_rate': 0.01654817099943183, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7265625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,801] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,836] Trial 57 finished with value: 0.7971631205673758 and parameters: {'max_features': 'log2', 'n_estimators': 22, 'learning_rate': 0.006978305848598664, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.6328125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,838] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:25,967] Trial 58 finished with value: 0.788741134751773 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.06978305848598666, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.8828125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:25,969] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,120] Trial 59 finished with value: 0.81427304964539 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.002206734069084591, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7578125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,122] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,178] Trial 60 finished with value: 0.7890957446808511 and parameters: {'max_features': 'sqrt', 'n_estimators': 45, 'learning_rate': 0.022067340690845913, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.5078125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,180] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,235] Trial 61 finished with value: 0.5445035460992907 and parameters: {'max_features': None, 'n_estimators': 34, 'learning_rate': 0.0012409377607517198, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6953125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,237] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,315] Trial 62 finished with value: 0.7805851063829787 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.0124093776075172, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9453125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,317] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,425] Trial 63 finished with value: 0.7720744680851063 and parameters: {'max_features': None, 'n_estimators': 56, 'learning_rate': 0.003924189758484535, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.8203125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,427] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,452] Trial 64 finished with value: 0.7681737588652482 and parameters: {'max_features': 'sqrt', 'n_estimators': 11, 'learning_rate': 0.03924189758484538, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9, 'subsample': 0.5703125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,455] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,491] Trial 65 finished with value: 0.7169326241134751 and parameters: {'max_features': None, 'n_estimators': 12, 'learning_rate': 0.00626433536656886, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.72265625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,492] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,592] Trial 66 finished with value: 0.776063829787234 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.06264335366568861, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.97265625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,594] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,723] Trial 67 finished with value: 0.814095744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.001980956778550339, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.84765625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,724] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,771] Trial 68 finished with value: 0.8058510638297873 and parameters: {'max_features': 'log2', 'n_estimators': 34, 'learning_rate': 0.019809567785503402, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.59765625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,772] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:26,841] Trial 69 finished with value: 0.5402482269503546 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.001113973859994803, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.66015625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:26,843] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,016] Trial 70 finished with value: 0.8059397163120569 and parameters: {'max_features': 'log2', 'n_estimators': 91, 'learning_rate': 0.011139738599948034, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.91015625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,019] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,107] Trial 71 finished with value: 0.7973404255319148 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.0035226946514731027, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.78515625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,108] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,145] Trial 72 finished with value: 0.788918439716312 and parameters: {'max_features': 'log2', 'n_estimators': 23, 'learning_rate': 0.03522694651473104, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.53515625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,146] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,192] Trial 73 finished with value: 0.6789893617021276 and parameters: {'max_features': 'log2', 'n_estimators': 29, 'learning_rate': 0.0026416483203860943, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.56640625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,194] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,282] Trial 74 finished with value: 0.788918439716312 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.026416483203860936, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.81640625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,284] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,393] Trial 75 finished with value: 0.8016843971631206 and parameters: {'max_features': 'log2', 'n_estimators': 97, 'learning_rate': 0.008353625469578265, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.94140625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,395] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,484] Trial 76 finished with value: 0.7889184397163121 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.08353625469578266, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.69140625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,486] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,543] Trial 77 finished with value: 0.7844858156028369 and parameters: {'max_features': 'log2', 'n_estimators': 40, 'learning_rate': 0.004697588816706496, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.50390625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,545] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,622] Trial 78 finished with value: 0.7934397163120568 and parameters: {'max_features': 'log2', 'n_estimators': 86, 'learning_rate': 0.04697588816706495, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.75390625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,625] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,734] Trial 79 finished with value: 0.7507978723404254 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.0014855080171727755, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.87890625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,735] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,771] Trial 80 finished with value: 0.7845744680851063 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.01485508017172776, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.62890625}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,772] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,808] Trial 81 finished with value: 0.52322695035461 and parameters: {'max_features': 'sqrt', 'n_estimators': 20, 'learning_rate': 0.0017154378963428801, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.76953125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,808] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:27,887] Trial 82 finished with value: 0.801595744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.017154378963428803, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.51953125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:27,889] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,088] Trial 83 finished with value: 0.8059397163120566 and parameters: {'max_features': 'log2', 'n_estimators': 88, 'learning_rate': 0.005424690937011328, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.64453125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,090] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,168] Trial 84 finished with value: 0.8016843971631206 and parameters: {'max_features': None, 'n_estimators': 43, 'learning_rate': 0.05424690937011329, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.89453125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,170] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,226] Trial 85 finished with value: 0.7975177304964539 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.009646616199111998, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.83203125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,228] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,440] Trial 86 finished with value: 0.801595744680851 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.09646616199112, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.58203125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,440] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,571] Trial 87 finished with value: 0.8144503546099291 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.003050527890267026, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.70703125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,572] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,651] Trial 88 finished with value: 0.7933510638297873 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.030505278902670276, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.95703125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,653] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,728] Trial 89 finished with value: 0.7550531914893617 and parameters: {'max_features': 'sqrt', 'n_estimators': 26, 'learning_rate': 0.0040679443210830495, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.92578125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,730] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,808] Trial 90 finished with value: 0.8016843971631206 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.04067944321083049, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.67578125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,808] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,897] Trial 91 finished with value: 0.7465425531914893 and parameters: {'max_features': 'log2', 'n_estimators': 94, 'learning_rate': 0.0012863969449369746, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.55078125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,899] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:28,997] Trial 92 finished with value: 0.750886524822695 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.01286396944936975, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3, 'subsample': 0.80078125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:28,998] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:29,097] Trial 93 finished with value: 0.7340425531914894 and parameters: {'max_features': None, 'n_estimators': 37, 'learning_rate': 0.0022875732003183966, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.98828125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:29,098] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:29,197] Trial 94 finished with value: 0.7846631205673759 and parameters: {'max_features': 'log2', 'n_estimators': 83, 'learning_rate': 0.02287573200318397, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.73828125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:29,197] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:29,266] Trial 95 finished with value: 0.8101063829787234 and parameters: {'max_features': 'log2', 'n_estimators': 60, 'learning_rate': 0.007233941627366754, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.61328125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:29,266] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:29,313] Trial 96 finished with value: 0.7718971631205673 and parameters: {'max_features': None, 'n_estimators': 14, 'learning_rate': 0.0723394162736675, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.86328125}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:29,313] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:29,351] Trial 97 finished with value: 0.52322695035461 and parameters: {'max_features': 'log2', 'n_estimators': 13, 'learning_rate': 0.0018434229924091112, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.80859375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:29,351] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:29,461] Trial 98 finished with value: 0.7886524822695036 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.018434229924091116, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1, 'subsample': 0.55859375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "[W 2025-12-28 19:46:29,463] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:46:29,571] Trial 99 finished with value: 0.771985815602837 and parameters: {'max_features': None, 'n_estimators': 81, 'learning_rate': 0.005829415347136074, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.68359375}. Best is trial 12 with value: 0.8228723404255319.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using QMCSampler: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.013335214321633242, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.53125}\n",
      "Best accuracy: 0.8229, at trial: 12\n",
      "QMC Base Models Training Time: 40.28 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    qmc_base_models_training_start = time.time()\n",
    "\n",
    "    # QMC Hyperparameter Tuning with Cross Validation\n",
    "    qmc_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    qmc_logistic_regression.fit(X_train, y_train)\n",
    "    qmc_decision_tree.fit(X_train, y_train)\n",
    "    qmc_random_forest.fit(X_train, y_train)\n",
    "    qmc_knn.fit(X_train, y_train)\n",
    "    qmc_svc.fit(X_train, y_train)\n",
    "    qmc_adaboost.fit(X_train, y_train)\n",
    "    qmc_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    qmc_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for QMC base models training\n",
    "    qmc_base_models_training_time = qmc_base_models_training_end - qmc_base_models_training_start\n",
    "    print(f'QMC Base Models Training Time: {qmc_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping QMC base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5 Save Every Best Model Config for each Tuning Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # Base Models Storage for all sampler types\n",
    "    base_models = {\n",
    "        'TPE': {\n",
    "            'Logistic Regression': tpe_logistic_regression,\n",
    "            'Decision Tree': tpe_decision_tree,\n",
    "            'Random Forest': tpe_random_forest,\n",
    "            'K-Nearest Neighbors': tpe_knn,\n",
    "            'Support Vector Machine': tpe_svc,\n",
    "            'AdaBoost': tpe_adaboost,\n",
    "            'Gradient Boosting': tpe_gradient_boosting\n",
    "        },\n",
    "        'GP': {\n",
    "            'Logistic Regression': gp_logistic_regression,\n",
    "            'Decision Tree': gp_decision_tree,\n",
    "            'Random Forest': gp_random_forest,\n",
    "            'K-Nearest Neighbors': gp_knn,\n",
    "            'Support Vector Machine': gp_svc,\n",
    "            'AdaBoost': gp_adaboost,\n",
    "            'Gradient Boosting': gp_gradient_boosting\n",
    "        },\n",
    "        'CMA-ES': {\n",
    "            'Logistic Regression': cmaes_logistic_regression,\n",
    "            'Decision Tree': cmaes_decision_tree,\n",
    "            'Random Forest': cmaes_random_forest,\n",
    "            'K-Nearest Neighbors': cmaes_knn,\n",
    "            'Support Vector Machine': cmaes_svc,\n",
    "            'AdaBoost': cmaes_adaboost,\n",
    "            'Gradient Boosting': cmaes_gradient_boosting\n",
    "        },\n",
    "        'QMC': {\n",
    "            'Logistic Regression': qmc_logistic_regression,\n",
    "            'Decision Tree': qmc_decision_tree,\n",
    "            'Random Forest': qmc_random_forest,\n",
    "            'K-Nearest Neighbors': qmc_knn,\n",
    "            'Support Vector Machine': qmc_svc,\n",
    "            'AdaBoost': qmc_adaboost,\n",
    "            'Gradient Boosting': qmc_gradient_boosting\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    print(\"Skipping base models storage (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Meta Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters to be tuned are:\n",
    "- Selection of the number and type of base models used\n",
    "- Number of layers in the neural network: 1 - 5\n",
    "- Number of neurons per layer: 10 - 100\n",
    "- Learning rate behavior: Constant or Adaptive\n",
    "- Learning rate value: 0.0001 - 0.01\n",
    "- L2 Regularization value: 0.0001 - 0.01\n",
    "\n",
    "Unchanged Preset hyperparameters:\n",
    "- Activation function: ReLU\n",
    "- Optimizer (Solver): Adam\n",
    "- Epochs (Max Iter): 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:29,818] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (TPESampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561ca6f2c8194375b4c337699b6cb25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:30,686] Trial 0 finished with value: 0.7833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.7833333333333333.\n",
      "[I 2025-12-28 19:46:31,751] Trial 1 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 37, 'n_neurons_2': 18, 'n_neurons_3': 72, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:35,941] Trial 2 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:36,867] Trial 3 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00013400367243354819, 'alpha': 0.0004187594718900631}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:46:37,731] Trial 4 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0010402587615883842, 'alpha': 0.006533305220227739}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:38,531] Trial 5 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007148510793512986, 'alpha': 0.00432543242796456}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:39,302] Trial 6 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.001656260589333597, 'alpha': 0.0010124137770478635}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:39,578] Trial 7 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 18, 'n_neurons_2': 86, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0015197980620034217, 'alpha': 0.0022653156413948872}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:39,581] Trial 8 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:40,622] Trial 9 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 17, 'n_neurons_2': 24, 'n_neurons_3': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.00015956700210656633, 'alpha': 0.002123261760236048}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:41,577] Trial 10 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 97, 'n_neurons_1': 57, 'n_neurons_2': 12, 'n_neurons_3': 80, 'n_neurons_4': 51, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003208447516296119, 'alpha': 0.007589158830942278}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:42,512] Trial 11 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 100, 'n_neurons_1': 62, 'n_neurons_2': 10, 'n_neurons_3': 81, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00028959877138004937, 'alpha': 0.00924996517208557}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:43,389] Trial 12 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 100, 'n_neurons_1': 54, 'n_neurons_2': 55, 'n_neurons_3': 67, 'n_neurons_4': 51, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00033095410418693377, 'alpha': 0.00011739143569617559}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:44,453] Trial 13 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 81, 'n_neurons_1': 50, 'n_neurons_2': 10, 'n_neurons_3': 57, 'n_neurons_4': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010625721497327523, 'alpha': 0.0033059913324901854}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:45,376] Trial 14 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 82, 'n_neurons_1': 70, 'n_neurons_2': 38, 'n_neurons_3': 11, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002939054635930825, 'alpha': 0.009475318792277119}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:46,347] Trial 15 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 90, 'n_neurons_1': 35, 'n_neurons_2': 89, 'n_neurons_3': 96, 'n_neurons_4': 11, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00022613595117699714, 'alpha': 0.0011712300016312027}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:47,083] Trial 16 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 71, 'n_neurons_1': 34, 'n_neurons_2': 96, 'n_neurons_3': 97, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007722032125521967, 'alpha': 0.0011474620887526224}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:47,965] Trial 17 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 90, 'n_neurons_1': 34, 'n_neurons_2': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017936089783930067, 'alpha': 0.0001830481288873882}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:48,808] Trial 18 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 68, 'n_neurons_1': 42, 'n_neurons_2': 67, 'n_neurons_3': 100, 'n_neurons_4': 10, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005041470618034526, 'alpha': 0.0017022178444786318}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:49,776] Trial 19 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 47, 'n_neurons_1': 25, 'n_neurons_2': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001919466479280304, 'alpha': 0.0007369042628989034}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:50,570] Trial 20 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 75, 'n_neurons_1': 10, 'n_neurons_2': 100, 'n_neurons_3': 74, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0029756218598556, 'alpha': 0.004465572843585025}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:51,351] Trial 21 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 69, 'n_neurons_1': 30, 'n_neurons_2': 100, 'n_neurons_3': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.008663006683555808, 'alpha': 0.0014413718769864707}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:52,104] Trial 22 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 90, 'n_neurons_1': 42, 'n_neurons_2': 87, 'n_neurons_3': 88, 'n_neurons_4': 10, 'learning_rate': 'adaptive', 'learning_rate_init': 0.008330052112900797, 'alpha': 0.000919864578802583}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:53,161] Trial 23 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 89, 'n_neurons_1': 45, 'n_neurons_2': 87, 'n_neurons_3': 63, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010362433048052998, 'alpha': 0.0002497206423265259}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:53,924] Trial 24 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 76, 'n_neurons_1': 24, 'n_neurons_2': 71, 'n_neurons_3': 45, 'n_neurons_4': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0034263400679484177, 'alpha': 0.0012276864519589624}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:54,838] Trial 25 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 61, 'n_neurons_1': 67, 'n_neurons_2': 80, 'n_neurons_3': 90, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00022115601905899648, 'alpha': 0.0031357622415690407}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:55,951] Trial 26 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 72, 'n_neurons_1': 31, 'n_neurons_2': 95, 'n_neurons_3': 72, 'n_neurons_4': 28, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00043465266703999344, 'alpha': 0.00068844401996909}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:56,679] Trial 27 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 38, 'n_neurons_2': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0024289863347430945, 'alpha': 0.0023653061993678887}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:57,426] Trial 28 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 87, 'n_neurons_1': 77, 'n_neurons_2': 23, 'n_neurons_3': 86, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006607450641436995, 'alpha': 0.005314401002502161}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:58,241] Trial 29 finished with value: 0.8333333333333334 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 94, 'n_neurons_1': 48, 'n_neurons_2': 77, 'n_neurons_3': 100, 'n_neurons_4': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005190007261993186, 'alpha': 0.000287608011927794}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:59,047] Trial 30 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 61, 'n_neurons_1': 24, 'n_neurons_2': 40, 'n_neurons_3': 45, 'n_neurons_4': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007016839801768235, 'alpha': 0.0005481353566881375}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:46:59,851] Trial 31 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 67, 'n_neurons_1': 41, 'n_neurons_2': 61, 'n_neurons_3': 100, 'n_neurons_4': 14, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005129900231762971, 'alpha': 0.0016451146712004724}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:00,819] Trial 32 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 79, 'n_neurons_1': 33, 'n_neurons_2': 67, 'n_neurons_3': 93, 'n_neurons_4': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00023903411071533233, 'alpha': 0.0017747323061134488}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:01,670] Trial 33 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 64, 'n_neurons_1': 45, 'n_neurons_2': 92, 'n_neurons_3': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045627893119909614, 'alpha': 0.0011522304528125485}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:02,440] Trial 34 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 49, 'n_neurons_1': 27, 'n_neurons_2': 48, 'n_neurons_3': 94, 'n_neurons_4': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001359330433585162, 'alpha': 0.003075050120238753}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:03,322] Trial 35 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 74, 'n_neurons_1': 54, 'n_neurons_2': 81, 'n_neurons_3': 84, 'n_neurons_4': 21, 'learning_rate': 'constant', 'learning_rate_init': 0.001013655872004855, 'alpha': 0.0006910580220000289}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:03,647] Trial 36 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 85, 'n_neurons_1': 18, 'n_neurons_2': 65, 'n_neurons_3': 75, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005381645926989968, 'alpha': 0.00044903736694868753}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:04,418] Trial 37 finished with value: 0.8333333333333334 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 34, 'n_neurons_1': 36, 'learning_rate': 'constant', 'learning_rate_init': 0.0013916911153674957, 'alpha': 0.0009273988398497965}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:47:05,325] Trial 38 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013789679986520097, 'alpha': 0.0013761674534209227}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:06,283] Trial 39 finished with value: 0.85 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 71, 'n_neurons_1': 94, 'n_neurons_2': 30, 'learning_rate': 'constant', 'learning_rate_init': 0.0003844651990912484, 'alpha': 0.0018295374974979777}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:07,126] Trial 40 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 78, 'n_neurons_1': 40, 'n_neurons_2': 90, 'n_neurons_3': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006694718076541636, 'alpha': 0.004130215091275801}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:08,014] Trial 41 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 25, 'n_neurons_2': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00020253420501435424, 'alpha': 0.0007391369148970338}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:47:08,881] Trial 42 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 54, 'n_neurons_1': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000165676810819796, 'alpha': 0.0005495784357032966}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:09,817] Trial 43 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 34, 'n_neurons_1': 29, 'n_neurons_2': 48, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00012176671980817125, 'alpha': 0.0008431895250277579}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:10,716] Trial 44 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 65, 'n_neurons_1': 19, 'n_neurons_2': 27, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000249025015496734, 'alpha': 0.00034385097169559886}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:11,095] Trial 45 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 19, 'n_neurons_1': 37, 'n_neurons_2': 19, 'n_neurons_3': 24, 'n_neurons_4': 38, 'learning_rate': 'constant', 'learning_rate_init': 0.00019357035907804516, 'alpha': 0.0022560774693562748}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:11,836] Trial 46 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 50, 'n_neurons_2': 34, 'n_neurons_3': 59, 'n_neurons_4': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0019196949309771526, 'alpha': 0.0010798571630559635}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:12,674] Trial 47 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 54, 'n_neurons_1': 22, 'n_neurons_2': 48, 'n_neurons_3': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00035730895835052467, 'alpha': 0.0005793136199217095}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:13,579] Trial 48 finished with value: 0.85 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 84, 'n_neurons_1': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00026800913011958187, 'alpha': 0.007211862736889739}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:13,848] Trial 49 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 60, 'n_neurons_1': 85, 'n_neurons_2': 54, 'learning_rate': 'constant', 'learning_rate_init': 0.0008931027324565411, 'alpha': 0.0014013716530576618}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:14,638] Trial 50 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 33, 'n_neurons_2': 83, 'n_neurons_3': 52, 'n_neurons_4': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013084077172133457, 'alpha': 0.0027316632175130215}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:15,371] Trial 51 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 70, 'n_neurons_1': 29, 'n_neurons_2': 99, 'n_neurons_3': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0068616816898367005, 'alpha': 0.0015619520162107848}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:16,116] Trial 52 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 80, 'n_neurons_1': 44, 'n_neurons_2': 95, 'n_neurons_3': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009153078309151954, 'alpha': 0.0008195690935807136}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:16,895] Trial 53 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 68, 'n_neurons_1': 34, 'n_neurons_2': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004958657949250432, 'alpha': 0.001166317391337912}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:17,655] Trial 54 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 56, 'n_neurons_1': 14, 'n_neurons_2': 94, 'n_neurons_3': 90, 'n_neurons_4': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0036587888360927055, 'alpha': 0.0020084900103543905}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:18,459] Trial 55 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 92, 'n_neurons_1': 21, 'n_neurons_2': 75, 'n_neurons_3': 85, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006091285725065865, 'alpha': 0.00010040877064250767}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:19,436] Trial 56 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 76, 'n_neurons_1': 30, 'n_neurons_2': 89, 'n_neurons_3': 78, 'n_neurons_4': 18, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015791458903317135, 'alpha': 0.0009758261585476009}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:20,193] Trial 57 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 85, 'n_neurons_1': 39, 'n_neurons_2': 15, 'n_neurons_3': 97, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009632306773629291, 'alpha': 0.003846353943377332}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:21,000] Trial 58 finished with value: 0.7833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 64, 'n_neurons_1': 48, 'n_neurons_2': 84, 'n_neurons_3': 91, 'n_neurons_4': 10, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00769929057843963, 'alpha': 0.0013946382593641058}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:22,077] Trial 59 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 98, 'n_neurons_1': 27, 'n_neurons_2': 96, 'n_neurons_3': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010004298526789726, 'alpha': 0.00042680425911817936}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:22,865] Trial 60 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 74, 'n_neurons_1': 36, 'n_neurons_2': 68, 'n_neurons_3': 84, 'n_neurons_4': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004152198878823594, 'alpha': 0.005486802872055517}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:23,751] Trial 61 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 60, 'n_neurons_1': 65, 'n_neurons_2': 79, 'n_neurons_3': 90, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00022500487835919097, 'alpha': 0.002842091327285611}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:24,586] Trial 62 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 50, 'n_neurons_1': 78, 'n_neurons_2': 86, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00029647332347343804, 'alpha': 0.005789343389059349}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:25,561] Trial 63 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 63, 'n_neurons_1': 67, 'n_neurons_2': 72, 'n_neurons_3': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00020398660984155453, 'alpha': 0.0024322837708958206}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:26,539] Trial 64 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 69, 'n_neurons_1': 32, 'n_neurons_2': 97, 'n_neurons_3': 100, 'n_neurons_4': 63, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011727632118815126, 'alpha': 0.0033509014466219316}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:27,469] Trial 65 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 43, 'n_neurons_2': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001507688479128055, 'alpha': 0.008712849619846363}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:28,298] Trial 66 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 56, 'n_neurons_1': 73, 'n_neurons_2': 78, 'n_neurons_3': 89, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005970036137838235, 'alpha': 0.001936677270662993}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:28,936] Trial 67 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 72, 'n_neurons_1': 57, 'n_neurons_2': 60, 'n_neurons_3': 81, 'n_neurons_4': 21, 'learning_rate': 'constant', 'learning_rate_init': 0.00041009542957018793, 'alpha': 0.001551635082510324}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:29,736] Trial 68 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 26, 'n_neurons_2': 90, 'n_neurons_3': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008282784016512737, 'alpha': 0.0006620463800704964}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:47:30,994] Trial 69 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 81, 'n_neurons_1': 52, 'n_neurons_2': 83, 'n_neurons_3': 97, 'n_neurons_4': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017696259085330096, 'alpha': 0.0013191963830403196}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:31,863] Trial 70 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 62, 'n_neurons_1': 47, 'n_neurons_2': 65, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00033989956389426115, 'alpha': 0.004913180752694505}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:32,587] Trial 71 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 45, 'n_neurons_1': 41, 'n_neurons_2': 57, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0028748343557766062, 'alpha': 0.001022754706014471}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:33,347] Trial 72 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 38, 'n_neurons_2': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0024955751998461165, 'alpha': 0.002584281976907584}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:34,106] Trial 73 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 51, 'n_neurons_1': 36, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0019438141922544616, 'alpha': 0.001639352054775364}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:47:35,059] Trial 74 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 58, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011852111703468316, 'alpha': 0.0034222748857533855}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:35,850] Trial 75 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 77, 'n_neurons_1': 34, 'n_neurons_2': 43, 'n_neurons_3': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0011703226555738974, 'alpha': 0.002158485735883782}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:36,556] Trial 76 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 87, 'n_neurons_1': 22, 'n_neurons_2': 58, 'n_neurons_3': 78, 'n_neurons_4': 23, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005640847218776455, 'alpha': 0.0008311749546441878}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:47:37,163] Trial 77 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 38, 'learning_rate': 'constant', 'learning_rate_init': 0.00023132410347972805, 'alpha': 0.0011655912864006216}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:37,943] Trial 78 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 28, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005038957912720539, 'alpha': 0.0018616986310065686}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:38,789] Trial 79 finished with value: 0.85 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 52, 'n_neurons_1': 43, 'n_neurons_2': 92, 'n_neurons_3': 97, 'n_neurons_4': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.008016858402489262, 'alpha': 0.006239953707291068}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:47:39,690] Trial 80 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 92, 'n_neurons_1': 15, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00014266156558321674, 'alpha': 0.0012791304172909087}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:40,457] Trial 81 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 59, 'n_neurons_1': 22, 'n_neurons_2': 40, 'n_neurons_3': 46, 'n_neurons_4': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007082369944051417, 'alpha': 0.0003583124294423698}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:41,311] Trial 82 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 61, 'n_neurons_1': 24, 'n_neurons_2': 50, 'n_neurons_3': 40, 'n_neurons_4': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002904369537360351, 'alpha': 0.0006137818920500333}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:42,089] Trial 83 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 48, 'n_neurons_1': 40, 'n_neurons_2': 37, 'n_neurons_3': 45, 'n_neurons_4': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0011254748311333893, 'alpha': 0.0007401516830686152}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:42,913] Trial 84 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 67, 'n_neurons_1': 35, 'n_neurons_2': 44, 'n_neurons_3': 50, 'n_neurons_4': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007982685623931584, 'alpha': 0.0005232840484363959}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:43,650] Trial 85 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 10, 'n_neurons_1': 31, 'n_neurons_2': 98, 'n_neurons_3': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0016532445929564358, 'alpha': 0.0004846293973810935}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:44,591] Trial 86 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 73, 'n_neurons_1': 38, 'n_neurons_2': 32, 'n_neurons_3': 62, 'n_neurons_4': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005820433547417742, 'alpha': 0.0014962673262950933}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:45,397] Trial 87 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 53, 'n_neurons_1': 26, 'n_neurons_2': 20, 'n_neurons_3': 67, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009453410447406929, 'alpha': 0.0023581364626154098}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:46,041] Trial 88 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 69, 'n_neurons_1': 29, 'n_neurons_2': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.00044825435042827123, 'alpha': 0.0008791117772724076}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:46,909] Trial 89 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 57, 'n_neurons_1': 18, 'n_neurons_2': 63, 'n_neurons_3': 94, 'n_neurons_4': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007126530931092839, 'alpha': 0.0010650423886745981}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:47,880] Trial 90 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 33, 'n_neurons_1': 84, 'n_neurons_2': 27, 'n_neurons_3': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018211535709158436, 'alpha': 0.0037619598244353855}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:48,740] Trial 91 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 63, 'n_neurons_1': 46, 'n_neurons_2': 53, 'n_neurons_3': 93, 'n_neurons_4': 14, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006406203672537239, 'alpha': 0.0017507549157100804}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:49,648] Trial 92 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 66, 'n_neurons_1': 41, 'n_neurons_2': 56, 'n_neurons_3': 100, 'n_neurons_4': 13, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005186285760948775, 'alpha': 0.0016778181539173621}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:50,583] Trial 93 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 70, 'n_neurons_1': 24, 'n_neurons_2': 60, 'n_neurons_3': 88, 'n_neurons_4': 10, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00038713378595601317, 'alpha': 0.0029929980709161707}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:51,512] Trial 94 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 78, 'n_neurons_1': 50, 'n_neurons_2': 67, 'n_neurons_3': 97, 'n_neurons_4': 19, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00026151660649767104, 'alpha': 0.0020716657399580864}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:52,265] Trial 95 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 65, 'n_neurons_1': 33, 'n_neurons_2': 51, 'learning_rate': 'adaptive', 'learning_rate_init': 0.008857886154372739, 'alpha': 0.0009776471441418674}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:47:53,610] Trial 96 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 38, 'n_neurons_2': 74, 'n_neurons_3': 93, 'n_neurons_4': 56, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002033446335710085, 'alpha': 0.0012671501955123917}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:54,387] Trial 97 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 72, 'n_neurons_1': 36, 'n_neurons_2': 94, 'n_neurons_3': 56, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004432319720628677, 'alpha': 0.0014416324749781206}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:55,309] Trial 98 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 75, 'n_neurons_1': 44, 'n_neurons_2': 63, 'n_neurons_3': 12, 'n_neurons_4': 25, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000318998236131801, 'alpha': 0.0001709176640337353}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:47:56,364] Trial 99 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 95, 'n_neurons_1': 62, 'n_neurons_2': 55, 'n_neurons_3': 73, 'n_neurons_4': 15, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004949363192364887, 'alpha': 0.0007467626213590211}. Best is trial 1 with value: 0.9166666666666666.\n",
      "\n",
      "Selected Base Models for Stacking using TPESampler:\n",
      "- Logistic Regression\n",
      "- Support Vector Machine\n",
      "- AdaBoost\n",
      "Best Hyperparameters for Meta Model (MLP) using TPESampler: {'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (83, 37, 18, 72, 50), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9167, at trial: 1\n",
      "TPE base models training time: 49.63 seconds\n",
      "TPE SEl-NNML Training Time: 87.62 seconds\n",
      "Total TPE Training Time (Base + Meta): 137.24 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    tpe_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    tpe_sel_nnml, tpe_meta_study = meta_model_tuning(base_models['TPE'], X_train, y_train, X_test, y_test, sampler='TPESampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    tpe_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for TPE SEl-NNML training\n",
    "    tpe_meta_model_training_time = tpe_meta_model_training_end - tpe_meta_model_training_start\n",
    "    print(f'TPE base models training time: {tpe_base_models_training_time:.2f} seconds')\n",
    "    print(f'TPE SEl-NNML Training Time: {tpe_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total TPE Training Time (Base + Meta): {tpe_base_models_training_time + tpe_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    tpe_meta_history = tpe_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    tpe_meta_history.columns = ['iteration', 'score']\n",
    "    tpe_meta_history['iteration'] = tpe_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping TPE meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:178: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:47:57,480] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (GPSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ef0fdd9e4c4db2bda01c8328495d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:47:58,391] Trial 0 finished with value: 0.8 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.8.\n",
      "[I 2025-12-28 19:47:59,466] Trial 1 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 37, 'n_neurons_2': 18, 'n_neurons_3': 72, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:00,270] Trial 2 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:00,978] Trial 3 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00013400367243354819, 'alpha': 0.0004187594718900631}. Best is trial 1 with value: 0.9166666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:01,884] Trial 4 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0010402587615883842, 'alpha': 0.006533305220227739}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:02,796] Trial 5 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007148510793512986, 'alpha': 0.00432543242796456}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:03,631] Trial 6 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.001656260589333597, 'alpha': 0.0010124137770478635}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:03,845] Trial 7 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 18, 'n_neurons_2': 86, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0015197980620034217, 'alpha': 0.0022653156413948872}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:03,847] Trial 8 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:04,876] Trial 9 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 17, 'n_neurons_2': 24, 'n_neurons_3': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.00015956700210656633, 'alpha': 0.002123261760236048}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:04,973] The parameter `n_layers` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:04,973] The parameter `n_neurons_0` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:04,973] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:04,973] The parameter `learning_rate_init` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:04,975] The parameter `alpha` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:05,797] Trial 10 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0020133650202440474, 'alpha': 0.0002808915139812627}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:05,914] The parameter `n_layers` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:05,915] The parameter `n_neurons_0` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:05,915] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:05,916] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:05,916] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:05,917] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:05,917] The parameter `learning_rate_init` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:05,917] The parameter `alpha` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:06,740] Trial 11 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 31, 'n_neurons_1': 39, 'n_neurons_2': 77, 'n_neurons_3': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.0013696739838480055, 'alpha': 0.00015393931002140855}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:06,830] The parameter `n_layers` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:06,831] The parameter `n_neurons_0` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:06,831] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:06,832] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:06,832] The parameter `learning_rate_init` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:06,832] The parameter `alpha` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:07,666] Trial 12 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 34, 'n_neurons_1': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.0060826539606401225, 'alpha': 0.0018292676411745708}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:07,733] The parameter `n_layers` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:07,733] The parameter `n_neurons_0` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:07,733] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:07,733] The parameter `n_neurons_2` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:07,733] The parameter `n_neurons_3` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:07,733] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:07,733] The parameter `learning_rate_init` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:07,733] The parameter `alpha` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:08,850] Trial 13 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 55, 'n_neurons_1': 62, 'n_neurons_2': 54, 'n_neurons_3': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0001118489555166451, 'alpha': 0.001954090133022007}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:08,930] The parameter `n_layers` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:08,930] The parameter `n_neurons_0` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:08,930] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:08,936] The parameter `learning_rate_init` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:08,936] The parameter `alpha` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:09,802] Trial 14 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.000549942648034561, 'alpha': 0.00010737748632897979}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:09,871] The parameter `n_layers` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:09,872] The parameter `n_neurons_0` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:09,873] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:09,873] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:09,874] The parameter `n_neurons_3` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:09,874] The parameter `n_neurons_4` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:09,875] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:09,875] The parameter `learning_rate_init` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:09,876] The parameter `alpha` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:10,785] Trial 15 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 48, 'n_neurons_1': 97, 'n_neurons_2': 97, 'n_neurons_3': 87, 'n_neurons_4': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004303720019143252, 'alpha': 0.00021826570038901196}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:10,842] The parameter `n_layers` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:10,843] The parameter `n_neurons_0` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:10,844] The parameter `n_neurons_1` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:10,844] The parameter `n_neurons_2` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:10,844] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:10,845] The parameter `learning_rate_init` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:10,845] The parameter `alpha` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:11,675] Trial 16 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 95, 'n_neurons_1': 73, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009552294429449873, 'alpha': 0.00019061980918553997}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:11,734] The parameter `n_layers` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:11,734] The parameter `n_neurons_0` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:11,734] The parameter `n_neurons_1` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:11,740] The parameter `n_neurons_2` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:11,740] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:11,740] The parameter `learning_rate_init` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:11,740] The parameter `alpha` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:12,592] Trial 17 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 77, 'n_neurons_2': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.0003865304288032154, 'alpha': 0.004156447611486069}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:12,656] The parameter `n_layers` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:12,658] The parameter `n_neurons_0` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:12,658] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:12,658] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:12,660] The parameter `n_neurons_3` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:12,660] The parameter `n_neurons_4` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:12,660] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:12,661] The parameter `learning_rate_init` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:12,661] The parameter `alpha` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:13,511] Trial 18 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 93, 'n_neurons_2': 56, 'n_neurons_3': 55, 'n_neurons_4': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0039046790191830895, 'alpha': 0.0060257440920984265}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:13,574] The parameter `n_layers` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:13,575] The parameter `n_neurons_0` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:13,575] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:13,576] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:13,576] The parameter `learning_rate_init` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:13,577] The parameter `alpha` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:14,334] Trial 19 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 18, 'learning_rate': 'constant', 'learning_rate_init': 0.0008534852819566894, 'alpha': 0.0012169963323841}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:14,412] Trial 20 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:14,489] The parameter `n_layers` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:14,491] The parameter `n_neurons_0` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:14,491] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:14,492] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:14,492] The parameter `learning_rate_init` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:14,493] The parameter `alpha` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:15,433] Trial 21 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 63, 'n_neurons_1': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005252684100000482, 'alpha': 0.00017952338368491265}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:15,496] The parameter `n_layers` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:15,497] The parameter `n_neurons_0` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:15,497] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:15,498] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:15,498] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:15,500] The parameter `learning_rate_init` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:15,500] The parameter `alpha` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:16,298] Trial 22 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 80, 'n_neurons_1': 29, 'n_neurons_2': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0011553385460530909, 'alpha': 0.0012057860169848358}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:16,361] The parameter `n_layers` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:16,361] The parameter `n_neurons_0` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:16,364] The parameter `n_neurons_1` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:16,364] The parameter `n_neurons_2` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:16,364] The parameter `n_neurons_3` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:16,364] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:16,364] The parameter `learning_rate_init` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:16,366] The parameter `alpha` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:17,191] Trial 23 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 76, 'n_neurons_1': 98, 'n_neurons_2': 56, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0007549928546183039, 'alpha': 0.00014352011136230925}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:17,272] The parameter `n_layers` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:17,272] The parameter `n_neurons_0` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:17,272] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:17,274] The parameter `learning_rate_init` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:17,274] The parameter `alpha` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:18,165] Trial 24 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.000657515339012736, 'alpha': 0.000222120498838994}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:18,228] The parameter `n_layers` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,228] The parameter `n_neurons_0` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,229] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,229] The parameter `learning_rate_init` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,230] The parameter `alpha` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:18,788] Trial 25 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0020911960669713066, 'alpha': 0.00036296754488993613}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:18,867] The parameter `n_layers` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,867] The parameter `n_neurons_0` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,868] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,868] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,869] The parameter `n_neurons_3` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,869] The parameter `n_neurons_4` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,870] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,870] The parameter `learning_rate_init` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:18,870] The parameter `alpha` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:19,523] Trial 26 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 77, 'n_neurons_1': 60, 'n_neurons_2': 65, 'n_neurons_3': 48, 'n_neurons_4': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010685306331940677, 'alpha': 0.00017066532063900338}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:19,619] The parameter `n_layers` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:19,620] The parameter `n_neurons_0` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:19,621] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:19,621] The parameter `learning_rate_init` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:19,622] The parameter `alpha` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:20,251] Trial 27 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 13, 'learning_rate': 'constant', 'learning_rate_init': 0.0008878664758716851, 'alpha': 0.00015691639471778163}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:20,338] The parameter `n_layers` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:20,339] The parameter `n_neurons_0` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:20,339] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:20,340] The parameter `n_neurons_2` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:20,341] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:20,341] The parameter `learning_rate_init` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:20,341] The parameter `alpha` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:21,139] Trial 28 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 53, 'n_neurons_1': 25, 'n_neurons_2': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001862890387420621, 'alpha': 0.00012319923739394199}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:21,204] The parameter `n_layers` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:21,205] The parameter `n_neurons_0` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:21,206] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:21,206] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:21,207] The parameter `learning_rate_init` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:21,207] The parameter `alpha` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:22,200] Trial 29 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 66, 'n_neurons_1': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.0002117721540886054, 'alpha': 0.00013840044764106221}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:22,293] The parameter `n_layers` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:22,296] The parameter `n_neurons_0` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:22,296] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:22,296] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:22,296] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:22,298] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:22,298] The parameter `learning_rate_init` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:22,298] The parameter `alpha` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:23,153] Trial 30 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 12, 'n_neurons_1': 63, 'n_neurons_2': 95, 'n_neurons_3': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008250984684608617, 'alpha': 0.0012337682181468137}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `n_layers` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `n_neurons_0` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `n_neurons_3` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `n_neurons_4` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `learning_rate_init` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:23,242] The parameter `alpha` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:24,255] Trial 31 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 45, 'n_neurons_1': 97, 'n_neurons_2': 92, 'n_neurons_3': 27, 'n_neurons_4': 16, 'learning_rate': 'constant', 'learning_rate_init': 0.00015448485924752335, 'alpha': 0.0023228092500006277}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:24,319] The parameter `n_layers` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:24,320] The parameter `n_neurons_0` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:24,320] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:24,321] The parameter `learning_rate_init` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:24,321] The parameter `alpha` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:24,476] Trial 32 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004255366449682059, 'alpha': 0.00036619258793526205}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:24,569] The parameter `n_layers` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:24,570] The parameter `n_neurons_0` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:24,570] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:24,571] The parameter `learning_rate_init` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:24,572] The parameter `alpha` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:25,279] Trial 33 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002952174928235019, 'alpha': 0.004045403638787863}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:25,355] The parameter `n_layers` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:25,355] The parameter `n_neurons_0` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:25,356] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:25,356] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:25,357] The parameter `learning_rate_init` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:25,357] The parameter `alpha` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:26,271] Trial 34 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 78, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006687062061347505, 'alpha': 0.0005546719086332962}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:26,336] The parameter `n_layers` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:26,336] The parameter `n_neurons_0` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:26,337] The parameter `n_neurons_1` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:26,337] The parameter `n_neurons_2` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:26,338] The parameter `n_neurons_3` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:26,338] The parameter `learning_rate` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:26,338] The parameter `learning_rate_init` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:26,339] The parameter `alpha` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:27,046] Trial 35 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 41, 'n_neurons_1': 94, 'n_neurons_2': 88, 'n_neurons_3': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001607858173371064, 'alpha': 0.006384190143734895}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:27,115] Trial 36 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:27,206] The parameter `n_layers` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:27,208] The parameter `n_neurons_0` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:27,209] The parameter `n_neurons_1` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:27,209] The parameter `n_neurons_2` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:27,210] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:27,210] The parameter `learning_rate_init` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:27,211] The parameter `alpha` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:28,157] Trial 37 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 39, 'n_neurons_2': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.006467909772210833, 'alpha': 0.00015225562752457967}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:28,225] The parameter `n_layers` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:28,225] The parameter `n_neurons_0` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:28,225] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:28,225] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:28,225] The parameter `learning_rate_init` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:28,225] The parameter `alpha` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:29,276] Trial 38 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 96, 'n_neurons_1': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007886622327732802, 'alpha': 0.00038585269984779924}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:29,361] The parameter `n_layers` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:29,361] The parameter `n_neurons_0` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:29,363] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:29,363] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:29,363] The parameter `learning_rate_init` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:29,363] The parameter `alpha` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:30,313] Trial 39 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 78, 'learning_rate': 'constant', 'learning_rate_init': 0.00015219914267510963, 'alpha': 0.0009746318720288899}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:30,376] The parameter `n_layers` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:30,377] The parameter `n_neurons_0` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:30,378] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:30,378] The parameter `learning_rate_init` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:30,378] The parameter `alpha` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:31,247] Trial 40 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005033035864411288, 'alpha': 0.00017144863541673278}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[I 2025-12-28 19:48:31,328] Trial 41 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:31,408] The parameter `n_layers` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:31,409] The parameter `n_neurons_0` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:31,410] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:31,411] The parameter `learning_rate_init` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:31,411] The parameter `alpha` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:32,277] Trial 42 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.00014730368526805275, 'alpha': 0.002523122072859775}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:32,356] The parameter `n_layers` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:32,357] The parameter `n_neurons_0` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:32,357] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:32,358] The parameter `learning_rate_init` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:32,358] The parameter `alpha` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:33,223] Trial 43 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.00014780033831850363, 'alpha': 0.00940327542674712}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:33,299] The parameter `n_layers` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:33,300] The parameter `n_neurons_0` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:33,301] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:33,301] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:33,302] The parameter `learning_rate_init` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:33,302] The parameter `alpha` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:34,200] Trial 44 finished with value: 0.85 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0032118582525883237, 'alpha': 0.0005656127243812504}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:34,265] The parameter `n_layers` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:34,270] The parameter `n_neurons_0` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:34,270] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:34,270] The parameter `learning_rate_init` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:34,270] The parameter `alpha` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:35,020] Trial 45 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0064969387159423365, 'alpha': 0.0001668764162919581}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:35,078] The parameter `n_layers` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,078] The parameter `n_neurons_0` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,078] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,078] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,078] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,078] The parameter `learning_rate_init` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,078] The parameter `alpha` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:35,672] Trial 46 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 11, 'n_neurons_1': 52, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0019880193364014637, 'alpha': 0.003105201294430152}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:35,742] The parameter `n_layers` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,742] The parameter `n_neurons_0` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,743] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,743] The parameter `n_neurons_2` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,744] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,744] The parameter `learning_rate_init` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:35,745] The parameter `alpha` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:36,509] Trial 47 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 44, 'n_neurons_2': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.008441994772287123, 'alpha': 0.00010575695778888723}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:36,575] The parameter `n_layers` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:36,576] The parameter `n_neurons_0` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:36,576] The parameter `n_neurons_1` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:36,577] The parameter `n_neurons_2` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:36,578] The parameter `n_neurons_3` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:36,578] The parameter `n_neurons_4` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:36,578] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:36,579] The parameter `learning_rate_init` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:36,579] The parameter `alpha` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:37,634] Trial 48 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 13, 'n_neurons_1': 91, 'n_neurons_2': 58, 'n_neurons_3': 100, 'n_neurons_4': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001112232774304946, 'alpha': 0.0018146683984526406}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:37,695] The parameter `n_layers` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:37,699] The parameter `n_neurons_0` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:37,699] The parameter `n_neurons_1` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:37,699] The parameter `n_neurons_2` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:37,699] The parameter `n_neurons_3` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:37,699] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:37,699] The parameter `learning_rate_init` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:37,699] The parameter `alpha` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:38,528] Trial 49 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 51, 'n_neurons_1': 67, 'n_neurons_2': 63, 'n_neurons_3': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007958348774085428, 'alpha': 0.006032920019762461}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:38,594] The parameter `n_layers` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:38,594] The parameter `n_neurons_0` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:38,594] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:38,594] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:38,594] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:38,594] The parameter `learning_rate_init` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:38,594] The parameter `alpha` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:39,485] Trial 50 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 66, 'n_neurons_1': 35, 'n_neurons_2': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0014699827002313925, 'alpha': 0.00014304387745680657}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:39,552] The parameter `n_layers` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:39,552] The parameter `n_neurons_0` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:39,552] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:39,552] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:39,552] The parameter `n_neurons_3` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:39,552] The parameter `n_neurons_4` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:39,552] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:39,552] The parameter `learning_rate_init` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:39,556] The parameter `alpha` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:40,348] Trial 51 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 99, 'n_neurons_1': 73, 'n_neurons_2': 58, 'n_neurons_3': 38, 'n_neurons_4': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.006635205362126859, 'alpha': 0.004416461875953999}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:40,425] The parameter `n_layers` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:40,425] The parameter `n_neurons_0` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:40,425] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:40,427] The parameter `n_neurons_2` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:40,427] The parameter `n_neurons_3` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:40,428] The parameter `n_neurons_4` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:40,428] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:40,428] The parameter `learning_rate_init` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:40,428] The parameter `alpha` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:41,244] Trial 52 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 76, 'n_neurons_1': 65, 'n_neurons_2': 48, 'n_neurons_3': 94, 'n_neurons_4': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0005661437715302432, 'alpha': 0.004179329972699849}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:41,323] The parameter `n_layers` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:41,323] The parameter `n_neurons_0` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:41,324] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:41,324] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:41,324] The parameter `n_neurons_3` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:41,324] The parameter `n_neurons_4` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:41,324] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:41,324] The parameter `learning_rate_init` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:41,324] The parameter `alpha` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:42,142] Trial 53 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 23, 'n_neurons_1': 64, 'n_neurons_2': 44, 'n_neurons_3': 98, 'n_neurons_4': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0006755212335411566, 'alpha': 0.00035222010634042685}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:42,223] The parameter `n_layers` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:42,224] The parameter `n_neurons_0` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:42,224] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:42,225] The parameter `learning_rate_init` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:42,225] The parameter `alpha` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:42,979] Trial 54 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009846313836604142, 'alpha': 0.0012908132395505268}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:43,052] The parameter `n_layers` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:43,053] The parameter `n_neurons_0` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:43,053] The parameter `n_neurons_1` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:43,054] The parameter `n_neurons_2` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:43,055] The parameter `n_neurons_3` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:43,055] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:43,056] The parameter `learning_rate_init` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:43,056] The parameter `alpha` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:43,944] Trial 55 finished with value: 0.8333333333333334 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 95, 'n_neurons_1': 87, 'n_neurons_2': 32, 'n_neurons_3': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0016306068743545592, 'alpha': 0.00028660621978595627}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:44,020] The parameter `n_layers` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,021] The parameter `n_neurons_0` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,021] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,022] The parameter `n_neurons_2` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,022] The parameter `n_neurons_3` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,024] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,024] The parameter `learning_rate_init` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,024] The parameter `alpha` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:44,845] Trial 56 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 42, 'n_neurons_2': 20, 'n_neurons_3': 71, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010973041007839744, 'alpha': 0.005062476271565486}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:44,925] The parameter `n_layers` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,925] The parameter `n_neurons_0` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,925] The parameter `n_neurons_1` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,928] The parameter `n_neurons_2` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,928] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,928] The parameter `learning_rate_init` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:44,928] The parameter `alpha` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:45,724] Trial 57 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 89, 'n_neurons_2': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.003237982605211301, 'alpha': 0.001740279894124974}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:45,796] The parameter `n_layers` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:45,797] The parameter `n_neurons_0` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:45,798] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:45,798] The parameter `n_neurons_2` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:45,799] The parameter `n_neurons_3` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:45,799] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:45,800] The parameter `learning_rate_init` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:45,800] The parameter `alpha` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:46,696] Trial 58 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 29, 'n_neurons_1': 22, 'n_neurons_2': 11, 'n_neurons_3': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0007498076102892463, 'alpha': 0.006431575749069943}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:46,781] The parameter `n_layers` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:46,782] The parameter `n_neurons_0` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:46,783] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:46,783] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:46,784] The parameter `learning_rate_init` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:46,784] The parameter `alpha` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:47,565] Trial 59 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005305513421197475, 'alpha': 0.007925766022280026}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:47,644] The parameter `n_layers` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:47,645] The parameter `n_neurons_0` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:47,646] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:47,646] The parameter `learning_rate_init` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:47,647] The parameter `alpha` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:48,445] Trial 60 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.0008284599389099161, 'alpha': 0.009121476646815571}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:48,524] The parameter `n_layers` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:48,525] The parameter `n_neurons_0` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:48,525] The parameter `n_neurons_1` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:48,526] The parameter `n_neurons_2` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:48,527] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:48,527] The parameter `learning_rate_init` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:48,528] The parameter `alpha` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:49,448] Trial 61 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 39, 'n_neurons_1': 67, 'n_neurons_2': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018033983912317568, 'alpha': 0.0002012822076129274}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:49,524] The parameter `n_layers` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:49,525] The parameter `n_neurons_0` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:49,526] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:49,526] The parameter `learning_rate_init` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:49,527] The parameter `alpha` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:50,057] Trial 62 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0062169420588097215, 'alpha': 0.000886999307004117}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:50,137] The parameter `n_layers` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:50,138] The parameter `n_neurons_0` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:50,139] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:50,139] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:50,140] The parameter `n_neurons_3` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:50,140] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:50,141] The parameter `learning_rate_init` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:50,141] The parameter `alpha` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:50,947] Trial 63 finished with value: 0.85 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 25, 'n_neurons_1': 27, 'n_neurons_2': 13, 'n_neurons_3': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0001504544604259194, 'alpha': 0.000174289707961261}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:51,038] The parameter `n_layers` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,039] The parameter `n_neurons_0` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,040] The parameter `n_neurons_1` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,040] The parameter `n_neurons_2` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,041] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,042] The parameter `learning_rate_init` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,042] The parameter `alpha` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:51,767] Trial 64 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 43, 'n_neurons_2': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.003970276908151301, 'alpha': 0.0018021908442002565}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:51,859] The parameter `n_layers` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,859] The parameter `n_neurons_0` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,861] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,861] The parameter `learning_rate_init` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:51,861] The parameter `alpha` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:52,520] Trial 65 finished with value: 0.8 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.00035789472410260544, 'alpha': 0.004096401906445582}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:52,602] The parameter `n_layers` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:52,603] The parameter `n_neurons_0` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:52,604] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:52,604] The parameter `n_neurons_2` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:52,605] The parameter `n_neurons_3` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:52,606] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:52,606] The parameter `learning_rate_init` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:52,607] The parameter `alpha` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:53,436] Trial 66 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 26, 'n_neurons_1': 29, 'n_neurons_2': 43, 'n_neurons_3': 54, 'learning_rate': 'constant', 'learning_rate_init': 0.0008415296693542193, 'alpha': 0.003125661016787662}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:53,525] The parameter `n_layers` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:53,526] The parameter `n_neurons_0` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:53,527] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:53,527] The parameter `learning_rate_init` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:53,528] The parameter `alpha` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:53,695] Trial 67 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010552488419684378, 'alpha': 0.0011593831134486484}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:53,786] The parameter `n_layers` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:53,787] The parameter `n_neurons_0` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:53,788] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:53,788] The parameter `learning_rate_init` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:53,788] The parameter `alpha` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:54,604] Trial 68 finished with value: 0.8 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 50, 'learning_rate': 'constant', 'learning_rate_init': 0.0003455305583136833, 'alpha': 0.0005682877914899339}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:54,690] The parameter `n_layers` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:54,691] The parameter `n_neurons_0` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:54,691] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:54,691] The parameter `learning_rate_init` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:54,693] The parameter `alpha` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:48:55,578] Trial 69 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017358982432215278, 'alpha': 0.006040245096887873}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:55,664] The parameter `n_layers` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:55,664] The parameter `n_neurons_0` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:55,664] The parameter `n_neurons_1` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:55,666] The parameter `n_neurons_2` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:55,666] The parameter `learning_rate` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:55,666] The parameter `learning_rate_init` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:55,666] The parameter `alpha` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:56,456] Trial 70 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 71, 'n_neurons_1': 81, 'n_neurons_2': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014917025634138866, 'alpha': 0.0030965560706362177}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:56,542] The parameter `n_layers` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:56,542] The parameter `n_neurons_0` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:56,544] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:56,544] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:56,545] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:56,545] The parameter `learning_rate_init` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:56,546] The parameter `alpha` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:57,333] Trial 71 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 21, 'n_neurons_1': 35, 'n_neurons_2': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.0005154581987502424, 'alpha': 0.009397893033412784}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:57,418] The parameter `n_layers` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:57,418] The parameter `n_neurons_0` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:57,418] The parameter `n_neurons_1` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:57,418] The parameter `n_neurons_2` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:57,418] The parameter `n_neurons_3` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:57,418] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:57,418] The parameter `learning_rate_init` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:57,418] The parameter `alpha` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:58,350] Trial 72 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 31, 'n_neurons_1': 19, 'n_neurons_2': 23, 'n_neurons_3': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00037169809679792504, 'alpha': 0.00022220160448344761}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:58,425] The parameter `n_layers` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:58,425] The parameter `n_neurons_0` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:58,426] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:58,426] The parameter `n_neurons_2` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:58,427] The parameter `n_neurons_3` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:58,427] The parameter `n_neurons_4` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:58,428] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:58,429] The parameter `learning_rate_init` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:58,429] The parameter `alpha` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:48:59,233] Trial 73 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 17, 'n_neurons_1': 57, 'n_neurons_2': 47, 'n_neurons_3': 99, 'n_neurons_4': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005382874466428148, 'alpha': 0.004306695255529367}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:48:59,309] The parameter `n_layers` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:59,310] The parameter `n_neurons_0` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:59,310] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:59,311] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:59,311] The parameter `learning_rate_init` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:48:59,312] The parameter `alpha` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:00,109] Trial 74 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 25, 'n_neurons_1': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.001390674140149984, 'alpha': 0.0003630431002952846}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:00,186] The parameter `n_layers` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:00,188] The parameter `n_neurons_0` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:00,188] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:00,188] The parameter `n_neurons_2` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:00,188] The parameter `n_neurons_3` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:00,188] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:00,190] The parameter `learning_rate_init` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:00,190] The parameter `alpha` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:00,989] Trial 75 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 27, 'n_neurons_1': 39, 'n_neurons_2': 48, 'n_neurons_3': 56, 'learning_rate': 'constant', 'learning_rate_init': 0.001664332465507855, 'alpha': 0.000377799263089713}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:01,063] The parameter `n_layers` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,063] The parameter `n_neurons_0` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,066] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,066] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,066] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,066] The parameter `learning_rate_init` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,067] The parameter `alpha` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:01,378] Trial 76 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 24, 'n_neurons_1': 53, 'n_neurons_2': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001857074616553881, 'alpha': 0.0001338905547392675}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:01,451] The parameter `n_layers` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,457] The parameter `n_neurons_0` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,457] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,457] The parameter `n_neurons_2` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,457] The parameter `n_neurons_3` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,457] The parameter `n_neurons_4` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,457] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,457] The parameter `learning_rate_init` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:01,457] The parameter `alpha` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:02,067] Trial 77 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 83, 'n_neurons_2': 33, 'n_neurons_3': 72, 'n_neurons_4': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.000666318433858052, 'alpha': 0.0004985819284806489}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:02,154] The parameter `n_layers` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:02,155] The parameter `n_neurons_0` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:02,156] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:02,157] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:02,157] The parameter `n_neurons_3` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:02,158] The parameter `n_neurons_4` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:02,158] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:02,158] The parameter `learning_rate_init` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:02,159] The parameter `alpha` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:02,987] Trial 78 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 97, 'n_neurons_2': 21, 'n_neurons_3': 76, 'n_neurons_4': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.0030355773144056086, 'alpha': 0.0014091143133651608}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:03,061] The parameter `n_layers` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:03,062] The parameter `n_neurons_0` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:03,062] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:03,062] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:03,063] The parameter `n_neurons_3` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:03,063] The parameter `n_neurons_4` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:03,063] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:03,064] The parameter `learning_rate_init` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:03,064] The parameter `alpha` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:03,954] Trial 79 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 22, 'n_neurons_1': 82, 'n_neurons_2': 28, 'n_neurons_3': 24, 'n_neurons_4': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0011120667338401567, 'alpha': 0.0005219885398322653}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:04,037] The parameter `n_layers` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,037] The parameter `n_neurons_0` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,038] The parameter `n_neurons_1` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,039] The parameter `n_neurons_2` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,039] The parameter `n_neurons_3` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,040] The parameter `n_neurons_4` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,040] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,040] The parameter `learning_rate_init` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,041] The parameter `alpha` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:04,390] Trial 80 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 45, 'n_neurons_1': 84, 'n_neurons_2': 49, 'n_neurons_3': 44, 'n_neurons_4': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010126066617091951, 'alpha': 0.0002913569554515852}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:04,469] The parameter `n_layers` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,470] The parameter `n_neurons_0` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,470] The parameter `n_neurons_1` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,471] The parameter `n_neurons_2` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,471] The parameter `n_neurons_3` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,472] The parameter `n_neurons_4` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,472] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,472] The parameter `learning_rate_init` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:04,473] The parameter `alpha` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:05,441] Trial 81 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 44, 'n_neurons_1': 59, 'n_neurons_2': 92, 'n_neurons_3': 66, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.00046753187944355057, 'alpha': 0.00018990838710732203}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:05,518] The parameter `n_layers` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:05,518] The parameter `n_neurons_0` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:05,525] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:05,525] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:05,526] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:05,526] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:05,527] The parameter `learning_rate_init` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:05,527] The parameter `alpha` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:06,453] Trial 82 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 58, 'n_neurons_2': 91, 'n_neurons_3': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00031403516315342447, 'alpha': 0.0030753360921253873}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:06,527] The parameter `n_layers` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:06,527] The parameter `n_neurons_0` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:06,527] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:06,529] The parameter `learning_rate_init` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:06,529] The parameter `alpha` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:07,389] Trial 83 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004832406918522534, 'alpha': 0.0043905063473000955}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:07,471] The parameter `n_layers` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:07,471] The parameter `n_neurons_0` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:07,477] The parameter `learning_rate` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:07,477] The parameter `learning_rate_init` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:07,477] The parameter `alpha` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:08,236] Trial 84 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003931793782370637, 'alpha': 0.00019945037385407478}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:08,308] The parameter `n_layers` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:08,309] The parameter `n_neurons_0` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:08,309] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:08,310] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:08,310] The parameter `learning_rate_init` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:08,312] The parameter `alpha` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:09,043] Trial 85 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 75, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012174437001359676, 'alpha': 0.00031885858743643943}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:09,122] The parameter `n_layers` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,123] The parameter `n_neurons_0` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,123] The parameter `n_neurons_1` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,124] The parameter `learning_rate` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,124] The parameter `learning_rate_init` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,125] The parameter `alpha` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:09,907] Trial 86 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.000839482422872308, 'alpha': 0.007844525502343443}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:09,972] The parameter `n_layers` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,974] The parameter `n_neurons_0` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,974] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,975] The parameter `learning_rate_init` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:09,975] The parameter `alpha` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:10,836] Trial 87 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001086977032427697, 'alpha': 0.005549422847797102}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:10,928] The parameter `n_layers` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:10,928] The parameter `n_neurons_0` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:10,929] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:10,930] The parameter `n_neurons_2` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:10,930] The parameter `n_neurons_3` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:10,931] The parameter `n_neurons_4` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:10,931] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:10,932] The parameter `learning_rate_init` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:10,932] The parameter `alpha` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:11,762] Trial 88 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 61, 'n_neurons_1': 73, 'n_neurons_2': 93, 'n_neurons_3': 74, 'n_neurons_4': 23, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007051172552124139, 'alpha': 0.0029709029926915354}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:11,840] The parameter `n_layers` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:11,841] The parameter `n_neurons_0` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:11,841] The parameter `n_neurons_1` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:11,842] The parameter `n_neurons_2` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:11,842] The parameter `n_neurons_3` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:11,843] The parameter `n_neurons_4` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:11,843] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:11,844] The parameter `learning_rate_init` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:11,844] The parameter `alpha` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:12,657] Trial 89 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 94, 'n_neurons_1': 51, 'n_neurons_2': 20, 'n_neurons_3': 99, 'n_neurons_4': 86, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005492786568761941, 'alpha': 0.0010906266715261731}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:12,736] The parameter `n_layers` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:12,737] The parameter `n_neurons_0` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:12,738] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:12,739] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:12,739] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:12,740] The parameter `learning_rate_init` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:12,740] The parameter `alpha` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:13,658] Trial 90 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 14, 'n_neurons_2': 40, 'learning_rate': 'constant', 'learning_rate_init': 0.0004645135033311032, 'alpha': 0.0006256585548186114}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:13,745] The parameter `n_layers` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:13,747] The parameter `n_neurons_0` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:13,748] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:13,749] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:13,749] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:13,749] The parameter `learning_rate_init` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:13,749] The parameter `alpha` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:14,669] Trial 91 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 93, 'n_neurons_1': 41, 'n_neurons_2': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0002813258539870692, 'alpha': 0.0008033023403902318}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:14,736] The parameter `n_layers` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:14,738] The parameter `n_neurons_0` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:14,738] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:14,738] The parameter `learning_rate_init` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:14,738] The parameter `alpha` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:15,549] Trial 92 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.006756033620862479, 'alpha': 0.0005306251107511992}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:15,642] The parameter `n_layers` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:15,642] The parameter `n_neurons_0` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:15,643] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:15,644] The parameter `n_neurons_2` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:15,644] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:15,644] The parameter `learning_rate_init` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:15,645] The parameter `alpha` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:16,697] Trial 93 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 11, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00019830125168914512, 'alpha': 0.0006749137054804921}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:16,789] The parameter `n_layers` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:16,790] The parameter `n_neurons_0` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:16,790] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:16,791] The parameter `learning_rate_init` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:16,791] The parameter `alpha` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:17,727] Trial 94 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013619242560057148, 'alpha': 0.0031617020498319144}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:17,808] The parameter `n_layers` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:17,809] The parameter `n_neurons_0` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:17,810] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:17,810] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:17,812] The parameter `learning_rate_init` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:17,812] The parameter `alpha` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:18,656] Trial 95 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 91, 'n_neurons_1': 28, 'learning_rate': 'constant', 'learning_rate_init': 0.0008792935556463842, 'alpha': 0.0013479763309946922}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:18,749] The parameter `n_layers` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:18,750] The parameter `n_neurons_0` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:18,751] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:18,751] The parameter `learning_rate_init` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:18,752] The parameter `alpha` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:19,667] Trial 96 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007612468242681232, 'alpha': 0.0006331784446999807}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:19,742] The parameter `n_layers` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:19,743] The parameter `n_neurons_0` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:19,743] The parameter `n_neurons_1` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:19,743] The parameter `n_neurons_2` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:19,743] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:19,743] The parameter `learning_rate_init` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:19,743] The parameter `alpha` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:20,025] Trial 97 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 24, 'n_neurons_1': 26, 'n_neurons_2': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0003479279724953084, 'alpha': 0.0019408817950172534}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:20,098] The parameter `n_layers` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:20,098] The parameter `n_neurons_0` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:20,098] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:20,098] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:20,098] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:20,098] The parameter `learning_rate_init` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:20,098] The parameter `alpha` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:21,117] Trial 98 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 12, 'n_neurons_1': 24, 'n_neurons_2': 75, 'learning_rate': 'constant', 'learning_rate_init': 0.0002779356934038156, 'alpha': 0.0002898341752547446}. Best is trial 1 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:49:21,219] The parameter `n_layers` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:21,221] The parameter `n_neurons_0` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:21,221] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:21,221] The parameter `n_neurons_2` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:21,223] The parameter `n_neurons_3` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:21,223] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:21,223] The parameter `learning_rate_init` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:21,223] The parameter `alpha` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:22,347] Trial 99 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 11, 'n_neurons_1': 19, 'n_neurons_2': 82, 'n_neurons_3': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.00015808213238348277, 'alpha': 0.0003064392438270023}. Best is trial 1 with value: 0.9166666666666666.\n",
      "\n",
      "Selected Base Models for Stacking using GPSampler:\n",
      "- Logistic Regression\n",
      "- Support Vector Machine\n",
      "- AdaBoost\n",
      "Best Hyperparameters for Meta Model (MLP) using GPSampler: {'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (83, 37, 18, 72, 50), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9167, at trial: 1\n",
      "GP base models training time: 182.54 seconds\n",
      "GP SEl-NNML Training Time: 85.93 seconds\n",
      "Total GP Training Time (Base + Meta): 268.47 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    gp_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    gp_sel_nnml, gp_meta_study = meta_model_tuning(base_models['GP'], X_train, y_train, X_test, y_test, sampler='GPSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    gp_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for GP SEl-NNML training\n",
    "    gp_meta_model_training_time = gp_meta_model_training_end - gp_meta_model_training_start\n",
    "    print(f'GP base models training time: {gp_base_models_training_time:.2f} seconds')\n",
    "    print(f'GP SEl-NNML Training Time: {gp_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total GP Training Time (Base + Meta): {gp_base_models_training_time + gp_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    gp_meta_history = gp_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    gp_meta_history.columns = ['iteration', 'score']\n",
    "    gp_meta_history['iteration'] = gp_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping GP meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:23,441] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (CmaEsSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455af258eb474d7e94ccf8a966ee7964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:24,228] Trial 0 finished with value: 0.8 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.8.\n",
      "[W 2025-12-28 19:49:24,231] The parameter `use_Logistic Regression` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:24,232] The parameter `use_Decision Tree` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:24,233] The parameter `use_Random Forest` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:24,233] The parameter `use_K-Nearest Neighbors` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:24,233] The parameter `use_Support Vector Machine` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:24,235] The parameter `use_AdaBoost` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:24,235] The parameter `use_Gradient Boosting` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:24,236] The parameter `n_neurons_1` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:24,236] The parameter `learning_rate` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:25,073] Trial 1 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.0005404052553935483, 'alpha': 0.000865808466690932}. Best is trial 1 with value: 0.9.\n",
      "[W 2025-12-28 19:49:25,077] The parameter `use_Logistic Regression` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,078] The parameter `use_Decision Tree` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,078] The parameter `use_Random Forest` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,079] The parameter `use_K-Nearest Neighbors` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,079] The parameter `use_Support Vector Machine` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,079] The parameter `use_AdaBoost` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,080] The parameter `use_Gradient Boosting` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,080] The parameter `n_neurons_1` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,081] The parameter `learning_rate` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:25,808] Trial 2 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 72, 'n_neurons_1': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0004843830630951302, 'alpha': 0.0009528924787594206}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:25,811] The parameter `use_Logistic Regression` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,812] The parameter `use_Decision Tree` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,812] The parameter `use_Random Forest` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,813] The parameter `use_K-Nearest Neighbors` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,813] The parameter `use_Support Vector Machine` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,814] The parameter `use_AdaBoost` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,814] The parameter `use_Gradient Boosting` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,815] The parameter `n_neurons_1` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,815] The parameter `n_neurons_2` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,816] The parameter `learning_rate` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:25,993] Trial 3 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 16, 'n_neurons_2': 99, 'learning_rate': 'constant', 'learning_rate_init': 0.001284803071084827, 'alpha': 0.002651575859618515}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:25,996] The parameter `use_Logistic Regression` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,997] The parameter `use_Decision Tree` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,997] The parameter `use_Random Forest` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,998] The parameter `use_K-Nearest Neighbors` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,998] The parameter `use_Support Vector Machine` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,999] The parameter `use_AdaBoost` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:25,999] The parameter `use_Gradient Boosting` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,000] The parameter `n_neurons_1` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,000] The parameter `n_neurons_2` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,000] The parameter `learning_rate` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:26,972] Trial 4 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 51, 'n_neurons_1': 76, 'n_neurons_2': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.0010997756098965073, 'alpha': 0.00010702593573937491}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:26,975] The parameter `use_Logistic Regression` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,976] The parameter `use_Decision Tree` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,976] The parameter `use_Random Forest` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,977] The parameter `use_K-Nearest Neighbors` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,977] The parameter `use_Support Vector Machine` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,978] The parameter `use_AdaBoost` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,978] The parameter `use_Gradient Boosting` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,979] The parameter `n_neurons_1` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,979] The parameter `n_neurons_2` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,980] The parameter `n_neurons_3` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:26,980] The parameter `learning_rate` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:27,744] Trial 5 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 79, 'n_neurons_1': 92, 'n_neurons_2': 32, 'n_neurons_3': 47, 'learning_rate': 'constant', 'learning_rate_init': 0.00037679762657228646, 'alpha': 0.001966714163929435}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:27,747] The parameter `use_Logistic Regression` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,748] The parameter `use_Decision Tree` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,748] The parameter `use_Random Forest` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,748] The parameter `use_K-Nearest Neighbors` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,749] The parameter `use_Support Vector Machine` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,749] The parameter `use_AdaBoost` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,749] The parameter `use_Gradient Boosting` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,750] The parameter `n_neurons_1` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,750] The parameter `n_neurons_2` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:27,752] The parameter `learning_rate` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:28,572] Trial 6 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 29, 'n_neurons_1': 20, 'n_neurons_2': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045488589409482236, 'alpha': 0.0023404594415393147}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:28,575] The parameter `use_Logistic Regression` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:28,576] The parameter `use_Decision Tree` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:28,576] The parameter `use_Random Forest` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:28,577] The parameter `use_K-Nearest Neighbors` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:28,577] The parameter `use_Support Vector Machine` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:28,578] The parameter `use_AdaBoost` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:28,578] The parameter `use_Gradient Boosting` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:28,579] The parameter `n_neurons_1` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:28,579] The parameter `learning_rate` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:29,524] Trial 7 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 38, 'n_neurons_1': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.00039738988185359975, 'alpha': 0.00195965433079867}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:29,526] The parameter `use_Logistic Regression` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:29,526] The parameter `use_Decision Tree` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:29,529] The parameter `use_Random Forest` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:29,529] The parameter `use_K-Nearest Neighbors` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:29,529] The parameter `use_Support Vector Machine` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:29,529] The parameter `use_AdaBoost` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:29,529] The parameter `use_Gradient Boosting` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:29,529] The parameter `n_neurons_1` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:29,529] The parameter `learning_rate` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:30,441] Trial 8 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 60, 'n_neurons_1': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.0022097738266210138, 'alpha': 0.00281718805195577}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:30,449] The parameter `use_Logistic Regression` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,450] The parameter `use_Decision Tree` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,450] The parameter `use_Random Forest` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,450] The parameter `use_K-Nearest Neighbors` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,452] The parameter `use_Support Vector Machine` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,452] The parameter `use_AdaBoost` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,452] The parameter `use_Gradient Boosting` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,452] The parameter `n_neurons_1` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,452] The parameter `n_neurons_2` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:30,452] The parameter `learning_rate` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:31,174] Trial 9 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 57, 'n_neurons_1': 25, 'n_neurons_2': 72, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006575580968475994, 'alpha': 0.0008488782731054051}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:31,174] The parameter `use_Logistic Regression` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,174] The parameter `use_Decision Tree` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,174] The parameter `use_Random Forest` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,180] The parameter `use_K-Nearest Neighbors` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,180] The parameter `use_Support Vector Machine` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,180] The parameter `use_AdaBoost` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,182] The parameter `use_Gradient Boosting` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,182] The parameter `n_neurons_1` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,182] The parameter `n_neurons_2` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:31,182] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:32,066] Trial 10 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 45, 'n_neurons_1': 67, 'n_neurons_2': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004334680646667721, 'alpha': 0.0009406866299882308}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:32,072] The parameter `use_Logistic Regression` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,076] The parameter `use_Decision Tree` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,077] The parameter `use_Random Forest` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,077] The parameter `use_K-Nearest Neighbors` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,077] The parameter `use_Support Vector Machine` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,077] The parameter `use_AdaBoost` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,078] The parameter `use_Gradient Boosting` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,079] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,079] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,079] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:32,080] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:33,207] Trial 11 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 84, 'n_neurons_1': 72, 'n_neurons_2': 69, 'n_neurons_3': 30, 'learning_rate': 'constant', 'learning_rate_init': 0.0003369052992274794, 'alpha': 0.0015683690317957312}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:33,207] The parameter `use_Logistic Regression` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,207] The parameter `use_Decision Tree` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,207] The parameter `use_Random Forest` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,213] The parameter `use_K-Nearest Neighbors` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,214] The parameter `use_Support Vector Machine` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,215] The parameter `use_AdaBoost` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,215] The parameter `use_Gradient Boosting` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,215] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,215] The parameter `n_neurons_2` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:33,215] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:34,081] Trial 12 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 51, 'n_neurons_1': 82, 'n_neurons_2': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.00027222277930301494, 'alpha': 0.0022245572413706707}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:34,084] The parameter `use_Logistic Regression` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,084] The parameter `use_Decision Tree` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,085] The parameter `use_Random Forest` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,086] The parameter `use_K-Nearest Neighbors` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,086] The parameter `use_Support Vector Machine` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,087] The parameter `use_AdaBoost` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,087] The parameter `use_Gradient Boosting` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,088] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,088] The parameter `n_neurons_2` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,089] The parameter `n_neurons_3` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,089] The parameter `n_neurons_4` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,090] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:34,861] Trial 13 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 48, 'n_neurons_1': 97, 'n_neurons_2': 87, 'n_neurons_3': 36, 'n_neurons_4': 45, 'learning_rate': 'constant', 'learning_rate_init': 0.001722380159654233, 'alpha': 0.000989601741713548}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:34,864] The parameter `use_Logistic Regression` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,864] The parameter `use_Decision Tree` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,865] The parameter `use_Random Forest` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,866] The parameter `use_K-Nearest Neighbors` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,866] The parameter `use_Support Vector Machine` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,866] The parameter `use_AdaBoost` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,867] The parameter `use_Gradient Boosting` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,867] The parameter `n_neurons_1` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,868] The parameter `n_neurons_2` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:34,868] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:35,823] Trial 14 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 77, 'n_neurons_1': 42, 'n_neurons_2': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004886266298448432, 'alpha': 0.0016360042887597268}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:35,827] The parameter `use_Logistic Regression` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,828] The parameter `use_Decision Tree` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,828] The parameter `use_Random Forest` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,829] The parameter `use_K-Nearest Neighbors` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,830] The parameter `use_Support Vector Machine` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,830] The parameter `use_AdaBoost` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,830] The parameter `use_Gradient Boosting` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,830] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,832] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:35,832] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:36,826] Trial 15 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 52, 'n_neurons_1': 52, 'n_neurons_2': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003796483317842531, 'alpha': 0.001825755141445576}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:36,829] The parameter `use_Logistic Regression` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:36,830] The parameter `use_Decision Tree` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:36,830] The parameter `use_Random Forest` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:36,831] The parameter `use_K-Nearest Neighbors` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:36,831] The parameter `use_Support Vector Machine` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:36,831] The parameter `use_AdaBoost` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:36,831] The parameter `use_Gradient Boosting` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:36,831] The parameter `n_neurons_1` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:36,831] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:36,999] Trial 16 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 66, 'n_neurons_1': 76, 'learning_rate': 'constant', 'learning_rate_init': 0.0019588371219224055, 'alpha': 0.0006433777517525617}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:37,003] The parameter `use_Logistic Regression` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,003] The parameter `use_Decision Tree` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,003] The parameter `use_Random Forest` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,004] The parameter `use_K-Nearest Neighbors` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,004] The parameter `use_Support Vector Machine` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,006] The parameter `use_AdaBoost` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,006] The parameter `use_Gradient Boosting` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,007] The parameter `n_neurons_1` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,007] The parameter `n_neurons_2` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,007] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:37,975] Trial 17 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 58, 'n_neurons_1': 75, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001509812724797515, 'alpha': 0.0006769253938336058}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:37,978] The parameter `use_Logistic Regression` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,979] The parameter `use_Decision Tree` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,979] The parameter `use_Random Forest` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,980] The parameter `use_K-Nearest Neighbors` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,981] The parameter `use_Support Vector Machine` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,981] The parameter `use_AdaBoost` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,981] The parameter `use_Gradient Boosting` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,982] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,982] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,983] The parameter `n_neurons_3` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:37,983] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:38,685] Trial 18 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 50, 'n_neurons_1': 18, 'n_neurons_2': 54, 'n_neurons_3': 53, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005227573656129182, 'alpha': 0.0007630325036950872}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:38,688] The parameter `use_Logistic Regression` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,689] The parameter `use_Decision Tree` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,689] The parameter `use_Random Forest` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,690] The parameter `use_K-Nearest Neighbors` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,691] The parameter `use_Support Vector Machine` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,691] The parameter `use_AdaBoost` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,691] The parameter `use_Gradient Boosting` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,692] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,693] The parameter `n_neurons_2` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,693] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:38,961] Trial 19 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 62, 'n_neurons_1': 95, 'n_neurons_2': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000698504825242282, 'alpha': 0.0007063760661567204}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:38,963] The parameter `use_Logistic Regression` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,964] The parameter `use_Decision Tree` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,965] The parameter `use_Random Forest` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,965] The parameter `use_K-Nearest Neighbors` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,966] The parameter `use_Support Vector Machine` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,966] The parameter `use_AdaBoost` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,967] The parameter `use_Gradient Boosting` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,967] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,968] The parameter `n_neurons_2` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:38,968] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:39,789] Trial 20 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 60, 'n_neurons_1': 86, 'n_neurons_2': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.00023104887894285245, 'alpha': 0.0020011816983097693}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:39,792] The parameter `use_Logistic Regression` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,792] The parameter `use_Decision Tree` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,793] The parameter `use_Random Forest` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,794] The parameter `use_K-Nearest Neighbors` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,794] The parameter `use_Support Vector Machine` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,794] The parameter `use_AdaBoost` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,795] The parameter `use_Gradient Boosting` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,796] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,796] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:39,796] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:40,808] Trial 21 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 57, 'n_neurons_1': 41, 'n_neurons_2': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.00041760822248098153, 'alpha': 0.0007330618433012642}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:40,811] The parameter `use_Logistic Regression` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,812] The parameter `use_Decision Tree` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,813] The parameter `use_Random Forest` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,813] The parameter `use_K-Nearest Neighbors` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,814] The parameter `use_Support Vector Machine` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,814] The parameter `use_AdaBoost` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,815] The parameter `use_Gradient Boosting` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,815] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,816] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:40,816] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:41,843] Trial 22 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 56, 'n_neurons_1': 96, 'n_neurons_2': 62, 'learning_rate': 'constant', 'learning_rate_init': 0.00021520974594356338, 'alpha': 0.0012959336725566805}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:41,846] The parameter `use_Logistic Regression` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,847] The parameter `use_Decision Tree` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,849] The parameter `use_Random Forest` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,849] The parameter `use_K-Nearest Neighbors` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,849] The parameter `use_Support Vector Machine` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,850] The parameter `use_AdaBoost` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,850] The parameter `use_Gradient Boosting` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,851] The parameter `n_neurons_1` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,852] The parameter `n_neurons_2` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,852] The parameter `n_neurons_3` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,853] The parameter `n_neurons_4` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:41,853] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:42,666] Trial 23 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 46, 'n_neurons_1': 23, 'n_neurons_2': 79, 'n_neurons_3': 66, 'n_neurons_4': 19, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0011435746848593319, 'alpha': 0.0008480736959780028}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:42,671] The parameter `use_Logistic Regression` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,672] The parameter `use_Decision Tree` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,673] The parameter `use_Random Forest` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,673] The parameter `use_K-Nearest Neighbors` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,674] The parameter `use_Support Vector Machine` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,674] The parameter `use_AdaBoost` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,675] The parameter `use_Gradient Boosting` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,675] The parameter `n_neurons_1` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,676] The parameter `n_neurons_2` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:42,677] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:43,862] Trial 24 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 62, 'n_neurons_1': 80, 'n_neurons_2': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010819579316880721, 'alpha': 0.001112116655323579}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:43,866] The parameter `use_Logistic Regression` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,867] The parameter `use_Decision Tree` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,867] The parameter `use_Random Forest` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,867] The parameter `use_K-Nearest Neighbors` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,869] The parameter `use_Support Vector Machine` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,869] The parameter `use_AdaBoost` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,869] The parameter `use_Gradient Boosting` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,869] The parameter `n_neurons_1` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,869] The parameter `n_neurons_2` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,869] The parameter `n_neurons_3` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:43,872] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:45,017] Trial 25 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 56, 'n_neurons_1': 30, 'n_neurons_2': 97, 'n_neurons_3': 11, 'learning_rate': 'constant', 'learning_rate_init': 0.00022882616872639015, 'alpha': 0.0028696203321164175}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:45,021] The parameter `use_Logistic Regression` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,022] The parameter `use_Decision Tree` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,023] The parameter `use_Random Forest` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,025] The parameter `use_K-Nearest Neighbors` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,025] The parameter `use_Support Vector Machine` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,026] The parameter `use_AdaBoost` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,027] The parameter `use_Gradient Boosting` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,027] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,028] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:45,028] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:46,092] Trial 26 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 66, 'n_neurons_1': 35, 'n_neurons_2': 96, 'learning_rate': 'constant', 'learning_rate_init': 0.00019480261732158336, 'alpha': 0.0015434906069225463}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:46,096] The parameter `use_Logistic Regression` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,097] The parameter `use_Decision Tree` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,098] The parameter `use_Random Forest` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,098] The parameter `use_K-Nearest Neighbors` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,099] The parameter `use_Support Vector Machine` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,099] The parameter `use_AdaBoost` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,100] The parameter `use_Gradient Boosting` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,101] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,101] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:46,101] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:47,112] Trial 27 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 24, 'n_neurons_2': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00016905039600054213, 'alpha': 0.00033705635280834587}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:47,116] The parameter `use_Logistic Regression` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,117] The parameter `use_Decision Tree` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,118] The parameter `use_Random Forest` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,118] The parameter `use_K-Nearest Neighbors` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,119] The parameter `use_Support Vector Machine` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,119] The parameter `use_AdaBoost` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,120] The parameter `use_Gradient Boosting` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,120] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,121] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:47,992] Trial 28 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 61, 'n_neurons_1': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.00017896639157943594, 'alpha': 0.0013451870189245068}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:47,997] The parameter `use_Logistic Regression` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,998] The parameter `use_Decision Tree` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,998] The parameter `use_Random Forest` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,998] The parameter `use_K-Nearest Neighbors` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:47,999] The parameter `use_Support Vector Machine` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:48,000] The parameter `use_AdaBoost` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:48,001] The parameter `use_Gradient Boosting` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:48,001] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:48,002] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:49:49,118] Trial 29 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 40, 'n_neurons_1': 96, 'learning_rate': 'constant', 'learning_rate_init': 0.0007150776537444856, 'alpha': 0.0015587902711522877}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:49,123] The parameter `use_Logistic Regression` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,124] The parameter `use_Decision Tree` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,124] The parameter `use_Random Forest` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,124] The parameter `use_K-Nearest Neighbors` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,125] The parameter `use_Support Vector Machine` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,126] The parameter `use_AdaBoost` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,126] The parameter `use_Gradient Boosting` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,126] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,128] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:49,128] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:50,571] Trial 30 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 53, 'n_neurons_1': 12, 'n_neurons_2': 78, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00022410608489922454, 'alpha': 0.0003908289383454777}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:50,575] The parameter `use_Logistic Regression` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,576] The parameter `use_Decision Tree` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,577] The parameter `use_Random Forest` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,578] The parameter `use_K-Nearest Neighbors` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,579] The parameter `use_Support Vector Machine` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,580] The parameter `use_AdaBoost` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,581] The parameter `use_Gradient Boosting` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,582] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,583] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:50,584] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:52,043] Trial 31 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 79, 'n_neurons_1': 96, 'n_neurons_2': 23, 'learning_rate': 'constant', 'learning_rate_init': 0.000202614835923082, 'alpha': 0.0007210014544076495}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:52,049] The parameter `use_Logistic Regression` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,050] The parameter `use_Decision Tree` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,050] The parameter `use_Random Forest` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,051] The parameter `use_K-Nearest Neighbors` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,052] The parameter `use_Support Vector Machine` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,052] The parameter `use_AdaBoost` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,053] The parameter `use_Gradient Boosting` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,055] The parameter `n_neurons_1` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,055] The parameter `n_neurons_2` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:52,055] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:53,298] Trial 32 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 41, 'n_neurons_1': 41, 'n_neurons_2': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000470392071149566, 'alpha': 0.0004358929081421264}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:53,307] The parameter `use_Logistic Regression` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,308] The parameter `use_Decision Tree` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,309] The parameter `use_Random Forest` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,310] The parameter `use_K-Nearest Neighbors` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,310] The parameter `use_Support Vector Machine` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,313] The parameter `use_AdaBoost` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,313] The parameter `use_Gradient Boosting` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,315] The parameter `n_neurons_1` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,315] The parameter `n_neurons_2` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,317] The parameter `n_neurons_3` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:53,318] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:54,631] Trial 33 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 54, 'n_neurons_1': 82, 'n_neurons_2': 67, 'n_neurons_3': 17, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00023446880588303486, 'alpha': 0.00042706714717191896}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:54,635] The parameter `use_Logistic Regression` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,636] The parameter `use_Decision Tree` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,638] The parameter `use_Random Forest` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,638] The parameter `use_K-Nearest Neighbors` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,640] The parameter `use_Support Vector Machine` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,640] The parameter `use_AdaBoost` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,640] The parameter `use_Gradient Boosting` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,641] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,642] The parameter `n_neurons_2` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,642] The parameter `n_neurons_3` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:54,643] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:55,101] Trial 34 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 47, 'n_neurons_1': 74, 'n_neurons_2': 91, 'n_neurons_3': 56, 'learning_rate': 'constant', 'learning_rate_init': 0.00013653927277287368, 'alpha': 0.001971064320533848}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:55,101] The parameter `use_Logistic Regression` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,101] The parameter `use_Decision Tree` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,106] The parameter `use_Random Forest` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,106] The parameter `use_K-Nearest Neighbors` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,107] The parameter `use_Support Vector Machine` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,107] The parameter `use_AdaBoost` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,108] The parameter `use_Gradient Boosting` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,110] The parameter `n_neurons_1` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,111] The parameter `n_neurons_2` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:55,111] The parameter `learning_rate` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:56,110] Trial 35 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 45, 'n_neurons_1': 55, 'n_neurons_2': 17, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005798519351937642, 'alpha': 0.00022565363521913223}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:56,113] The parameter `use_Logistic Regression` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,114] The parameter `use_Decision Tree` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,115] The parameter `use_Random Forest` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,115] The parameter `use_K-Nearest Neighbors` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,116] The parameter `use_Support Vector Machine` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,116] The parameter `use_AdaBoost` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,117] The parameter `use_Gradient Boosting` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,118] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,118] The parameter `n_neurons_2` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:56,119] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:57,180] Trial 36 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 53, 'n_neurons_1': 24, 'n_neurons_2': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.00014190002311289588, 'alpha': 0.0013066325545596411}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:57,184] The parameter `use_Logistic Regression` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,185] The parameter `use_Decision Tree` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,185] The parameter `use_Random Forest` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,186] The parameter `use_K-Nearest Neighbors` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,186] The parameter `use_Support Vector Machine` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,187] The parameter `use_AdaBoost` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,188] The parameter `use_Gradient Boosting` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,189] The parameter `n_neurons_1` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,189] The parameter `n_neurons_2` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:57,190] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:58,296] Trial 37 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 60, 'n_neurons_1': 60, 'n_neurons_2': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013643954049028114, 'alpha': 0.000611964994623725}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:58,299] The parameter `use_Logistic Regression` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,300] The parameter `use_Decision Tree` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,300] The parameter `use_Random Forest` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,301] The parameter `use_K-Nearest Neighbors` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,301] The parameter `use_Support Vector Machine` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,302] The parameter `use_AdaBoost` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,302] The parameter `use_Gradient Boosting` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,303] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,304] The parameter `n_neurons_2` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,304] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:49:58,988] Trial 38 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 70, 'n_neurons_1': 22, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0010516415333924139, 'alpha': 0.0006970777768118031}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:49:58,992] The parameter `use_Logistic Regression` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,993] The parameter `use_Decision Tree` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,994] The parameter `use_Random Forest` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,994] The parameter `use_K-Nearest Neighbors` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,995] The parameter `use_Support Vector Machine` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,995] The parameter `use_AdaBoost` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,996] The parameter `use_Gradient Boosting` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,997] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,997] The parameter `n_neurons_2` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:49:58,998] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:00,077] Trial 39 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 70, 'n_neurons_1': 26, 'n_neurons_2': 16, 'learning_rate': 'constant', 'learning_rate_init': 0.00012019694482836245, 'alpha': 0.0017740080164428712}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:00,080] The parameter `use_Logistic Regression` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,081] The parameter `use_Decision Tree` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,082] The parameter `use_Random Forest` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,083] The parameter `use_K-Nearest Neighbors` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,083] The parameter `use_Support Vector Machine` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,083] The parameter `use_AdaBoost` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,084] The parameter `use_Gradient Boosting` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,085] The parameter `n_neurons_1` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,085] The parameter `n_neurons_2` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:00,086] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:01,091] Trial 40 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 65, 'n_neurons_1': 44, 'n_neurons_2': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005464537830708312, 'alpha': 0.0007918629900405858}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:01,095] The parameter `use_Logistic Regression` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,096] The parameter `use_Decision Tree` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,098] The parameter `use_Random Forest` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,098] The parameter `use_K-Nearest Neighbors` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,099] The parameter `use_Support Vector Machine` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,099] The parameter `use_AdaBoost` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,100] The parameter `use_Gradient Boosting` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,100] The parameter `n_neurons_1` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,101] The parameter `n_neurons_2` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,101] The parameter `n_neurons_3` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:01,102] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:02,289] Trial 41 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 61, 'n_neurons_1': 58, 'n_neurons_2': 91, 'n_neurons_3': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018179850093237446, 'alpha': 0.00030152972915328135}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:02,304] The parameter `use_Logistic Regression` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,305] The parameter `use_Decision Tree` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,306] The parameter `use_Random Forest` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,307] The parameter `use_K-Nearest Neighbors` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,307] The parameter `use_Support Vector Machine` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,308] The parameter `use_AdaBoost` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,308] The parameter `use_Gradient Boosting` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:02,308] Trial 42 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:02,308] The parameter `use_Logistic Regression` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,308] The parameter `use_Decision Tree` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,308] The parameter `use_Random Forest` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,313] The parameter `use_K-Nearest Neighbors` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,313] The parameter `use_Support Vector Machine` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,313] The parameter `use_AdaBoost` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,314] The parameter `use_Gradient Boosting` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,314] The parameter `n_layers` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,314] The parameter `n_neurons_0` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,316] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,316] The parameter `learning_rate_init` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:02,316] The parameter `alpha` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:03,246] Trial 43 finished with value: 0.8 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001086977032427697, 'alpha': 0.005549422847797102}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:03,248] The parameter `use_Logistic Regression` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,249] The parameter `use_Decision Tree` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,249] The parameter `use_Random Forest` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,250] The parameter `use_K-Nearest Neighbors` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,250] The parameter `use_Support Vector Machine` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,251] The parameter `use_AdaBoost` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,251] The parameter `use_Gradient Boosting` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,251] The parameter `n_layers` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,251] The parameter `n_neurons_0` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,253] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,253] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,254] The parameter `n_neurons_3` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,254] The parameter `n_neurons_4` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,255] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,255] The parameter `learning_rate_init` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:03,255] The parameter `alpha` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:04,445] Trial 44 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 21, 'n_neurons_2': 93, 'n_neurons_3': 89, 'n_neurons_4': 57, 'learning_rate': 'constant', 'learning_rate_init': 0.00012868362240023423, 'alpha': 0.00046816019279276647}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:04,447] The parameter `use_Logistic Regression` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,448] The parameter `use_Decision Tree` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,449] The parameter `use_Random Forest` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,449] The parameter `use_K-Nearest Neighbors` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,450] The parameter `use_Support Vector Machine` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,450] The parameter `use_AdaBoost` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,450] The parameter `use_Gradient Boosting` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,451] The parameter `n_layers` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,451] The parameter `n_neurons_0` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,452] The parameter `n_neurons_1` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,452] The parameter `n_neurons_2` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,453] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,453] The parameter `learning_rate_init` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,454] The parameter `alpha` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:04,912] Trial 45 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 48, 'n_neurons_1': 93, 'n_neurons_2': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010621574831902212, 'alpha': 0.002123609913367681}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:04,914] The parameter `use_Logistic Regression` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,914] The parameter `use_Decision Tree` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,915] The parameter `use_Random Forest` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,916] The parameter `use_K-Nearest Neighbors` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,916] The parameter `use_Support Vector Machine` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,917] The parameter `use_AdaBoost` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,917] The parameter `use_Gradient Boosting` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:04,918] Trial 46 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:04,918] The parameter `use_Logistic Regression` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,921] The parameter `use_Decision Tree` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,921] The parameter `use_Random Forest` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,921] The parameter `use_K-Nearest Neighbors` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,922] The parameter `use_Support Vector Machine` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,922] The parameter `use_AdaBoost` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,923] The parameter `use_Gradient Boosting` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,924] The parameter `n_layers` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,924] The parameter `n_neurons_0` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,925] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,925] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,926] The parameter `learning_rate_init` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:04,926] The parameter `alpha` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:05,737] Trial 47 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 34, 'n_neurons_1': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.00020526041126466539, 'alpha': 0.0027036125745955072}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:05,742] The parameter `use_Logistic Regression` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,742] The parameter `use_Decision Tree` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,744] The parameter `use_Random Forest` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,744] The parameter `use_K-Nearest Neighbors` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,745] The parameter `use_Support Vector Machine` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,745] The parameter `use_AdaBoost` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,745] The parameter `use_Gradient Boosting` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,745] The parameter `n_layers` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,745] The parameter `n_neurons_0` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,748] The parameter `n_neurons_1` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,748] The parameter `n_neurons_2` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,749] The parameter `n_neurons_3` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,749] The parameter `n_neurons_4` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,750] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,750] The parameter `learning_rate_init` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:05,750] The parameter `alpha` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:06,954] Trial 48 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 46, 'n_neurons_2': 70, 'n_neurons_3': 28, 'n_neurons_4': 36, 'learning_rate': 'constant', 'learning_rate_init': 0.00014825763285498622, 'alpha': 0.0002604788766691677}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:06,961] The parameter `use_Logistic Regression` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,962] The parameter `use_Decision Tree` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,963] The parameter `use_Random Forest` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,963] The parameter `use_K-Nearest Neighbors` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,964] The parameter `use_Support Vector Machine` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,965] The parameter `use_AdaBoost` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,965] The parameter `use_Gradient Boosting` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,965] The parameter `n_layers` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,965] The parameter `n_neurons_0` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,965] The parameter `n_neurons_1` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,968] The parameter `n_neurons_2` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,968] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,969] The parameter `learning_rate_init` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:06,969] The parameter `alpha` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:07,680] Trial 49 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 36, 'n_neurons_1': 96, 'n_neurons_2': 79, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000943761803860813, 'alpha': 0.006153248489920153}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:07,682] The parameter `use_Logistic Regression` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,683] The parameter `use_Decision Tree` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,684] The parameter `use_Random Forest` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,684] The parameter `use_K-Nearest Neighbors` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,685] The parameter `use_Support Vector Machine` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,685] The parameter `use_AdaBoost` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,685] The parameter `use_Gradient Boosting` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,686] The parameter `n_layers` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,686] The parameter `n_neurons_0` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,687] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,687] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,688] The parameter `n_neurons_3` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,689] The parameter `n_neurons_4` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,689] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,690] The parameter `learning_rate_init` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:07,690] The parameter `alpha` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:08,892] Trial 50 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 20, 'n_neurons_1': 62, 'n_neurons_2': 34, 'n_neurons_3': 60, 'n_neurons_4': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.00010519416661057535, 'alpha': 0.00018783272544168123}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:08,894] The parameter `use_Logistic Regression` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,895] The parameter `use_Decision Tree` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,895] The parameter `use_Random Forest` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,896] The parameter `use_K-Nearest Neighbors` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,896] The parameter `use_Support Vector Machine` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,897] The parameter `use_AdaBoost` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,897] The parameter `use_Gradient Boosting` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,898] The parameter `n_layers` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,899] The parameter `n_neurons_0` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,899] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,900] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,900] The parameter `n_neurons_3` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,900] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,901] The parameter `learning_rate_init` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:08,901] The parameter `alpha` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:09,661] Trial 51 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 45, 'n_neurons_2': 36, 'n_neurons_3': 42, 'learning_rate': 'constant', 'learning_rate_init': 0.0013577170773699243, 'alpha': 0.0008955726134171263}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:09,663] The parameter `use_Logistic Regression` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,663] The parameter `use_Decision Tree` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,664] The parameter `use_Random Forest` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,664] The parameter `use_K-Nearest Neighbors` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,665] The parameter `use_Support Vector Machine` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,665] The parameter `use_AdaBoost` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,666] The parameter `use_Gradient Boosting` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,666] The parameter `n_layers` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,667] The parameter `n_neurons_0` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,667] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,668] The parameter `n_neurons_2` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,668] The parameter `n_neurons_3` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,669] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,669] The parameter `learning_rate_init` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:09,670] The parameter `alpha` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:10,368] Trial 52 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 55, 'n_neurons_1': 72, 'n_neurons_2': 49, 'n_neurons_3': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.0024512801122407576, 'alpha': 0.00035017914213813497}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:10,370] The parameter `use_Logistic Regression` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,371] The parameter `use_Decision Tree` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,371] The parameter `use_Random Forest` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,372] The parameter `use_K-Nearest Neighbors` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,372] The parameter `use_Support Vector Machine` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,373] The parameter `use_AdaBoost` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,373] The parameter `use_Gradient Boosting` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,374] The parameter `n_layers` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,374] The parameter `n_neurons_0` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,375] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,375] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,376] The parameter `n_neurons_3` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,376] The parameter `n_neurons_4` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,377] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,377] The parameter `learning_rate_init` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,377] The parameter `alpha` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:10,522] Trial 53 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 32, 'n_neurons_1': 54, 'n_neurons_2': 30, 'n_neurons_3': 99, 'n_neurons_4': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007087558145736653, 'alpha': 0.00022969454974259052}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:10,525] The parameter `use_Logistic Regression` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,525] The parameter `use_Decision Tree` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,526] The parameter `use_Random Forest` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,526] The parameter `use_K-Nearest Neighbors` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,527] The parameter `use_Support Vector Machine` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,528] The parameter `use_AdaBoost` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,528] The parameter `use_Gradient Boosting` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,528] The parameter `n_layers` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,530] The parameter `n_neurons_0` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,530] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,531] The parameter `n_neurons_2` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,531] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,532] The parameter `learning_rate_init` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:10,532] The parameter `alpha` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:11,415] Trial 54 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 30, 'n_neurons_1': 20, 'n_neurons_2': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.002815357452964348, 'alpha': 0.00013511783615174891}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:11,416] The parameter `use_Logistic Regression` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,417] The parameter `use_Decision Tree` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,418] The parameter `use_Random Forest` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,418] The parameter `use_K-Nearest Neighbors` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,419] The parameter `use_Support Vector Machine` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,419] The parameter `use_AdaBoost` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,420] The parameter `use_Gradient Boosting` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,420] The parameter `n_layers` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,421] The parameter `n_neurons_0` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,421] The parameter `n_neurons_1` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,422] The parameter `n_neurons_2` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,422] The parameter `n_neurons_3` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,423] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,423] The parameter `learning_rate_init` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,424] The parameter `alpha` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:11,636] Trial 55 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 100, 'n_neurons_1': 41, 'n_neurons_2': 79, 'n_neurons_3': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005589258917257331, 'alpha': 0.009293235406855402}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:11,639] The parameter `use_Logistic Regression` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,639] The parameter `use_Decision Tree` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,640] The parameter `use_Random Forest` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,641] The parameter `use_K-Nearest Neighbors` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,641] The parameter `use_Support Vector Machine` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,642] The parameter `use_AdaBoost` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,642] The parameter `use_Gradient Boosting` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,642] The parameter `n_layers` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,642] The parameter `n_neurons_0` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,642] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,642] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,642] The parameter `learning_rate_init` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:11,646] The parameter `alpha` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:12,652] Trial 56 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 29, 'learning_rate': 'constant', 'learning_rate_init': 0.00015094613753824642, 'alpha': 0.0006841661003247827}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:12,654] The parameter `use_Logistic Regression` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,655] The parameter `use_Decision Tree` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,656] The parameter `use_Random Forest` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,656] The parameter `use_K-Nearest Neighbors` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,657] The parameter `use_Support Vector Machine` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,657] The parameter `use_AdaBoost` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,657] The parameter `use_Gradient Boosting` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,657] The parameter `n_layers` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,657] The parameter `n_neurons_0` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,657] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,657] The parameter `learning_rate_init` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:12,661] The parameter `alpha` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:13,414] Trial 57 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.008673717241575788, 'alpha': 0.00585560495923566}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:13,415] The parameter `use_Logistic Regression` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,415] The parameter `use_Decision Tree` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,415] The parameter `use_Random Forest` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,417] The parameter `use_K-Nearest Neighbors` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,417] The parameter `use_Support Vector Machine` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,418] The parameter `use_AdaBoost` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,418] The parameter `use_Gradient Boosting` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,418] The parameter `n_layers` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,419] The parameter `n_neurons_0` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,420] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,420] The parameter `n_neurons_2` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,421] The parameter `n_neurons_3` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,421] The parameter `n_neurons_4` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,422] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,422] The parameter `learning_rate_init` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:13,422] The parameter `alpha` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:14,143] Trial 58 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 34, 'n_neurons_1': 21, 'n_neurons_2': 90, 'n_neurons_3': 96, 'n_neurons_4': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0012639059001467116, 'alpha': 0.0001492703392407429}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:14,144] The parameter `use_Logistic Regression` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,145] The parameter `use_Decision Tree` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,146] The parameter `use_Random Forest` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,146] The parameter `use_K-Nearest Neighbors` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,147] The parameter `use_Support Vector Machine` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,147] The parameter `use_AdaBoost` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,148] The parameter `use_Gradient Boosting` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,149] The parameter `n_layers` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,149] The parameter `n_neurons_0` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,150] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,150] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,151] The parameter `learning_rate_init` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,151] The parameter `alpha` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:14,996] Trial 59 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003934160224360252, 'alpha': 0.0020744533327664858}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:14,998] The parameter `use_Logistic Regression` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:14,999] The parameter `use_Decision Tree` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,000] The parameter `use_Random Forest` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,001] The parameter `use_K-Nearest Neighbors` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,001] The parameter `use_Support Vector Machine` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,002] The parameter `use_AdaBoost` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,003] The parameter `use_Gradient Boosting` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,003] The parameter `n_layers` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,004] The parameter `n_neurons_0` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,005] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,005] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,005] The parameter `learning_rate_init` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,006] The parameter `alpha` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:15,897] Trial 60 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010349883647557926, 'alpha': 0.00010298447122215186}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:15,900] The parameter `use_Logistic Regression` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,901] The parameter `use_Decision Tree` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,901] The parameter `use_Random Forest` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,902] The parameter `use_K-Nearest Neighbors` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,902] The parameter `use_Support Vector Machine` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,903] The parameter `use_AdaBoost` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,903] The parameter `use_Gradient Boosting` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:15,904] Trial 61 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:15,905] The parameter `use_Logistic Regression` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,906] The parameter `use_Decision Tree` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,908] The parameter `use_Random Forest` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,908] The parameter `use_K-Nearest Neighbors` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,909] The parameter `use_Support Vector Machine` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,910] The parameter `use_AdaBoost` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,910] The parameter `use_Gradient Boosting` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,911] The parameter `n_layers` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,911] The parameter `n_neurons_0` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,912] The parameter `n_neurons_1` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,912] The parameter `n_neurons_2` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,913] The parameter `n_neurons_3` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,913] The parameter `n_neurons_4` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,914] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,914] The parameter `learning_rate_init` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:15,915] The parameter `alpha` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:16,832] Trial 62 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 78, 'n_neurons_1': 21, 'n_neurons_2': 79, 'n_neurons_3': 12, 'n_neurons_4': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0034738801863753908, 'alpha': 0.002325898471109331}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:16,834] The parameter `use_Logistic Regression` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,835] The parameter `use_Decision Tree` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,835] The parameter `use_Random Forest` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,836] The parameter `use_K-Nearest Neighbors` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,836] The parameter `use_Support Vector Machine` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,837] The parameter `use_AdaBoost` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,837] The parameter `use_Gradient Boosting` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,838] The parameter `n_layers` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,839] The parameter `n_neurons_0` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,839] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,840] The parameter `learning_rate_init` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:16,841] The parameter `alpha` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:17,685] Trial 63 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 49, 'learning_rate': 'constant', 'learning_rate_init': 0.0018925697547456676, 'alpha': 0.0006240060436145399}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:17,687] The parameter `use_Logistic Regression` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,688] The parameter `use_Decision Tree` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,689] The parameter `use_Random Forest` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,689] The parameter `use_K-Nearest Neighbors` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,689] The parameter `use_Support Vector Machine` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,691] The parameter `use_AdaBoost` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,691] The parameter `use_Gradient Boosting` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:17,691] Trial 64 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:17,693] The parameter `use_Logistic Regression` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,694] The parameter `use_Decision Tree` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,694] The parameter `use_Random Forest` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,694] The parameter `use_K-Nearest Neighbors` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,695] The parameter `use_Support Vector Machine` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,696] The parameter `use_AdaBoost` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,697] The parameter `use_Gradient Boosting` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,697] The parameter `n_layers` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,697] The parameter `n_neurons_0` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,699] The parameter `n_neurons_1` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,699] The parameter `n_neurons_2` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,700] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,700] The parameter `learning_rate_init` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:17,701] The parameter `alpha` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:18,556] Trial 65 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 54, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.003936572019640482, 'alpha': 0.00041756483518393106}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:18,559] The parameter `use_Logistic Regression` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,559] The parameter `use_Decision Tree` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,561] The parameter `use_Random Forest` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,561] The parameter `use_K-Nearest Neighbors` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,562] The parameter `use_Support Vector Machine` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,563] The parameter `use_AdaBoost` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,563] The parameter `use_Gradient Boosting` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,563] The parameter `n_layers` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,563] The parameter `n_neurons_0` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,563] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,565] The parameter `n_neurons_2` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,565] The parameter `n_neurons_3` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,567] The parameter `n_neurons_4` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,567] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,567] The parameter `learning_rate_init` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,567] The parameter `alpha` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:18,714] Trial 66 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 22, 'n_neurons_1': 55, 'n_neurons_2': 66, 'n_neurons_3': 73, 'n_neurons_4': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010849838825181713, 'alpha': 0.00014987631213878993}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:18,714] The parameter `use_Logistic Regression` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,714] The parameter `use_Decision Tree` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,725] The parameter `use_Random Forest` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,725] The parameter `use_K-Nearest Neighbors` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,725] The parameter `use_Support Vector Machine` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,726] The parameter `use_AdaBoost` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,726] The parameter `use_Gradient Boosting` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,727] The parameter `n_layers` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,727] The parameter `n_neurons_0` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,728] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,729] The parameter `n_neurons_2` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,729] The parameter `n_neurons_3` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,730] The parameter `n_neurons_4` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,731] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,731] The parameter `learning_rate_init` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:18,731] The parameter `alpha` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:19,395] Trial 67 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 59, 'n_neurons_2': 74, 'n_neurons_3': 89, 'n_neurons_4': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.004262360980898247, 'alpha': 0.0001446204447457985}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:19,398] The parameter `use_Logistic Regression` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,398] The parameter `use_Decision Tree` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,398] The parameter `use_Random Forest` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,401] The parameter `use_K-Nearest Neighbors` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,401] The parameter `use_Support Vector Machine` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,402] The parameter `use_AdaBoost` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,402] The parameter `use_Gradient Boosting` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,403] The parameter `n_layers` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,403] The parameter `n_neurons_0` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,403] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,405] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,405] The parameter `learning_rate_init` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:19,405] The parameter `alpha` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:20,076] Trial 68 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 81, 'learning_rate': 'constant', 'learning_rate_init': 0.001290408163534379, 'alpha': 0.0027441228904630938}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:20,079] The parameter `use_Logistic Regression` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,079] The parameter `use_Decision Tree` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,080] The parameter `use_Random Forest` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,081] The parameter `use_K-Nearest Neighbors` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,081] The parameter `use_Support Vector Machine` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,082] The parameter `use_AdaBoost` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,083] The parameter `use_Gradient Boosting` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,083] The parameter `n_layers` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,084] The parameter `n_neurons_0` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,084] The parameter `n_neurons_1` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,084] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,085] The parameter `learning_rate_init` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,085] The parameter `alpha` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:20,937] Trial 69 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014366494705598603, 'alpha': 0.0007537560974952886}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:20,940] The parameter `use_Logistic Regression` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,940] The parameter `use_Decision Tree` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,941] The parameter `use_Random Forest` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,942] The parameter `use_K-Nearest Neighbors` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,942] The parameter `use_Support Vector Machine` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,943] The parameter `use_AdaBoost` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,944] The parameter `use_Gradient Boosting` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,944] The parameter `n_layers` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,945] The parameter `n_neurons_0` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,945] The parameter `n_neurons_1` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,945] The parameter `n_neurons_2` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,946] The parameter `n_neurons_3` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,947] The parameter `n_neurons_4` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,947] The parameter `learning_rate` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,948] The parameter `learning_rate_init` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:20,948] The parameter `alpha` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:21,681] Trial 70 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 26, 'n_neurons_1': 31, 'n_neurons_2': 98, 'n_neurons_3': 26, 'n_neurons_4': 87, 'learning_rate': 'constant', 'learning_rate_init': 0.005514419516648056, 'alpha': 0.0007773390943180892}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:21,683] The parameter `use_Logistic Regression` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,683] The parameter `use_Decision Tree` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,685] The parameter `use_Random Forest` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,686] The parameter `use_K-Nearest Neighbors` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,686] The parameter `use_Support Vector Machine` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,686] The parameter `use_AdaBoost` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,687] The parameter `use_Gradient Boosting` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,687] The parameter `n_layers` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,688] The parameter `n_neurons_0` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,688] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,688] The parameter `learning_rate_init` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:21,689] The parameter `alpha` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:22,393] Trial 71 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.004547437426011357, 'alpha': 0.0007274029320947825}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:22,396] The parameter `use_Logistic Regression` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,396] The parameter `use_Decision Tree` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,397] The parameter `use_Random Forest` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,398] The parameter `use_K-Nearest Neighbors` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,399] The parameter `use_Support Vector Machine` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,399] The parameter `use_AdaBoost` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,400] The parameter `use_Gradient Boosting` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,400] The parameter `n_layers` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,401] The parameter `n_neurons_0` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,401] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,402] The parameter `learning_rate_init` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:22,402] The parameter `alpha` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:23,238] Trial 72 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007468121665987528, 'alpha': 0.00011986353489802667}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:23,242] The parameter `use_Logistic Regression` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,243] The parameter `use_Decision Tree` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,243] The parameter `use_Random Forest` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,244] The parameter `use_K-Nearest Neighbors` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,245] The parameter `use_Support Vector Machine` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,245] The parameter `use_AdaBoost` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,245] The parameter `use_Gradient Boosting` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,245] The parameter `n_layers` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,247] The parameter `n_neurons_0` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,248] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,249] The parameter `n_neurons_2` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,249] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,250] The parameter `learning_rate_init` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:23,251] The parameter `alpha` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:24,087] Trial 73 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 70, 'n_neurons_2': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002566619712518178, 'alpha': 0.0002533418305370726}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:24,089] The parameter `use_Logistic Regression` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,090] The parameter `use_Decision Tree` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,090] The parameter `use_Random Forest` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,091] The parameter `use_K-Nearest Neighbors` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,092] The parameter `use_Support Vector Machine` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,092] The parameter `use_AdaBoost` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,093] The parameter `use_Gradient Boosting` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:24,093] Trial 74 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:24,094] The parameter `use_Logistic Regression` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,095] The parameter `use_Decision Tree` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,096] The parameter `use_Random Forest` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,096] The parameter `use_K-Nearest Neighbors` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,097] The parameter `use_Support Vector Machine` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,097] The parameter `use_AdaBoost` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,098] The parameter `use_Gradient Boosting` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,098] The parameter `n_layers` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,099] The parameter `n_neurons_0` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,099] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,100] The parameter `n_neurons_2` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,100] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,101] The parameter `learning_rate_init` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,101] The parameter `alpha` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:24,866] Trial 75 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 81, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006431031596032392, 'alpha': 0.00045088555611044626}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:24,868] The parameter `use_Logistic Regression` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,869] The parameter `use_Decision Tree` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,870] The parameter `use_Random Forest` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,870] The parameter `use_K-Nearest Neighbors` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,871] The parameter `use_Support Vector Machine` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,871] The parameter `use_AdaBoost` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,872] The parameter `use_Gradient Boosting` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:24,872] Trial 76 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:24,873] The parameter `use_Logistic Regression` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,874] The parameter `use_Decision Tree` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,875] The parameter `use_Random Forest` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,876] The parameter `use_K-Nearest Neighbors` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,876] The parameter `use_Support Vector Machine` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,877] The parameter `use_AdaBoost` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,877] The parameter `use_Gradient Boosting` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,878] The parameter `n_layers` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,878] The parameter `n_neurons_0` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,879] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,879] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,880] The parameter `learning_rate_init` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:24,880] The parameter `alpha` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:25,749] Trial 77 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.0016436531848333894, 'alpha': 0.00338662042319669}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:25,753] The parameter `use_Logistic Regression` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,753] The parameter `use_Decision Tree` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,755] The parameter `use_Random Forest` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,755] The parameter `use_K-Nearest Neighbors` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,756] The parameter `use_Support Vector Machine` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,756] The parameter `use_AdaBoost` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,757] The parameter `use_Gradient Boosting` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,757] The parameter `n_layers` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,757] The parameter `n_neurons_0` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,759] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,759] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,759] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,760] The parameter `learning_rate_init` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:25,760] The parameter `alpha` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:26,614] Trial 78 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 33, 'n_neurons_1': 35, 'n_neurons_2': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0004193874191709548, 'alpha': 0.001662139868133609}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:26,617] The parameter `use_Logistic Regression` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,618] The parameter `use_Decision Tree` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,618] The parameter `use_Random Forest` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,619] The parameter `use_K-Nearest Neighbors` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,619] The parameter `use_Support Vector Machine` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,620] The parameter `use_AdaBoost` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,620] The parameter `use_Gradient Boosting` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,620] The parameter `n_layers` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,621] The parameter `n_neurons_0` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,621] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,622] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,622] The parameter `n_neurons_3` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,623] The parameter `n_neurons_4` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,623] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,625] The parameter `learning_rate_init` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:26,625] The parameter `alpha` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:27,632] Trial 79 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 60, 'n_neurons_1': 13, 'n_neurons_2': 67, 'n_neurons_3': 96, 'n_neurons_4': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002858640510403272, 'alpha': 0.00026551537824360454}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:27,634] The parameter `use_Logistic Regression` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,635] The parameter `use_Decision Tree` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,635] The parameter `use_Random Forest` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,636] The parameter `use_K-Nearest Neighbors` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,636] The parameter `use_Support Vector Machine` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,637] The parameter `use_AdaBoost` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,637] The parameter `use_Gradient Boosting` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,639] The parameter `n_layers` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,639] The parameter `n_neurons_0` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,640] The parameter `n_neurons_1` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,640] The parameter `n_neurons_2` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,640] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,641] The parameter `learning_rate_init` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:27,641] The parameter `alpha` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:28,741] Trial 80 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 25, 'n_neurons_1': 77, 'n_neurons_2': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00011150059170836743, 'alpha': 0.0019228393487042126}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:28,744] The parameter `use_Logistic Regression` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,745] The parameter `use_Decision Tree` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,745] The parameter `use_Random Forest` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,746] The parameter `use_K-Nearest Neighbors` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,746] The parameter `use_Support Vector Machine` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,747] The parameter `use_AdaBoost` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,748] The parameter `use_Gradient Boosting` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,748] The parameter `n_layers` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,749] The parameter `n_neurons_0` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,749] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,750] The parameter `learning_rate_init` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:28,750] The parameter `alpha` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:29,480] Trial 81 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.0003534445856055918, 'alpha': 0.0001441579965339067}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:29,482] The parameter `use_Logistic Regression` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,483] The parameter `use_Decision Tree` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,484] The parameter `use_Random Forest` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,484] The parameter `use_K-Nearest Neighbors` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,485] The parameter `use_Support Vector Machine` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,486] The parameter `use_AdaBoost` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,486] The parameter `use_Gradient Boosting` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:29,487] Trial 82 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:29,488] The parameter `use_Logistic Regression` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,489] The parameter `use_Decision Tree` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,490] The parameter `use_Random Forest` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,490] The parameter `use_K-Nearest Neighbors` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,491] The parameter `use_Support Vector Machine` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,491] The parameter `use_AdaBoost` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,492] The parameter `use_Gradient Boosting` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,492] The parameter `n_layers` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,493] The parameter `n_neurons_0` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,495] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,495] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,496] The parameter `learning_rate_init` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:29,496] The parameter `alpha` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:30,187] Trial 83 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 58, 'n_neurons_1': 18, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004956134097083741, 'alpha': 0.002137093133753237}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:30,188] The parameter `use_Logistic Regression` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,189] The parameter `use_Decision Tree` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,190] The parameter `use_Random Forest` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,190] The parameter `use_K-Nearest Neighbors` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,191] The parameter `use_Support Vector Machine` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,191] The parameter `use_AdaBoost` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,192] The parameter `use_Gradient Boosting` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,192] The parameter `n_layers` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,193] The parameter `n_neurons_0` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,193] The parameter `n_neurons_1` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,194] The parameter `n_neurons_2` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,194] The parameter `n_neurons_3` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,195] The parameter `n_neurons_4` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,195] The parameter `learning_rate` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,196] The parameter `learning_rate_init` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,196] The parameter `alpha` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:30,978] Trial 84 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 81, 'n_neurons_1': 74, 'n_neurons_2': 13, 'n_neurons_3': 37, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.007480241960748882, 'alpha': 0.001281163276357022}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:30,980] The parameter `use_Logistic Regression` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,980] The parameter `use_Decision Tree` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,981] The parameter `use_Random Forest` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,982] The parameter `use_K-Nearest Neighbors` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,982] The parameter `use_Support Vector Machine` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,983] The parameter `use_AdaBoost` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,983] The parameter `use_Gradient Boosting` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,984] The parameter `n_layers` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,984] The parameter `n_neurons_0` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,985] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,985] The parameter `n_neurons_2` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,986] The parameter `n_neurons_3` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,986] The parameter `n_neurons_4` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,987] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,987] The parameter `learning_rate_init` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:30,988] The parameter `alpha` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:31,894] Trial 85 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 83, 'n_neurons_2': 81, 'n_neurons_3': 37, 'n_neurons_4': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.0024541560696713445, 'alpha': 0.0004922655605142162}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:31,897] The parameter `use_Logistic Regression` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,898] The parameter `use_Decision Tree` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,898] The parameter `use_Random Forest` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,900] The parameter `use_K-Nearest Neighbors` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,901] The parameter `use_Support Vector Machine` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,902] The parameter `use_AdaBoost` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,902] The parameter `use_Gradient Boosting` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,902] The parameter `n_layers` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,903] The parameter `n_neurons_0` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,903] The parameter `learning_rate` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,904] The parameter `learning_rate_init` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:31,904] The parameter `alpha` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:32,757] Trial 86 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012562008177756832, 'alpha': 0.008543667186048135}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:32,759] The parameter `use_Logistic Regression` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,760] The parameter `use_Decision Tree` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,761] The parameter `use_Random Forest` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,761] The parameter `use_K-Nearest Neighbors` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,761] The parameter `use_Support Vector Machine` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,762] The parameter `use_AdaBoost` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,762] The parameter `use_Gradient Boosting` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,763] The parameter `n_layers` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,763] The parameter `n_neurons_0` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,763] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,764] The parameter `n_neurons_2` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,765] The parameter `n_neurons_3` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,765] The parameter `n_neurons_4` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,765] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,766] The parameter `learning_rate_init` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:32,766] The parameter `alpha` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:33,877] Trial 87 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 15, 'n_neurons_1': 73, 'n_neurons_2': 99, 'n_neurons_3': 31, 'n_neurons_4': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015925446667814006, 'alpha': 0.002422828554185797}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:33,882] The parameter `use_Logistic Regression` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,883] The parameter `use_Decision Tree` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,884] The parameter `use_Random Forest` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,884] The parameter `use_K-Nearest Neighbors` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,884] The parameter `use_Support Vector Machine` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,884] The parameter `use_AdaBoost` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,884] The parameter `use_Gradient Boosting` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,884] The parameter `n_layers` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,887] The parameter `n_neurons_0` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,887] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,888] The parameter `n_neurons_2` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,888] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,889] The parameter `learning_rate_init` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:33,890] The parameter `alpha` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:34,848] Trial 88 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 76, 'n_neurons_2': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009176737380720279, 'alpha': 0.00010924071993869074}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:34,850] The parameter `use_Logistic Regression` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,850] The parameter `use_Decision Tree` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,851] The parameter `use_Random Forest` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,852] The parameter `use_K-Nearest Neighbors` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,852] The parameter `use_Support Vector Machine` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,853] The parameter `use_AdaBoost` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,853] The parameter `use_Gradient Boosting` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,854] The parameter `n_layers` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,855] The parameter `n_neurons_0` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,855] The parameter `n_neurons_1` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,855] The parameter `n_neurons_2` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,856] The parameter `n_neurons_3` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,856] The parameter `n_neurons_4` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,856] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,857] The parameter `learning_rate_init` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:34,857] The parameter `alpha` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:35,900] Trial 89 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 18, 'n_neurons_1': 54, 'n_neurons_2': 23, 'n_neurons_3': 39, 'n_neurons_4': 77, 'learning_rate': 'constant', 'learning_rate_init': 0.0006151096737070389, 'alpha': 0.0008296473623735454}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:35,903] The parameter `use_Logistic Regression` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,903] The parameter `use_Decision Tree` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,904] The parameter `use_Random Forest` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,905] The parameter `use_K-Nearest Neighbors` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,905] The parameter `use_Support Vector Machine` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,906] The parameter `use_AdaBoost` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,906] The parameter `use_Gradient Boosting` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,907] The parameter `n_layers` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,908] The parameter `n_neurons_0` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,908] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,909] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,909] The parameter `n_neurons_3` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,910] The parameter `n_neurons_4` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,911] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,911] The parameter `learning_rate_init` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:35,912] The parameter `alpha` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:36,911] Trial 90 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 67, 'n_neurons_1': 65, 'n_neurons_2': 16, 'n_neurons_3': 57, 'n_neurons_4': 23, 'learning_rate': 'constant', 'learning_rate_init': 0.0022932719467128214, 'alpha': 0.00012115624400696192}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:36,914] The parameter `use_Logistic Regression` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,914] The parameter `use_Decision Tree` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,915] The parameter `use_Random Forest` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,916] The parameter `use_K-Nearest Neighbors` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,916] The parameter `use_Support Vector Machine` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,917] The parameter `use_AdaBoost` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,917] The parameter `use_Gradient Boosting` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,918] The parameter `n_layers` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,918] The parameter `n_neurons_0` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,919] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,920] The parameter `learning_rate_init` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:36,920] The parameter `alpha` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:37,846] Trial 91 finished with value: 0.7833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.00011012601445612862, 'alpha': 0.0001459967993464517}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:37,852] The parameter `use_Logistic Regression` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,853] The parameter `use_Decision Tree` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,853] The parameter `use_Random Forest` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,854] The parameter `use_K-Nearest Neighbors` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,854] The parameter `use_Support Vector Machine` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,854] The parameter `use_AdaBoost` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,854] The parameter `use_Gradient Boosting` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,854] The parameter `n_layers` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,857] The parameter `n_neurons_0` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,857] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,858] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,858] The parameter `learning_rate_init` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:37,859] The parameter `alpha` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:38,737] Trial 92 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004202808250827565, 'alpha': 0.0020556880660352003}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:38,739] The parameter `use_Logistic Regression` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,739] The parameter `use_Decision Tree` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,740] The parameter `use_Random Forest` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,742] The parameter `use_K-Nearest Neighbors` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,742] The parameter `use_Support Vector Machine` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,742] The parameter `use_AdaBoost` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,743] The parameter `use_Gradient Boosting` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,743] The parameter `n_layers` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,744] The parameter `n_neurons_0` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,744] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,745] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,746] The parameter `learning_rate_init` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:38,746] The parameter `alpha` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:39,549] Trial 93 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 84, 'n_neurons_1': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003195082233827963, 'alpha': 0.0032365614534194923}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:39,551] The parameter `use_Logistic Regression` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,552] The parameter `use_Decision Tree` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,553] The parameter `use_Random Forest` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,553] The parameter `use_K-Nearest Neighbors` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,554] The parameter `use_Support Vector Machine` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,554] The parameter `use_AdaBoost` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,556] The parameter `use_Gradient Boosting` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,556] The parameter `n_layers` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,557] The parameter `n_neurons_0` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,558] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,558] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,559] The parameter `learning_rate_init` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:39,559] The parameter `alpha` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:40,382] Trial 94 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0015159866641908737, 'alpha': 0.0010392525381080842}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:40,384] The parameter `use_Logistic Regression` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,385] The parameter `use_Decision Tree` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,385] The parameter `use_Random Forest` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,386] The parameter `use_K-Nearest Neighbors` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,386] The parameter `use_Support Vector Machine` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,387] The parameter `use_AdaBoost` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,387] The parameter `use_Gradient Boosting` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:40,388] Trial 95 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:40,389] The parameter `use_Logistic Regression` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,390] The parameter `use_Decision Tree` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,391] The parameter `use_Random Forest` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,391] The parameter `use_K-Nearest Neighbors` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,391] The parameter `use_Support Vector Machine` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,392] The parameter `use_AdaBoost` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,392] The parameter `use_Gradient Boosting` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,393] The parameter `n_layers` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,393] The parameter `n_neurons_0` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,394] The parameter `n_neurons_1` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,394] The parameter `n_neurons_2` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,395] The parameter `n_neurons_3` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,395] The parameter `n_neurons_4` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,395] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,396] The parameter `learning_rate_init` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:40,396] The parameter `alpha` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:41,385] Trial 96 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 39, 'n_neurons_2': 23, 'n_neurons_3': 37, 'n_neurons_4': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.0007892621240300501, 'alpha': 0.0027806214997722505}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:41,388] The parameter `use_Logistic Regression` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,388] The parameter `use_Decision Tree` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,389] The parameter `use_Random Forest` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,389] The parameter `use_K-Nearest Neighbors` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,390] The parameter `use_Support Vector Machine` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,390] The parameter `use_AdaBoost` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,391] The parameter `use_Gradient Boosting` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,391] The parameter `n_layers` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,392] The parameter `n_neurons_0` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,392] The parameter `n_neurons_1` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,393] The parameter `n_neurons_2` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,393] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,394] The parameter `learning_rate_init` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:41,394] The parameter `alpha` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:42,397] Trial 97 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 61, 'n_neurons_2': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003464506976855204, 'alpha': 0.004467852431220893}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:42,399] The parameter `use_Logistic Regression` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,400] The parameter `use_Decision Tree` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,400] The parameter `use_Random Forest` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,401] The parameter `use_K-Nearest Neighbors` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,401] The parameter `use_Support Vector Machine` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,402] The parameter `use_AdaBoost` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,402] The parameter `use_Gradient Boosting` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,403] The parameter `n_layers` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,403] The parameter `n_neurons_0` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,404] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,404] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,405] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,405] The parameter `learning_rate_init` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:42,407] The parameter `alpha` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:43,052] Trial 98 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 76, 'n_neurons_1': 100, 'n_neurons_2': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.0018722107277466084, 'alpha': 0.0037265181101734106}. Best is trial 2 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:50:43,054] The parameter `use_Logistic Regression` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,055] The parameter `use_Decision Tree` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,056] The parameter `use_Random Forest` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,056] The parameter `use_K-Nearest Neighbors` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,056] The parameter `use_Support Vector Machine` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,057] The parameter `use_AdaBoost` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,057] The parameter `use_Gradient Boosting` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,058] The parameter `n_layers` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,059] The parameter `n_neurons_0` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,059] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,059] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,061] The parameter `learning_rate_init` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:43,061] The parameter `alpha` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:43,262] Trial 99 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 95, 'n_neurons_1': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00482911039455259, 'alpha': 0.00023561494581810438}. Best is trial 2 with value: 0.9333333333333333.\n",
      "\n",
      "Selected Base Models for Stacking using CmaEsSampler:\n",
      "- Decision Tree\n",
      "- Random Forest\n",
      "- K-Nearest Neighbors\n",
      "- Support Vector Machine\n",
      "Best Hyperparameters for Meta Model (MLP) using CmaEsSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.0004843830630951302, 'alpha': 0.0009528924787594206, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (72, 80), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9333, at trial: 2\n",
      "CMA-ES base models training time: 46.42 seconds\n",
      "CMA-ES SEl-NNML Training Time: 80.53 seconds\n",
      "Total CMA-ES Training Time (Base + Meta): 126.95 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    cmaes_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    cmaes_sel_nnml, cmaes_meta_study = meta_model_tuning(base_models['CMA-ES'], X_train, y_train, X_test, y_test, sampler='CmaEsSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE) \n",
    "    cmaes_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    cmaes_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for CMA-ES SEl-NNML training\n",
    "    cmaes_meta_model_training_time = cmaes_meta_model_training_end - cmaes_meta_model_training_start\n",
    "    print(f'CMA-ES base models training time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "    print(f'CMA-ES SEl-NNML Training Time: {cmaes_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total CMA-ES Training Time (Base + Meta): {cmaes_base_models_training_time + cmaes_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    cmaes_meta_history = cmaes_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    cmaes_meta_history.columns = ['iteration', 'score']\n",
    "    cmaes_meta_history['iteration'] = cmaes_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping CMA-ES meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:178: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:50:43,987] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (QMCSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be7b7a38c06489a88c31395d1171ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:44,620] Trial 0 finished with value: 0.7833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.7833333333333333.\n",
      "[W 2025-12-28 19:50:44,621] The parameter `use_Logistic Regression` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:44,625] The parameter `use_Decision Tree` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:44,625] The parameter `use_Random Forest` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:44,625] The parameter `use_K-Nearest Neighbors` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:44,626] The parameter `use_Support Vector Machine` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:44,626] The parameter `use_AdaBoost` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:44,627] The parameter `use_Gradient Boosting` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:44,627] The parameter `learning_rate` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:50:45,568] Trial 1 finished with value: 0.4 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 10, 'learning_rate': 'constant', 'learning_rate_init': 0.00010000000000000009, 'alpha': 0.00010000000000000009}. Best is trial 0 with value: 0.7833333333333333.\n",
      "[W 2025-12-28 19:50:45,571] The parameter `use_Logistic Regression` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,573] The parameter `use_Decision Tree` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,573] The parameter `use_Random Forest` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,574] The parameter `use_K-Nearest Neighbors` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,575] The parameter `use_Support Vector Machine` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,575] The parameter `use_AdaBoost` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,576] The parameter `use_Gradient Boosting` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,577] The parameter `n_neurons_1` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,577] The parameter `n_neurons_2` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:45,578] The parameter `learning_rate` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:46,089] Trial 2 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 55, 'n_neurons_1': 98, 'n_neurons_2': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0010000000000000002, 'alpha': 0.0010000000000000002}. Best is trial 2 with value: 0.8833333333333333.\n",
      "[W 2025-12-28 19:50:46,093] The parameter `use_Logistic Regression` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,095] The parameter `use_Decision Tree` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,096] The parameter `use_Random Forest` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,097] The parameter `use_K-Nearest Neighbors` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,097] The parameter `use_Support Vector Machine` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,097] The parameter `use_AdaBoost` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,097] The parameter `use_Gradient Boosting` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,099] The parameter `n_neurons_1` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,100] The parameter `n_neurons_2` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,100] The parameter `n_neurons_3` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,101] The parameter `learning_rate` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:46,379] Trial 3 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 16, 'n_neurons_2': 99, 'n_neurons_3': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0003162277660168384, 'alpha': 0.0003162277660168384}. Best is trial 2 with value: 0.8833333333333333.\n",
      "[W 2025-12-28 19:50:46,379] The parameter `use_Logistic Regression` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,379] The parameter `use_Decision Tree` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,379] The parameter `use_Random Forest` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,385] The parameter `use_K-Nearest Neighbors` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,385] The parameter `use_Support Vector Machine` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,386] The parameter `use_AdaBoost` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,386] The parameter `use_Gradient Boosting` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,387] The parameter `n_neurons_1` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,387] The parameter `learning_rate` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:46,555] Trial 4 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 78, 'n_neurons_1': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.003162277660168382, 'alpha': 0.003162277660168382}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:46,557] The parameter `use_Logistic Regression` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,557] The parameter `use_Decision Tree` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,561] The parameter `use_Random Forest` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,562] The parameter `use_K-Nearest Neighbors` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,563] The parameter `use_Support Vector Machine` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,563] The parameter `use_AdaBoost` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,564] The parameter `use_Gradient Boosting` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,564] The parameter `n_neurons_1` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:46,565] The parameter `learning_rate` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:47,190] Trial 5 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017782794100389236, 'alpha': 0.005623413251903492}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:47,193] The parameter `use_Logistic Regression` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,194] The parameter `use_Decision Tree` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,194] The parameter `use_Random Forest` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,195] The parameter `use_K-Nearest Neighbors` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,196] The parameter `use_Support Vector Machine` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,196] The parameter `use_AdaBoost` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,197] The parameter `use_Gradient Boosting` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,197] The parameter `n_neurons_1` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,198] The parameter `n_neurons_2` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,198] The parameter `n_neurons_3` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,198] The parameter `n_neurons_4` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,200] The parameter `learning_rate` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:47,726] Trial 6 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 89, 'n_neurons_1': 91, 'n_neurons_2': 38, 'n_neurons_3': 20, 'n_neurons_4': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017782794100389232, 'alpha': 0.0005623413251903495}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:47,728] The parameter `use_Logistic Regression` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,729] The parameter `use_Decision Tree` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,729] The parameter `use_Random Forest` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,731] The parameter `use_K-Nearest Neighbors` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,731] The parameter `use_Support Vector Machine` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,732] The parameter `use_AdaBoost` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,732] The parameter `use_Gradient Boosting` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,733] The parameter `n_neurons_1` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,733] The parameter `n_neurons_2` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,734] The parameter `n_neurons_3` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:47,734] The parameter `learning_rate` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:48,633] Trial 7 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 21, 'n_neurons_1': 32, 'n_neurons_2': 55, 'n_neurons_3': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.005623413251903492, 'alpha': 0.0017782794100389236}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:48,635] The parameter `use_Logistic Regression` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:48,636] The parameter `use_Decision Tree` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:48,637] The parameter `use_Random Forest` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:48,637] The parameter `use_K-Nearest Neighbors` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:48,638] The parameter `use_Support Vector Machine` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:48,638] The parameter `use_AdaBoost` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:48,640] The parameter `use_Gradient Boosting` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:48,640] The parameter `learning_rate` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:49,254] Trial 8 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 66, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005623413251903495, 'alpha': 0.00017782794100389232}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:49,257] The parameter `use_Logistic Regression` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:49,258] The parameter `use_Decision Tree` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:49,259] The parameter `use_Random Forest` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:49,259] The parameter `use_K-Nearest Neighbors` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:49,260] The parameter `use_Support Vector Machine` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:49,260] The parameter `use_AdaBoost` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:49,260] The parameter `use_Gradient Boosting` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:49,261] The parameter `learning_rate` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:50,263] Trial 9 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 38, 'learning_rate': 'constant', 'learning_rate_init': 0.007498942093324564, 'alpha': 0.0007498942093324562}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:50,266] The parameter `use_Logistic Regression` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,267] The parameter `use_Decision Tree` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,268] The parameter `use_Random Forest` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,269] The parameter `use_K-Nearest Neighbors` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,269] The parameter `use_Support Vector Machine` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,269] The parameter `use_AdaBoost` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,270] The parameter `use_Gradient Boosting` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,270] The parameter `n_neurons_1` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,271] The parameter `n_neurons_2` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,272] The parameter `n_neurons_3` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:50,272] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:51,435] Trial 10 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 67, 'n_neurons_3': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007498942093324562, 'alpha': 0.007498942093324564}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:51,439] The parameter `use_Logistic Regression` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,440] The parameter `use_Decision Tree` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,441] The parameter `use_Random Forest` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,441] The parameter `use_K-Nearest Neighbors` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,442] The parameter `use_Support Vector Machine` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,442] The parameter `use_AdaBoost` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,442] The parameter `use_Gradient Boosting` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,444] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,444] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,445] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,445] The parameter `n_neurons_4` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:51,445] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:52,326] Trial 11 finished with value: 0.85 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 15, 'n_neurons_1': 72, 'n_neurons_2': 69, 'n_neurons_3': 30, 'n_neurons_4': 74, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002371373705661656, 'alpha': 0.00023713737056616573}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:52,329] The parameter `use_Logistic Regression` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,330] The parameter `use_Decision Tree` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,330] The parameter `use_Random Forest` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,331] The parameter `use_K-Nearest Neighbors` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,332] The parameter `use_Support Vector Machine` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,332] The parameter `use_AdaBoost` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,332] The parameter `use_Gradient Boosting` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,333] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,334] The parameter `n_neurons_2` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:52,335] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:53,070] Trial 12 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 55, 'n_neurons_2': 62, 'learning_rate': 'constant', 'learning_rate_init': 0.00023713737056616573, 'alpha': 0.002371373705661656}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:53,073] The parameter `use_Logistic Regression` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,074] The parameter `use_Decision Tree` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,074] The parameter `use_Random Forest` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,075] The parameter `use_K-Nearest Neighbors` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,075] The parameter `use_Support Vector Machine` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,076] The parameter `use_AdaBoost` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,077] The parameter `use_Gradient Boosting` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,077] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,078] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:53,937] Trial 13 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 27, 'n_neurons_1': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00042169650342858235, 'alpha': 0.0013335214321633251}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:53,937] The parameter `use_Logistic Regression` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,937] The parameter `use_Decision Tree` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,942] The parameter `use_Random Forest` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,942] The parameter `use_K-Nearest Neighbors` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,943] The parameter `use_Support Vector Machine` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,943] The parameter `use_AdaBoost` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,943] The parameter `use_Gradient Boosting` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,944] The parameter `n_neurons_1` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,944] The parameter `n_neurons_2` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,945] The parameter `n_neurons_3` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,946] The parameter `n_neurons_4` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:53,946] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:54,467] Trial 14 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 72, 'n_neurons_1': 73, 'n_neurons_2': 73, 'n_neurons_3': 42, 'n_neurons_4': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004216965034285825, 'alpha': 0.0001333521432163326}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:54,470] The parameter `use_Logistic Regression` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,472] The parameter `use_Decision Tree` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,473] The parameter `use_Random Forest` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,473] The parameter `use_K-Nearest Neighbors` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,473] The parameter `use_Support Vector Machine` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,474] The parameter `use_AdaBoost` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,474] The parameter `use_Gradient Boosting` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,475] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,476] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:54,476] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:55,474] Trial 15 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 52, 'n_neurons_2': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001333521432163326, 'alpha': 0.004216965034285825}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:55,478] The parameter `use_Logistic Regression` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,479] The parameter `use_Decision Tree` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,479] The parameter `use_Random Forest` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,480] The parameter `use_K-Nearest Neighbors` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,481] The parameter `use_Support Vector Machine` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,481] The parameter `use_AdaBoost` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,482] The parameter `use_Gradient Boosting` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,482] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:55,609] Trial 16 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013335214321633251, 'alpha': 0.00042169650342858235}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:55,611] The parameter `use_Logistic Regression` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,612] The parameter `use_Decision Tree` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,613] The parameter `use_Random Forest` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,613] The parameter `use_K-Nearest Neighbors` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,614] The parameter `use_Support Vector Machine` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,614] The parameter `use_AdaBoost` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,614] The parameter `use_Gradient Boosting` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:55,615] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:56,498] Trial 17 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000865964323360066, 'alpha': 0.0020535250264571477}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:56,501] The parameter `use_Logistic Regression` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,502] The parameter `use_Decision Tree` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,502] The parameter `use_Random Forest` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,503] The parameter `use_K-Nearest Neighbors` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,503] The parameter `use_Support Vector Machine` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,504] The parameter `use_AdaBoost` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,504] The parameter `use_Gradient Boosting` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,505] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,505] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,506] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:56,963] Trial 18 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 98, 'n_neurons_1': 87, 'n_neurons_2': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.008659643233600654, 'alpha': 0.0002053525026457149}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:56,965] The parameter `use_Logistic Regression` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,965] The parameter `use_Decision Tree` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,966] The parameter `use_Random Forest` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,966] The parameter `use_K-Nearest Neighbors` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,967] The parameter `use_Support Vector Machine` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,967] The parameter `use_AdaBoost` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,968] The parameter `use_Gradient Boosting` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,968] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,969] The parameter `n_neurons_2` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,969] The parameter `n_neurons_3` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,970] The parameter `n_neurons_4` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:56,970] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:57,614] Trial 19 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 29, 'n_neurons_1': 16, 'n_neurons_2': 68, 'n_neurons_3': 12, 'n_neurons_4': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.0002738419634264362, 'alpha': 0.0064938163157621165}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:57,616] The parameter `use_Logistic Regression` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:57,617] The parameter `use_Decision Tree` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:57,618] The parameter `use_Random Forest` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:57,618] The parameter `use_K-Nearest Neighbors` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:57,618] The parameter `use_Support Vector Machine` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:57,619] The parameter `use_AdaBoost` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:57,619] The parameter `use_Gradient Boosting` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:57,620] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:57,620] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:58,434] Trial 20 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0027384196342643626, 'alpha': 0.0006493816315762115}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:58,437] The parameter `use_Logistic Regression` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,437] The parameter `use_Decision Tree` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,438] The parameter `use_Random Forest` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,438] The parameter `use_K-Nearest Neighbors` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,439] The parameter `use_Support Vector Machine` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,440] The parameter `use_AdaBoost` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,440] The parameter `use_Gradient Boosting` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,441] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,441] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:58,442] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:50:59,137] Trial 21 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 18, 'n_neurons_1': 47, 'n_neurons_2': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.004869675251658635, 'alpha': 0.000365174127254838}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:50:59,139] The parameter `use_Logistic Regression` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,140] The parameter `use_Decision Tree` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,141] The parameter `use_Random Forest` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,141] The parameter `use_K-Nearest Neighbors` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,142] The parameter `use_Support Vector Machine` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,142] The parameter `use_AdaBoost` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,143] The parameter `use_Gradient Boosting` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,144] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,144] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,144] The parameter `n_neurons_3` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,145] The parameter `n_neurons_4` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:50:59,145] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:00,436] Trial 22 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 64, 'n_neurons_1': 18, 'n_neurons_2': 39, 'n_neurons_3': 96, 'n_neurons_4': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00048696752516586337, 'alpha': 0.0036517412725483775}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:00,440] The parameter `use_Logistic Regression` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,441] The parameter `use_Decision Tree` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,442] The parameter `use_Random Forest` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,442] The parameter `use_K-Nearest Neighbors` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,443] The parameter `use_Support Vector Machine` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,444] The parameter `use_AdaBoost` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,445] The parameter `use_Gradient Boosting` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,446] The parameter `n_neurons_1` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,447] The parameter `n_neurons_2` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,448] The parameter `n_neurons_3` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:00,449] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:01,414] Trial 23 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 41, 'n_neurons_1': 20, 'n_neurons_2': 23, 'n_neurons_3': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.0015399265260594922, 'alpha': 0.00011547819846894585}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:01,417] The parameter `use_Logistic Regression` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:01,417] The parameter `use_Decision Tree` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:01,418] The parameter `use_Random Forest` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:01,418] The parameter `use_K-Nearest Neighbors` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:01,419] The parameter `use_Support Vector Machine` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:01,420] The parameter `use_AdaBoost` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:01,420] The parameter `use_Gradient Boosting` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:01,421] The parameter `n_neurons_1` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:01,421] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:02,181] Trial 24 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 86, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015399265260594933, 'alpha': 0.0011547819846894588}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:02,184] The parameter `use_Logistic Regression` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,185] The parameter `use_Decision Tree` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,185] The parameter `use_Random Forest` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,186] The parameter `use_K-Nearest Neighbors` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,186] The parameter `use_Support Vector Machine` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,187] The parameter `use_AdaBoost` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,187] The parameter `use_Gradient Boosting` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,188] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:02,811] Trial 25 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0011547819846894588, 'alpha': 0.004869675251658635}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:02,814] The parameter `use_Logistic Regression` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,814] The parameter `use_Decision Tree` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,815] The parameter `use_Random Forest` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,815] The parameter `use_K-Nearest Neighbors` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,816] The parameter `use_Support Vector Machine` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,817] The parameter `use_AdaBoost` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,817] The parameter `use_Gradient Boosting` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,818] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,818] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,819] The parameter `n_neurons_3` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:02,820] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:03,661] Trial 26 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 69, 'n_neurons_1': 73, 'n_neurons_2': 51, 'n_neurons_3': 67, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011547819846894585, 'alpha': 0.00048696752516586337}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:03,667] The parameter `use_Logistic Regression` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,667] The parameter `use_Decision Tree` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,668] The parameter `use_Random Forest` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,669] The parameter `use_K-Nearest Neighbors` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,669] The parameter `use_Support Vector Machine` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,669] The parameter `use_AdaBoost` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,670] The parameter `use_Gradient Boosting` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,670] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,671] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,671] The parameter `n_neurons_3` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,672] The parameter `n_neurons_4` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:03,672] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:04,510] Trial 27 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 46, 'n_neurons_1': 73, 'n_neurons_2': 58, 'n_neurons_3': 38, 'n_neurons_4': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.0036517412725483775, 'alpha': 0.0015399265260594922}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:04,513] The parameter `use_Logistic Regression` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,514] The parameter `use_Decision Tree` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,514] The parameter `use_Random Forest` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,515] The parameter `use_K-Nearest Neighbors` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,515] The parameter `use_Support Vector Machine` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,515] The parameter `use_AdaBoost` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,517] The parameter `use_Gradient Boosting` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,517] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,518] The parameter `n_neurons_2` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:04,518] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:05,387] Trial 28 finished with value: 0.85 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 92, 'n_neurons_1': 64, 'n_neurons_2': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.000365174127254838, 'alpha': 0.00015399265260594933}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:05,393] The parameter `use_Logistic Regression` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,394] The parameter `use_Decision Tree` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,395] The parameter `use_Random Forest` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,395] The parameter `use_K-Nearest Neighbors` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,396] The parameter `use_Support Vector Machine` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,397] The parameter `use_AdaBoost` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,397] The parameter `use_Gradient Boosting` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,398] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,398] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:05,974] Trial 29 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 35, 'n_neurons_1': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002053525026457149, 'alpha': 0.0002738419634264362}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:05,976] The parameter `use_Logistic Regression` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,977] The parameter `use_Decision Tree` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,978] The parameter `use_Random Forest` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,978] The parameter `use_K-Nearest Neighbors` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,979] The parameter `use_Support Vector Machine` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,979] The parameter `use_AdaBoost` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,980] The parameter `use_Gradient Boosting` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,981] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,981] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,982] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:05,982] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:06,870] Trial 30 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 81, 'n_neurons_1': 46, 'n_neurons_2': 22, 'n_neurons_3': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0020535250264571477, 'alpha': 0.0027384196342643626}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:06,872] The parameter `use_Logistic Regression` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,873] The parameter `use_Decision Tree` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,874] The parameter `use_Random Forest` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,874] The parameter `use_K-Nearest Neighbors` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,874] The parameter `use_Support Vector Machine` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,875] The parameter `use_AdaBoost` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,875] The parameter `use_Gradient Boosting` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,876] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,877] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:06,877] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:07,156] Trial 31 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 12, 'n_neurons_1': 88, 'n_neurons_2': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006493816315762115, 'alpha': 0.000865964323360066}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:07,158] The parameter `use_Logistic Regression` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,159] The parameter `use_Decision Tree` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,159] The parameter `use_Random Forest` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,160] The parameter `use_K-Nearest Neighbors` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,160] The parameter `use_Support Vector Machine` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,162] The parameter `use_AdaBoost` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,162] The parameter `use_Gradient Boosting` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,163] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:07,732] Trial 32 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0064938163157621165, 'alpha': 0.008659643233600654}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:07,736] The parameter `use_Logistic Regression` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,737] The parameter `use_Decision Tree` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,738] The parameter `use_Random Forest` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,738] The parameter `use_K-Nearest Neighbors` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,739] The parameter `use_Support Vector Machine` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,739] The parameter `use_AdaBoost` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,740] The parameter `use_Gradient Boosting` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:07,741] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:08,322] Trial 33 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0025482967479793484, 'alpha': 0.0012409377607517208}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:08,325] The parameter `use_Logistic Regression` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,325] The parameter `use_Decision Tree` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,327] The parameter `use_Random Forest` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,327] The parameter `use_K-Nearest Neighbors` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,327] The parameter `use_Support Vector Machine` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,327] The parameter `use_AdaBoost` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,327] The parameter `use_Gradient Boosting` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,328] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,328] The parameter `n_neurons_2` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,329] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:08,650] Trial 34 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 79, 'n_neurons_1': 66, 'n_neurons_2': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002548296747979348, 'alpha': 0.00012409377607517218}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:08,653] The parameter `use_Logistic Regression` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,654] The parameter `use_Decision Tree` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,655] The parameter `use_Random Forest` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,655] The parameter `use_K-Nearest Neighbors` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,656] The parameter `use_Support Vector Machine` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,656] The parameter `use_AdaBoost` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,656] The parameter `use_Gradient Boosting` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:08,657] Trial 35 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:08,659] The parameter `use_Logistic Regression` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,660] The parameter `use_Decision Tree` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,661] The parameter `use_Random Forest` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,662] The parameter `use_K-Nearest Neighbors` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,663] The parameter `use_Support Vector Machine` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,663] The parameter `use_AdaBoost` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,663] The parameter `use_Gradient Boosting` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,664] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:08,664] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:09,154] Trial 36 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 35, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008058421877614828, 'alpha': 0.0003924189758484538}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:09,154] The parameter `use_Logistic Regression` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,154] The parameter `use_Decision Tree` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,154] The parameter `use_Random Forest` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,159] The parameter `use_K-Nearest Neighbors` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,159] The parameter `use_Support Vector Machine` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,160] The parameter `use_AdaBoost` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,160] The parameter `use_Gradient Boosting` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,161] The parameter `n_neurons_1` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,161] The parameter `n_neurons_2` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:09,161] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:10,254] Trial 37 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 22, 'n_neurons_1': 57, 'n_neurons_2': 47, 'learning_rate': 'constant', 'learning_rate_init': 0.00014330125702369644, 'alpha': 0.0006978305848598669}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:10,256] The parameter `use_Logistic Regression` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,258] The parameter `use_Decision Tree` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,259] The parameter `use_Random Forest` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,259] The parameter `use_K-Nearest Neighbors` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,259] The parameter `use_Support Vector Machine` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,260] The parameter `use_AdaBoost` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,260] The parameter `use_Gradient Boosting` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,262] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,262] The parameter `n_neurons_2` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,262] The parameter `n_neurons_3` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,263] The parameter `n_neurons_4` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,263] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:10,852] Trial 38 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 68, 'n_neurons_1': 48, 'n_neurons_2': 56, 'n_neurons_3': 32, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.0014330125702369636, 'alpha': 0.006978305848598664}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:10,855] The parameter `use_Logistic Regression` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,855] The parameter `use_Decision Tree` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,856] The parameter `use_Random Forest` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,856] The parameter `use_K-Nearest Neighbors` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,857] The parameter `use_Support Vector Machine` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,857] The parameter `use_AdaBoost` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,859] The parameter `use_Gradient Boosting` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,859] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,860] The parameter `n_neurons_2` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,860] The parameter `n_neurons_3` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:10,861] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:11,852] Trial 39 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 45, 'n_neurons_1': 64, 'n_neurons_2': 52, 'n_neurons_3': 47, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045315836376008217, 'alpha': 0.00022067340690845924}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:11,854] The parameter `use_Logistic Regression` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:11,855] The parameter `use_Decision Tree` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:11,856] The parameter `use_Random Forest` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:11,856] The parameter `use_K-Nearest Neighbors` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:11,856] The parameter `use_Support Vector Machine` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:11,857] The parameter `use_AdaBoost` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:11,857] The parameter `use_Gradient Boosting` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:11,859] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:12,380] Trial 40 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0045315836376008225, 'alpha': 0.002206734069084591}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:12,382] The parameter `use_Logistic Regression` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:12,384] The parameter `use_Decision Tree` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:12,384] The parameter `use_Random Forest` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:12,385] The parameter `use_K-Nearest Neighbors` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:12,385] The parameter `use_Support Vector Machine` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:12,386] The parameter `use_AdaBoost` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:12,386] The parameter `use_Gradient Boosting` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:12,386] The parameter `n_neurons_1` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:12,387] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:13,351] Trial 41 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 17, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00033982083289425634, 'alpha': 0.009305720409296997}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:13,353] The parameter `use_Logistic Regression` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,355] The parameter `use_Decision Tree` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,355] The parameter `use_Random Forest` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,356] The parameter `use_K-Nearest Neighbors` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,356] The parameter `use_Support Vector Machine` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,356] The parameter `use_AdaBoost` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,358] The parameter `use_Gradient Boosting` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,359] The parameter `n_neurons_1` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,361] The parameter `n_neurons_2` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,362] The parameter `n_neurons_3` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:13,362] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:14,280] Trial 42 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 62, 'n_neurons_1': 77, 'n_neurons_2': 13, 'n_neurons_3': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003398208328942561, 'alpha': 0.0009305720409296995}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:14,282] The parameter `use_Logistic Regression` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,283] The parameter `use_Decision Tree` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,283] The parameter `use_Random Forest` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,284] The parameter `use_K-Nearest Neighbors` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,285] The parameter `use_Support Vector Machine` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,285] The parameter `use_AdaBoost` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,286] The parameter `use_Gradient Boosting` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,287] The parameter `n_neurons_1` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,287] The parameter `n_neurons_2` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,288] The parameter `n_neurons_3` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,288] The parameter `n_neurons_4` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:14,289] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:15,536] Trial 43 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 32, 'n_neurons_2': 41, 'n_neurons_3': 26, 'n_neurons_4': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.00010746078283213182, 'alpha': 0.002942727176209285}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:15,539] The parameter `use_Logistic Regression` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,540] The parameter `use_Decision Tree` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,541] The parameter `use_Random Forest` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,542] The parameter `use_K-Nearest Neighbors` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,543] The parameter `use_Support Vector Machine` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,543] The parameter `use_AdaBoost` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,544] The parameter `use_Gradient Boosting` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,545] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,545] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:15,546] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:16,013] Trial 44 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 62, 'n_neurons_2': 65, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010746078283213184, 'alpha': 0.0002942727176209287}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:16,015] The parameter `use_Logistic Regression` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:16,016] The parameter `use_Decision Tree` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:16,017] The parameter `use_Random Forest` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:16,017] The parameter `use_K-Nearest Neighbors` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:16,018] The parameter `use_Support Vector Machine` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:16,018] The parameter `use_AdaBoost` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:16,019] The parameter `use_Gradient Boosting` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:16,019] The parameter `n_neurons_1` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:16,020] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:17,005] Trial 45 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 51, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006042963902381333, 'alpha': 0.00016548170999431823}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:17,009] The parameter `use_Logistic Regression` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,010] The parameter `use_Decision Tree` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,011] The parameter `use_Random Forest` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,011] The parameter `use_K-Nearest Neighbors` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,012] The parameter `use_Support Vector Machine` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,012] The parameter `use_AdaBoost` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,013] The parameter `use_Gradient Boosting` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,013] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,014] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,015] The parameter `n_neurons_3` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,015] The parameter `n_neurons_4` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,016] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:17,282] Trial 46 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 96, 'n_neurons_1': 42, 'n_neurons_2': 62, 'n_neurons_3': 67, 'n_neurons_4': 11, 'learning_rate': 'constant', 'learning_rate_init': 0.0006042963902381332, 'alpha': 0.0016548170999431827}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:17,284] The parameter `use_Logistic Regression` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,285] The parameter `use_Decision Tree` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,285] The parameter `use_Random Forest` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,286] The parameter `use_K-Nearest Neighbors` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,287] The parameter `use_Support Vector Machine` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,288] The parameter `use_AdaBoost` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,288] The parameter `use_Gradient Boosting` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,289] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,290] The parameter `n_neurons_2` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,290] The parameter `n_neurons_3` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:17,291] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:18,143] Trial 47 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 28, 'n_neurons_1': 52, 'n_neurons_2': 61, 'n_neurons_3': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0019109529749704425, 'alpha': 0.0005232991146814953}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:18,149] The parameter `use_Logistic Regression` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:18,150] The parameter `use_Decision Tree` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:18,150] The parameter `use_Random Forest` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:18,151] The parameter `use_K-Nearest Neighbors` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:18,152] The parameter `use_Support Vector Machine` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:18,152] The parameter `use_AdaBoost` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:18,153] The parameter `use_Gradient Boosting` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:18,153] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:19,102] Trial 48 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.00019109529749704405, 'alpha': 0.005232991146814949}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:19,107] The parameter `use_Logistic Regression` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,108] The parameter `use_Decision Tree` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,109] The parameter `use_Random Forest` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,111] The parameter `use_K-Nearest Neighbors` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,111] The parameter `use_Support Vector Machine` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,111] The parameter `use_AdaBoost` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,111] The parameter `use_Gradient Boosting` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,113] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:19,229] Trial 49 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.003924189758484535, 'alpha': 0.00019109529749704405}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:19,231] The parameter `use_Logistic Regression` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,232] The parameter `use_Decision Tree` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,233] The parameter `use_Random Forest` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,233] The parameter `use_K-Nearest Neighbors` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,233] The parameter `use_Support Vector Machine` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,235] The parameter `use_AdaBoost` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,235] The parameter `use_Gradient Boosting` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,236] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,237] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,237] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:19,961] Trial 50 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 76, 'n_neurons_1': 33, 'n_neurons_2': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.0003924189758484538, 'alpha': 0.0019109529749704425}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:19,963] The parameter `use_Logistic Regression` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,964] The parameter `use_Decision Tree` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,965] The parameter `use_Random Forest` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,965] The parameter `use_K-Nearest Neighbors` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,966] The parameter `use_Support Vector Machine` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,966] The parameter `use_AdaBoost` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,967] The parameter `use_Gradient Boosting` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,968] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,968] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,968] The parameter `n_neurons_3` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,969] The parameter `n_neurons_4` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:19,970] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:21,059] Trial 51 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 54, 'n_neurons_1': 34, 'n_neurons_2': 59, 'n_neurons_3': 67, 'n_neurons_4': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012409377607517208, 'alpha': 0.0006042963902381332}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:21,062] The parameter `use_Logistic Regression` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,063] The parameter `use_Decision Tree` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,063] The parameter `use_Random Forest` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,064] The parameter `use_K-Nearest Neighbors` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,065] The parameter `use_Support Vector Machine` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,065] The parameter `use_AdaBoost` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,066] The parameter `use_Gradient Boosting` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,067] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,067] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:21,785] Trial 52 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 22, 'learning_rate': 'constant', 'learning_rate_init': 0.00012409377607517218, 'alpha': 0.006042963902381333}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:21,790] The parameter `use_Logistic Regression` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,791] The parameter `use_Decision Tree` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,791] The parameter `use_Random Forest` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,791] The parameter `use_K-Nearest Neighbors` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,793] The parameter `use_Support Vector Machine` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,794] The parameter `use_AdaBoost` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,795] The parameter `use_Gradient Boosting` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,795] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,796] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:21,797] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:22,788] Trial 53 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 45, 'n_neurons_2': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006978305848598669, 'alpha': 0.003398208328942561}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:22,792] The parameter `use_Logistic Regression` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,793] The parameter `use_Decision Tree` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,793] The parameter `use_Random Forest` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,794] The parameter `use_K-Nearest Neighbors` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,795] The parameter `use_Support Vector Machine` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,795] The parameter `use_AdaBoost` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,795] The parameter `use_Gradient Boosting` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,797] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,798] The parameter `n_neurons_2` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,799] The parameter `n_neurons_3` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,799] The parameter `n_neurons_4` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:22,799] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:23,357] Trial 54 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 80, 'n_neurons_2': 19, 'n_neurons_3': 16, 'n_neurons_4': 76, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006978305848598664, 'alpha': 0.00033982083289425634}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:23,361] The parameter `use_Logistic Regression` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,362] The parameter `use_Decision Tree` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,362] The parameter `use_Random Forest` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,363] The parameter `use_K-Nearest Neighbors` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,363] The parameter `use_Support Vector Machine` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,364] The parameter `use_AdaBoost` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,365] The parameter `use_Gradient Boosting` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,365] The parameter `n_neurons_1` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,365] The parameter `n_neurons_2` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,365] The parameter `n_neurons_3` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:23,367] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:24,282] Trial 55 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 19, 'n_neurons_1': 59, 'n_neurons_2': 89, 'n_neurons_3': 76, 'learning_rate': 'constant', 'learning_rate_init': 0.00022067340690845924, 'alpha': 0.0010746078283213184}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:24,286] The parameter `use_Logistic Regression` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,287] The parameter `use_Decision Tree` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,287] The parameter `use_Random Forest` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,288] The parameter `use_K-Nearest Neighbors` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,288] The parameter `use_Support Vector Machine` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,289] The parameter `use_AdaBoost` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,289] The parameter `use_Gradient Boosting` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,290] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,290] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:24,822] Trial 56 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 65, 'n_neurons_1': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002206734069084591, 'alpha': 0.00010746078283213182}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:24,824] The parameter `use_Logistic Regression` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,825] The parameter `use_Decision Tree` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,826] The parameter `use_Random Forest` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,826] The parameter `use_K-Nearest Neighbors` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,826] The parameter `use_Support Vector Machine` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,827] The parameter `use_AdaBoost` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,827] The parameter `use_Gradient Boosting` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:24,827] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:25,753] Trial 57 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 48, 'learning_rate': 'constant', 'learning_rate_init': 0.0002942727176209287, 'alpha': 0.00045315836376008217}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:25,755] The parameter `use_Logistic Regression` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,756] The parameter `use_Decision Tree` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,757] The parameter `use_Random Forest` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,757] The parameter `use_K-Nearest Neighbors` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,758] The parameter `use_Support Vector Machine` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,759] The parameter `use_AdaBoost` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,759] The parameter `use_Gradient Boosting` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,760] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,760] The parameter `n_neurons_2` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,761] The parameter `n_neurons_3` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,761] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:25,912] Trial 58 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 93, 'n_neurons_1': 82, 'n_neurons_2': 100, 'n_neurons_3': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.002942727176209285, 'alpha': 0.0045315836376008225}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:25,914] The parameter `use_Logistic Regression` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,914] The parameter `use_Decision Tree` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,915] The parameter `use_Random Forest` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,915] The parameter `use_K-Nearest Neighbors` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,916] The parameter `use_Support Vector Machine` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,916] The parameter `use_AdaBoost` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,917] The parameter `use_Gradient Boosting` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,917] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,918] The parameter `n_neurons_2` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,919] The parameter `n_neurons_3` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,919] The parameter `n_neurons_4` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:25,920] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:26,905] Trial 59 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 25, 'n_neurons_1': 13, 'n_neurons_2': 11, 'n_neurons_3': 99, 'n_neurons_4': 48, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009305720409296995, 'alpha': 0.00014330125702369644}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:26,907] The parameter `use_Logistic Regression` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:26,907] The parameter `use_Decision Tree` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:26,908] The parameter `use_Random Forest` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:26,908] The parameter `use_K-Nearest Neighbors` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:26,909] The parameter `use_Support Vector Machine` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:26,910] The parameter `use_AdaBoost` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:26,910] The parameter `use_Gradient Boosting` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:26,911] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:26,911] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:27,793] Trial 60 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 65, 'learning_rate': 'constant', 'learning_rate_init': 0.009305720409296997, 'alpha': 0.0014330125702369636}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:27,797] The parameter `use_Logistic Regression` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:27,799] The parameter `use_Decision Tree` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:27,799] The parameter `use_Random Forest` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:27,800] The parameter `use_K-Nearest Neighbors` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:27,800] The parameter `use_Support Vector Machine` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:27,801] The parameter `use_AdaBoost` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:27,801] The parameter `use_Gradient Boosting` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:27,801] The parameter `n_neurons_1` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:27,801] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:28,401] Trial 61 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 14, 'n_neurons_1': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0016548170999431827, 'alpha': 0.0025482967479793484}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:28,408] The parameter `use_Logistic Regression` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,409] The parameter `use_Decision Tree` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,409] The parameter `use_Random Forest` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,410] The parameter `use_K-Nearest Neighbors` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,411] The parameter `use_Support Vector Machine` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,411] The parameter `use_AdaBoost` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,412] The parameter `use_Gradient Boosting` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,412] The parameter `n_neurons_1` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,413] The parameter `n_neurons_2` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,414] The parameter `n_neurons_3` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:28,414] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:29,629] Trial 62 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 59, 'n_neurons_1': 17, 'n_neurons_2': 47, 'n_neurons_3': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00016548170999431823, 'alpha': 0.0002548296747979348}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:29,632] The parameter `use_Logistic Regression` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,633] The parameter `use_Decision Tree` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,633] The parameter `use_Random Forest` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,634] The parameter `use_K-Nearest Neighbors` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,634] The parameter `use_Support Vector Machine` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,635] The parameter `use_AdaBoost` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,635] The parameter `use_Gradient Boosting` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,636] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,636] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:29,637] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:30,074] Trial 63 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 37, 'n_neurons_1': 89, 'n_neurons_2': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005232991146814949, 'alpha': 0.008058421877614822}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:30,077] The parameter `use_Logistic Regression` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,078] The parameter `use_Decision Tree` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,078] The parameter `use_Random Forest` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,079] The parameter `use_K-Nearest Neighbors` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,080] The parameter `use_Support Vector Machine` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,080] The parameter `use_AdaBoost` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,081] The parameter `use_Gradient Boosting` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,081] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:30,708] Trial 64 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 82, 'learning_rate': 'constant', 'learning_rate_init': 0.0005232991146814953, 'alpha': 0.0008058421877614828}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:30,710] The parameter `use_Logistic Regression` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,711] The parameter `use_Decision Tree` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,711] The parameter `use_Random Forest` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,712] The parameter `use_K-Nearest Neighbors` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,712] The parameter `use_Support Vector Machine` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,713] The parameter `use_AdaBoost` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,713] The parameter `use_Gradient Boosting` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,714] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:30,849] Trial 65 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004371444812611091, 'alpha': 0.004697588816706496}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:30,851] The parameter `use_Logistic Regression` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,852] The parameter `use_Decision Tree` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,854] The parameter `use_Random Forest` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,854] The parameter `use_K-Nearest Neighbors` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,855] The parameter `use_Support Vector Machine` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,855] The parameter `use_AdaBoost` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,855] The parameter `use_Gradient Boosting` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,856] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,857] The parameter `n_neurons_2` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:30,858] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:31,720] Trial 66 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 91, 'n_neurons_1': 89, 'n_neurons_2': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.0004371444812611094, 'alpha': 0.0004697588816706495}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:31,722] The parameter `use_Logistic Regression` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,723] The parameter `use_Decision Tree` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,723] The parameter `use_Random Forest` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,724] The parameter `use_K-Nearest Neighbors` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,725] The parameter `use_Support Vector Machine` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,725] The parameter `use_AdaBoost` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,726] The parameter `use_Gradient Boosting` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,726] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,727] The parameter `n_neurons_2` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,727] The parameter `n_neurons_3` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:31,728] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:32,625] Trial 67 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 23, 'n_neurons_1': 82, 'n_neurons_2': 73, 'n_neurons_3': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013823722273579005, 'alpha': 0.0014855080171727755}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:32,627] The parameter `use_Logistic Regression` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:32,628] The parameter `use_Decision Tree` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:32,629] The parameter `use_Random Forest` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:32,629] The parameter `use_K-Nearest Neighbors` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:32,629] The parameter `use_Support Vector Machine` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:32,630] The parameter `use_AdaBoost` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:32,630] The parameter `use_Gradient Boosting` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:32,631] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:32,631] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:33,614] Trial 68 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 69, 'n_neurons_1': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013823722273579014, 'alpha': 0.00014855080171727767}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:33,616] The parameter `use_Logistic Regression` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:33,617] The parameter `use_Decision Tree` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:33,618] The parameter `use_Random Forest` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:33,618] The parameter `use_K-Nearest Neighbors` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:33,619] The parameter `use_Support Vector Machine` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:33,619] The parameter `use_AdaBoost` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:33,620] The parameter `use_Gradient Boosting` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:33,620] The parameter `n_neurons_1` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:33,620] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:34,483] Trial 69 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 12, 'n_neurons_1': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0007773650302387768, 'alpha': 0.00026416483203860934}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:34,485] The parameter `use_Logistic Regression` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,485] The parameter `use_Decision Tree` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,486] The parameter `use_Random Forest` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,487] The parameter `use_K-Nearest Neighbors` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,488] The parameter `use_Support Vector Machine` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,488] The parameter `use_AdaBoost` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,488] The parameter `use_Gradient Boosting` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:34,488] Trial 70 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 4 with value: 0.9166666666666666.\n",
      "[W 2025-12-28 19:51:34,488] The parameter `use_Logistic Regression` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,488] The parameter `use_Decision Tree` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,488] The parameter `use_Random Forest` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,488] The parameter `use_K-Nearest Neighbors` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,488] The parameter `use_Support Vector Machine` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,493] The parameter `use_AdaBoost` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,494] The parameter `use_Gradient Boosting` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,494] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,494] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,494] The parameter `n_neurons_3` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,494] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:34,807] Trial 71 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 34, 'n_neurons_1': 66, 'n_neurons_2': 73, 'n_neurons_3': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002458244068920199, 'alpha': 0.000835362546957827}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:34,810] The parameter `use_Logistic Regression` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,811] The parameter `use_Decision Tree` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,812] The parameter `use_Random Forest` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,812] The parameter `use_K-Nearest Neighbors` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,813] The parameter `use_Support Vector Machine` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,813] The parameter `use_AdaBoost` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,814] The parameter `use_Gradient Boosting` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:34,814] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:35,650] Trial 72 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0024582440689201977, 'alpha': 0.008353625469578265}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:35,653] The parameter `use_Logistic Regression` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:35,654] The parameter `use_Decision Tree` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:35,654] The parameter `use_Random Forest` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:35,656] The parameter `use_K-Nearest Neighbors` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:35,656] The parameter `use_Support Vector Machine` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:35,656] The parameter `use_AdaBoost` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:35,657] The parameter `use_Gradient Boosting` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:35,657] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:35,658] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:36,670] Trial 73 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 29, 'n_neurons_1': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018434229924091107, 'alpha': 0.001980956778550341}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:36,674] The parameter `use_Logistic Regression` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,675] The parameter `use_Decision Tree` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,675] The parameter `use_Random Forest` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,676] The parameter `use_K-Nearest Neighbors` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,676] The parameter `use_Support Vector Machine` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,678] The parameter `use_AdaBoost` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,678] The parameter `use_Gradient Boosting` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,679] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,679] The parameter `n_neurons_2` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,680] The parameter `n_neurons_3` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:36,680] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:37,571] Trial 74 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 74, 'n_neurons_1': 30, 'n_neurons_2': 100, 'n_neurons_3': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.0018434229924091127, 'alpha': 0.0001980956778550342}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:37,579] The parameter `use_Logistic Regression` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,580] The parameter `use_Decision Tree` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,580] The parameter `use_Random Forest` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,581] The parameter `use_K-Nearest Neighbors` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,581] The parameter `use_Support Vector Machine` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,582] The parameter `use_AdaBoost` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,582] The parameter `use_Gradient Boosting` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,582] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,583] The parameter `n_neurons_2` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,583] The parameter `n_neurons_3` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,585] The parameter `n_neurons_4` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:37,585] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:38,046] Trial 75 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 51, 'n_neurons_1': 62, 'n_neurons_2': 49, 'n_neurons_3': 75, 'n_neurons_4': 54, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005829415347136078, 'alpha': 0.00626433536656886}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:38,052] The parameter `use_Logistic Regression` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,053] The parameter `use_Decision Tree` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,054] The parameter `use_Random Forest` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,054] The parameter `use_K-Nearest Neighbors` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,055] The parameter `use_Support Vector Machine` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,055] The parameter `use_AdaBoost` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,056] The parameter `use_Gradient Boosting` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,057] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,057] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,057] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:38,866] Trial 76 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 26, 'n_neurons_2': 87, 'learning_rate': 'constant', 'learning_rate_init': 0.0058294153471360795, 'alpha': 0.0006264335366568858}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:38,867] The parameter `use_Logistic Regression` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,867] The parameter `use_Decision Tree` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,867] The parameter `use_Random Forest` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,870] The parameter `use_K-Nearest Neighbors` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,871] The parameter `use_Support Vector Machine` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,871] The parameter `use_AdaBoost` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,871] The parameter `use_Gradient Boosting` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,872] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:38,873] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:39,498] Trial 77 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 40, 'n_neurons_1': 51, 'learning_rate': 'constant', 'learning_rate_init': 0.001036632928437698, 'alpha': 0.0003522694651473105}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:39,500] The parameter `use_Logistic Regression` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,501] The parameter `use_Decision Tree` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,502] The parameter `use_Random Forest` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,502] The parameter `use_K-Nearest Neighbors` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,503] The parameter `use_Support Vector Machine` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,504] The parameter `use_AdaBoost` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,504] The parameter `use_Gradient Boosting` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,504] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,504] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,504] The parameter `n_neurons_3` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,506] The parameter `n_neurons_4` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:39,506] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:40,424] Trial 78 finished with value: 0.85 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 86, 'n_neurons_2': 83, 'n_neurons_3': 63, 'n_neurons_4': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.00010366329284376988, 'alpha': 0.0035226946514731027}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:40,430] The parameter `use_Logistic Regression` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,431] The parameter `use_Decision Tree` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,431] The parameter `use_Random Forest` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,432] The parameter `use_K-Nearest Neighbors` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,432] The parameter `use_Support Vector Machine` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,433] The parameter `use_AdaBoost` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,433] The parameter `use_Gradient Boosting` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,435] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,435] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,435] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:40,821] Trial 79 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 17, 'n_neurons_1': 10, 'n_neurons_2': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003278121151393461, 'alpha': 0.0001113973859994803}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:40,823] The parameter `use_Logistic Regression` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,823] The parameter `use_Decision Tree` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,825] The parameter `use_Random Forest` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,825] The parameter `use_K-Nearest Neighbors` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,825] The parameter `use_Support Vector Machine` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,826] The parameter `use_AdaBoost` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,826] The parameter `use_Gradient Boosting` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:40,827] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:41,743] Trial 80 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.00032781211513934627, 'alpha': 0.001113973859994803}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:41,746] The parameter `use_Logistic Regression` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:41,746] The parameter `use_Decision Tree` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:41,747] The parameter `use_Random Forest` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:41,748] The parameter `use_K-Nearest Neighbors` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:41,748] The parameter `use_Support Vector Machine` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:41,748] The parameter `use_AdaBoost` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:41,750] The parameter `use_Gradient Boosting` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:41,750] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:42,592] Trial 81 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002128751661796374, 'alpha': 0.0009646616199111995}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:42,594] The parameter `use_Logistic Regression` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,595] The parameter `use_Decision Tree` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,596] The parameter `use_Random Forest` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,596] The parameter `use_K-Nearest Neighbors` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,597] The parameter `use_Support Vector Machine` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,597] The parameter `use_AdaBoost` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,598] The parameter `use_Gradient Boosting` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,599] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,599] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,600] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:42,600] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:43,811] Trial 82 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 83, 'n_neurons_2': 79, 'n_neurons_3': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00021287516617963755, 'alpha': 0.009646616199111998}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:43,813] The parameter `use_Logistic Regression` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,814] The parameter `use_Decision Tree` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,814] The parameter `use_Random Forest` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,815] The parameter `use_K-Nearest Neighbors` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,816] The parameter `use_Support Vector Machine` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,817] The parameter `use_AdaBoost` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,817] The parameter `use_Gradient Boosting` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,817] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,818] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,819] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,820] The parameter `n_neurons_4` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:43,820] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:44,698] Trial 83 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 70, 'n_neurons_2': 66, 'n_neurons_3': 52, 'n_neurons_4': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.006731703824144984, 'alpha': 0.00030505278902670253}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:44,704] The parameter `use_Logistic Regression` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,705] The parameter `use_Decision Tree` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,705] The parameter `use_Random Forest` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,706] The parameter `use_K-Nearest Neighbors` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,707] The parameter `use_Support Vector Machine` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,707] The parameter `use_AdaBoost` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,707] The parameter `use_Gradient Boosting` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:44,707] Trial 84 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:44,710] The parameter `use_Logistic Regression` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,712] The parameter `use_Decision Tree` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,712] The parameter `use_Random Forest` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,712] The parameter `use_K-Nearest Neighbors` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,712] The parameter `use_Support Vector Machine` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,714] The parameter `use_AdaBoost` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,714] The parameter `use_Gradient Boosting` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,714] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,714] The parameter `n_neurons_2` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:44,716] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:45,569] Trial 85 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 59, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011970850304957301, 'alpha': 0.0017154378963428801}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:45,573] The parameter `use_Logistic Regression` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,574] The parameter `use_Decision Tree` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,575] The parameter `use_Random Forest` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,576] The parameter `use_K-Nearest Neighbors` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,576] The parameter `use_Support Vector Machine` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,576] The parameter `use_AdaBoost` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,578] The parameter `use_Gradient Boosting` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:45,580] Trial 86 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:45,582] The parameter `use_Logistic Regression` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,584] The parameter `use_Decision Tree` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,585] The parameter `use_Random Forest` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,585] The parameter `use_K-Nearest Neighbors` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,587] The parameter `use_Support Vector Machine` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,587] The parameter `use_AdaBoost` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,587] The parameter `use_Gradient Boosting` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,589] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,591] The parameter `n_neurons_2` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,592] The parameter `n_neurons_3` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:45,592] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:46,274] Trial 87 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 31, 'n_neurons_2': 81, 'n_neurons_3': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.0003785515249258633, 'alpha': 0.005424690937011328}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:46,276] The parameter `use_Logistic Regression` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:46,277] The parameter `use_Decision Tree` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:46,278] The parameter `use_Random Forest` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:46,279] The parameter `use_K-Nearest Neighbors` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:46,279] The parameter `use_Support Vector Machine` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:46,279] The parameter `use_AdaBoost` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:46,279] The parameter `use_Gradient Boosting` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:46,280] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:46,281] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:47,048] Trial 88 finished with value: 0.9166666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00378551524925863, 'alpha': 0.0005424690937011332}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:47,054] The parameter `use_Logistic Regression` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,055] The parameter `use_Decision Tree` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,056] The parameter `use_Random Forest` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,057] The parameter `use_K-Nearest Neighbors` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,057] The parameter `use_Support Vector Machine` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,058] The parameter `use_AdaBoost` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,058] The parameter `use_Gradient Boosting` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,059] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:47,547] Trial 89 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 37, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005048065716667477, 'alpha': 0.00012863969449369766}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:47,549] The parameter `use_Logistic Regression` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,550] The parameter `use_Decision Tree` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,551] The parameter `use_Random Forest` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,551] The parameter `use_K-Nearest Neighbors` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,552] The parameter `use_Support Vector Machine` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,552] The parameter `use_AdaBoost` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,553] The parameter `use_Gradient Boosting` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,553] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,554] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,555] The parameter `n_neurons_3` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:47,555] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:48,304] Trial 90 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 83, 'n_neurons_1': 39, 'n_neurons_2': 40, 'n_neurons_3': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.005048065716667474, 'alpha': 0.0012863969449369757}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:48,307] The parameter `use_Logistic Regression` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,308] The parameter `use_Decision Tree` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,309] The parameter `use_Random Forest` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,309] The parameter `use_K-Nearest Neighbors` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,310] The parameter `use_Support Vector Machine` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,310] The parameter `use_AdaBoost` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,311] The parameter `use_Gradient Boosting` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,311] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,312] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,312] The parameter `n_neurons_3` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,313] The parameter `n_neurons_4` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:48,313] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:49,330] Trial 91 finished with value: 0.8 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 70, 'n_neurons_2': 82, 'n_neurons_3': 94, 'n_neurons_4': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.00015963385442879435, 'alpha': 0.0004067944321083049}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:49,333] The parameter `use_Logistic Regression` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,334] The parameter `use_Decision Tree` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,334] The parameter `use_Random Forest` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,335] The parameter `use_K-Nearest Neighbors` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,336] The parameter `use_Support Vector Machine` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,337] The parameter `use_AdaBoost` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,337] The parameter `use_Gradient Boosting` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,338] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,338] The parameter `n_neurons_2` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:49,339] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:50,178] Trial 92 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 60, 'n_neurons_1': 33, 'n_neurons_2': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015963385442879423, 'alpha': 0.0040679443210830495}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:50,182] The parameter `use_Logistic Regression` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,183] The parameter `use_Decision Tree` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,183] The parameter `use_Random Forest` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,184] The parameter `use_K-Nearest Neighbors` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,185] The parameter `use_Support Vector Machine` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,185] The parameter `use_AdaBoost` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,187] The parameter `use_Gradient Boosting` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,187] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,187] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:50,769] Trial 93 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.00897687132447315, 'alpha': 0.007233941627366754}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:50,771] The parameter `use_Logistic Regression` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,773] The parameter `use_Decision Tree` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,773] The parameter `use_Random Forest` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,774] The parameter `use_K-Nearest Neighbors` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,774] The parameter `use_Support Vector Machine` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,775] The parameter `use_AdaBoost` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,775] The parameter `use_Gradient Boosting` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,776] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,776] The parameter `n_neurons_2` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,778] The parameter `n_neurons_3` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,778] The parameter `n_neurons_4` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:50,778] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:51,975] Trial 94 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 71, 'n_neurons_1': 54, 'n_neurons_2': 65, 'n_neurons_3': 79, 'n_neurons_4': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0008976871324473148, 'alpha': 0.0007233941627366753}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:51,978] The parameter `use_Logistic Regression` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,980] The parameter `use_Decision Tree` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,980] The parameter `use_Random Forest` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,981] The parameter `use_K-Nearest Neighbors` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,982] The parameter `use_Support Vector Machine` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,983] The parameter `use_AdaBoost` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,983] The parameter `use_Gradient Boosting` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,984] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,984] The parameter `n_neurons_2` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:51,985] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:52,839] Trial 95 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 29, 'n_neurons_2': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0028387359647587583, 'alpha': 0.0022875732003183966}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:52,842] The parameter `use_Logistic Regression` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:52,842] The parameter `use_Decision Tree` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:52,843] The parameter `use_Random Forest` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:52,844] The parameter `use_K-Nearest Neighbors` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:52,844] The parameter `use_Support Vector Machine` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:52,845] The parameter `use_AdaBoost` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:52,845] The parameter `use_Gradient Boosting` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:52,846] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:53,509] Trial 96 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 94, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002838735964758755, 'alpha': 0.0002287573200318398}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:53,512] The parameter `use_Logistic Regression` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:53,513] The parameter `use_Decision Tree` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:53,514] The parameter `use_Random Forest` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:53,515] The parameter `use_K-Nearest Neighbors` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:53,515] The parameter `use_Support Vector Machine` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:53,515] The parameter `use_AdaBoost` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:53,516] The parameter `use_Gradient Boosting` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:53,517] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:51:54,152] Trial 97 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006264335366568858, 'alpha': 0.0005048065716667477}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:54,155] The parameter `use_Logistic Regression` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,156] The parameter `use_Decision Tree` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,157] The parameter `use_Random Forest` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,158] The parameter `use_K-Nearest Neighbors` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,158] The parameter `use_Support Vector Machine` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,158] The parameter `use_AdaBoost` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,160] The parameter `use_Gradient Boosting` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,161] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,161] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,161] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:54,271] Trial 98 finished with value: 0.8833333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 54, 'n_neurons_2': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.00626433536656886, 'alpha': 0.005048065716667474}. Best is trial 71 with value: 0.9333333333333333.\n",
      "[W 2025-12-28 19:51:54,273] The parameter `use_Logistic Regression` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,274] The parameter `use_Decision Tree` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,275] The parameter `use_Random Forest` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,275] The parameter `use_K-Nearest Neighbors` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,275] The parameter `use_Support Vector Machine` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,276] The parameter `use_AdaBoost` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,276] The parameter `use_Gradient Boosting` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,278] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,278] The parameter `n_neurons_2` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,278] The parameter `n_neurons_3` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:51:54,278] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:51:54,876] Trial 99 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 44, 'n_neurons_1': 38, 'n_neurons_2': 72, 'n_neurons_3': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001980956778550342, 'alpha': 0.00015963385442879435}. Best is trial 71 with value: 0.9333333333333333.\n",
      "\n",
      "Selected Base Models for Stacking using QMCSampler:\n",
      "- Decision Tree\n",
      "- K-Nearest Neighbors\n",
      "- Support Vector Machine\n",
      "Best Hyperparameters for Meta Model (MLP) using QMCSampler: {'learning_rate': 'adaptive', 'learning_rate_init': 0.0002458244068920199, 'alpha': 0.000835362546957827, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (34, 66, 73, 60), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9333, at trial: 71\n",
      "QMC base models training time: 40.28 seconds\n",
      "QMC SEl-NNML Training Time: 71.23 seconds\n",
      "Total QMC Training Time (Base + Meta): 111.51 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    qmc_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    qmc_sel_nnml, qmc_meta_study = meta_model_tuning(base_models['QMC'], X_train, y_train, X_test, y_test, sampler='QMCSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    qmc_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for QMC SEl-NNML training\n",
    "    qmc_meta_model_training_time = qmc_meta_model_training_end - qmc_meta_model_training_start\n",
    "    print(f'QMC base models training time: {qmc_base_models_training_time:.2f} seconds')\n",
    "    print(f'QMC SEl-NNML Training Time: {qmc_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total QMC Training Time (Base + Meta): {qmc_base_models_training_time + qmc_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    qmc_meta_history = qmc_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    qmc_meta_history.columns = ['iteration', 'score']\n",
    "    qmc_meta_history['iteration'] = qmc_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping QMC meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sampler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Best Hyperparameters",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "2f9c09af-d191-4e67-be29-a8579fdf09a5",
       "rows": [
        [
         "0",
         "TPE",
         "Logistic Regression",
         "{'C': 0.10511058777298, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "1",
         "TPE",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "2",
         "TPE",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 43, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "3",
         "TPE",
         "K-Nearest Neighbors",
         "{'algorithm': 'brute', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 44, 'p': 2, 'weights': 'uniform'}"
        ],
        [
         "4",
         "TPE",
         "Support Vector Machine",
         "{'C': 0.009989167941012688, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 4, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "5",
         "TPE",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.13311216080736885, 'n_estimators': 64, 'random_state': 42}"
        ],
        [
         "6",
         "TPE",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.0031766373787891163, 'loss': 'log_loss', 'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 7, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 79, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.7774219392909123, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "7",
         "TPE",
         "SEL-NNML",
         "{'cv': None, 'estimators': [('Logistic Regression', LogisticRegression(C=0.10511058777298, max_iter=1000, n_jobs=-1,\n                   random_state=42)), ('Support Vector Machine', SVC(C=0.009989167941012688, degree=4, kernel='poly', random_state=42)), ('AdaBoost', AdaBoostClassifier(learning_rate=0.13311216080736885, n_estimators=64,\n                   random_state=42))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.006586289317583112, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (83, 37, 18, 72, 50), 'final_estimator__learning_rate': 'adaptive', 'final_estimator__learning_rate_init': 0.00011715937392307068, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.006586289317583112,\n              hidden_layer_sizes=(83, 37, 18, 72, 50), learning_rate='adaptive',\n              learning_rate_init=0.00011715937392307068, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Logistic Regression': LogisticRegression(C=0.10511058777298, max_iter=1000, n_jobs=-1,\n                   random_state=42), 'Support Vector Machine': SVC(C=0.009989167941012688, degree=4, kernel='poly', random_state=42), 'AdaBoost': AdaBoostClassifier(learning_rate=0.13311216080736885, n_estimators=64,\n                   random_state=42), 'Logistic Regression__C': 0.10511058777298, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'deprecated', 'Logistic Regression__n_jobs': -1, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 42, 'Logistic Regression__solver': 'lbfgs', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False, 'Support Vector Machine__C': 0.009989167941012688, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 4, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False, 'AdaBoost__algorithm': 'deprecated', 'AdaBoost__estimator': None, 'AdaBoost__learning_rate': 0.13311216080736885, 'AdaBoost__n_estimators': 64, 'AdaBoost__random_state': 42}"
        ],
        [
         "8",
         "GP",
         "Logistic Regression",
         "{'C': 0.10971272926314876, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cholesky', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "9",
         "GP",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 7, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "10",
         "GP",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 81, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "11",
         "GP",
         "K-Nearest Neighbors",
         "{'algorithm': 'ball_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}"
        ],
        [
         "12",
         "GP",
         "Support Vector Machine",
         "{'C': 0.01, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 4, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "13",
         "GP",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.13311216080736885, 'n_estimators': 64, 'random_state': 42}"
        ],
        [
         "14",
         "GP",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.0053601954809141235, 'loss': 'log_loss', 'max_depth': 3, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 10, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 75, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "15",
         "GP",
         "SEL-NNML",
         "{'cv': None, 'estimators': [('Logistic Regression', LogisticRegression(C=0.10971272926314876, max_iter=1000, n_jobs=-1,\n                   random_state=42, solver='newton-cholesky')), ('Support Vector Machine', SVC(C=0.01, degree=4, kernel='poly', random_state=42)), ('AdaBoost', AdaBoostClassifier(learning_rate=0.13311216080736885, n_estimators=64,\n                   random_state=42))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.006586289317583112, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (83, 37, 18, 72, 50), 'final_estimator__learning_rate': 'adaptive', 'final_estimator__learning_rate_init': 0.00011715937392307068, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.006586289317583112,\n              hidden_layer_sizes=(83, 37, 18, 72, 50), learning_rate='adaptive',\n              learning_rate_init=0.00011715937392307068, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Logistic Regression': LogisticRegression(C=0.10971272926314876, max_iter=1000, n_jobs=-1,\n                   random_state=42, solver='newton-cholesky'), 'Support Vector Machine': SVC(C=0.01, degree=4, kernel='poly', random_state=42), 'AdaBoost': AdaBoostClassifier(learning_rate=0.13311216080736885, n_estimators=64,\n                   random_state=42), 'Logistic Regression__C': 0.10971272926314876, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'deprecated', 'Logistic Regression__n_jobs': -1, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 42, 'Logistic Regression__solver': 'newton-cholesky', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False, 'Support Vector Machine__C': 0.01, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 4, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False, 'AdaBoost__algorithm': 'deprecated', 'AdaBoost__estimator': None, 'AdaBoost__learning_rate': 0.13311216080736885, 'AdaBoost__n_estimators': 64, 'AdaBoost__random_state': 42}"
        ],
        [
         "16",
         "CMA-ES",
         "Logistic Regression",
         "{'C': 0.084423328736445, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cholesky', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "17",
         "CMA-ES",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "18",
         "CMA-ES",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 7, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 60, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "19",
         "CMA-ES",
         "K-Nearest Neighbors",
         "{'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 31, 'p': 1, 'weights': 'uniform'}"
        ],
        [
         "20",
         "CMA-ES",
         "Support Vector Machine",
         "{'C': 0.00977884880613245, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 4, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "21",
         "CMA-ES",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.5602864813134, 'n_estimators': 72, 'random_state': 42}"
        ],
        [
         "22",
         "CMA-ES",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.009210476518456951, 'loss': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 57, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.6999388305477132, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "23",
         "CMA-ES",
         "SEL-NNML",
         "{'cv': None, 'estimators': [('Decision Tree', DecisionTreeClassifier(max_depth=6, max_features='sqrt', min_samples_leaf=6,\n                       min_samples_split=8, random_state=42)), ('Random Forest', RandomForestClassifier(max_depth=8, min_samples_leaf=7, min_samples_split=4,\n                       n_estimators=60, n_jobs=-1, random_state=42)), ('K-Nearest Neighbors', KNeighborsClassifier(algorithm='kd_tree', n_jobs=-1, n_neighbors=31, p=1)), ('Support Vector Machine', SVC(C=0.00977884880613245, degree=4, kernel='poly', random_state=42))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.0009528924787594206, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (72, 80), 'final_estimator__learning_rate': 'constant', 'final_estimator__learning_rate_init': 0.0004843830630951302, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.0009528924787594206, hidden_layer_sizes=(72, 80),\n              learning_rate_init=0.0004843830630951302, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Decision Tree': DecisionTreeClassifier(max_depth=6, max_features='sqrt', min_samples_leaf=6,\n                       min_samples_split=8, random_state=42), 'Random Forest': RandomForestClassifier(max_depth=8, min_samples_leaf=7, min_samples_split=4,\n                       n_estimators=60, n_jobs=-1, random_state=42), 'K-Nearest Neighbors': KNeighborsClassifier(algorithm='kd_tree', n_jobs=-1, n_neighbors=31, p=1), 'Support Vector Machine': SVC(C=0.00977884880613245, degree=4, kernel='poly', random_state=42), 'Decision Tree__ccp_alpha': 0.0, 'Decision Tree__class_weight': None, 'Decision Tree__criterion': 'gini', 'Decision Tree__max_depth': 6, 'Decision Tree__max_features': 'sqrt', 'Decision Tree__max_leaf_nodes': None, 'Decision Tree__min_impurity_decrease': 0.0, 'Decision Tree__min_samples_leaf': 6, 'Decision Tree__min_samples_split': 8, 'Decision Tree__min_weight_fraction_leaf': 0.0, 'Decision Tree__monotonic_cst': None, 'Decision Tree__random_state': 42, 'Decision Tree__splitter': 'best', 'Random Forest__bootstrap': True, 'Random Forest__ccp_alpha': 0.0, 'Random Forest__class_weight': None, 'Random Forest__criterion': 'gini', 'Random Forest__max_depth': 8, 'Random Forest__max_features': 'sqrt', 'Random Forest__max_leaf_nodes': None, 'Random Forest__max_samples': None, 'Random Forest__min_impurity_decrease': 0.0, 'Random Forest__min_samples_leaf': 7, 'Random Forest__min_samples_split': 4, 'Random Forest__min_weight_fraction_leaf': 0.0, 'Random Forest__monotonic_cst': None, 'Random Forest__n_estimators': 60, 'Random Forest__n_jobs': -1, 'Random Forest__oob_score': False, 'Random Forest__random_state': 42, 'Random Forest__verbose': 0, 'Random Forest__warm_start': False, 'K-Nearest Neighbors__algorithm': 'kd_tree', 'K-Nearest Neighbors__leaf_size': 30, 'K-Nearest Neighbors__metric': 'minkowski', 'K-Nearest Neighbors__metric_params': None, 'K-Nearest Neighbors__n_jobs': -1, 'K-Nearest Neighbors__n_neighbors': 31, 'K-Nearest Neighbors__p': 1, 'K-Nearest Neighbors__weights': 'uniform', 'Support Vector Machine__C': 0.00977884880613245, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 4, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False}"
        ],
        [
         "24",
         "QMC",
         "Logistic Regression",
         "{'C': 0.0930572040929699, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "25",
         "QMC",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "26",
         "QMC",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 48, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "27",
         "QMC",
         "K-Nearest Neighbors",
         "{'algorithm': 'brute', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}"
        ],
        [
         "28",
         "QMC",
         "Support Vector Machine",
         "{'C': 0.008058421877614822, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 5, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "29",
         "QMC",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.27384196342643613, 'n_estimators': 72, 'random_state': 42}"
        ],
        [
         "30",
         "QMC",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.013335214321633242, 'loss': 'log_loss', 'max_depth': 4, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 9, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 49, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.53125, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "31",
         "QMC",
         "SEL-NNML",
         "{'cv': None, 'estimators': [('Decision Tree', DecisionTreeClassifier(criterion='log_loss', max_depth=3, min_samples_leaf=6,\n                       min_samples_split=10, random_state=42)), ('K-Nearest Neighbors', KNeighborsClassifier(algorithm='brute', n_jobs=-1, n_neighbors=22, p=1)), ('Support Vector Machine', SVC(C=0.008058421877614822, degree=5, kernel='poly', random_state=42))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.000835362546957827, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (34, 66, 73, 60), 'final_estimator__learning_rate': 'adaptive', 'final_estimator__learning_rate_init': 0.0002458244068920199, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.000835362546957827, hidden_layer_sizes=(34, 66, 73, 60),\n              learning_rate='adaptive',\n              learning_rate_init=0.0002458244068920199, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Decision Tree': DecisionTreeClassifier(criterion='log_loss', max_depth=3, min_samples_leaf=6,\n                       min_samples_split=10, random_state=42), 'K-Nearest Neighbors': KNeighborsClassifier(algorithm='brute', n_jobs=-1, n_neighbors=22, p=1), 'Support Vector Machine': SVC(C=0.008058421877614822, degree=5, kernel='poly', random_state=42), 'Decision Tree__ccp_alpha': 0.0, 'Decision Tree__class_weight': None, 'Decision Tree__criterion': 'log_loss', 'Decision Tree__max_depth': 3, 'Decision Tree__max_features': None, 'Decision Tree__max_leaf_nodes': None, 'Decision Tree__min_impurity_decrease': 0.0, 'Decision Tree__min_samples_leaf': 6, 'Decision Tree__min_samples_split': 10, 'Decision Tree__min_weight_fraction_leaf': 0.0, 'Decision Tree__monotonic_cst': None, 'Decision Tree__random_state': 42, 'Decision Tree__splitter': 'best', 'K-Nearest Neighbors__algorithm': 'brute', 'K-Nearest Neighbors__leaf_size': 30, 'K-Nearest Neighbors__metric': 'minkowski', 'K-Nearest Neighbors__metric_params': None, 'K-Nearest Neighbors__n_jobs': -1, 'K-Nearest Neighbors__n_neighbors': 22, 'K-Nearest Neighbors__p': 1, 'K-Nearest Neighbors__weights': 'uniform', 'Support Vector Machine__C': 0.008058421877614822, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 5, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False}"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 32
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Best Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.10511058777298, 'class_weight': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPE</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'brute', 'leaf_size': 30, 'metri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.009989167941012688, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPE</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TPE</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Logistic Regress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GP</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.10971272926314876, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GP</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GP</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 30, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GP</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.01, 'break_ties': False, 'cache_size':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GP</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GP</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Logistic Regress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.084423328736445, 'class_weight': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 30, 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.00977884880613245, 'break_ties': False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Decision Tree', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.0930572040929699, 'class_weight': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>QMC</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'brute', 'leaf_size': 30, 'metri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.008058421877614822, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>QMC</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>QMC</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Decision Tree', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sampler              Model Name  \\\n",
       "0      TPE     Logistic Regression   \n",
       "1      TPE           Decision Tree   \n",
       "2      TPE           Random Forest   \n",
       "3      TPE     K-Nearest Neighbors   \n",
       "4      TPE  Support Vector Machine   \n",
       "5      TPE                AdaBoost   \n",
       "6      TPE       Gradient Boosting   \n",
       "7      TPE                SEL-NNML   \n",
       "8       GP     Logistic Regression   \n",
       "9       GP           Decision Tree   \n",
       "10      GP           Random Forest   \n",
       "11      GP     K-Nearest Neighbors   \n",
       "12      GP  Support Vector Machine   \n",
       "13      GP                AdaBoost   \n",
       "14      GP       Gradient Boosting   \n",
       "15      GP                SEL-NNML   \n",
       "16  CMA-ES     Logistic Regression   \n",
       "17  CMA-ES           Decision Tree   \n",
       "18  CMA-ES           Random Forest   \n",
       "19  CMA-ES     K-Nearest Neighbors   \n",
       "20  CMA-ES  Support Vector Machine   \n",
       "21  CMA-ES                AdaBoost   \n",
       "22  CMA-ES       Gradient Boosting   \n",
       "23  CMA-ES                SEL-NNML   \n",
       "24     QMC     Logistic Regression   \n",
       "25     QMC           Decision Tree   \n",
       "26     QMC           Random Forest   \n",
       "27     QMC     K-Nearest Neighbors   \n",
       "28     QMC  Support Vector Machine   \n",
       "29     QMC                AdaBoost   \n",
       "30     QMC       Gradient Boosting   \n",
       "31     QMC                SEL-NNML   \n",
       "\n",
       "                                 Best Hyperparameters  \n",
       "0   {'C': 0.10511058777298, 'class_weight': None, ...  \n",
       "1   {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "2   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "3   {'algorithm': 'brute', 'leaf_size': 30, 'metri...  \n",
       "4   {'C': 0.009989167941012688, 'break_ties': Fals...  \n",
       "5   {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "6   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "7   {'cv': None, 'estimators': [('Logistic Regress...  \n",
       "8   {'C': 0.10971272926314876, 'class_weight': Non...  \n",
       "9   {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "10  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "11  {'algorithm': 'ball_tree', 'leaf_size': 30, 'm...  \n",
       "12  {'C': 0.01, 'break_ties': False, 'cache_size':...  \n",
       "13  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "14  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "15  {'cv': None, 'estimators': [('Logistic Regress...  \n",
       "16  {'C': 0.084423328736445, 'class_weight': None,...  \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "18  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "19  {'algorithm': 'kd_tree', 'leaf_size': 30, 'met...  \n",
       "20  {'C': 0.00977884880613245, 'break_ties': False...  \n",
       "21  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "22  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "23  {'cv': None, 'estimators': [('Decision Tree', ...  \n",
       "24  {'C': 0.0930572040929699, 'class_weight': None...  \n",
       "25  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "26  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "27  {'algorithm': 'brute', 'leaf_size': 30, 'metri...  \n",
       "28  {'C': 0.008058421877614822, 'break_ties': Fals...  \n",
       "29  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "30  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "31  {'cv': None, 'estimators': [('Decision Tree', ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # All Models Storage for all sampler types\n",
    "    all_models = {\n",
    "        'TPE': {\n",
    "            'Logistic Regression': tpe_logistic_regression,\n",
    "            'Decision Tree': tpe_decision_tree,\n",
    "            'Random Forest': tpe_random_forest,\n",
    "            'K-Nearest Neighbors': tpe_knn,\n",
    "            'Support Vector Machine': tpe_svc,\n",
    "            'AdaBoost': tpe_adaboost,\n",
    "            'Gradient Boosting': tpe_gradient_boosting,\n",
    "            'SEL-NNML': tpe_sel_nnml\n",
    "        },\n",
    "        'GP': {\n",
    "            'Logistic Regression': gp_logistic_regression,\n",
    "            'Decision Tree': gp_decision_tree,\n",
    "            'Random Forest': gp_random_forest,\n",
    "            'K-Nearest Neighbors': gp_knn,\n",
    "            'Support Vector Machine': gp_svc,\n",
    "            'AdaBoost': gp_adaboost,\n",
    "            'Gradient Boosting': gp_gradient_boosting,\n",
    "            'SEL-NNML': gp_sel_nnml\n",
    "        },\n",
    "        'CMA-ES': {\n",
    "            'Logistic Regression': cmaes_logistic_regression,\n",
    "            'Decision Tree': cmaes_decision_tree,\n",
    "            'Random Forest': cmaes_random_forest,\n",
    "            'K-Nearest Neighbors': cmaes_knn,\n",
    "            'Support Vector Machine': cmaes_svc,\n",
    "            'AdaBoost': cmaes_adaboost,\n",
    "            'Gradient Boosting': cmaes_gradient_boosting,\n",
    "            'SEL-NNML': cmaes_sel_nnml\n",
    "        },\n",
    "        'QMC': {\n",
    "            'Logistic Regression': qmc_logistic_regression,\n",
    "            'Decision Tree': qmc_decision_tree,\n",
    "            'Random Forest': qmc_random_forest,\n",
    "            'K-Nearest Neighbors': qmc_knn,\n",
    "            'Support Vector Machine': qmc_svc,\n",
    "            'AdaBoost': qmc_adaboost,\n",
    "            'Gradient Boosting': qmc_gradient_boosting,\n",
    "            'SEL-NNML': qmc_sel_nnml\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save Every Best Model Config for each Tuning Method (Base + Meta) as CSV\n",
    "    all_model_hyperparameters = []\n",
    "    for sampler, models in all_models.items():\n",
    "        for model_name, model in models.items():\n",
    "            # Some meta models (e.g., stacking) may not have get_params, handle gracefully\n",
    "            params = model.get_params() if hasattr(model, 'get_params') else None\n",
    "            all_model_hyperparameters.append({\n",
    "                'Sampler': sampler,\n",
    "                'Model Name': model_name,\n",
    "                'Best Hyperparameters': params\n",
    "            })\n",
    "    all_model_hyperparameters_df = pd.DataFrame(all_model_hyperparameters)\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs('../artifacts/ds2/models', exist_ok=True)\n",
    "    \n",
    "    all_model_hyperparameters_df.to_csv('../artifacts/ds2/models/all_model_hyperparameters.csv', index=False)\n",
    "\n",
    "    # Show All Model Hyperparameters for all samplers\n",
    "    display(all_model_hyperparameters_df)\n",
    "else:\n",
    "    print(\"Skipping model storage (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Logistic Regression model tuned with TPE to ../artifacts/ds2/models/tpe/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with TPE to ../artifacts/ds2/models/tpe/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with TPE to ../artifacts/ds2/models/tpe/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with TPE to ../artifacts/ds2/models/tpe/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with TPE to ../artifacts/ds2/models/tpe/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with TPE to ../artifacts/ds2/models/tpe/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with TPE to ../artifacts/ds2/models/tpe/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with TPE to ../artifacts/ds2/models/tpe/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with GP to ../artifacts/ds2/models/gp/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with GP to ../artifacts/ds2/models/gp/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with GP to ../artifacts/ds2/models/gp/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with GP to ../artifacts/ds2/models/gp/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with GP to ../artifacts/ds2/models/gp/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with GP to ../artifacts/ds2/models/gp/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with GP to ../artifacts/ds2/models/gp/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with GP to ../artifacts/ds2/models/gp/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with CMA-ES to ../artifacts/ds2/models/cmaes/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with CMA-ES to ../artifacts/ds2/models/cmaes/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with CMA-ES to ../artifacts/ds2/models/cmaes/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with CMA-ES to ../artifacts/ds2/models/cmaes/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with CMA-ES to ../artifacts/ds2/models/cmaes/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with CMA-ES to ../artifacts/ds2/models/cmaes/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with CMA-ES to ../artifacts/ds2/models/cmaes/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with CMA-ES to ../artifacts/ds2/models/cmaes/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with QMC to ../artifacts/ds2/models/qmc/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with QMC to ../artifacts/ds2/models/qmc/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with QMC to ../artifacts/ds2/models/qmc/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with QMC to ../artifacts/ds2/models/qmc/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with QMC to ../artifacts/ds2/models/qmc/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with QMC to ../artifacts/ds2/models/qmc/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with QMC to ../artifacts/ds2/models/qmc/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with QMC to ../artifacts/ds2/models/qmc/sel-nnml_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # Save Every Best Meta Model for each Tuning Method as .pkl\n",
    "    for sampler, models in all_models.items():\n",
    "        folder = sampler.lower().replace(\"-\", \"\")\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(f'../artifacts/ds2/models/{folder}', exist_ok=True)\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            filename = f'../artifacts/ds2/models/{folder}/{model_name.replace(\" \", \"_\").lower()}_best_model.pkl'\n",
    "            joblib.dump(model, filename)\n",
    "            print(f'Saved {model_name} model tuned with {sampler} to {filename}')\n",
    "else:\n",
    "    print(\"Skipping model saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sampler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Base Models Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Meta Model Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "61c80160-341a-4dc3-ad5d-d7b5047270ed",
       "rows": [
        [
         "0",
         "TPE",
         "49.62716460227966",
         "87.61603283882141",
         "137.24319744110107"
        ],
        [
         "1",
         "GP",
         "182.5392243862152",
         "85.93063640594482",
         "268.46986079216003"
        ],
        [
         "2",
         "CMA-ES",
         "46.424803495407104",
         "80.5283453464508",
         "126.95314884185791"
        ],
        [
         "3",
         "QMC",
         "40.27592945098877",
         "71.22925209999084",
         "111.50518155097961"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Base Models Training Time (seconds)</th>\n",
       "      <th>Meta Model Training Time (seconds)</th>\n",
       "      <th>Total Training Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPE</td>\n",
       "      <td>49.627165</td>\n",
       "      <td>87.616033</td>\n",
       "      <td>137.243197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>182.539224</td>\n",
       "      <td>85.930636</td>\n",
       "      <td>268.469861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>46.424803</td>\n",
       "      <td>80.528345</td>\n",
       "      <td>126.953149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QMC</td>\n",
       "      <td>40.275929</td>\n",
       "      <td>71.229252</td>\n",
       "      <td>111.505182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sampler  Base Models Training Time (seconds)  \\\n",
       "0     TPE                            49.627165   \n",
       "1      GP                           182.539224   \n",
       "2  CMA-ES                            46.424803   \n",
       "3     QMC                            40.275929   \n",
       "\n",
       "   Meta Model Training Time (seconds)  Total Training Time (seconds)  \n",
       "0                           87.616033                     137.243197  \n",
       "1                           85.930636                     268.469861  \n",
       "2                           80.528345                     126.953149  \n",
       "3                           71.229252                     111.505182  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # SAVE TRAIN TIME FOR EACH SAMPLER TYPE (BASE + META) IN A FILE\n",
    "    train_times = {\n",
    "        'Sampler': ['TPE', 'GP', 'CMA-ES', 'QMC'],\n",
    "        'Base Models Training Time (seconds)': [\n",
    "            tpe_base_models_training_time,\n",
    "            gp_base_models_training_time,\n",
    "            cmaes_base_models_training_time,\n",
    "            qmc_base_models_training_time\n",
    "        ],\n",
    "        'Meta Model Training Time (seconds)': [\n",
    "            tpe_meta_model_training_time,\n",
    "            gp_meta_model_training_time,\n",
    "            cmaes_meta_model_training_time,\n",
    "            qmc_meta_model_training_time\n",
    "        ],\n",
    "        'Total Training Time (seconds)': [\n",
    "            tpe_base_models_training_time + tpe_meta_model_training_time,\n",
    "            gp_base_models_training_time + gp_meta_model_training_time,\n",
    "            cmaes_base_models_training_time + cmaes_meta_model_training_time,\n",
    "            qmc_base_models_training_time + qmc_meta_model_training_time\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    train_times_df = pd.DataFrame(train_times)\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs('../artifacts/ds2/models', exist_ok=True)\n",
    "    \n",
    "    train_times_df.to_csv('../artifacts/ds2/models/training_times.csv', index=False)\n",
    "    display(train_times_df)\n",
    "else:\n",
    "    print(\"Skipping training times saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TPE SEL-NNML training history to ../artifacts/ds2/models/tpe/sel-nnml_training_history.csv\n",
      "Saved GP SEL-NNML training history to ../artifacts/ds2/models/gp/sel-nnml_training_history.csv\n",
      "Saved CMA-ES SEL-NNML training history to ../artifacts/ds2/models/cmaes/sel-nnml_training_history.csv\n",
      "Saved QMC SEL-NNML training history to ../artifacts/ds2/models/qmc/sel-nnml_training_history.csv\n",
      "\n",
      "Sample of TPE SEL-NNML Training History (first 10 iterations):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "iteration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ccb168cb-a01e-42f6-ae74-8541b25a959c",
       "rows": [
        [
         "0",
         "1",
         "0.7833333333333333"
        ],
        [
         "1",
         "2",
         "0.9166666666666666"
        ],
        [
         "2",
         "3",
         "0.8833333333333333"
        ],
        [
         "3",
         "4",
         "0.8833333333333333"
        ],
        [
         "4",
         "5",
         "0.8666666666666667"
        ],
        [
         "5",
         "6",
         "0.8833333333333333"
        ],
        [
         "6",
         "7",
         "0.8666666666666667"
        ],
        [
         "7",
         "8",
         "0.8666666666666667"
        ],
        [
         "8",
         "9",
         "0.0"
        ],
        [
         "9",
         "10",
         "0.8833333333333333"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration     score\n",
       "0          1  0.783333\n",
       "1          2  0.916667\n",
       "2          3  0.883333\n",
       "3          4  0.883333\n",
       "4          5  0.866667\n",
       "5          6  0.883333\n",
       "6          7  0.866667\n",
       "7          8  0.866667\n",
       "8          9  0.000000\n",
       "9         10  0.883333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # SAVE SEL-NNML TRAINING HISTORY (CONVERGENCE DATA) FOR EACH SAMPLER\n",
    "    # These will be used to create convergence plots showing how the model performance\n",
    "    # improved over the 100 optimization iterations\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    # Ensure directories exist for each sampler\n",
    "    samplers = ['tpe', 'gp', 'cmaes', 'qmc']\n",
    "    for sampler in samplers:\n",
    "        os.makedirs(f'../artifacts/ds2/models/{sampler}', exist_ok=True)\n",
    "    \n",
    "    # Save TPE SEL-NNML training history\n",
    "    tpe_meta_history.to_csv('../artifacts/ds2/models/tpe/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved TPE SEL-NNML training history to ../artifacts/ds2/models/tpe/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save GP SEL-NNML training history\n",
    "    gp_meta_history.to_csv('../artifacts/ds2/models/gp/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved GP SEL-NNML training history to ../artifacts/ds2/models/gp/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save CMA-ES SEL-NNML training history\n",
    "    cmaes_meta_history.to_csv('../artifacts/ds2/models/cmaes/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved CMA-ES SEL-NNML training history to ../artifacts/ds2/models/cmaes/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save QMC SEL-NNML training history\n",
    "    qmc_meta_history.to_csv('../artifacts/ds2/models/qmc/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved QMC SEL-NNML training history to ../artifacts/ds2/models/qmc/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Display a sample of one history to verify the data\n",
    "    print(\"\\nSample of TPE SEL-NNML Training History (first 10 iterations):\")\n",
    "    display(tpe_meta_history.head(10))\n",
    "else:\n",
    "    print(\"Skipping SEL-NNML training history saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP_TRAINING is False. Models should be trained in steps 4 and 5.\n"
     ]
    }
   ],
   "source": [
    "# Skip step 4 and load every best model for each tuning method if SKIP_TRAINING is True\n",
    "if SKIP_TRAINING:\n",
    "    print(\"Loading pre-existing models...\")\n",
    "    all_models = {sampler: {\n",
    "            'Logistic Regression': joblib.load(f'../artifacts/ds2/models/{sampler.lower().replace(\"-\", \"\")}/logistic_regression_best_model.pkl'),\n",
    "            'Decision Tree': joblib.load(f'../artifacts/ds2/models/{sampler.lower().replace(\"-\", \"\")}/decision_tree_best_model.pkl'),\n",
    "            'Random Forest': joblib.load(f'../artifacts/ds2/models/{sampler.lower().replace(\"-\", \"\")}/random_forest_best_model.pkl'),\n",
    "            'K-Nearest Neighbors': joblib.load(f'../artifacts/ds2/models/{sampler.lower().replace(\"-\", \"\")}/k-nearest_neighbors_best_model.pkl'),\n",
    "            'Support Vector Machine': joblib.load(f'../artifacts/ds2/models/{sampler.lower().replace(\"-\", \"\")}/support_vector_machine_best_model.pkl'),\n",
    "            'AdaBoost': joblib.load(f'../artifacts/ds2/models/{sampler.lower().replace(\"-\", \"\")}/adaboost_best_model.pkl'),\n",
    "            'Gradient Boosting': joblib.load(f'../artifacts/ds2/models/{sampler.lower().replace(\"-\", \"\")}/gradient_boosting_best_model.pkl'),\n",
    "            'SEL-NNML': joblib.load(f'../artifacts/ds2/models/{sampler.lower().replace(\"-\", \"\")}/sel-nnml_best_model.pkl')\n",
    "        } for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']}\n",
    "    print(\"All models loaded successfully!\")\n",
    "    \n",
    "    # Load training times\n",
    "    print(\"Loading training times...\")\n",
    "    train_times_df = pd.read_csv('../artifacts/ds2/models/training_times.csv')\n",
    "    \n",
    "    # Extract individual training times for each sampler\n",
    "    for idx, row in train_times_df.iterrows():\n",
    "        sampler = row['Sampler']\n",
    "        if sampler == 'TPE':\n",
    "            tpe_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            tpe_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'GP':\n",
    "            gp_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            gp_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'CMA-ES':\n",
    "            cmaes_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            cmaes_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'QMC':\n",
    "            qmc_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            qmc_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "    \n",
    "    print(\"Training times loaded successfully!\")\n",
    "    display(train_times_df)\n",
    "    \n",
    "    # Load SEL-NNML training histories for convergence plots\n",
    "    print(\"\\nLoading SEL-NNML training histories...\")\n",
    "    tpe_meta_history = pd.read_csv('../artifacts/ds2/models/tpe/sel-nnml_training_history.csv')\n",
    "    gp_meta_history = pd.read_csv('../artifacts/ds2/models/gp/sel-nnml_training_history.csv')\n",
    "    cmaes_meta_history = pd.read_csv('../artifacts/ds2/models/cmaes/sel-nnml_training_history.csv')\n",
    "    qmc_meta_history = pd.read_csv('../artifacts/ds2/models/qmc/sel-nnml_training_history.csv')\n",
    "    print(\"SEL-NNML training histories loaded successfully!\")\n",
    "else:\n",
    "    print(\"SKIP_TRAINING is False. Models should be trained in steps 4 and 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 Save Baseline Models**\n",
    "\n",
    "Save default base models and stacking models for later evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Logistic Regression default model to ../artifacts/ds2/models/baseline/logistic_regression_default_model.pkl\n",
      "Saved Decision Tree default model to ../artifacts/ds2/models/baseline/decision_tree_default_model.pkl\n",
      "Saved Random Forest default model to ../artifacts/ds2/models/baseline/random_forest_default_model.pkl\n",
      "Saved K-Nearest Neighbors default model to ../artifacts/ds2/models/baseline/k-nearest_neighbors_default_model.pkl\n",
      "Saved Support Vector Machine default model to ../artifacts/ds2/models/baseline/support_vector_machine_default_model.pkl\n",
      "Saved AdaBoost default model to ../artifacts/ds2/models/baseline/adaboost_default_model.pkl\n",
      "Saved Gradient Boosting default model to ../artifacts/ds2/models/baseline/gradient_boosting_default_model.pkl\n",
      "Saved Stacking + Linear Regression model to ../artifacts/ds2/models/baseline/stacking_lr_model.pkl\n",
      "Saved Stacking + Default MLP model to ../artifacts/ds2/models/baseline/stacking_mlp_default_model.pkl\n",
      "Saved baseline training times to ../artifacts/ds2/models/baseline/baseline_training_times.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "087e8cd7-451b-4c11-9fd1-804d3600999f",
       "rows": [
        [
         "0",
         "Default Base Models",
         "0.3286871910095215"
        ],
        [
         "1",
         "Stacking + Linear Regression",
         "5.249487638473511"
        ],
        [
         "2",
         "Stacking + Default MLP",
         "2.6517975330352783"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Training Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default Base Models</td>\n",
       "      <td>0.328687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stacking + Linear Regression</td>\n",
       "      <td>5.249488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking + Default MLP</td>\n",
       "      <td>2.651798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Type  Training Time (seconds)\n",
       "0           Default Base Models                 0.328687\n",
       "1  Stacking + Linear Regression                 5.249488\n",
       "2        Stacking + Default MLP                 2.651798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # Save default base models\n",
    "    os.makedirs('../artifacts/ds2/models/baseline', exist_ok=True)\n",
    "    \n",
    "    for model_name, model in default_base_models.items():\n",
    "        filename = f'../artifacts/ds2/models/baseline/{model_name.replace(\" \", \"_\").lower()}_default_model.pkl'\n",
    "        joblib.dump(model, filename)\n",
    "        print(f'Saved {model_name} default model to {filename}')\n",
    "    \n",
    "    # Save stacking models\n",
    "    joblib.dump(stacking_lr, '../artifacts/ds2/models/baseline/stacking_lr_model.pkl')\n",
    "    print(f'Saved Stacking + Linear Regression model to ../artifacts/ds2/models/baseline/stacking_lr_model.pkl')\n",
    "    \n",
    "    joblib.dump(stacking_mlp, '../artifacts/ds2/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    print(f'Saved Stacking + Default MLP model to ../artifacts/ds2/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    \n",
    "    # Save baseline training times\n",
    "    baseline_times = pd.DataFrame({\n",
    "        'Model Type': ['Default Base Models', 'Stacking + Linear Regression', 'Stacking + Default MLP'],\n",
    "        'Training Time (seconds)': [default_models_training_time, stack_lr_training_time, stack_mlp_training_time]\n",
    "    })\n",
    "    baseline_times.to_csv('../artifacts/ds2/models/baseline/baseline_training_times.csv', index=False)\n",
    "    print(f'Saved baseline training times to ../artifacts/ds2/models/baseline/baseline_training_times.csv')\n",
    "    \n",
    "    display(baseline_times)\n",
    "else:\n",
    "    print(\"Skipping baseline model saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP_TRAINING is False. Models should be trained in sections 3.1-3.3.\n"
     ]
    }
   ],
   "source": [
    "if SKIP_TRAINING:\n",
    "    print(\"Loading baseline models...\")\n",
    "    \n",
    "    # Load default base models\n",
    "    default_base_models = {\n",
    "        'Logistic Regression': joblib.load('../artifacts/ds2/models/baseline/logistic_regression_default_model.pkl'),\n",
    "        'Decision Tree': joblib.load('../artifacts/ds2/models/baseline/decision_tree_default_model.pkl'),\n",
    "        'Random Forest': joblib.load('../artifacts/ds2/models/baseline/random_forest_default_model.pkl'),\n",
    "        'K-Nearest Neighbors': joblib.load('../artifacts/ds2/models/baseline/k-nearest_neighbors_default_model.pkl'),\n",
    "        'Support Vector Machine': joblib.load('../artifacts/ds2/models/baseline/support_vector_machine_default_model.pkl'),\n",
    "        'AdaBoost': joblib.load('../artifacts/ds2/models/baseline/adaboost_default_model.pkl'),\n",
    "        'Gradient Boosting': joblib.load('../artifacts/ds2/models/baseline/gradient_boosting_default_model.pkl')\n",
    "    }\n",
    "    \n",
    "    # Load stacking models\n",
    "    stacking_lr = joblib.load('../artifacts/ds2/models/baseline/stacking_lr_model.pkl')\n",
    "    stacking_mlp = joblib.load('../artifacts/ds2/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    \n",
    "    # Load baseline training times\n",
    "    baseline_times = pd.read_csv('../artifacts/ds2/models/baseline/baseline_training_times.csv')\n",
    "    \n",
    "    # Extract training times\n",
    "    default_models_training_time = baseline_times[baseline_times['Model Type'] == 'Default Base Models']['Training Time (seconds)'].values[0]\n",
    "    stack_lr_training_time = baseline_times[baseline_times['Model Type'] == 'Stacking + Linear Regression']['Training Time (seconds)'].values[0]\n",
    "    stack_mlp_training_time = baseline_times[baseline_times['Model Type'] == 'Stacking + Default MLP']['Training Time (seconds)'].values[0]\n",
    "    \n",
    "    print(\"âœ“ All baseline models loaded successfully!\")\n",
    "    display(baseline_times)\n",
    "else:\n",
    "    print(\"SKIP_TRAINING is False. Models should be trained in sections 3.1-3.3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage contains model evaluation on the test set, with details as follows:\n",
    "- `plot_evaluation_metrics()`: Shows the confusion matrix graph & scores for accuracy, precision, recall, and F1-Score\n",
    "- `Model Performance Comparison Plot`: Displays accuracy, precision, recall, F1-Score, and ROC AUC scores\n",
    "- `overfitting_index_plot()`: Shows the percentage of the difference between model scores on test data versus training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Model Evaluation Dashboard\n",
    "def evaluation_metrics_plot(y_true, y_pred):\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "    }\n",
    "    metric_order = ['F1-Score', 'Recall', 'Precision', 'Accuracy']\n",
    "    values = [metrics[name] for name in metric_order]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    cm_pos = [0.08, 0.15, 0.53, 0.7]\n",
    "    metrics_pos = [0.75, 0.15, 0.21, 0.7]\n",
    "\n",
    "    # Confusion Matrix\n",
    "    ax_cm = fig.add_axes(cm_pos)\n",
    "    im = ax_cm.imshow(cm, cmap='Blues', interpolation='nearest', aspect='equal')\n",
    "    cbar_ax = fig.add_axes([cm_pos[0] + cm_pos[2] + 0.02, cm_pos[1], 0.02, cm_pos[3]])\n",
    "    fig.colorbar(im, cax=cbar_ax).ax.tick_params(labelsize=16)\n",
    "\n",
    "    cm_pct = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            count, pct = int(cm[i, j]), cm_pct[i, j]\n",
    "            color = 'white' if count > cm.max() / 2 else 'black'\n",
    "            ax_cm.text(j, i, f'{count}\\n({pct:.1f}%)', ha='center', va='center',\n",
    "                    color=color, fontsize=18, fontweight='bold', linespacing=1.1)\n",
    "\n",
    "    ax_cm.set_xticks([0, 1])\n",
    "    ax_cm.set_yticks([0, 1])\n",
    "    ax_cm.set_xticklabels(['No\\n(0)', 'Disease\\n(1)'], fontsize=16)\n",
    "    ax_cm.set_yticklabels(['No (0)', 'Disease (1)'], fontsize=16, rotation=90, va='center')\n",
    "    ax_cm.set_xlabel('Predicted', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_ylabel('Actual', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_title('Confusion Matrix', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_cm.set_ylim(1.5, -0.5)\n",
    "\n",
    "    # Metrics Bar\n",
    "    ax_metrics = fig.add_axes(metrics_pos)\n",
    "    y_positions = np.arange(len(metric_order)) * 2\n",
    "    bars = ax_metrics.barh(y_positions, values, height=0.8, color='#31688E', alpha=0.8)\n",
    "\n",
    "    for bar, value in zip(bars, values):\n",
    "        color = 'white' if value > 0.5 else 'black'\n",
    "        x_pos = value - 0.02 if value > 0.5 else value + 0.02\n",
    "        ha = 'right' if value > 0.5 else 'left'\n",
    "        ax_metrics.text(x_pos, bar.get_y() + bar.get_height()/2, f'{value:.3f}',\n",
    "                        ha=ha, va='center', fontsize=18, fontweight='bold', color=color)\n",
    "\n",
    "    ax_metrics.set_xlim(-0.05, 1.05)\n",
    "    ax_metrics.set_ylim(-0.8, len(metric_order) * 2 - 0.2)\n",
    "    ax_metrics.set_xticks([0, 0.5, 1.0])\n",
    "    ax_metrics.set_xticklabels(['0.0', '0.5', '1.0'], fontsize=16)\n",
    "    ax_metrics.set_yticks(y_positions)\n",
    "    ax_metrics.set_yticklabels(metric_order, fontsize=16, rotation=90, ha='left', va='center')\n",
    "    ax_metrics.tick_params(axis='y', pad=15)\n",
    "    ax_metrics.tick_params(axis='x', pad=8)\n",
    "    ax_metrics.set_xlabel('Score', fontsize=16, fontweight='bold')\n",
    "    ax_metrics.set_title('Performance Metrics', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_metrics.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    for spine in ['top', 'right', 'left']:\n",
    "        ax_metrics.spines[spine].set_visible(False)\n",
    "    ax_metrics.spines['bottom'].set_alpha(0.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Model Comparison Dashboard (for comparing all models)\n",
    "def model_comparison_plot(models, x_test, y_test):\n",
    "    metrics = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'F1-Score': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "    \n",
    "    # Map full names to short names\n",
    "    short_names = {\n",
    "        'Logistic Regression': 'LR',\n",
    "        'Decision Tree': 'DT',\n",
    "        'Random Forest': 'RF',\n",
    "        'K-Nearest Neighbors': 'KNN',\n",
    "        'Support Vector Machine': 'SVM',\n",
    "        'AdaBoost': 'AdaBoost',\n",
    "        'Gradient Boosting': 'Gradient Boosting',\n",
    "        'SEL-NNML': 'SEL-NNML'\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics for each model\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(x_test)\n",
    "        metrics['Model'].append(short_names[model_name])\n",
    "        metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        metrics['F1-Score'].append(f1_score(y_test, y_pred))\n",
    "        metrics['Precision'].append(precision_score(y_test, y_pred))\n",
    "        metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "        \n",
    "        # Calculate AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        metrics['AUC'].append(roc_auc)\n",
    "    \n",
    "    # Convert metrics to DataFrame for sorting\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "    fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold') \n",
    "    \n",
    "    # Helper function to plot sorted bar charts\n",
    "    def plot_sorted_bar_chart(ax, metric_name):\n",
    "        sorted_df = metrics_df.sort_values(by=metric_name, ascending=False)\n",
    "        colors = ['tab:orange' if model == 'SEL-NNML' else 'tab:blue' for model in sorted_df['Model']]\n",
    "        ax.bar(sorted_df['Model'], sorted_df[metric_name], color=colors)\n",
    "        ax.set_title(metric_name)\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_xticks(range(len(sorted_df['Model'])))\n",
    "        ax.set_xticklabels(sorted_df['Model'], rotation=30, ha='center')\n",
    "        for i, v in enumerate(sorted_df[metric_name]):\n",
    "            ax.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "    # Plot each metric\n",
    "    plot_sorted_bar_chart(axes[0, 0], 'Accuracy')\n",
    "    plot_sorted_bar_chart(axes[0, 1], 'F1-Score')\n",
    "    plot_sorted_bar_chart(axes[1, 0], 'Precision')\n",
    "    plot_sorted_bar_chart(axes[1, 1], 'Recall')\n",
    "    \n",
    "    # ROC Curve\n",
    "    ax_roc = axes[2, 0]\n",
    "    for model_name, model in models.items():\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax_roc.plot(fpr, tpr, lw=2, label=f'{short_names[model_name]} (AUC = {roc_auc:.3f})')\n",
    "    ax_roc.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_title('Receiver Operating Characteristic')\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Bar chart for AUC\n",
    "    plot_sorted_bar_chart(axes[2, 1], 'AUC')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfitting_index_plot(all_models, x_train, y_train, x_test, y_test):\n",
    "    metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "    overfitting_indices = {metric: [] for metric in metrics}\n",
    "\n",
    "    for _, model in all_models.items():\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "        overfitting_indices['Accuracy'].append(abs(accuracy_score(y_train, y_train_pred) - accuracy_score(y_test, y_test_pred)) / accuracy_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['F1-Score'].append(abs(f1_score(y_train, y_train_pred) - f1_score(y_test, y_test_pred)) / f1_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Precision'].append(abs(precision_score(y_train, y_train_pred) - precision_score(y_test, y_test_pred)) / precision_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Recall'].append(abs(recall_score(y_train, y_train_pred) - recall_score(y_test, y_test_pred)) / recall_score(y_train, y_train_pred) * 100)\n",
    "\n",
    "    overfitting_df = pd.DataFrame(overfitting_indices, index=all_models.keys())\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Overfitting Index for All Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "    def get_bar_colors(models, highlight_model='SEL-NNML', default_color='tab:blue', highlight_color='tab:orange'):\n",
    "        return [highlight_color if model == highlight_model else default_color for model in models]\n",
    "\n",
    "    # Accuracy\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Accuracy', ascending=False)\n",
    "    axes[0, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Accuracy'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 0].set_title('Accuracy Overfitting Index')\n",
    "    axes[0, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 0].set_ylim([0, 100])\n",
    "    axes[0, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Accuracy']):\n",
    "        axes[0, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # F1-Score\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='F1-Score', ascending=False)\n",
    "    axes[0, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['F1-Score'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 1].set_title('F1-Score Overfitting Index')\n",
    "    axes[0, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 1].set_ylim([0, 100])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['F1-Score']):\n",
    "        axes[0, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Precision\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Precision', ascending=False)\n",
    "    axes[1, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Precision'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 0].set_title('Precision Overfitting Index')\n",
    "    axes[1, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 0].set_ylim([0, 100])\n",
    "    axes[1, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Precision']):\n",
    "        axes[1, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Recall\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Recall', ascending=False)\n",
    "    axes[1, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['Recall'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 1].set_title('Recall Overfitting Index')\n",
    "    axes[1, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 1].set_ylim([0, 100])\n",
    "    axes[1, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Recall']):\n",
    "        axes[1, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 SEL-NNML Model Evaluation**\n",
    "\n",
    "This section evaluates the SEL-NNML model from the selected sampler. Change `SELECTED_SAMPLER` in the cell below to evaluate a different sampler's SEL-NNML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected sampler: TPE\n",
      "Models available: ['Logistic Regression', 'Decision Tree', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine', 'AdaBoost', 'Gradient Boosting', 'SEL-NNML']\n"
     ]
    }
   ],
   "source": [
    "# Select which sampler's models to evaluate\n",
    "# Options: 'TPE', 'GP', 'CMA-ES', 'QMC'\n",
    "SELECTED_SAMPLER = 'TPE'\n",
    "\n",
    "# Extract models and training times for the selected sampler\n",
    "selected_models = all_models[SELECTED_SAMPLER]\n",
    "sel_nnml = selected_models['SEL-NNML']\n",
    "\n",
    "# Extract training times for the selected sampler\n",
    "if SELECTED_SAMPLER == 'TPE':\n",
    "    base_models_training_time = tpe_base_models_training_time\n",
    "    meta_model_training_time = tpe_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'GP':\n",
    "    base_models_training_time = gp_base_models_training_time\n",
    "    meta_model_training_time = gp_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'CMA-ES':\n",
    "    base_models_training_time = cmaes_base_models_training_time\n",
    "    meta_model_training_time = cmaes_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'QMC':\n",
    "    base_models_training_time = qmc_base_models_training_time\n",
    "    meta_model_training_time = qmc_meta_model_training_time\n",
    "\n",
    "print(f'Selected sampler: {SELECTED_SAMPLER}')\n",
    "print(f'Models available: {list(selected_models.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show SEL-NNML Evaluation Metrics\n",
    "y_pred_stack = sel_nnml.predict(X_test)\n",
    "evaluation_metrics_plot(y_test, y_pred_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: [0.8125     0.8125     0.91489362 0.72340426 0.85106383]\n",
      "Mean: 0.8229\n",
      "Standard Deviation: 0.0622\n"
     ]
    }
   ],
   "source": [
    "# Show SEL-NNM: all fold scores with mean and std \n",
    "sel_nnml_cv_scores = cross_val_score(sel_nnml, X_train, y_train, cv=CV_FOLDS, scoring='accuracy', n_jobs=N_JOBS)\n",
    "print(f'SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: {sel_nnml_cv_scores}')\n",
    "print(f'Mean: {sel_nnml_cv_scores.mean():.4f}')\n",
    "print(f'Standard Deviation: {sel_nnml_cv_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Models Tuning & Training Time: 49.63 seconds\n",
      "Meta Model Tuning & Training Time: 87.62 seconds\n",
      "Total SEL-NNML Tuning & Training Time: 137.24 seconds\n"
     ]
    }
   ],
   "source": [
    "# Show SELL-NNML Training Time\n",
    "Total_training_time = base_models_training_time + meta_model_training_time\n",
    "print(f'Base Models Tuning & Training Time: {base_models_training_time:.2f} seconds')\n",
    "print(f'Meta Model Tuning & Training Time: {meta_model_training_time:.2f} seconds')\n",
    "print(f'Total SEL-NNML Tuning & Training Time: {Total_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Multiple Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation below compares all models (base models + SEL-NNML) for the selected sampler. To compare models across different samplers, change the `SELECTED_SAMPLER` variable in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the selected sampler's models for comparison\n",
    "model_comparison_plot(selected_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABi8AAASdCAYAAAA438+CAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdCbyU4///8c/RHu2LVipbmyVFFC1UKCmyb9mjLJUtQgtJJKUIIUsoa7ZQkiWhRbZKhTaU0nJOlNb5P97X73/P9545c7aac+Y+M6/n4zF1ZuaeOffcc8+c63N9rs91pYVCoZABAAAAAAAAAAAExD6J3gEAAAAAAAAAAAA/khcAAAAAAAAAACBQSF4AAAAAAAAAAIBAIXkBAAAAAAAAAAACheQFAAAAAAAAAAAIFJIXAAAAAAAAAAAgUEheAAAAAAAAAACAQCF5AQAAAAAAAAAAAoXkBQAAAAAAAAAACBSSFwAAANgjoVDInn76aTv++OOtbNmylpaWFr5MnjzZbeO/rU6dOvl+pJcvXx7xO9u0aZPvvzOZ6Hj5j5+OZ2Hwzz//2F133WUNGza0UqVKRbyGTZs2WbLRZ8n/Gv0+/fTTiPsuu+yyhO1nkPFdAQAAEHxFE70DAAAAyWju3Ln2wgsv2Oeff26rVq2yzZs3W/ny5V2nY9u2be2qq66yQw45xAqz/v3729ChQ/f48epUHjlyZPi6jk1WHa3qkNXF07VrVzvqqKMs2egYrFixInx9xowZJGBykUQ79dRT7csvv7TCZt26dVajRg3buXNnxO3Tpk2zdu3aJSyB9dlnn0Xcdswxx9js2bNjbv/ee+9Z586dM90ez3M3VT7/AAAAiETyAgAAIM4jwK+++mqbOHFizI5KXebMmWMPP/yw3XDDDfbQQw9Z0aKFr0n277//2ogRIyJuK1GihEvQSMmSJd3/+++/f/j+KlWqZEpeDBo0KHy9devW2SYv/Nuqkz9W52WRIkUifmfFihX34NWhMJk+fXqmxEWZMmWsdOnS7ud99glusfmkSZMyJS7kpZdeSljyIhZ9Z82fP9+aNGmS6b4nn3wy339/bj//ecF3BQAAQPAVvkgZAAAgoLZu3epGGs+bNy/idnWealql9PR0N0pcdu3a5aoOfvvtNzfFUvTUL0G3cOFC27ZtW/j60Ucf7TqQvaSFZ82aNQW6X7Vr1y7w34nEUqe6X8+ePe2xxx6zwuDll1+Oefubb75pY8eOzfR5SqSnnnrK7ZOfqso++OADK4z4rgAAAAi+4A5DAgAAKGR69+4dkbhQQmLw4MG2fv1627hxo23YsMFd9ycq3nnnHVd9Udhs2bIl4vrhhx8eqI5WpI7oc1FTHBUGy5Yts6+++irmfRkZGW46piBRNYgqrvzGjRvnErEAAABAfiB5AQAAEKfFX5999tmI2wYMGGB33313eCol/a/r99xzT8R2w4YNc9NNyTXXXBOx2O4nn3wSs2NTiQJvm/r162fa5rvvvnPPpfv2228/N4XOoYcear169XLVHrFoyib/79ZULd9++62deeaZbsonVZA899xzMRfCfv7552MuIJzVgt26Xrdu3Yjn0Dz70dt7v88/ZYxcfvnlEdsOHDgwVwt2azv//Xr+1atX23XXXedGYmvqK/3e22+/PVOnuEfT/AwfPtwtDq33oXr16u7YaRS6t7/R+5WfCzV/9NFH1r59e3d+6X1u3ry5vfXWW9l2ml9yySVWtWpVt/2RRx5pjz/+eLgqKCd6/RMmTLDTTz/dvfbixYtbhQoV7IQTTrBHH300oiJH/v77b7edt89aUHvJkiUR2/Tr1y/idfXt2zfH/fCOdfQx9p8b0e+/Ot9V8aR1Z3ROFytWzE0tdtxxx7nEovY1t8f9tddec6+5XLlye7S4eXTVRYcOHbK9P1H0fonW7XnllVcizoNnnnkmfN2bpisnWgdI51+9evXcY/T9pOSnPnN//fVXxLbx+Pzv2LHDrc3TqFEj91q876HcLtitpPMDDzzgprXTOaPzXf+r2uzWW291nye/H374wa688ko77LDDbN9993Xbayq7I444wn1PqIIlOgkEAACALIQAAACw14YNG6ae3/ClTJkyoS1btsTcVrfrfv/2r732mrvviy++iLj9mmuuyfT4F154IWKbIUOGRNx/9913h9LS0iK28V9KlCgRmjhxYqbn7d69e8R2t912W6hYsWIRt40fPz7L5/VfPP7bDjzwwJi3Z3XR9rn9fQMGDHDPu2zZsojbW7duHfEatZ3//l69eoUqVqwY8zk7dOgQ2r17d8Tjd+zYEerUqVPM7fU8t9xyS8z9yi29Zv/jZ8yYke39eq+zOiYTJkzI9Pzz588PlS9fPub255xzTujEE0+MuE3H0+/PP/8MNW/ePNv34vDDDw+tWrUq4nHvvfdexDatWrUKH9t58+aFihYtGr6vYcOGoa1bt+Z4rHJzbvjf/++//z5Up06dbLevVKlSaPr06Tm+L/3798/02OhjlZNGjRpFPH7BggXu9/s/pxs3boz52Oj98dM5479Pn+u80DGLfrz3c7NmzcLbvfnmm+Hb69Wr597T7M5dfXauuOKKbI+/zk3/4/b283/88ceHTjrppEzfK7n5rpCPPvooVLly5Wx/t/bRv33x4sVz3N8ff/wxT+8JAABAqqLyAgAAIA5mzpwZcV2jeL0Ry9F0u0bxxnq8RnIfdNBBEXPfRy/o++qrr4Z/1ojhiy++OHxdC4Hfe++9EaPoNfLXP6WTRsbrMVlNWeN58MEH3ahlLSiu0eWi6gKNItZIez89v273LjnRNpUrV464TaPg/c+h0c06VvpZI5j9tIaIf1uN3t4TWhtBI6v1GvX7/aZOnWoffvhhpiqZ999/P9PCvzrGeh5VZBQkvdcS61y77bbbIqb02b59u5133nluoXQ/b8S8KgmiF7720+NVbfHNN99kWhzbX23z448/2hlnnOG293Tq1MlVAvlH32sEus7tK664InyO6z1QVUdupiDLzbnhLdi+bt06O+200zJVR0RXC2iKt65du2aqDIk2ZMgQ97/2M/r354YqoxYsWBC+3rhxY1fJ07lz54jP6RtvvGGJpnPGqx6bO3dueI0R/0LdV199dY7r9vTp0ydTdZreQ//nTudmly5d7Ndffw3fvzeff33HedVrekz0ZzynRcq1L9HVOP7vw2h33nlnxHmvbXUOBnnReAAAgCCjFQUAABAHv//+e8T1Qw45JNvto+/3P96fjFDHmX/qKC36rU51f5LkgAMOCHe8+qfQUcfqpEmT3ELimqZk/Pjx4Q5GdRbfcsstOb4ubaP1OtSp+Oeff7rpXrQgtpIq0R2cut275ETbqHPQr0WLFhHPofu9543e11GjRkVsm5vXkhVNV6PjqtepTnc//2LEOo7RyQl12urYaEqdRKxdoiTSxx9/7N5fdSpXqlQpfJ/er++//z58XckJf6e8OnyViNGUZZqu56STTrLdu3dn+bs0hY+mEfMce+yxtnjxYjeNmc49TS/m0b5oKjG/ESNGRCTmlFzROjH+fdT526RJk1y99tycG955qvdGx8Nz8MEHu9+r46aEhqba8ui91PRu2dH0Yi+++KLbVsdPUwVFJ+OyEz0lVLdu3dz/Z511VrbbJYISCPrce5S00FRJ3veQEgKaxik7ixYtclOTeXSeTp8+3R1/Xe67777wfTqfvKn14vH51zRRSmLoM67PsL4Tc0NTl/3333/h6wceeKD7PtD+6jOv72wlD5UU8Sfu/N/j+p36bOh5lJB5+umnXUJEyU4AAADkjOQFAABAHKgT0y+n+d+jRxKrk8tz6aWXZllpMXny5IiRvf5tvY5oz0033WTnnnuuG/Wri+Zb19oInlmzZtnKlSuz3Ed1TqvT1xvVrHUL/OtWJIOjjjrKzWev90vvSXQnqH99EFXH+KsWqlWrZmPGjHHHR52RemyrVq0KdP+1rsrJJ5/sklJ6LeoYzWr/oytGtP5Jx44d3WO1/oXWL1AVSVYmTpwYcV3JCa2j4iVRVMXi518fQXR8X3jhhfDvUCe1/zFKXimRlB+UuPHTuhdag8DrlFanst+7776bae0OP3221DmtkfWiNRtyW/2jqqjoY+klLfT59D+P1p3xJ10SpUePHhEJFSWivOouVarkVG2l4+9PjClZoWSZzj0lP/r37x8+l0RJp+yOf14oaaI1TUTnnj9RlRVVmPmr6fT9qSqYU089NZx4qFmzpt11110RCSf/e6ff5b1mvUat8aG1MPQd7n+tAAAAyBrJCwAAgDjQ1Dl+WS327IlesNU/DYk6uVq2bBm+rsWXNX1TdCJDHe5nn312+LpGf0dPceRfkFYXf9WGNw1MVvyjrZNVdKWFOvGzep8WLlwYcZ+m/ooeQd2uXTsL6v5r9LufOo/9lJiKXkTdL/r8atCgQcS5VaNGjRzPLSUoVHERTZ2+/sRGPCmhFz1dlBI+fpq2yd8BrxH6v/zyS758NjRlljrH/VUgXiJF1VKa3sqjzu/oREciaLFr7ztJiVol7WIlNnJ77lx33XWZvpv8VUGqVPBPq7WnVA3jP5655a8G8l5/06ZNc3ycf9ovJff0va5qI023pimlVG2SXXUTAAAAIpG8AAAAiINatWpFXF+6dGm220ffr1G8fv6KCq2loKmBNOpf/3s04tc/0tdfvZFb0fO5+yVblUVu3rfoZIR/7ZDo6proREFWtwV1/2NNc5Td1Ed5Pb/0+/xVQtmtj6CKFf+UUvEUvd9KNMZaU0NrrGT3uHh9NqKngoqeKso//Vas7RMlVpJCiZfoJFgs8f5uyi1V1eyJ6P2tXbt2rh6nih4lKjxKVKj6SVVPQ4cOdclNJaqik2kAAACI7f/qnAEAALBXNCpZU834p3vR6O1YCynr9s8++yziNi3U7afpnm688cbw1CmquNDc7llNGSXRi8hqkV3NzZ+d7Baw3dNFsAuT6Nef3aLD/rntRXPZR9PC0EHd/+jqoFidw9l1GOv88l6zN9VUTrS2ij+homSKOsH9SRWZMmWKmyoouiM/HqI/F0qqaGR/dAIj+r3LalHmvflsqILq9ddfj7jtwQcfdJeszJs3z60tcthhh1kinXPOOW6NEiVTPVqEPaeFumMdS6154U25lZV4LHK9p++Tt0C5x18pk9Pj9HdAyelp06bZTz/95Cp4tH6PN+WcKkp0HDV9FAAAALJH5QUAAEAcKNngn/JGHaRZdUhqOif/KHitF6C51KM7wfxTkKija8KECRGVGtFT33hTz3iuv/76iEVtoy+aSz+nhXbzU3Tn5K5du+KybX5p2LBhxHXNiR+9H+qwDCpN8+TnXwheNBpcCzFnxX9+Kfmg15/T+RW99oumG/IfI//7qqSGFg6PN3VgR1dKaPoeP3Uy+3+3ko6qKog3Lfjs7/zPrSBUXyjZ40+YKimldXRyI/q7Sd+BOZ07/inYCvrzf+SRR0ZcV8LBv1h9Tg455BDr2bOnW29DU/Xp9Wg6QM+MGTPiur8AAADJiuQFAABAHGitgOhEwODBg93CtN4UJPr/3nvvdbf7aZHi6FHx4u8o1Khdf2fzRRddlKlDr1OnThELgWux7aeeeipi3YONGze6qaf69Oljxx9/vCVS9Gjsn3/+2dauXZurbdVxXtBzx6u6RokmjxY71yLdWt9EFTHDhw936xkElX86G9Fi2ap4UCJCx/2qq67KtlNYCbrokfhff/11uIpC/yv5obn+tXC4psnxU/WAf0FuVRL4E3Kq+tCCxvnBvzaM6Pz31mFYsWKFe+3RxyqnqqU9EZ2EUJJSa21EX6KnsApC8kKuvfZalzTVRed+9H5md/z931e33nqrq0DxV5LpHFTVgqo5oitwCvrzr+nY/NVw+l16DUpEeOsPKdmlz7wqhjwXXHCBS8zMnz8/YsFxfbfpu9fjPQcAAACyR/ICAAAgTkaNGmVHHXVURIfX3XffbRUrVgxf7rnnnogpc5RwUEdeLFpoNqvOwegpo7ypWAYOHBi+rs4zjWbXyHP9biVI9H/79u3d3Oz5Mco9L9QhecABB0R0XmvRZ01HVK1aNRsyZEiWI7efe+4597q0nS7ZLa4cLxqNf/PNN0fcpuOo6aR0bPU+5mYKnURR5+uhhx4asZC1zj8dR3WYR1cjRLviiiusSZMm4evfffedS4BpBL7WytDIfI0u12j8d955J6KDVtNH6ZzVlGmijuxnnnnGdfbq4tHaAOPGjYvzKze3SHj16tXD1zWtj0bXe1UZ33zzTfg+3aYkY7zpePunlpPZs2fHrDxYvXp1xPoj3tRDiaaEk5Kfuvg/n7mpWtIi3R515Cv5pXNG31tKuuoc1AL0ev+9KZYS+fkfMWJExNRiSsydcsoprppISUz9Xn3mMzIywtssWrTI+vXrZ0cffbTbTt+3+n7QdX/yonnz5nHfXwAAgGRE8gIAACBO1FmlkffRo7yVxFDHlX+ksDpvNa3TW2+9leXc7poT3t+x61FHWKNGjWI+RqOhlTCJfk79fnWe+sWq9ihovXr1iriukf9ae0CJFf/UWlrQuXHjxhHbqiNc2+mizvGCoMqBjh07ZtpnjSBXoslfWRCvefvjRUmGiRMnZprPX5UjoqRWdtU4erySC9Hb6NhrLYzoxbn96w2oo1sd9Z4bbrjBVbLI6NGjXce1p2/fvm6R43jSe6Mpm6IXcPZXJYk60t9+++18WV9Cn3XvWIsSnZpeKBZNQde1a9eI21566SUrzJToi65wUSJX02j5j0us76ZEfP6POeYYN12fzgk//a7o5Eos3ve+/3tMlPh45JFH4r6/AAAAySg40RQAAEASUKfba6+95jpq1TF/+OGHu84qJSI0krpZs2YuwbBw4ULXaZvdgtlZVVjEus1P01J9//337verw0/7pM5QdVor8aFqDHXKaSHgRNPI5UcffdR15MZa3Nyj/ddaCZpWSFO65LTYb37R71Xntqbkql+/vptaSCP6VZWgSgT/tF3in2YqCFQ5obn7Ne2YOvS1/xoV/8ADD7gppPyLa8ei1/rFF1+4JMiZZ57p3gs9hx6nqhlNJ6TqH51/Os9l7ty5bvo0j6oz7r///vB1dQ6PHTs2fF1JNp3j8Z4WSJUWWttCHcetW7cOLxqtCqBjjz3W7bem9znppJMsP0RP/aTKg+xE3z9p0qSErPUSLzrWqqqYNWuW+7yoCkifF92u90LVCDfddJObmkmfsSB8/lVpsWTJEjcF2oknnhg+Z/S/PkuqxNK55Hn22Wfdua01jJSY0neu9t2rvlByU+egv0IPAAAAWUsL+ectAAAAALBXnZ3qfPWow9W/8DAAAAAAIHeovAAAAADyoHv37m70tJ9GxD/88MMRiQut3eFf9BcAAAAAkHtUXgAAAAB5aUD//0W5Nf2RpobRfP2LFy+2tWvXRmynKWQuv/xyji0AAAAA7AGSFwAAAMAeJC+yovUftIZEnz59OK4AAAAAsIcSs9IhAAAAUEg9+eST9vHHH9v8+fNt3bp19u+//7oFeVWF0aZNG7vmmmtcVQYAAAAAYM9ReQEAAAAAAAAAAAKFBbsBAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AJBSHn30UUtLS7PGjRsnelcKpVWrVtn1119vBx10kJUsWdIqVKhgbdq0sZdeeslCoVBC923+/PnWunVrK1eunHuPR44caZ9++qn7Wf97pkyZYgMHDoz5HPfff79Nnjw50+2xnqegeL/79ddfj+vz6jmzOg4AAADI2XPPPefaVLEut9xyS3i79957zy699FI7/PDDrVixYu7+PWmH9+zZ0w499FArVaqUVaxY0T3f1Vdf7e4rjBYtWmSXXXaZHXDAAVa8eHGrXLmydezY0T744INE75pNnz7dmjVrZvvuu697vxQjeO/38uXLw9u9/PLLLu6ItmXLFtfWjhU/xHqeguL97rlz58btOfU69Jx6bgCIt6Jxf0YACLBnn33W/b9gwQL75ptvrHnz5onepULjyy+/tNNPP932228/u/XWW+2II46w9PR0e/XVV+3iiy+2d9991zXe99knMXnxK664wv7991+bOHGiS6rUqVPHSpcubV999ZU1bNgwInnx2GOPxey4V/Li7LPPtq5du0bcfvTRR2d6HgAAAEDGjx9v9evXjzgYNWrUCP/81ltv2ddff21NmjSxEiVK2Lx58/J04H7//XfXHi1fvrzdfPPNdthhh7l2+MKFC11b/LfffrPatWsXqjfjzTfftAsvvNDq1atnd999t3tNf/31lzuWSmAo3njwwQcTsm8alHXuuee6RNE777zjEhjav507d7qYoHr16uFtFf/89NNP1rt370zJi0GDBrmfNdjLr1OnTpmeBwAQG8kLAClDo0u+//5711h8//337Zlnngls8kKNXXW8B8WmTZvsrLPOclUNSvrsv//+4fu6dOniEhn9+vWzo446yv1fUHbt2uWCCAWBCho08uy0006L2Oa4447b699TtmzZuDwPAAAAko+qujVKPyvjxo0LD/BRFXNekxd6/N9//22zZ8+2unXrhm/XgJs777zTdu/ebQVl69atrgJ7T6pHPL/++qtdcsklrnJElQlKDnjOOeccu+666+yhhx5yCZvzzz/fCsqOHTvc61ISZcOGDXbmmWfaySefHLFNlSpV9vr36Dni8TwAkAqYNgpAylCyQh544AFr0aKFG6GvJEG0P/74w6655ho3eknlyxo1pdH4asT6O/M16kkjhdRxXrVqVTdC6Oeff852mqFYJbUqlVY1w48//mgdOnSwMmXKhBvJ06ZNc8mBWrVquSDh4IMPth49erjgJZp+9wUXXOASC9onlV+rPH3btm3u9xYtWtSGDh2a6XGff/6526fXXnsty2P39NNP29q1a92x8ycuPLfddpsbbaYgQ43+devWuWOnUVSx9lO/T1N4edasWeNel16nHqegTCOVlJiIPnYagXXfffe5bfQ6NTpLt2vbsWPHhkv1Y70POtaquhB/Wb/33KrceP7558O3e6OkYr2f3vv2yy+/uPdeP+uc0XmhYx49Wk7nkN5bjZi76KKLbM6cOXtcXq2qET1WFUR6z5VU0vui6hONwvPLyMhwSZ1KlSq5fTz11FNtyZIlMZ936dKlbgSczmcd2wYNGoSPl/z3339uxKDOQ//v0ftXrVo1d7yUUAIAAMD/7G1l8vr1691zqI2Wm+fXYKPOnTu79p9iCE35Gl0ZMHPmTBdzqH2qQVOKjzTAK9YUQ1OnTnXtTHW4a1uvrTtp0iQ7/vjjXfJB7cxTTjnFTeWak0ceecTFYaNHj45IXHgefvhh12YeMmSIu64BaNoPL57z0xRTuk8VErlt0/rb9y+++KJrv9esWdNtq4pyxSRy++23u21U0R1ruie1fXXMVqxYkSm28JITimm82xU/xHoe77mUBFOMcOKJJ7rjrFhT8Vd0ckoxgOJGbaPf06tXL7cfezrNbV7imj///NNVpei8UQxy3nnnuVggq8GDZ5xxhpviTOeh4ghVCnkU0+r36NxTDOlRRZHOCyW4AIDkBYCUoBFCr7zyih1zzDGuUajG9+bNmzN12CtxoW1U2t23b1/XGNYcpmqYbdy40W2jx51wwgn25JNP2uWXX+6mS3riiSdcWfHq1av3aP+2b9/uGnYnnXSSvf322+ESY41KUkCgTnkFDffcc48LRvT7/Q08Nei13ypHHzx4sNtvJSrU2NRzq8Gt59d+RncujxkzxiVoNLIoK0qiFClSxAVBsaihrOfXCCWNJFMjWlNMKREQ3dhWskEJCnXgixq7xx57rH300Ufu9Wnfr7zySrf/6nSPpqTHJ598YsOHD3fbNm3a1JVdixIE+tm7Hk3JFG0j3nZeybb+1/zBarB7tz/++OOWHb0Het0K/PS+6bxSMDZs2LDwNkqItG3b1mbMmOFuV4NdiQY19PdWt27d3Hn3xhtvuIoXla336dMnouRdI/K8oEzntSpIoqtTvCBB55AqWBQwam5mVSndeOON4fNRQYf2X4ksvVbR+6v3Ur9LnzGdJwAAAKnEqwb2X+JJ8YDaXKqEVptZg1OyovvV+b1y5UobMWKEay/fddddEQOxPvvsMxd3aDCKEgJqw6kzWm19JSSiqd2ntTrUptQ6bPpZ061qEI2mVVX7UPcpTtLvVrsyO4ot1B7OqrJZnfLqnFe7VLHCkUce6Tq+FUdEUyLAG0iW2zat3x133OGOleIkxXUaKKUpreSGG25wMYHa0LEoVmjZsqUbxBMdW3z44YduG8U13u2xBnb56bWqXa0EipIxarNr/yZMmBDeRvGm1vlbvHixixFfeOEFd9xV0bM3chPXKKZu166di0sVqymW1muPFdco9tGx0aA/HVs9p6r0ta03eEtrnGhAoRI2ShSJklqqvtFAPD0OANTZAABJ74UXXtBq0qEnnnjCXd+8eXNov/32C5144okR211xxRWhYsWKhRYuXJjlcw0ePNg917Rp07LcZsaMGW4b/e+3bNkyd/v48ePDt3Xv3t3d9uyzz2b7Gnbv3h3asWNHaMWKFW77t99+O3zfSSedFCpfvnxo7dq1Oe7TW2+9Fb7tjz/+CBUtWjQ0aNCgbH93/fr1Q9WqVct2m7Fjx7rnnzRpkrv+zjvvuOtTp04Nb7Nz585QjRo1Qt26dQvf1qNHD/de6HX5DR8+3D1+wYIFEcfuoIMOCm3fvj3T79d9vXr1yvF90Db/16+f2b777uvej2ixnsd731599dWIbTt27Bg67LDDwtcfe+wxt90HH3wQsZ1ed/S5EIv3u1977bXwbQMGDHC3PfjggxHb9uzZM1SyZEl3roh+p7YbNWpUxHZDhgxxt+t5PKecckqoVq1aofT09Ihtr7/+evecGzZsCN+m91iPHzlyZOiee+4J7bPPPhHvMwAAQCpQO05tolgXtdtjya4tmhW17dR2VJtLj01LSws1aNAg1KdPH9dG9lNbWZetW7dm+XzHHXdcqGrVqi4m8rfTGzdu7NqDXlvSe32XXnppxONXrlzpYogbbrgh4nY9n2KGc889N9vXo7al9iE7t99+u/vd33zzjbv+6KOPuuuLFy8Ob6P2aYkSJUI333xzntu0Xhu7VatWmX63F3c89NBDEbd7x8N/zDt16hQ68MADMz3HunXrMrW3s3ue1q1bR7xeT8OGDd1r8tx6663u/fdiJP/rjhV/ZvW758yZk+e4xov3/HGoXH311ZniGsWPTZo0yfQ5OP3000PVq1cP7dq1K3zbsGHDwnGq9qVUqVKhH374IdvXASB1UHkBICVoRJFG1XtzpqoUViM6vvjiC1dW7NHIJI2SV2lxVrSNRrtr1Ek8aRR9NI1wv/baa105raZ90iinAw880N23aNGi8OgUjZ5S+W52c6eqFFmjlvwl0xrNoqoJTZO1t/4vf/B/VRiikUIaieMfIaWRYCo19kbti0ZD6Zir+sM/Ws2rDtBr89OIIB2HINBrja5G0fofKh33aP81kk3TNflppNre0rGI/t2a2knnjTfiSbwqF4/K6P30mOnTp7vqG410878PGsWm+1XV49G5prmItZCipvDSXMvt27ff69cDAABQGGn0u0aP+y9qu+dVdPWGv32tdrsW5tZof1V/a6S8RsY3atQo3F7W1KCq3NZof1XMxqKqYFVyqxpZMZFH1bOapkfTnWpUf3Zxitr02j9NUevfX/1OVQXsydRFOcUWas9qWif/lKuqGFGluY7HnrRpY722RFLspIr0nGILzSSgipd4xha5iWsUWyiuiY5BomMLTT+lqYK9GCT6fVD1iP8cU0yh6hi9BlXuazoxrYcCAELyAkDSU+NJ6zqoQaRGsEpXdfGmD3r22WfD22qtBm+O06zkZpu8UuNai0L7qTRc5dIqW9aaEmqIa5E+r8Gtsl3RdFYqVc/NPqlcWs+jxqICHi3+p+OghnJ2VLar161gJyvenK1KtIgCNgVAKrPW8RYFGyqj1ny4HpWwq0RbCQn/RYGYRK/voccHhd636MBQQZUCI/8cxbHWCYl1W15pHuPo3+0/N/S79T5Ebxf9fms7BRMKFKLfB68EP/p9UAJK55CeX+cVAABAqtLAJy3Y7b/sieh2mDpy/TSISQNINDBLA7A0xZPaner8FbXXJbu4QLGDYqJYbWoNJvLahn7R23pTUGl6puh91j7FWp8vOrZYtmxZtttExxZaN0Gd5koUedPgKrZQZ78XN+xJmzZIsUV0m91r33tt+/yMLfYmromOLbzz45Zbbsn0PvTs2TPT++CtB6LfpedirQsAfnkfCgAAhYySE2qga35WXaIpKNDocY02UuWCRhtlJzfbeA2/6AXOsmrIeyOK/DRPq9ayUKO8e/fuEckYPzXkte857ZM3Kkbziar6QnPMal5VLfCWE42q19ymSjJ41St+Or6al1X7ojUoPBoFpUW8NZep5jfVNlos0L8uguY61ageb0G+rIKo7I5VkCkIUdIpWlYL28X7dyuAU6DhD4aif3eFChXCo+2yOh+0QLpHSSxtqwokBSdXXXWVm8cWAAAAe04VG1m1v2JRNazWHlDcIF4VdnZxgdp9WuA71lp9qpD22ufZtb+9+xVbeVXheaHYQvGIBmXFWvdCleVaF0MVBv6OccUWWmdB9ykBouOldR/2tE0b67UFndr0/vVLCjq2yE1c450fWq9D67TEcthhh4V/1rmo90trYmgxciU9tM4hAAiVFwCSmkblKDlx0EEHuTLX6IsWMVZjSVNBiaYq0u3RpdJ+2kYl2Vo0OitaIFt++OGHiNvVeZ9bXkPaG03v0ULhfpoOS+XZasjnNMpJSRVNEaVjogX81EDUQmo5Uee0FsJTA9SbkshPC9upNFgVIv4pnTQKrXnz5m7qKC0m7S/r9mhhbwVceo+iR6zpEp282FvR1QnR98W6fW/ovdEiet455lFCJ79pOi556aWXIm7XexE90krbzp8/3yWSYr0P/uSHpjLTwoaqCtLIP53XmrYAAAAAey6r9lesRIP8888/tmrVqnB7WQNL1KbW4K3oQVSefffd17XP1Y7zt3tV9a2FoVW1oefJjqqoVX2rKapitRtzqjzp06ePi2G0IHasym51XqtCRAuN+6kqvWbNmi620EWxjX+6pLy2aeMhq/ghu5hjb2MLxU7Ri6IXVGyhuCY6po2OLZSYOOSQQ9xAvKzOD00/5cXreg8V+ypeUjJOlTPeoukAQOUFgKSmBpBGEA0bNsyt+RBNo3nGjBnjOmDViT548GD3mFatWrl5/DXXpqY8+vDDD61v375Wv359VzmgcuguXbpYv379XKmyGqWaf1TPoUadRghpTQw1vjQCSCOSNF1TXhph+l0KPvQ7VNmgqgZVPmikUTQlIk444QQXiGj7gw8+2I3IUcNSyQ6vcSgq1VWyYd68efb000/nal/Kly/v9l2vT5UVKk3X+hkZGRnuWKhzXJUVXsl69PRCPXr0cO9DixYtIkbZiI65XpPu0/RDul8lwyoVnzJlipvfN57TdHnzp+qcUCJKo7MU3BQvXtzdpzl6dZxVQq7jFr2/eaWqGXXsX3zxxa7CR++NzjHNFSwa+ZZfFODpXFZSSYGhAoUvv/zSXnzxxUzbjho1yp1DJ554opuOQAk4BSeq9NHx8JJ1OmcU2CpgVIm+Ltdff72r6FEiLHqeXgAAgFSndQO8qgp1+ItXEa42V06d/apQVhtO7W0NPlLHv6ZdUhyjCltVOntU0aC1C1TRoCSBKhQ06ERtT29Ai2IUVT8oblGiQO1graWhTnGtI5FTNYL2WW34/v37u3U4tLabYh7FHxqZrwTJoEGDsny8Yhy1R7UmgqaeUpylNrcer8SL2sraL71eP7Xbtc6GYh9NuatR/eXKldujNm28KH5QnKQKEMVJatt7nfOKAVWdfPLJJ7tYThUJ3iC3PaVYVMdIcYzeA03jpOSBBpLld2yhY6+4Rv/rnFSCQvGaF9f4KQbVPirRpSmhlHTasGGDW7fx22+/dQPvZMCAAW4dSlX5K4bW4ELF1Vq3pUmTJjlWHwFIAYleMRwA8lPXrl1DxYsXD61duzbLbc4///xQ0aJFQ2vWrHHXV61aFbriiitC1apVCxUrVixUo0aN0Lnnnhv666+/wo/ZuHFj6KabbgodcMABbpuqVauGOnXqFPr555/D26xevTp09tlnhypWrBgqV65c6OKLLw7NnTtXK8+Fxo8fH96ue/fuoX333Tfmvi1cuDDUvn37UJkyZUIVKlQInXPOOaGVK1e65xgwYECmbXV/pUqV3GvWvl122WWh//77L9PztmnTxu3Xli1b8nQ89bt79eoVqlevnvsdel2tWrUKTZgwIbR79+6Yj0lPTw+VKlXK7fO4ceNibrNu3brQjTfeGKpbt647ntq3pk2bhvr37x/6559/3DbLli1zz/HQQw/FfA7dp33zmzFjhrtd/3u2bdsWuuqqq0JVqlQJpaWlufv13PLdd9+FWrZsGSpdurS7vXXr1lk+T1bvm96X6D+vOm5nnXVWaL/99nPvZbdu3UJTpkxx27399ttZHm//737ttdcy/Q4dNz+dV/7XI5s2bXLnc/ny5d3r0vmk8zTWOaTHaduaNWu690HHqEWLFqH77rvP3f/DDz+491Kv3U/nmN6vOnXquM8GAABAKvDaXnPmzMnVdrEu0e2qWL7++mvXzj3yyCNdO7lIkSKunXbqqae6NmW0r776KnTaaae5tnqJEiVCBx10UKhPnz4R23zxxRehk046ybVn1b477rjjQu+++26eXt/kyZNDbdu2DZUtW9b9ngMPPNDFPx9//HEoNxYsWOBef61atcIxgF7T+++/n+VjlixZEj5206ZNi7lNTm3arNrY/sfHijtitbU3bNjgXrPa2l5s4dFxaNKkiTs2/vc61vMo7mjUqFGmfdFjdFz9fvrpp1C7du1CJUuWdMfsyiuvDD3//PPuOb///vssj11W72le4prff//dxTL+uGbWrFmZYlzRviiOVqys90Hxtc65J554wt0/derU0D777JMpJlm/fr2LZY855hgXuwFIbWn6J9EJFABAwdG0TxoFpDJtVWAgMe6//35XCq+RcPFeAB4AAABA6tDUwKqaUSWOKmkAIFkwbRQApAgt3KeybpWVq5z4pptuSvQupQyV9HtTge3YscOVq2sROk0lReICAAAAQG5puiitc1KvXj237sl7773npnbVwCgSFwCSDckLAEgRatCqoat5VjXfreYdRcHQ4oGaH1breGjxRM09rDUiohchBAAAAIDsFCtWzA1I0+C0nTt3urUntA4Ig9MAJCOmjQIAAAAAAAAAAIGyTyJ/+eeff26dO3d25W5paWk2efLkiPu1HMfAgQPd/aVKlbI2bdrYggULIrbRCFbN2165cmXbd9997YwzznDZZwAAAACphxgDAAAASA4JTV78+++/duSRR4bnAo+mhWRV+qb758yZY9WqVbP27dvb5s2bw9v07t3b3nrrLZs4caLNnDnTzfd3+umn265duwrwlQAAAAAIAmIMAAAAIDkEZtooVV4oCdG1a1d3XbuligslJzQvuFdlsf/++9uwYcOsR48elp6eblWqVLEXX3zRzjvvPLfNn3/+abVr17YpU6bYKaecktDXBAAAACBxiDEAAACAwiuwC3YvW7bM1qxZYx06dAjfVqJECWvdurXNmjXLJS/mzZtnO3bsiNhGCY/GjRu7bbJKXigJootn9+7dtmHDBqtUqZILcAAAAABYeFCRKp/Vzt5nn4QWbgc2xiC+AAAAAOIfYwQ2eaGgQlRp4afrK1asCG9TvHhxq1ChQqZtvMfHMnToUBs0aFC+7DcAAACQjFatWmW1atWywiy/YgziCwAAACD+MUZgkxee6EoIZWVyqo7IaZs77rjD+vbtG76u6acOOOAAd7DKli0bh70GAAAAkkNGRoablrVMmTKWLOIdYxBfAAAAAPGPMQKbvNDi3KLRTdWrVw/fvnbt2vBIKW2zfft227hxY8TIKG3TokWLLJ9bpeG6RFPiguQFAAAAkFkyTK+aXzEG8QUAAAAQ/xgjsJPW1q1b1wUO06ZNC9+mIOKzzz4LBw1Nmza1YsWKRWyzevVq++mnn7JNXgAAAABIPcQYAAAAQOGR0MqLf/75x3755ZeIBfS+++47q1ixopvGqXfv3nb//ffbIYcc4i76uXTp0nbhhRe67cuVK2dXXnml3XzzzW6xbT3ulltuscMPP9zatWuXwFcGAAAAIBGIMQAAAIDkkNDkxdy5c61t27bh6946FN27d7fnnnvObrvtNtu6dav17NnTlW03b97cpk6dGjEX1iOPPGJFixa1c88912178sknu8cWKVIkIa8JAAAAQOIQYwAAAADJIS2kledSnBYIURWHFu5mzQsAAACAtjLxBQAAAJDY/vjArnkBAAAAAAAAAABSE8kLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgBDp5sXPnTrvrrrusbt26VqpUKatXr54NHjzYdu/eHd4mFArZwIEDrUaNGm6bNm3a2IIFCxK63wAAAACCiRgDAAAAKBwCnbwYNmyYPfHEEzZmzBhbtGiRPfjgg/bQQw/Z6NGjw9vothEjRrht5syZY9WqVbP27dvb5s2bE7rvAAAAAIKHGAMAAAAoHAKdvPjqq6+sS5cu1qlTJ6tTp46dffbZ1qFDB5s7d2646mLkyJHWv39/O+uss6xx48b2/PPP25YtW+zll19O9O4DAAAACBhiDAAAAKBwCHTy4oQTTrDp06fbkiVL3PXvv//eZs6caR07dnTXly1bZmvWrHEJDU+JEiWsdevWNmvWrCyfd9u2bZaRkRFxAQAAAJD88iPGIL4AAAAA4q+oBdjtt99u6enpVr9+fStSpIjt2rXLhgwZYhdccIG7X0GF7L///hGP0/UVK1Zk+bxDhw61QYMG5fPeAwAAAEiFGIP4AgAAAEixyotJkybZhAkT3BRQ3377rZsSavjw4e5/v7S0tIjrmk4q+ja/O+64wwUs3mXVqlX59hoAAAAAJHeMQXwBAAAApFjlxa233mr9+vWz888/310//PDD3WgnjWzq3r27W5zbGx1VvXr18OPWrl2baaSUn8q+dQEAAACQWvIjxiC+AAAAAFKs8kILb++zT+QuqrR79+7d7ue6deu64GLatGnh+7dv326fffaZtWjRosD3FwAAAECwEWMAAAAAhUOgKy86d+7s5p894IADrFGjRjZ//nwbMWKEXXHFFe5+lW337t3b7r//fjvkkEPcRT+XLl3aLrzwwkTvPgAAAICAIcYAAAAACodAJy9Gjx5td999t/Xs2dOVadeoUcN69Ohh99xzT3ib2267zbZu3eq22bhxozVv3tymTp1qZcqUSei+AwAAAAgeYgwAAACgcEgLaeW5FJeRkWHlypVzi3eXLVs20bsDAAAABAZtZY4ZAAAAkIgYI9BrXgAAAAAAAAAAgNRD8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICAAAAAAAAAAAECskLAAAAAAAAAAAQKCQvAAAAAAAAAABAoJC8AAAAAAAAAAAAgVI0rw/Ytm2bzZ4925YvX25btmyxKlWqWJMmTaxu3br5s4cAAAAAkhbxBQAAAIC9Sl7MmjXLRo8ebZMnT7bt27db+fLlrVSpUrZhwwYXcNSrV8+uueYau/baa61MmTK5fVoAAAAAKYj4AgAAAMBeTxvVpUsXO/vss61mzZr20Ucf2ebNm239+vX2+++/u+qLpUuX2l133WXTp0+3Qw891KZNm5abpwUAAACQgogvAAAAAMSl8qJDhw722muvWfHixWPer6oLXbp3724LFiywP//8MzdPCwAAACAFEV8AAAAAyElaKBQKWYrLyMiwcuXKWXp6upUtWzbRuwMAAAAEBm1ljhkAAACQiBgjzwt2+/3000/22Wef2a5du6xFixbWrFmzvXk6AAAAACmM+AIAAABAnta8iOWxxx6zk08+2SUvZsyY4X4eMmTInj4dAAAAgBRGfAEAAABgj6aN0uLctWrVCl9v0KCBffHFF1a5cmV3/auvvrIzzjjD1q1bZ4UNpfAAAABAwbaViS8AAACA1JSRyxgj15UXqqwYNWqUebmOSpUq2UcffWTbtm2zzZs328cff2xVqlSJz94DAAAASGrEFwAAAACyk+vkxZw5c+znn3+25s2b2/z58+2pp56yESNGWKlSpax8+fI2adIke/7553P7dAAAAABSGPEFAAAAgOzkesFulW+MHTvWvvzyS7vsssusXbt2btooLdatixIYAAAAAEB8AQAAAKDAF+xu2bKlzZ07181J1aRJE/v8889JXAAAAADYI8QXAAAAAPZqwe6dO3fauHHjbOHChXbkkUfa5Zdfbr/++qv16NHDLdo9evRoq1atmhVGLNgNAAAAFGxbmfgCAAAASE0Z8V6w++qrr3YJin333dfGjx9vffr0sUMPPdRmzJhhp5xyih1//PFuWikAAAAAIL4AAAAAUCCVFxUqVLBZs2ZZgwYNbOvWrda4cWNXeeFZu3at9e7d215++WUrbKi8AAAAAAq2rUx8AQAAAKSmjHhXXlStWtWmTp1q27dvt+nTp1ulSpUy3V8YExcAAAAACh7xBQAAAIDsFLVcGjNmjF188cXWt29fq169ur366qu5fSgAAAAAEF8AAAAAiH/yon379rZmzRr7+++/rUqVKrn/DQAAAABAfAEAAAAgD3I9bZSkpaWRuAAAAAAQF8QXAAAAAPYqeXHqqae6xbpzsnnzZhs2bJg99thjuXlaAAAAACmI+AIAAABAXKaNOuecc+zcc8+1MmXK2BlnnGHNmjWzGjVqWMmSJW3jxo22cOFCmzlzpk2ZMsVOP/10e+ihh3LztAAAAABSEPEFAAAAgJykhUKhUI5bmdn27dvt9ddft0mTJtkXX3xhmzZt+r8nSEuzhg0b2imnnGJXX321HXbYYVbYZGRkWLly5Sw9Pd3Kli2b6N0BAAAAkr6tTHwBAAAApKaMXMYYuU5eRNMTb9261SpVqmTFihWzwozkBQAAAJDYtjLxBQAAAJAaMnIZY+Rq2qhY9OS6AAAAAMDeIr4AAAAAkOcFuwEAAAAAAAAAAAoKyQsAAAAAAAAAABAogU9e/PHHH3bxxRe7tTVKly5tRx11lM2bNy98v5bsGDhwoNWoUcNKlSplbdq0sQULFiR0nwEAAAAEFzEGAAAAEHyBTl5s3LjRWrZs6RYE/+CDD2zhwoX28MMPW/ny5cPbPPjggzZixAgbM2aMzZkzx6pVq2bt27e3zZs3J3TfAQAAAAQPMQYAAACQpMmLjz/+OMv7nnzyyb3dnwjDhg2z2rVr2/jx4+3YY4+1OnXq2Mknn2wHHXRQuOpi5MiR1r9/fzvrrLOscePG9vzzz9uWLVvs5Zdfjuu+AAAAAIi/gowvhBgDAAAASNLkRadOnezmm2+27du3h29bt26dde7c2e6444647tw777xjzZo1s3POOceqVq1qTZo0sXHjxoXvX7Zsma1Zs8Y6dOgQvq1EiRLWunVrmzVrVpbPu23bNsvIyIi4AAAAACh4BRlf5FeMQXwBAAAABCB58fnnn9u7775rxxxzjFtb4v3333cVD//88499//33cd253377zcaOHWuHHHKIffTRR3bttdfajTfeaC+88IK7X0GF7L///hGP03XvvliGDh1q5cqVC19U3QEAAACg4BVkfJFfMQbxBQAAABCA5EXz5s1t/vz5dsQRR1jTpk3tzDPPdCOlPvnkk7gnAXbv3m1HH3203X///W5EVI8ePezqq692wYZfWlpaxHVNJxV9m59GcKWnp4cvq1atiut+AwAAAAhefJFfMQbxBQAAABCQBbsXL17sFseuVauWFS1a1H7++We3zkS8Va9e3Ro2bBhxW4MGDWzlypXuZy3OLdEjoNauXZtppJSfyr7Lli0bcQEAAACQGAUVX+RXjEF8AQAAAAQgefHAAw/Y8ccfb+3bt7effvrJBRneSKmvvvoqrjvXsmVLF8j4LVmyxA488ED3c926dV1wMW3atPD9miv3s88+sxYtWsR1XwAAAADEX0HGF0KMAQAAABQORfP6gFGjRtnkyZPttNNOc9cbNWpks2fPtjvvvNPatGnjFquLlz59+rgkhEq6zz33XPd7nnrqKXcRlW337t3b3a85a3XRz6VLl7YLL7wwbvsBAAAAIH8UZHwhxBgAAABA4ZAW0uStefD3339b5cqVY96niofWrVtbPL333ntuDtmlS5e6Sou+ffu6OWk92v1BgwbZk08+aRs3bnRz5j722GNukb/cysjIcAt3a/0LppACAAAACq6tXNDxRUHEGMQXAAAAwN63l/OcvJBNmzbZ66+/br/++qvdeuutVrFiRfv222/dHLA1a9a0wobgAgAAAEhcW5n4AgAAAEgdGbmMMfI8bdQPP/xg7dq1c0++fPlyN0JJyYu33nrLVqxYYS+88MLe7jsAAACAFEF8AQAAACAuC3arpPqyyy5zJdYlS5YM3645aj///PO8Ph0AAACAFEZ8AQAAACAuyYs5c+ZYjx49Mt2u6aLWrFmT16cDAAAAkMKILwAAAADEJXmhagvNSRVt8eLFVqVKlbw+HQAAAIAURnwBAAAAIC7Jiy5dutjgwYNtx44d7npaWpqtXLnS+vXrZ926dcvr0wEAAABIYcQXAAAAAOKSvBg+fLitW7fOqlatalu3brXWrVvbwQcfbGXKlLEhQ4bk9ekAAAAApDDiCwAAAACxFLU8Klu2rM2cOdM++eQT+/bbb2337t129NFHW7t27fL6VAAAAABSHPEFAAAAgFjSQqFQyFKc1vAoV66cpaenu+AJAAAAAG1l4gsAAAAgcf3xuaq8ePTRR3P9i2+88cZcbwsAAAAg9RBfAAAAAIhL5UXdunUjrmvNiy1btlj58uXd9U2bNlnp0qXdOhi//fabFTZUXgAAAAAF11YmvgAAAABSV0YuY4xcLdi9bNmy8EWLch911FG2aNEi27Bhg7voZ617ce+998bzNQAAAABIQsQXAAAAAOK+5sVBBx1kr7/+ujVp0iTi9nnz5tnZZ5/tApHChsoLAAAAIDFtZeILAAAAILVkxLPywm/16tW2Y8eOTLfv2rXL/vrrr7zvKQAAAICURXwBAAAAIC7Ji5NPPtmuvvpqmzt3rnlFG/q5R48e1q5du7w+HQAAAIAURnwBAAAAIC7Ji2effdZq1qxpxx57rJUsWdJKlChhzZs3t+rVq9vTTz+d16cDAAAAkMKILwAAAADEUtTyqEqVKjZlyhRbsmSJ/fzzz676okGDBnbooYfm9akAAAAApDjiCwAAAABxSV54lKwgYQEAAAAgHogvAAAAAOxV8kILcz/33HM2ffp0W7t2re3evTvi/k8++SSvTwkAAAAgRRFfAAAAAIhL8uKmm25yyYtOnTpZ48aNLS0tLa9PAQAAAADEFwAAAADil7yYOHGivfrqq9axY8e8PhQAAAAAiC8AAAAA5Ggfy6PixYvbwQcfnNeHAQAAAADxBQAAAID8SV7cfPPNNmrUKAuFQnl9KAAAAAAQXwAAAACI/7RRM2fOtBkzZtgHH3xgjRo1smLFikXc/+abb+b1KQEAAACkKOILAAAAAHFJXpQvX97OPPPMvD4MAAAAAIgvAAAAAORP8mL8+PF5fQgAAAAAEF8AAAAAyL81LwAAAAAAAAAAAAJRedGkSRNLS0vLcbtvv/12b/cJAAAAQJIjvgAAAAAQl+RF165dc7spAAAAABBfAAAAANhjaaFQKGQpLiMjw8qVK2fp6elWtmzZRO8OAAAAEBi0lTlmAAAAQCJiDNa8AAAAAAAAAAAAgULyAgAAAAAAAAAABArJCwAAAAAAAAAAECgkLwAAAAAAAAAAQKCQvAAAAAAAAAAAAIFSNK8PePTRR2PenpaWZiVLlrSDDz7YWrVqZUWKFInH/gEAAABIYsQXAAAAAOKSvHjkkUds3bp1tmXLFqtQoYKFQiHbtGmTlS5d2vbbbz9bu3at1atXz2bMmGG1a9fO69MDAAAASCHEFwAAAADiMm3U/fffb8ccc4wtXbrU1q9fbxs2bLAlS5ZY8+bNbdSoUbZy5UqrVq2a9enTJ69PDQAAACDFEF8AAAAAiCUtpNKJPDjooIPsjTfesKOOOiri9vnz51u3bt3st99+s1mzZrmfV69ebYVBRkaGlStXztLT061s2bKJ3h0AAAAgZdrKxBcAAABAasnIZYyR58oLJSR27tyZ6XbdtmbNGvdzjRo1bPPmzXl9agAAAAAphvgCAAAAQFySF23btrUePXq4SguPfr7uuuvspJNOctd//PFHq1u3bl6fGgAAAECKIb4AAAAAEJfkxTPPPGMVK1a0pk2bWokSJdylWbNm7jbdJ1q4++GHH87rUwMAAABIMcQXAAAAAOKy5oXn559/dgt16+H169e3ww47zAor1rwAAAAAEttWJr4AAAAAUkNGLmOMonv6C5Sw0AUAAAAA9hbxBQAAAIC9Sl7s2rXLnnvuOZs+fbqtXbvWdu/eHXH/J598ktenBAAAAJCiiC8AAAAAxCV5cdNNN7nkRadOnaxx48aWlpaW16cAAAAAAOILAAAAAPFLXkycONFeffVV69ixY14fCgAAAADEFwAAAABytI/lUfHixe3ggw/O68MAAAAAgPgCAAAAQP4kL26++WYbNWqUhUKhvD4UAAAAAIgvAAAAAMR/2qiZM2fajBkz7IMPPrBGjRpZsWLFIu5/88038/qUAAAAAFIU8QUAAACAuCQvypcvb2eeeWZeHwYAAAAAxBcAAAAA8id5MX78+Lw+BAAAAACILwAAAADk35oXAAAAAAAAAAAACa+8OProo2369OlWoUIFa9KkiaWlpWW57bfffhvP/QMAAACQZIgvAAAAAMQledGlSxcrUaJE+OfskhcAAAAAQHwBAAAAYG+khUKhkKW4jIwMK1eunKWnp1vZsmUTvTsAAABAYNBW5pgBAAAAiYgx8rzmRb169Wz9+vWZbt+0aZO7DwAAAACILwAAAADsjTwnL5YvX267du3KdPu2bdvs999/36udAQAAAJBaiC8AAAAA7PGaF/LOO++Ef/7oo49cWYdHyQwt6F23bt3cPh0AAACAFEZ8AQAAACAuyYuuXbuGf+7evXvEfcWKFbM6derYww8/nNunAwAAAJDCiC8AAAAAxCV5sXv3bve/qivmzJljlStXzu1DAQAAAID4AgAAAED+rXkxaNAgK1OmTKbbt2/fbi+88EJenw4AAABACiO+AAAAABBLWigUClkeFClSxFavXm1Vq1aNuH39+vXutliLeQddRkaGW8MjPT3dypYtm+jdAQAAAFKmrUx8AQAAAKSWjFzGGHmuvFCuIy0tLdPtv//+e8Qi3gAAAABAfAEAAAAgX9e8aNKkiUta6HLyySdb0aL/e6iqLZYtW2annnrqHu0EAAAAgNRCfAEAAAAgLsmLrl27uv+/++47O+WUU2y//fYL31e8eHGrU6eOdevWLbdPBwAAACCFEV8AAAAAiEvyYsCAAe5/JSnOO+88K1myZG4fCgAAAADEFwAAAADin7zwdO/ePa8PAQAAAADiCwAAAADxTV5UrFjRlixZYpUrV7YKFSrEXLDbs2HDhtz/dgAAAAAph/gCAAAAQFySF4888oiVKVPG/Txy5MjcPAQAAAAAiC8AAAAA5F/y4vvvv7ezzz7bSpQoYXXr1rUWLVpY0aJ5nnEKAAAAAIgvAAAAAORon5w3MRs9erT9888/7ue2bdsmbGqooUOHuimrevfuHb4tFArZwIEDrUaNGlaqVClr06aNLViwICH7BwAAAKDwxBdCjAEAAAAEU67KJ+rUqWOPPvqodejQwSULvvrqK7f2RSytWrWy/DBnzhx76qmn7Igjjoi4/cEHH7QRI0bYc889Z4ceeqjdd9991r59e1u8eHF4qisAAAAAwRGE+EKIMQAAAIDgSgspWsjB5MmT7dprr7W1a9e6yoesHqL7du3aFfed1Kiso48+2h5//HGXnDjqqKPc2hvaD1VcqBLj9ttvd9tu27bN9t9/fxs2bJj16NEjV8+fkZFh5cqVs/T0dCtbtmzc9x8AAAAorPKjrZzo+CK/YwziCwAAAGDv28u5mjaqa9eutmbNGvekaswvWbLENm7cmOmSX+XevXr1sk6dOlm7du0ibl+2bJnbL43Y8mhdjtatW9usWbPyZV8AAAAA7J1ExxdCjAEAAAAEW55W3S5ZsqQ9++yz7n9lRgrCxIkT7dtvv3Ul3dEU8IhGQfnp+ooVK7J8To2c0sWjoAkAAABAwUpEfJEfMQbxBQAAABB/uaq88BQtWtR69uyZb6Xb0VatWmU33XSTTZgwwQU0WVE5uZ9Gb0XfFr0on4Ij71K7du247jcAAACA4MUX+RVjEF8AAAAACU5eSPPmze27776zgjBv3jw3D27Tpk1dYKPLZ5995hb308/eaChvdJRHj4keKeV3xx13uPm0vIsCGAAAAAAFryDji/yKMYgvAAAAgARPGyUaGdW3b1/X4a8G/7777htx/xFHHBG3nTv55JPtxx9/jLjt8ssvt/r167vF8+rVq2fVqlWzadOmWZMmTdz927dvd8GHFtPLitbF0AUAAABAYhVkfJFfMQbxBQAAABCA5MV5553n/r/xxhvDt6l82iujjmfJd5kyZaxx48YRtymYqVSpUvj23r172/3332+HHHKIu+jn0qVL24UXXhi3/QAAAACQPwoyvhBiDAAAAKBwyHPyYtmyZRYkt912m23dutWN2Nq4caMrO586daoLSgAAAAAEW9DiCyHGAAAAABIvLaQhTSkuIyPDLdyt9S/Kli2b6N0BAAAAAoO2MscMAAAASESMkecFu+XFF1+0li1bWo0aNWzFihXutpEjR9rbb7+953sMAAAAICURXwAAAADY6+TF2LFj3YJ6HTt2tE2bNoXnoC1fvrxLYAAAAAAA8QUAAACAAk1ejB492saNG2f9+/e3IkWKhG9v1qyZ/fjjj3u1MwAAAABSC/EFAAAAgLgkL7SgXpMmTTLdXqJECfv333/z+nQAAAAAUhjxBQAAAIC4JC/q1q1r3333XabbP/jgA2vYsGFenw4AAABACiO+AAAAABBLUcujW2+91Xr16mX//fefhUIhmz17tr3yyis2dOhQe/rpp/P6dAAAAABSGPEFAAAAgLgkLy6//HLbuXOn3XbbbbZlyxa78MILrWbNmjZq1Cg7//zz8/p0AAAAAFIY8QUAAACAWNJCKp/YQ3///bft3r3bqlataoVZRkaGlStXztLT061s2bKJ3h0AAAAgJdvKxBcAAABA8svIZYyR5zUvBg0aZL/++qv7uXLlyoU+cQEAAAAgcYgvAAAAAMQlefHGG2/YoYceascdd5yNGTPG1q1bl9enAAAAAADiCwAAAADxS1788MMP7nLSSSfZiBEj3HoXHTt2tJdfftmtgQEAAAAAxBcAAAAAErbmhXz55ZcucfHaa6/Zf//95+arKmxY8wIAAAAIRluZ+AIAAABIbvm25kW0fffd10qVKmXFixe3HTt27O3TAQAAAEhhxBcAAAAA9jh5sWzZMhsyZIg1bNjQmjVrZt9++60NHDjQ1qxZw1EFAAAAQHwBAAAAYK8UzesDjj/+eJs9e7Ydfvjhdvnll9uFF17o1r0AAAAAAOILAAAAAAlJXrRt29aefvppa9SoUVx2AAAAAEDqIr4AAAAAENcFu//++29LS0uzSpUqWWHHgt0AAABAYtvKxBcAAABAasjIjwW7N23aZL169bLKlSvb/vvvb1WrVnU/X3/99e4+AAAAACC+AAAAAFBg00Zt2LDBrXfxxx9/2EUXXWQNGjQwFW0sWrTInnvuOZs+fbrNmjXLKlSosNc7BQAAACC5EV8AAAAAiEvyYvDgwVa8eHH79ddfXdVF9H0dOnRw/z/yyCO5fUoAAAAAKYr4AgAAAEB2cj1t1OTJk2348OGZEhdSrVo1e/DBB+2tt97K7dMBAAAASGHEFwAAAADikrxYvXq1NWrUKMv7GzdubGvWrMnt0wEAAABIYcQXAAAAAOKSvNDC3MuXL8/y/mXLllmlSpVy+3QAAAAAUhjxBQAAAIC4JC9OPfVU69+/v23fvj3Tfdu2bbO7777bbQMAAAAAxBcAAAAA9kZaKBQK5WbD33//3Zo1a2YlSpSwXr16Wf369d3tCxcutMcff9wlMObOnWu1a9e2wiYjI8PKlStn6enpVrZs2UTvDgAAAJD0bWXiCwAAACA1ZeQyxiia2yesVauWffXVV9azZ0+74447zMt5pKWlWfv27W3MmDGFMnEBAAAAoOARXwAAAADITq6TF1K3bl374IMPbOPGjbZ06VJ328EHH2wVK1bMy9MAAAAAAPEFAAAAgPgkLzwVKlSwY489dk8eCgAAAADEFwAAAADis2A3AAAAAAAAAABAQSB5AQAAAAAAAAAAAoXkBQAAAAAAAAAACBSSFwAAAAAAAAAAIFBIXgAAAAAAAAAAgEAheQEAAAAAAAAAAAKF5AUAAAAAAAAAAAgUkhcAAAAAAAAAACBQSF4AAAAAAAAAAIBAIXkBAAAAAAAAAAACheQFAAAAAAAAAAAIFJIXAAAAAAAAAAAgUEheAAAAAAAAAACAQCF5AQAAAAAAAAAAAoXkBQAAAAAAAAAACBSSFwAAAAAAAAAAIFBIXgAAAAAAAAAAgEAheQEAAAAAAAAAAAKF5AUAAAAAAAAAAAgUkhcAAAAAAAAAACBQSF4AAAAAAAAAAIBAIXkBAAAAAAAAAAACheQFAAAAAAAAAAAIFJIXAAAAAAAAAAAgUEheAAAAAAAAAACAQCF5AQAAAAAAAAAAAoXkBQAAAAAAAAAACBSSFwAAAAAAAAAAIFBIXgAAAAAAAAAAgEAheQEAAAAAAAAAAAKF5AUAAAAAAAAAAAgUkhcAAAAAAAAAACBQSF4AAAAAAAAAAIBAIXkBAAAAAAAAAAACheQFAAAAAAAAAAAIFJIXAAAAAAAAAAAgUEheAAAAAAAAAACAQCF5AQAAAAAAAAAAAoXkBQAAAAAAAAAACBSSFwAAAAAAAAAAIFBIXgAAAAAAAAAAgEAheQEAAAAAAAAAAAKF5AUAAAAAAAAAAAiUQCcvhg4dasccc4yVKVPGqlatal27drXFixdHbBMKhWzgwIFWo0YNK1WqlLVp08YWLFiQsH0GAAAAEFzEGAAAAEDhEOjkxWeffWa9evWyr7/+2qZNm2Y7d+60Dh062L///hve5sEHH7QRI0bYmDFjbM6cOVatWjVr3769bd68OaH7DgAAACB4iDEAAACAwiEtpNKFQmLdunWuAkMBR6tWrVzVhSouevfubbfffrvbZtu2bbb//vvbsGHDrEePHrl63oyMDCtXrpylp6db2bJl8/lVAAAAAIVHsreV8yPGSPZjBgAAAOyN3LaXA115EU0vRipWrOj+X7Zsma1Zs8ZVY3hKlChhrVu3tlmzZiVsPwEAAAAUDsQYsX3++efWuXNnl8hJS0uzyZMnZ9pm0aJFdsYZZ7jAU1P9HnfccbZy5cosj/WOHTts8ODBdtBBB1nJkiXtyCOPtA8//DBimzp16rjfF31RRT4AAABSS1ErJDQCqm/fvnbCCSdY48aN3W1KXIhGQfnp+ooVK7J8Lo2c0sWf6QEAAACQWuIVYyRjfKGpepVcuPzyy61bt26Z7v/111/dcbvyyitt0KBBLoGhZIaSElm56667bMKECTZu3DirX7++ffTRR3bmmWe6gWdNmjRx22gq4F27doUf89NPP7lpgc8555x8eqUAAAAIqkKTvLj++uvthx9+sJkzZ2a6TyNxooOQ6NuiF+lTAxsAAABA6opXjJGM8cVpp53mLlnp37+/dezY0a1B6KlXr162z/niiy+GHyfXXXedS2A8/PDDLqkhVapUiXjMAw884Co1VF0PAACA1FIopo264YYb7J133rEZM2ZYrVq1wrdrcW7/6CjP2rVrM42U8rvjjjtcebh3WbVqVT7uPQAAAIBkjjFSLb7YvXu3vf/++3booYfaKaec4tYMad68ecyppfxUnRJdmVGqVKmYySPZvn27S2pcccUV2Q5OAwAAQHIKdPJCo5s0GurNN9+0Tz75xOrWrRtxv64ruJg2bVpEA1eL7bVo0SLL59W6GFoIxH8BAAAAkPzyI8ZItfhCiZx//vnHVUWceuqpNnXqVDf901lnneWOU1aU6BgxYoQtXbrUJUB0jN9++21bvXp1zO2VDNm0aZNddtll+fhqAAAAEFSBTl5oUTaNtHn55ZfdAnAa/aTL1q1b3f0afdO7d2+7//777a233nLzoaphW7p0abvwwgsTvfsAAAAAAoYYY+8p8SBdunSxPn362FFHHWX9+vWz008/3Z544oksHzdq1Cg75JBD3HoXxYsXd0kkralRpEiRmNs/88wzbuoqLRqezIufK4aNXqBci5/nZOTIkXbYYYe56pXatWu79+K///4L379z5063zogSctpG03ppwXTv/QMAAAi6QK95MXbsWPd/mzZtIm4fP358ePTNbbfd5pIZPXv2tI0bN7pyZY38UbIDAAAAAIgx4qty5cpWtGhRa9iwYcTtDRo0yHIKKG89C3Xcq4N9/fr1rjNfSY/o6hfR4ugff/yxq5BJ9sXPRRUsinM9Su5k56WXXnLH7tlnn3UVQUuWLAnHyI888oj7f9iwYS6Z9Pzzz1ujRo1s7ty5bh+0uPpNN90U19cIAACQcskLlXTnRKNSBg4c6C4AAAAAQIyRv9Sxfswxx9jixYsjblcH+oEHHpjj47XuRc2aNW3Hjh32xhtv2LnnnptpG3Xkay2NTp06WbIvfu5NPeatt5IbX331lbVs2TI840CdOnXsggsusNmzZ0dso+oY7xhqm1deecUlMQAAAAqDQE8bBQAAAAAoeFrT4rvvvnMXWbZsmft55cqV7vqtt95qkyZNsnHjxtkvv/xiY8aMsXfffddVxHsuvfRSt5i555tvvnGVFL/99pt98cUXrtpAUxipmt5Ptyl50b17d1fhkQo+/fRTl6zRIuhXX321W1ckOyeccILNmzcvnKzQMZ0yZUpEskfbTJ8+3SWV5Pvvv3eVMR07dsznVwMAABAfqdESBAAAAADkmkbnt23bNny9b9++7n8lFJ577jm3QLemJBo6dKjdeOONbu0FVVGow9yjRMc++/xvvJymi9IaDOpo32+//Vwn+osvvmjly5eP+N2aLkqPveKKK1LiHVNVxjnnnOOqVpQkuvvuu+2kk05yyQlVZMRy/vnn27p169zx1owFWt/iuuuuc1NJeW6//XZLT093a4xoXZFdu3bZkCFDXIUGAABAYZAWys3cTEkuIyPDzfuphl3ZsmUTvTsAAABAYNBW5pghfjTt8VtvvWVdu3bNcpvVq1e7RMbEiRPtrLPOyrJSQwmM++67z637qOoXrWOhqg0lP0SPV4XMQw895Na8UOVM7969bcSIES4JBQAAEPQYg8oLAAAAAAAConr16i55sXTp0iy3UYLikksusauuuspdP/zww93C4Ndcc43179/fVbwocaFKDCU5vG20ELqqZUheAACAwoA1LwAAAAAACIj169fbqlWrXBIjK1u2bImYkks0NZQmVvAmV8hqG60pAgAAUBhQeQEAAAAAQD4ufq5pnTze4ucVK1Z0l4EDB1q3bt1csmL58uV25513WuXKld26Iv7Fz2vWrOmqJqRz585u+qcmTZqEp41SNcYZZ5zhEhTeNlrj4oADDnDTRs2fP989JlXWEgEAAIUfyQsAAAAASEJ1+r2f6F0IjOUPdArk4udjx461H3/80V544QXbtGmTS2Bo20mTJlmZMmWyXPxcC59r/Qz9/8cff1iVKlXCyQrP6NGjXUKjZ8+etnbtWqtRo4b16NHD7rnnngJ77QAAAHuDBbtZhBAAAADIEgt2F95jRvIiGMkLAAAA7Fl7mTUvAAAAAAAAAABAoJC8AAAAAAAAAAAAgULyAgAAAAAAAAAABAoLdgMAAAAAkA3WD/kf1g8BAAAFhcoLAAAAAAAAAAAQKCQvksDnn39unTt3tho1alhaWppNnjw54v4333zTTjnlFKtcubK7/7vvvsvxOdu0aeO2jb506tQpvM3OnTvtrrvusrp161qpUqWsXr16NnjwYNu9e3e+vE4AAAAAAAAAQGogeZEE/v33XzvyyCNtzJgxWd7fsmVLe+CBB3L9nEp4rF69Onz56aefrEiRInbOOeeEtxk2bJg98cQT7vcuWrTIHnzwQXvooYds9OjRcXldAAAAAAAAAIDUxJoXSeC0005zl6xccskl7v/ly5fn+jkrVqwYcX3ixIlWunTpiOTFV199ZV26dAlXY9SpU8deeeUVmzt37h68CgAAAAAAAAAA/g+VF8iVZ555xs4//3zbd999w7edcMIJNn36dFuyZIm7/v3339vMmTOtY8eOHFUAAAAAAAAAwB6j8gI5mj17tps2SgkMv9tvv93S09Otfv36bkqpXbt22ZAhQ+yCCy7gqAIAAAAAAAAA9hjJC+RISYvGjRvbscceG3H7pEmTbMKECfbyyy9bo0aN3ELgvXv3dguHd+/enSMLAAAAAAAAANgjJC+QrS1btrj1LgYPHpzpvltvvdX69evnppOSww8/3FasWGFDhw4leQEAAAAAAAAA2GOseYFsvfrqq7Zt2za7+OKLYyY29tkn8hTS9FG7d+/mqAIAAAAAAAAA9hiVF0ngn3/+sV9++SV8fdmyZW4Kp4oVK9oBBxxgGzZssJUrV9qff/7p7l+8eLH7v1q1au4il156qdWsWdNVTURPGdW1a1erVKlSpt/buXNnt8aFfoemjZo/f76NGDHCrrjiinx+xQAAAAAAAACAZEbyIgnMnTvX2rZtG77et29f97/WnXjuuefsnXfescsvvzx8vzfN04ABA2zgwIHuZyU3oqsolixZYjNnzrSpU6fG/L2jR4+2u+++23r27Glr1651a1306NHD7rnnnnx5nQAAAAAAAACA1JAWCoVCluIyMjKsXLlylp6ebmXLlk307gAAAACBQVu58B6zOv3eT9jvDprlD3Taq8dzLON3LAEAADJy2V5mzQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBwoLdAcEcqv/DHKoAAAAAAAAAkNqovAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAAAAAAABAoJC8AAAAAAAAAAECgkLwAAAAAAAAAAACBQvICyEGdOnUsLS0t06VXr15ZPuazzz6zpk2bWsmSJa1evXr2xBNPRNw/btw4O/HEE61ChQru0q5dO5s9ezbvBQAAAAAAAACQvAByNmfOHFu9enX4Mm3aNHf7OeecE3P7ZcuWWceOHV1yYv78+XbnnXfajTfeaG+88UZ4m08//dQuuOACmzFjhn311Vd2wAEHWIcOHeyPP/7gLQEAAACAPFAcdfHFF1ulSpWsdOnSdtRRR9m8efOy3P6yyy6LOUCtUaNGEdtt2rTJDVqrXr26G5jWoEEDmzJlCu8NAAAFpChHGshelSpVIq4/8MADdtBBB1nr1q1jbq8qCyUjRo4c6a6rgTt37lwbPny4devWzd320ksvZarEeP3112369Ol26aWX8pYAAAAAQC5s3LjRWrZsaW3btrUPPvjAqlatar/++quVL18+y8eMGjXKxXWenTt32pFHHhkxQG379u3Wvn1793yK1WrVqmWrVq2yMmXK8L4AAFBASF4AeaAG7IQJE6xv375uZE4sqqRQFYXfKaecYs8884zt2LHDihUrlukxW7ZscfdVrFiR9wMAAAAAcmnYsGFWu3ZtGz9+fMTUv9kpV66cu3gmT57skiCXX355+LZnn33WNmzYYLNmzQrHcAceeCDvCwAABYg1L4A8UKNWpcMqM87KmjVrbP/994+4Tdc1mufvv/+O+Zh+/fpZzZo13doXyWzgwIGZSrOrVauW7WMee+wxV71SqlQpO+yww+yFF17ItI2qXHSftlHg0qdPH/vvv//y8ZUAAAAACIJ33nnHmjVr5qomVCXRpEkTV9meFxpopljMn5zQ8x5//PFu2ijFc40bN7b777/fdu3alQ+vAgAAxELyAshjo/a0006zGjVqZLtddFVGKBSKebs8+OCD9sorr9ibb77p5lFNdppH1r+GyI8//pjltmPHjrU77rjDJT0WLFhggwYNcsHDu+++G95GU3Ap+TNgwABbtGiRe48mTZrkHpfs8poMys3cvjoPFfypzH7fffd18wW/+OKLBfSKAAAAgLz57bffXNxwyCGH2EcffWTXXnutW3Mw1qCnWBSTaLqpq666KtPzarooJSu0zsVdd91lDz/8sA0ZMoS3CACAAsK0UUAurVixwj7++GPXuZsddR6r+sJv7dq1VrRoUbeAnJ/WwdDoHT3vEUcckRLvhY5DTtUWHnWa9+jRw8477zx3vV69evb111+70vDOnTuHp+nSHLcXXnhhuERci6HPnj3bUoESDzp/PEWKFNmruX01dVn//v2tfv36Vrx4cXvvvfdc+bxGsWn6MwAAACBIdu/e7QbfKK4SVV5o4JMSGrlZT/C5555zA3e6du2a6XnVBn7qqadcG7tp06b2559/2kMPPWT33HNPvr0eAADwP1ReALmkOVTVeO3UqVO226m0eNq0aRG3TZ061TWo/etdqNF777332ocffujuSxVLly51lSt169a1888/341oysq2bdsyVaNoaiglJrRGiJxwwgk2b968cLJCz6eRUTm9T8mWDPIu0QvM+2leX/+2Wkg+em7fNm3a2Jlnnumm6tLC9DfddJNLrM2cObOAXhEAAACQe9WrV7eGDRtG3Ka27MqVK3N8rCrktbbFJZdc4gbuRD/voYceGjE4SM+rgWpaCxEAAOQ/khdALmjUjZIX3bt3d53FfpqeyD+iR2XKqtLQot6axkiNYU1ldMstt0RMFaWyY92nSgE1gHX5559/kvr9aN68uSvfVjm35qHVa27RooWtX78+5vYa6f/000+75IQCC3W265gpceGtH6IEiJJASmIoOaQO97Zt27qppFJBXpJBuZnb10/HfPr06bZ48WJr1apVHPcaAAAAiA9VYau96rdkyZJcLa792Wef2S+//GJXXnllzOfVfYoF/c+rpEZ0ogMAAOQPkhdALmhaHo3cueKKK2LOkeof1aNOZI38//TTT916AepYf/TRR61bt27hbR5//HE3Wufss892jV/vommkkpnWC9FxOPzww12n+fvvv+9uf/7552Nuf/fdd7vHHHfccS4x0aVLl/Bi6d4IKB1nzTurY/rtt9+6ab001ZGOe7LLazIoN3P7Snp6uu23334uKFMFy+jRo619+/aWSoYOHerWA+ndu/derSGiRNvgwYNdUk1VRJqmS9VWAAAAiI8+ffq4qWU1bZSSDS+//LKb6klr5WU14Mw/mEdtai3GHe26665z7WpVIitpodhFv8P/vMkuXm1iv4kTJ7r7o6fpAgAgFta8AHKhQ4cO4UW3Y82RGq1169auIz0ry5cv57ibuQWhlchQ9UAsmiJKlRZPPvmk/fXXXy7Bo0CkTJkyVrly5XCCQ2XeXie8nu/ff/+1a665xq3dsM8+yZujVWLHo9etKcvUSa5kkCp/9mRuX9Hx/e6771wlkCov9Fxab0RTSqWCOXPmuPMsp3VocrOGiCqsJkyY4JJLWkdEiSZNyzVr1iw3HzMAAAD2zjHHHGNvvfWWS1Bo0IgGk40cOdIuuuiiLAeceQN23njjDdemi6V27dpu+l8lR9QurFmzpktk3H777SnxlsWzTezRDAWakeDEE0/Ml30GACSf5O3VAxB4WtNCU2spKZEdVV3UqlXLVVtopM7pp58eTkps2bIlU4JC2ynZlFXCKVWTQbmZ21d0PA8++GBXOXTzzTe7CiGNukoFStgo0FWyoUKFCtlum5s1RLTo/J133mkdO3Z0CSCN4NN0aA8//HABvBoAAIDUoPjgxx9/tP/++8/FF1dffXWmgTuq2I5uyymWiN7WT4ODVNWh5/31119du86/BkayinebWHbt2uWec9CgQa5dnGpyU8WiWQRU8a51DMuWLevOPw1+ygpVLABSAckLAAVGo2w0r+yyZcvsm2++cZ3iGRkZbi2RWOXcKs/WqHV1xmtBbq3p8NNPP7lybU/nzp1t7NixruGm59Vi6arGOOOMM1IisNiTZFB2c/tmlezQc6cCTQOgqbI0rVlexVpDJKtF51kAHQAAAKnSJhZVxahTPrcxSCpWsXz++ecueaFpqLXuo9ZyVLw7f/78TNtSxQIgVTBtFIAC8/vvv9sFF1zgFttWw1VrWWgkk9ewjS7n1ugcjVDXAnyqvlDjTdPtaJFz/7Q8GsGi///44w/3vGrgaR2MVEgG6bUecMABtnbtWrvvvvsyJYN0TLQuRm7n9tWIoGbNmrnpp7QuixrOerwSRMlOCTBN96bgIq+8NUQ0x7KfqixGjBjhFjzXMdU0XG+//bY7twEAAIBUaBN/+eWXLgbR1LSpxl/FongtO5ruzE+D9hQ7vPvuuxFTzvqrWL744gvbtGlTvu0/ACQayQskpTr9/m8haJgtf6BToBrC2YleP6RBgwYxR5n4FS1a1AYMGOAuqSavyaDczO2r9UJ69uzpnlsVAlqnQdUv5513niWzVatWuTmMNa9xdKVEbmS1hoiOs6Yi0HFUkk0JDJXQjx8/Po57DwAAAASzTbx582a7+OKLXee9t25hqlax5JS8iLZ79253/CpWrJhlFYuSF6lAg+l08dYP1YLw99xzT8Q6kH6aJk6DH6NppgLFZrJjxw43eE9rRmrQ32GHHWbDhg2zU089NZ9fDYC8IHkBAIVUXpNB/rl9s6IGdV4b1clAZdmqXmnatGnEiCaVbo8ZM8ZN/5TVNGTZrSGioGLy5MlunuT169dbjRo1rF+/fm4hSQAAgFTFYLPgDTTLrzax1gpRh7Mqxv2d8t5ANFXZa4BPMtqbKhbRLAQaXHbuuedaqlexaA1MLQyvtRlFCYcuXbq4wY5KZGRF55fWD/HHZx7N3qCBekqsKaGh9UXOPPNMN9uDv9IFQGKx5gUAIOWdfPLJbpFHBQHeRdNnqRxbP2e3fkpu1hDRyLWaNWvazp07XeWLGtrJSiOiNJ+vggRvoUFNH5AVVQhdeOGFbqSTFouPtYihFi/U+6GRfFqYXovJazF0AAAABLtNrE7h6OfU+oQaFa+fa9eundRVLOoc35MqlldeecUGDhxokyZNsqpVq1qqV7Eo+dWxY0c79NBD3UXTRO+3335u5oHs6Nj5F5T3n8OKJ+688073vFpE/rrrrnPT/ippBCA4qLwAAKS8MmXKZFoDRJ3klSpVCt++J2uIaGF6PUad7fpfAYhGmt12221Je8zzOipKI/g0Aqp///72yCOPxHxOlcrrfgW/Gsn33nvvuem3FIwowAAAAEAw28TquI++TQNSJFb7OVnsTRWLEhZKAr322msRi6anchWLn46jjo2qUjRQKjuqoFAVfMOGDV2lhX8qKb0H0YklTZ08c+bMfNt3AHlH8gJA9gaW4wiFj0U6xyKF7ckaImooq5H822+/uZFBGtWjET5ewJaM/MGUaFSUqjE0KipW8qJOnTrh46epBmJp06ZNxHWNYlNSRIEFyQsAAIBgt4lTuYrFT4NvNBjn9ttvzzJxoYqLK664wv2vtTJiVbH4KdZQRYaOfbJWsXj02pWsUIyl2Oqtt95ySYlYqlevbk899ZRLHilJoRhM74nWwmjVqpXbRnHEiBEj3HUlfaZPn+4WSFdyBEBwkLwAgALE/L7BnN83FjVs93YNkdatW9vChQstVeVlVFRuaT7lTz75xI0s04J6AAAACHabOFqs50g2e1LFooTFpZde6hIRxx13nK1ZsyZcDaBjnKpVLB5NM6upxjZt2uSSZd27d3fTlcVKYGhbXTyKRTSV1/Dhw8PJCx3nq6++2iWF0tLSXAJDCabx48cX6OsCkD3WvAAAAHEfFaXRUCVKlLBrr70221FRuaURfXpOTRulUWijR4+29u3bx22fAQAAgERWsTz55JNujbxevXq5ygHvoqpjmIsDNDWt1mEZOnSoHXnkkXmq9lFCaOnSpeHrmrp28uTJbqDVihUr7Oeff3bxRt26dTncQIBQeQEAABI2Kiovo9f0nP/8848r6e7bt69bWC96SikAAACgMFaxRN+fG6lQxZJdRbamhMotrcGnZFA0VbTUrFnTduzY4WKXc889N857CmBvkLwAAAD5MipKNDJqzpw5blSURpPtqX322Sf8nFoAfdGiRW7EFckLAAAAILndeeeddtppp7l1PbTGx8SJE12y58MPP4w5BdfIkSPd2npac2/79u02YcIEl5jQxfPNN9+4xyi20P8DBw50C6DfdtttCXudADIjeQEAKJRYP6TwrCGS11FRiXpOAACAQmdguUTvQXAMTE/0HiCf/PXXX3bJJZe4qba0/scRRxzhEhfeNLLRU3ApYXHLLbe4pITWDFES4/3337eOHTuGt9HC31rw/LfffnPTRek+LeztrSOSzD7//HN76KGHbN68ee7YaZrfrl27Zrn9zJkz3ULzmlpL69sceOCB1qNHD+vTp0/EdkoajR071r0XlStXtrPPPtsNOFN1C7CnSF4AAICEjYoSTQclmhJq3bp17rqqN7xpptTgVQWHFtFTIDJlyhT3eDWMk11eAwttc/PNN7vtNafvjTfe6IKIrOj9ueCCC6xLly5uzl8AAAAgaJ555pk8TZ+l6omcKihat25tCxcutFSkdT60ZogWKO/WrVuO22ux+euvv94ljfSzkhlKXujna665xm3z0ksvWb9+/ezZZ5+1Fi1a2JIlS+yyyy5z9z3yyCP5/pqQvEheAACAhI2KkiZNmoR/Vqf7yy+/7EbzLF++PNy47tmzp/3+++9u5FT9+vVd6fd5552X9O9cXgMLVaNo8cH+/fvnGCRoYUKNSDvxxBMtlTz++OMuIaRzUaPwlNzJ6hgo4Hr++ecz3a7E2oIFC9zPmrpMa7pE0+g9jfADAACFB9XdhaOyG3tHg810yS3Fa/6YTVNyvfnmm/bFF1+EkxdfffWVtWzZ0i688MLwNhokNXv2bN4u7BWSFwAAIGGjorwpoLJz3333uUsqymtgoSBB64uIRj1lZdeuXXbRRRfZoEGDXNChxdVTwaRJk6x3794ugaHgSuuw6Phq1N0BBxyQaXsdywceeCB8fefOnS6ZdM4554RvU+CmiiDP+vXrM20DAAAAJAstfj5r1qyIGO2EE05wA8yUrDj22GPddFyqmO/evXtC9xWF3z6J3gEAAAAUrMGDB7sKjSuvvDKlDv2IESPca77qqqusQYMGrupCU5xlNQWZqoeqVasWvsydO9c2btzoKmE8FStWjNhm2rRpVrp0aZIXAAAASCq1atWyEiVKuCl9e/Xq5drUnvPPP9/uvfdel8QoVqyYm/K3bdu2biqpZKeBUXXr1nVrezRt2tQNDsuKptzSIKpKlSqFZxWIrphXhbeq7jUwLS0tLdtpgFMBlRcAAAAp5Msvv3QVMt5aI6lC1RGaliw6gOrQoYMbOZYbOm7t2rVz05plt42CN80BDAAAkKqYgiv5puFSp7zWKfz6669dm/rggw92U0OJ1jkcMmSI68hv3ry5/fLLL3bTTTdZ9erV7e6777ZkldfK7tysH6JF0evVq+cGQ/WJWhQ9FZG8AAAASBFaRP3iiy+2cePGWeXKlS2V/P333266rP333z/idl1fs2ZNjo/XGhkffPCBW5MlKyqT/+mnn3KcPg0AAAAobFRdIIcffrhb63DgwIHh5IUSFFr70KvG0DZav08d8lqPb5999kn6ym5RlcRHH33kKruHDh26R+uHHHPMMe4i/VKgciUnJC8AAEhxjIpKvlFRWfn111/dQuidO3cO37Z79273f9GiRW3x4sWuxDuZqfQ6es2V6NuyWq+lfPny1rVr1yy3UdKicePGbp5fAAAAIFmpDb1t27bwdVULRCcoihQp4rbLaY3DVK7sjrV+CCKRvAAAAEgRmlP1xx9/jLjtrrvuchUZWpxa6z8kK1WaKICKrrJYu3ZtpmqMaAq4tAC6RpMVL1485jYK2CZOnOjWEwEAAACCSlM/aVonz7Jly9yUslrLTVMd3XHHHfbHH3/YCy+84O5/7LHH3O2KJURTHQ0fPtxuuOGG8HNocJSqEFRV4E0bpWqMM844w7XBk9HeVHZr/ZB169bZzp07XQWLf/0QRCJ5AQAAkCSBhXhrWeixahDrujrcGzZs6BaRU2WAn6oJJPr2ZKNjoAX0tKD2mWeeGb5d17t06ZLtYz/77DP3PmS3wPmrr77qRp9pWi4AAAAgqObOnesW0/b07dvX/d+9e3dXbazpUleuXBlRqa24Q7GIqrVVqf3AAw+4tRr8A6JUzaz/FZ9UqVLFJTS0Dkay25PK7uzWD0EkkhcAAABJEliIfw5VlTFrjQYtMK3polKdjp+qJ5o1a2bHH3+8PfXUU+74XXvtte7+WMkgbzoojSDLLsGjbTSlVKVKlfL9dQAAAAB7qk2bNtlO5aQ4w08VFv4qi1iU1BgwYIC7pIq9qezObv0QRCJ5AQAAkCSBheR1TtlYz5GszjvvPFu/fr2b2kmJHyUjpkyZ4pI7EisZlJ6ebm+88YabVisrS5YsceXzU6dOzffXAAAAAKBwV3Znt34IIpG8AAAAQMro2bOnu+Q2kVOuXDm3nkV2Dj300KRdiBAAAABAfCq7c7N+iBYCX7hwYfjnP/74w00FvN9++7nppVINyQsAAAAAAAAAAPKxsjs364f8+eefEVMBDx8+3F1at25tn376acq9PyQvAAAAAAAAACCA6vR7P9G7EBjLH+hkhbmyOzfrh9SpU4eq7mRMXjz++OP20EMPuYxWo0aNbOTIkXbiiScmercAAECKIbgIdnAB5AUxBgAAAJA4SZG8mDRpkvXu3dsFFy1btrQnn3zSTjvtNDc/mOYRAwAAQOFDIuh/SAQVPGIMAAAAILH2sSQwYsQIu/LKK+2qq66yBg0auKqL2rVr29ixYxO9awAAAAAKIWIMAAAAILEKfeWFVl2fN2+e9evXL+L2Dh062KxZsxK2XwAAAAAKJ2IMAACA5ER1d+Gq7C70yYu///7bdu3aZfvvv3/E7bq+Zs2amI/Ztm2bu3jS09Pd/xkZGZYou7dtSdjvDpp4vA8czzgez22hvX07kgfnZhwPJZ/zIB1PvjPjdyw5npE4N+Mnke1U73eHQqnTJshrjBHE+EL4fv8fvo/ih7+VwTqWxGsRB3SvDyffm96h5FjGE3+DgnMshc+5BaKdmtsYo9AnLzxpaWkR1/XCo2/zDB061AYNGpTpdk01hcQrNzLRe5BcOJ5x9EC5eD5bSuO85HgGFecmxzOognBubt682cqVS62/hbmNMYgvgi8In6FkwbHkWAYW8Vrc8DmPL44nxzKIygWkbZRTjFHokxeVK1e2IkWKZBoBtXbt2kwjpTx33HGH9e3bN3x99+7dtmHDBqtUqVKWCY9UoIyXEjirVq2ysmXLJnp3CjWOJcczqDg3OZZBxbnJsQwqzs3/67BXUFGjRg1LFXmNMYgvYuPzE18cT45lEHFecjyDinOT4xlUnJt5izEKffKiePHi1rRpU5s2bZqdeeaZ4dt1vUuXLjEfU6JECXfxK1++fL7va2GhxAXJC45lEHFuciyDiPOS4xlUnJscz3hKtYqLvMYYxBfZ4/sovjieHMsg4rzkeAYV5ybHM6g4Ny1XMUahT16IqiguueQSa9asmR1//PH21FNP2cqVK+3aa69N9K4BAAAAKISIMQAAAIDESorkxXnnnWfr16+3wYMH2+rVq61x48Y2ZcoUO/DAAxO9awAAAAAKIWIMAAAAILGSInkhPXv2dBfsOZW7DxgwINOUWuBYJhrnJscyiDgvOZ5BxbnJ8UT8EGPsHb6P4ovjybEMIs5LjmdQcW5yPIOKczNv0kJaHQMAAAAAAAAAACAg9kn0DgAAAAAAAAAAAPiRvAAAAAAAAAAAAIFC8gIAAAAAAAAAAAQKyQsAAAAUuJ07d3LUAQAAACCAdgYkXiN5gUBiHfnMdu/eHfEzxwgI7h9XQPieju3LL790/xctWtT9v337dk6YfMa5CIDvlfxHvAbQ7ihIxL57jzZy4YjXSF4gUHbt2uW+PNLS0hK9K4Gzzz772K+//mpff/21+1nHaNOmTYneLSAw3x3eH1f9YZ06daqtXbs20buVEvSd7Q/W8b/zkb9lmb399tt29tln2zvvvGM//fSTnXrqqTZr1ixOmwI6F3XclyxZwvEGClgy/a0kXssa8RpSHe2Ogj3OxL57fwyJ1wpHvEbyAoFSpEgR9+Xx0Ucf2YABA+zJJ5+0NWvWJHq3AmHbtm02cOBA69y5s+ucvfjii91l/fr1id61Qkvn2ccff0y2PUm+O+SRRx6xGjVq2BNPPGHffvttoncrJRp9+s5WsK5kaqqP/vE6przz8fXXX7exY8faggULLNV5x6ZVq1bWpk0bu+aaa6xp06bWuHFjO/744xO9e0nbWeqdiz/88IO9/PLLds4559gHH3yQ8p9VoCAl299K4rWsEa/FH/Fa4UG7o+AQ++454rXCGa+lhaiRQYCkp6fb5Zdfbp988okLsDV6Wh+Wc889184//3xL1S8QBTvy22+/uS8OXT/mmGNszJgx1qhRo0TvYqF1wgknuOTPtGnTrFatWoneHexBZ4DXcNOfsuuvv959Z9x7773Wrl07K1GihJUpU4ZqrnymY9+7d2+XCKxZs6YdeOCB9thjj1nx4sUtVW3ZssU6duxoS5cutdKlS7vblJBXwtl/3qaC6Ne7fPlyN3pn2bJldsMNN9jw4cMTun/JTsdb7ae///7bjjvuOHvrrbdcu0GDQ5o0aZLo3QNSRjL9rSRey4x4Lf8QrxUutDvyD7FvfBGvFa54jcoLBIrKkjZs2OBGqY4bN86mT59u8+fPt9GjR9vWrVst1YIcfYl4iQvR8fjvv//cfR9++KHrgEiWEvSCoGP36quv2l9//eWu62d9Ib/xxhu2Y8eORO8e8ljiqT+wK1eutKeeesr+/PNPW7x4sd18882uo65UqVKu0/jff/8Nf0bI1cefOkRPOukkmzt3rj3wwAPWp08flwy8+uqr3XuTalQVpySaqi00OkXHQH/XVDGnhp++g3Tepsq5qM+e1xB+7733bPz48bbvvvu6ipRbb73Vjab0pjDyPteIL7Wf5LvvvnOVaTrmKv/W373NmzdzuIECkGx/K4nX/od4Lf6I1wo32h3xR+wbX8RrhTNeI3mBhM2TGn2bOo81aloZPo1Ievzxx125kkYmPfzww64zMlV4637oS2TFihV2yy232Pvvv28XXnih/fHHH1anTh3r2bNnonezUFGFRZUqVVzH9syZM90fLU0vpA7Fhx56yHV8o3Dw/riqQkuVWb/88ov7nGRkZLipUdQx0LdvX/dd0rx5czfdGvb+OylWh7uSy/ru1jQ06qCvX7++Czr1fiR7Z3Ss17d69WrXuFNDT98vOlcbNGhg1113nfv+6dWrl9suVZLOSr7//PPP1qJFC9dJp6nc9DlVBeEpp5xiFStWtAcffNBtm0pJnYI4F3WO6Vh/8cUX1rZtW9tvv/2sUqVKbgSrvh8nTJhg33zzTUL2F0hWyfS3kngtZ8Rr8Ue8VjjQ7ihYxL57jngteeI1khdISFZPHfMaBThlyhRXkqTbihUrZosWLXIdP5raYNiwYTZkyBCbMWOGu67Fd1NlgWpv0aDbbrvNVVdo6hEvwVO9enW78847XUZUwZC+bAr73LkFQZ02+kLWeTZixIhw9YUSFwogVemjUfpCB1qw6btDo9o1clhT8eiPqd5bdQwrCaVRApUrV7aTTz7ZLr30Uhs6dKh7DItx7d1c3bpENwA///xz99kqW7asnXnmmW4amksuucRNTVO3bl1L5kVXvUBCVT/ed4aS7TfddJObrkwL6Im2rVevnt1xxx3ue3vhwoXusamQwNi4caNde+217vXrb7s+qwcddJC7T59ZdeIpmay/86JzTIllZM3/98nrKPXOxS+//NLefPNN11ZS20CfS7Ub9DfOm4tdNLWepn156aWX3PkLYO8l099K4rXcIV6LP+K14KHdkXjEvnlHvJaE8ZrWvAAK0t9//x0644wzQvvvv3/oqKOOCtWtWzd0zz33uPvGjh0bSktLC/Xt2ze0efPm8GOWL18eGjhwYOjzzz9Pyjdr9+7dmW574YUXQvXr1w99/fXXmbZJT08PtW/fPtSmTZuIx2zdurUA9rZw2LZtW6bz7rLLLgs9/PDDof322y80ZMiQ8PEaP358qGTJkqEZM2ZEPGbHjh2hWbNmhdasWVOg+45Q+JzfuXNnzMNRvnx5913x0UcfRdyuz4Z47+2nn34aatKkSeinn37isObBrl27Mh37u+++O9S9e3f3GfI+X88991yoSpUq7vNzzjnnRBxnfZ5+/fXXQn/cV61aFdqyZUum27/77rtQy5YtQ4cffnjoxBNPDD3//PPu9n///Td0zTXXhGrVqhXxvf3XX3+FTj311NDRRx8dSjZZfU4/+eQT97f+t99+c9d1Pug4eOeJrp955pmhZs2ahVauXOn+9t9xxx2hjIyMAt3/wkLH8ffffw9/Rj06XmpXVahQIVS9enXXNnj//ffdfcOHDw+VKVMmfEz1Xul8btiwYahevXqhV155JUGvBij8kvlvJfFaZsRr8Ue8Fmy0OwoWse+eI15L/niN5AXytVG3ffv2TNvccMMNruP9jz/+cNfffvtt1wn55ptvhpYsWRI69NBDQxdddFFo2bJl7vH6IrrwwgtDJ5xwQtJ1QMb6A6VASK/7uuuuC3Xr1s3dtnr16tD3338fmj59emjRokXuti+//NIdNyV+nn322VDz5s1DL7/8ciiVeeefOg7VmRjdsd2pUyd3vBRElitXLuJ8UiKtc+fOLliTefPmhU455RR3jJXAQMHyd8xt3LgxNH/+/PB7I6+++qp7b/R/9PeOEhebNm0KzZ49O9SqVSv3x1YdysievouHDRuW6XZ9B5977rmhxo0bu8+WjvtNN93k3hd9TtSQ0WfLb926de64jxs3rlAf9tdeey103HHHhb799ttMjTwlJ3QcdA7q+1pJ0UcffdR9p+u4KDHfr18/t713jr7zzjsu8RbEjqo95f/8ffHFF+6YecdLn8UiRYqELr300lCHDh3cOVGnTh3XQL7//vvdY9Vxd8wxx7jjedhhh7mkEDJT+6h169ahp59+OuLYK2k2aNCg0PXXXx9au3at+3ulv2Xt2rVzgceff/4ZatSoUahr167ue1E0KEKf5aZNm4bOPvvsmMk5AMn7t5J4Le/Hi3gt/ucf8Vqw0e4oWMS+e454LTXiNZIXiAud0P4v3EmTJmWqInjrrbdCGzZsCNWsWTPcAa8R7wcffLDrOP7xxx/DnfLq9NGHRY18dfQo2aGgIJn4v0DU4aAOia+++io8clyd7EcccYTrXNAoSnVElChRwo0iV+Ak6ijTKN4DDzww9MgjjyTstQSJOmcUMOqiY+c/LurkOe2000L//fdf6JBDDgldeeWV4YyxOnOKFi0aevzxx12CTT937NjRZZeROP3793eJJn0WNEr4qaeeCt+n7w19Ryj493+uhg4dGjrrrLPcd4cCI1XQIGd9+vRx39Oi73N9Ti644AI3glTH0fusTJw4MXTQQQeF3wsdb432vvXWW0Pvvvuuu19VY/re8r7rCyt9H69YsSLT7aoEPP744yMS9Oo8VpJdDULvPKxcuXLE43VMo0cZJgMl2NXYrVatmjsulSpVciNy5OOPP3YjjW+55RaXaFdjVx16+vx6f9e9zj1kTZ9JJSP8lKjQcdTxVnvKozaC3oe77rorvJ3ORX0ulZQvVqyYq7iYPHlyqHjx4iR3gRT5W0m8tmfHzEO8Fj/Ea8FHuyMxiH3zjngtNeI1khfYa/6RKN98803oyCOPdB3HGu23fv16NyJQCYsJEya46Q6OPfZYF2SrsV6jRo3QmDFjwp2L3lQvP//8sxuhOnr06ExT+SQbZTOVlNDUI0rYKDmxcOFC12BQJYW+NBQkacqsBQsWuOPWo0eP8OPVMeZPHKWiuXPnhj744INwp6BGxKnj+t577w0dcMAB7hxUwPH666+7aVvkjTfecBlmjaD2jp9GoOrc1ShVfYEjsTTlgjL7CvKV3Lz22mvdVCd6X70OOb1f6oTzfwZUpaHvFa/0MbsySUSO9BF1xHiVKuqQ1zFWos9PjRsllfVdre9vfacrIaiRpeqsUSdNMnRWeMdGyU1/ZZsaft4x8b539PdNyfgHHnjAXdf3uL7XTz755EzPX5jPx1h/b2688UaX7FWjVjRlkc6bJ598MuZx1d92/S0jsZi74+0/5jqv9Ln0aFooTRflH7mtttRtt93mEvje1JNz5sxxnaiqElKCzXusql319zHWdCgAkudvJfHa3iFe23vEa4UD7Y7EIfbNG+K11IrXSF4gLh8IZTsvv/xy1xmsEUVar0JBskYiaaoCdSZ6Qbem4FBnvQJo74MjSlJ4a1+kCnUgKHiZMmWKO2bqbFXyR8dMxyqaOiQ0PZRGa+F/LrnkEpc59o9w1tzCGh2tagtNO6bRpkquqZNHSTU56aSTXFCpjhvvPH7ppZc4tAVIfwy9gNrfeabvF53rqoLx6DOi91SVRt57rY4BJfyymoZHz53qyb3sRHdYqoNTU215I0X/+eefUIMGDULnnXdexNovCkCVWFIiyeu80feTOvDVoVOYO+ljNdD0PaEpe7zRJprTXCNoox+jBKim7BFVZSjx7K09kGznyogRI1yVpUYZqypKyXVR4lBJY03d590mSkDq75pG+Oj7euTIke456TSPfazVPtKx0kAQ0f/6PKmSVQMdvEBD331a70IX72+bKGmhSkN9dmNR8lfJNSU5ACTv30ritb1HvBYfxGvBRbuj4BD7xu84RiNeCyV1vEbyAnEpbdMUBMra+afo0QgVjX7X3Gh+WuBFUx1pugJ/CZOSH5orVlNLpcI8qaKOWJViqZPC20ZJHHUoaEoobad5/lUFoE51jZDUF4zWA8H//mgp6aAvVx1Pb+5uHa9SpUqFpk6d6gJFTeei0dI6T1WlIfqi1nWVxtHBXXCfB71P0R1mCuIV/Hs0PYo6i6NHJapDTiMWNWJY9H2h91DXo9/DIPyRDRr/2g2x1iTS8dRnRXNe/vLLL+42TaWmqfxUreSnslJVKakyJlphTFr4zxd9t6ixNnPmTHdd38H6WzZgwAC33Q8//OASpPfdd1/EOawqC53byXzuqWNOI8NUUalqFHWYayTx2LFj3eAEJRf1nerRd7I67XSs9DdM1QCffvppQl9DYaCkuvfd1qtXr/DfLh1/Df7Q96DXXlIHqpK9ClD8vDaGNxhCfwv1HBogUbp0afcZBpAafyuJ17JHvJZ/iNcKB9od+YPYN/7H00O8llrxGskL7NUolKpVq7oPgeZEUwNeI6C1uJPX2FeArGle/Nk8jRLUSHglNjRCSaXWmotZazokW6e8vzNVXwZadFtfDN6XrgIaJSq8bb3btUiORlGKHqNjoxFdhX0qlnjQSGadM0p4+amjsWzZshGLB2mKMlVX6FxUZ7iOnxIY+jL3jrVGr2oEHAqGzn8tYlymTJnw6ER1sCnzr44ATYnmjUZUR7ASmv5RjOp8U7WSf4oUdcaxIHfOpk2b5qoFnnjiifBtS5cuDT322GNu8XpvvR2N7NZ3uT8Z3bJly1C3bt0iKlz0GVSVgbdeUbLQ8VAyVHOBekkyURWQksdeQ07fOepQvv322905eOedd7o5RJN1qkN9Z6p8WElFjej3OveWL1/uKttUealjoQopj46Vvnf1WFVLafpD5Nxm8DpLVdqtNSnUjtKaWB5V8yh5oeMtGgChASDe9DQefXdGDwhRG01/91jPCUiNv5XEazkjXos/4rXCgXZH/iP2zR/Ea6kXr5G8wB7T1EXPPfdc+LoqBFSBoYoLbwS11q3QNEjRne66XyOUbr75ZpfAePPNNwv1O5HTKNshQ4a4BI1GXimLqTItUWeEFob2Oru8DguN7lXG02tQaNotbz2QVKbjoISZOgyV0PHmlvcokXbxxReHA0slMrStztPo9yiZR0YHnRambNGihZvySVOXqBJLnQA672vXru067HS+f/bZZy7J8cwzz4Qfqz+omoLBWyzTj+qZ7OnYXXXVVa5TXp+RUaNGue9sLRiq0Rea8s+j90YNHm++/I8++shto+/toMx7Gc+FS73vA41M0XevzkfxFl71On01ur1nz55uoUnR3zY1DnUMNcL9yy+/DCWDrEYD6/3Xuh56rX6aEkV/37T+jEed45o6UglItQ+Q+xG/Or/0HaiRUfoOVOLM//2mNpRGUWtQgwY4yHvvvefaF/41sTz+wREAUutvJfHa/xCvFQziteCj3VGwiH33HPFa1namWLxG8gJxafh5C5ZqBLWm0vCXW2s0oEZQe9NvJFMHY6wSY/99oqBHZeRK0ChZoekflMjwOsc0R7ru15eFjo2CHXXMa051/F/FinfuqJxVnYXlypVznTkaga8qFW9OeY1+VrJCwaP3vmh+VVW3eGX9/vcGBSN6nkS9N1qLpGLFiqHGjRuHJkyYEL5PIxO1LonKHOWaa65x22ikgMoc9QdXo99VSYPc8X/nKqGsiiR1wN90001uPm510GtRe3Xav/jii2676dOnu6SSOkj9o8A12tu/toz3fhY2/k4ljTzxXoMqCL2qN3Ugr1q1yo1U8UavqxJDx8B/zkr090th+Y6Jta/+6xp5M3v27NC6devCneZXX311qEaNGm7qLI+OkRaBU5WAPqv6u6/v6dNPPz28ZgNyppJuLfirJLyOqShRq+Oq0eB+6ixVW0F/4zxqN+gzDiDvku1vJfFa5LEgXstfxGuFE+2O/EHsGx/Ea7HPp1SN10heIC78Hx59SNTh6HX2aIFTjR7UFEnJNLWLvxGsEbkKaLTOgjcKUsdESR0FNf5RWuooU6mWEhjaRp2wGs2lBXRUaq6OdlUQeIucpzKVWfbp08d1ZnvVPFokUefTtddeG/rjjz9C559/vlvbQtUt6mxUp4/K9r1ppfQ4JTTuuuuuwIyCS4UOgNdeey38cyxanP6yyy5zfzy9jl/v/VGCTyOKRZ0F6rzr0qWLS1poah7sebCu7x9N26XpjXRMPfosqdP0iCOOCD9GHTZt2rQJV7loejVNmZFM9F2syonXX389nJzQ941ee6dOnVziXWsDaL0Lnaf6G6apedTgi7VIfGFK5ESP9Pf/Hdf7rNE6tWrVctVQGtH/4Ycfuvs++eQTVznVu3fvTM+ppLz+FmrUspLIyD1NhacqC3V86jPnn2JG55/OOSXwPXq/NDhC52thr14FEimV/lYSrxGv5QfitcKJdkf8EPvmL+K1/5Pq8RrJC+S6TCsnXsejOi01FZI+CP61HTRSKajzp+0pJSe6d+8eKlmypOtYqFOnjpsmS6N1vcZcq1atQvfcc0/4MTom+qJRWbnmo/PKtbRgjhbhHDZsWMJeTxBpoVwlgLwFnnVMNV/3vvvuG17fQouUajoXBZP6WXP5aVSclyybNGlSeC0W5L8pU6a4hJGmffJoQVklHrxOYq9SZr/99nNrB4g3NdrixYvdFA3eIrPe94u3FkZh6yRONI3+VEJInwN9/2gEqUaFaj0YPzV2lDTyvq/0mVHJqTpw9F3nfZ8XlqqCnOYA9xp5mlLD+9ukzmElOtWBrHnM9T2i46cEqTf9oaahUyPav8B8YeL/m65BBhq9r/WpvOn29B2rc0OJYN2vkcVXXHGF6yRX2bvonNCUKlOnTnXXSQznXqzPj0ZK6W+Yfy0fP31m9Z3qr/jR6CmNmFTiXh2q2T0/gOT+W0m8lj3itfxHvBZctDvyH7Fv/iBe+z/Ea/+H5AVy1cGhzoy80MK7p556anghZAXmQVutfm9pHn6NklRywivHUiePkhdeZ6xKyNUJpgSHf3FMfQFpkT8veeFJ9U4HjWzWCFL/Ytwa/Xbfffe5jLLXma3tNCpa2WSPRuhrvj6de+rk0ZRSybYAfGGi8kONaNd0aFqoUsm6tm3busSmppfz3jNN/6VOUf+iUapgUkeAOueiPxPM3Z43mttSHe+aCkmd9Pru0TFVx7yqvZRA8qjzWp0xWjzdq4bRmiTJNk+qqDM+1toAWdH3vH/x1mSgaU5U+aT52v1VJJqmT59JVbn5qbNO02qJKgP1HXzRRReFp430pPrfsexkleRRJ6k+jxr8oe9FJXmV8NW6Tt7UM5oeSt+jGgyiak0lj5JpGk4gkQrz30ritewRr8Uf8VrhQbuj4BD77jnitawRr/0PyQtk2wjWF4mm7dF0Lepw9NayyCpg9kZDq7JAHcjjx49P2uBaHQeaf9/fQa6R/kpKqCLA68DRMWjYsGHoscceC2+nygytc/H2228nZN+DSNNtabS9zhuNdNN0Y17lhH5WSb7WBxEd28mTJ7s1E7x5h0Xbe9OUaTQqCpa/GkLvpypgVJKoKRWUAFVlhSqMlMDwqjL0fqkDQIkOJfO0eL2mTtM0DdGdosgbdYiqk1OfFfF/F//8889umjqNuvfTujyqYBozZkzE7YXxe9x/PnpzkYvOK6+yQLRomaq5+vbt60YOetsrKa2OfH336JxcunSpu8/7bi+Mx0RUPaFKSH3uvPWE/PT3W9WEXkLDq4h69dVX3Xe0t1j5/fff757Hq75A7ujvlEZoDx482I3wljVr1rhEUNWqVUM1a9Z0CV99Dg877DBXeeg9TtVr+swqoe9HwghIvb+VxGu5Q7wWX8RrhQ/tjvxD7BvfY0i89j/Ea5mRvECWNNpPI/w0ul2BtoJodeJ4a1nklMDQqMGgr1i/J7zX9+WXX7rOHy8poUVuvPnRdcw0mtWbPkrzyen4KQDStBD/j717gZOxbv84fq3zIdb5fExOUZJTKFQORaISpSdSSUVOPYlUDhWRRJTOSiJFdFIRItGTU0KFcggRFbtEhPm/vr/nf88zO7vLLrO7Mzuf9+u1ZWfumZ25556Z+/pdv991qVSJ+jJ4K1PwXzfeeKPbN5p1r0aJ6mfhzcjXzCn1U/nwww/d71qdob4X6g8S/IVHCZP0FfxZ4L1H1OtFySitrgikFRj60cm0XjPVbdf7Ru+Zzp07u9cVZ9+EUo1G9X7SPva2CXytlPjToHzgigJtF7jyKbPMqFUyTMeVV5NciTKt5tLqOfWw0PGoJL1+V5JCZaQ0071kyZLu8zuwZFlmWNquhLqSNYE0SKcffW/p+0nf/8FLtzWwru8+r8QWvZlSxksuaMJCgQIF3GCaZngrkatVQEpeaBsl0rTiRf0ulDRS+c2cOXP6y3Xp/Rn4/cZ3HZDy92Bm/a4kXksa8VraIV4Lf5x3pC1i39AjXkuIeC0xkhdIRAHzoEGD3KCwBo+9BIRmV2pAWfVgTzXTLzPOAAwOeLznqIbDmuWvAdf8+fO7kznNKFeAo5UVmqmlYGj//v2uHIT6YqjxplazIPH+nT9/viv7pONPS/R1DCqgfOONN9wKl27durlVGR7NGi5atGiSjYiQPidugSdvGzZscLOEv/nmG3+5OA12ep8Z3rYamMuSJYtrFiUamFO9d62WCZxxQV+LUwvcP+q/oGRQ4Oev3hd6/yT32azP9u7du7tBfC8pHfz6RpLgkmIqO6bjUeWONDtWn9dKInsDUBqE//rrr129cvUO0G3Vg0UDyPoeVKlDr2RPZjgevX2j56b3mmYae89PA+gqmaLkuvajPoO179TszaNyiDoH8FZi4PT7OpA+25SgVb8Uj441TXbwPiOD6T3csWPHBJ+LQvk8IOUy63cl8VpixGtpi3gtfHHekT6IfUOzD4nXkke8ljySF1EuuVl7zz77rGs+reRF4EnymDFj3GCkllhnhsGc1H5BKYAJ/LDVagvVoNbs3A8++CDBbVViQ7POAxtFawAitf1Doo2alqu+vJYla39rkC02NtbXqVMn35AhQ9xApDf4qKSQjlX1yUDa0+zgpN7zqvWsgWGV3tExr9ImXmkZzXDXqgqvX4n3/tFMR71vAvvieLRNZkyCnqnT7Qs1mNZAtFbG6XXwaFVYzZo1fR9//LH73Xvt9DpqFr3XeFSvUaTv88DHrhUBooF4rbjw6HtLSWYNygeWJPNuq0bcSqIFfmYn9T0QybznqhKQGkjXCgwlgLVqUImcwESkymqpfJRWnmjgTomdUaNGRfyxklHnVUqmqXZ+YFNunROoEbwmNfznP/9xl+lcYtKkSa4EpVZ3KqkPILq/K4nXTo14Lf0Rr4UPzjvSDrFvaBGvpW4/Ea8lRPIiCiV10j1r1iw3sKPBeFHZCDU/VtNjr++AN6ChAQ+VO8iMAvtXBO4nDc6qpIhKaWj1hPaDF9yooaZm83p1v73bKcgpUaKE2xanP+nyBgdVtkSze3v16uWSE6KAUsdj3rx5XZkN9bpQw0SkHyUu1ZciuNSZBuKUnFCJGTW21MoZvU5e7wC9H1QXWsmnwAFgJTc0MOclQj2ZZZA4LegEJvC437hxo5u1fdFFF/mmTZvm6ueXLVvWJYb0+aT30nXXXedeEyVN9T7T6zFgwAAXdAZ+tkeqwM9pDQRrdVbr1q3dQLFWEzzyyCPumNLlGnzXDPfAY1irtzRQ3LJlS1cySp/b0UJJ4MCVUUnR95sSF0oCqcY7UkbH3NSpU93A565du9xlWuWiRNFbb73l30b0GajeIVrp461w0XmW+owBiN7vSuK15BGvZQzitfDFeUfoEfuGDvHamSNe+x+SF1FCdZa92UOB1JxOwbSSFDqR1yC815RbA8Y60VdTyUAKyDXIo/9nJgsWLHBLwrViwjsJ0EmaBhDURFODs7pOAU6tWrUSNDrVfurSpYs/+aOG3Sondccdd1CT+hQzQvRFFjhY7TWI1YCZZqIGNuOW559/3q280MCOemEw+zfteftYtZ1/+eWXRK+rmqhrYNijgQC9H6666io3W8WbsZgjRw7/DOJIb3ic3nSsK3mnfegNrmsf6jNa5X3i4+P9SWfNKtVKJW81kpJIej30GdamTRs3SKrPe2+g1BOp7yXvcev5aOWEEhdqtK0eFfqsVtLZW1nglTMTrTLQIJV6W2gGrpKl3mqhSHe6PgjePtPgj/p6aB95K1G89yTvzdPvv+SoHJ5W+Ggmt/o06f/eqhb1vdK5QWDpGZ03ZM2a1ffRRx+53zXoGrhCk74WQPR8VxKvnR7xWtohXgtPnHdkzP4m9g39PiVe+x/itdQjeREFFASrT4AGaQLp5L1GjRquZIFmFWnAXasKdPKuGvQqE6VZRyoroQamHs0e1NLrwIGgzEBlbTQ7XH0qvA9YzdDVPlCSxzNixAhXGkeDXV5D7rffftsFOZrBqxIbul6ztaJ90EHPX81wVe7pVJQIUqB4/fXXu32vwRu9DrfcckuCmvPiNfBG+vLeE4sWLUqQuNPgnDdI4A2AqpeA3gNKPnnvAb2e6mES3Pg4s5eeC0WAoiSQSmyp5Iz66qhniJfs0woDrThQzW4NxKhJukpi6DPfm/Gt99NLL73kGzhwoEsARrrggXXtDx1vWkWgHgIeHX+6PPjzZ8uWLS7h5q2W8wa0vOMxUhM5wVSGyFu9lpyZM2e6ZLzOA4SkxakF7p/A73fvc0zvR50zaRWartdroO81leFUEKzvMzXgVt8LnXPpWNO+V0LDm/wQ+Lcyy7EIhFpm/K4kXksZ4rXQI14LX5x3ZBxi37NDvJYyxGspR/Iik/MCau/DI3CgULMDtdJAJ/Teh7NmA2ow0hvs0SClZqx27drVl1lpn3j7Rysr1LRv9OjR/oHyNWvWuH9r1vh5553nrr/vvvt8BQsWdEkLzxVXXOEGyjSL1avvH600GOjNuh88eLCvcOHCbsAwKZotrVlyWtkS2PdAg5AXXHCB7/HHH0+3x42EvPeF9/mg4EYDA6qF75Xe0QCBBgA83rYawFOZKZVr8GZ5U7s99bzPbM0mVWJZJfv0ngqk5JFWKi1evNj9rlmmek8pmarmpEmJxMRq4GPWQK96A3iJB5U+0uevVvkEUt8AlYRSqR6tHPrss8/cYJUu81Z6eSJ14D74faoykCqtp4S6EhOBvSw8gd/5+uzVdt5nNAPmiQWeO+nY69Gjh0uAPfroowm2U98ffUZqvwY23NNsbk36EA2O6jyiePHi7vgsUKCAK2UDIHq/K4nXUraPiNdCi3gtfHHekTGIfc8e8VrKji3itdQjeZGJBQ/EvPvuu77OnTv7ezCo5qvKP3kUYIuC8YoVK/o/fIYNG+aaUqsmbGamJM4rr7ziBmZVo/+3337zX6dBHTVy1b7wAhz1s9DArRpLiwZpFy5c6It2/fr1c4M33qxmHVdK+mhFSlJ0PAYOIgYOnKkk0auvvpoOjxrJnTB7tZ89kydPdrMavcSdkkx6fQMH3/R+0eBBlixZfE8//TQ7NxWU4NGqLa+/gD7HtaJFn8sqe6H+A0oKeaUsNLNes7bvv/9+/8mits2dO7crXRNYFzozDExrf2g2rXowqByPtx9U8knNpTVYFVhyR5/PKt+nAaqGDRu6pLNmvWfG73nvfatSUHqfqnyWEjUqpeUlMJJ6/VWCQ8lGb/UFktenTx9X4knln/SdpvdZ//79/derBI2S9V6NfO+8SvtWE0M8muk9e/Zs9zpFatIMyEiZ6buSeC11iNdCg3gtMnDekT6IfUOLeC3x/gg+1ojXUo/kRSakN0fgB7DXtE71lDVwo6Yvul4DQBp0fOqpp9z13sm8soAamPfK9Wi2qrekOlKdanBA+6J3795u4Et9KzToqhm8gQNcmimpwR2V0/IabKpHSPbs2d2MLUrf/LdEiwZttFrCa9bs0TGlAR+VE0rpayLBJYYQWl5wnlyQrs+Gyy+/3HfTTTe5PiSBq4xUE1qfDZphrAEEfbaoD45WKulEW03O9B5SqSikzKpVq9xsbH3+aNa8BmW8wU8NuGgFnD6XGzdu7Pa5d52ajKrHiAbqVdarbdu27rMqeBVCpFOCTM3gO3bs6Gas6zNbwffevXvd9erPpM8gr29T4GfNpk2b3ErC33//3X95JH9uBz52rXJT0l3libQPtCLAK+Gm0kRKYGh1hXe8BL/f9d2/fv36dH4Gkffe1KQO/XgTFrTf9DmnZL3K0Yi+++rXr+9fventa69fk1dqMjOshAIySmb5riReS3qfJId4LTSI1yID5x1pg9g37RGv/Q/xWmiRvMgEvORE8KCETsg16Kj6rt5AhjJ8OplX4kIn8xrQKFeunJvF4lE5BM14z4ySKuekAS0lcTTooP2nFRdadq5BV29GlwYeNEChmZIaKFLZqJdfftmV3vKComil2WqNGjVyM9e0ciU56nmggfCkEhLMPM1Y3sCb9wWrGYoqq6MVFjrO1bRePUk0k1GWLVvmZhGPHz/evXaa6a7BAm2jcjUqQaM+OVqdoZIoweV5kDTtS31ea3BFZWXU80U9d0Q9hjRIo32tgVHNIFUpJNFgvZpSa2A1T548/vI0mYmSZOrRpNVvgf2IVI5HDU496nuhGfFeOamkEnOZqa/FTz/95Lv66qvdj5I6GszTZ20grUbRqhN9f+HMqLyMVvp470ePkmdK1nr9KlRqUv2wNAlCK188t99+uzsfS0pmORaB9BKp35XEaylHvBZ6xGuRhfOOtEXsmzaI15JGvBYaJC8i3KhRo1xdV6+/gBcIa8m0ZqXedtttrqyLl5zQ/5WseOSRR9yHtsq7qKeFBoA0YH/NNde4RnZq4pmZaCBLAw8qHaIB1cAsqLLDRYoUSbAP1ThH+0UzWT1K+igg0iC9BiYCEz7RyNuH2p8aMHvjjTcS7XPVF1aTUm8GcLZs2fxBpEdL+jX7TbP4kf4DAAr4VVohcBBN5RjUx8Kbpa7ZwtWqVXNNZ72ZwxqM06CAV45G96Wkh9cg09sm8D2EU78WotVJKomkEn96HTTQMmLECPf+0me0Pne0Ek6lgPS793ooKNV7KXBlQSRKbga6ytBpRaA+mwMpoaHyfV6/BpXt0edRYEIjMwge4NZqk06dOrkSh0qme7TaSZfNnTvXf5k+g/V+VvmsSF9FmZHUxFeJem/lhd5/Ota0v1V6RjO+//jjD1dCUudlOgdTwkJ9sHSO8cknn7jbkawAou+7kngtZYjXQo94LXJx3hF6xL6hQbyWNOK1tEXyIsLfGAqig8s96IReM5+XLFmS5G01C1MDkV5pH53UjB071nf33Xe75dVeCY7MRM9JJaE0mKreFRrg8VYAqOyTSpAEDrqKBoQ0a9ybrarkxooVK9xS82in0mPal94xpFn61113nRu4EZUYUj+VFi1auAy8595773UJIA1yaza+Zuur9JZmz1EiKm0ltbpFnyNKJmkAzmtgKU888YSvffv2/vfBOeec416rwBUUGhRQLxw1Stbr6dGAgQYGdHvNglfJMCTe76dabaQm9So9o/2owXqVBNJnes6cOV1ZLlGtfA3cP/bYY5lyZYF6NOk7zCtfqO869VDxei95PQWUPFVJutdee80foGuVQWbplaPXMakAQb2XNElB5doC+8roe8wbrAtcFfjcc8+5Uofar0i8j0/Fe6/qvdeqVSuXrNAkBg2cqoSkVgE988wzLjmvcynPs88+6/phPPDAAwn6sACInu9K4rXUIV4LLeK18MR5R/og9k17xGv/RbyWPkheZJJ6fTpJ92YDarBQgbUGjTXDaM6cOa70iwYvRAMhOrlXssIbGMrspXs0cKDnrABHyR2VL9IghPbRvn37XJJCJXACBxgU6GgwomrVqgysB8x+1ux7rWLRoIyX2NHAd5kyZdwxpRJcqu2d1CCZghLVKdYyfw26aQWLanoi/WiFS+DKIyWcVG5GCU2PmlhefPHFbrawVhwFJjY0QOCtOtIKLiUCvaW3otdds7yVvPBW3SDpgEUl6gJfC+8zWKsINDCqfahBes0Q1aCMZnJ/+eWXbhuVAlTiyGtGmlkCtnfeecd9Ruj4UxkyfW57q3uUlFCj5MD7Ua1yJUA1012ruyTweIxkgftK5YiUqNmwYYO/9Ii+97X6ScnjQPouU5JeCZ3AY8ub+Q/fGfed0L7V6lWVhgqm70Al9ZPrpUJfCyD6viuJ11KHeC00iNciA+cd6YPYN/WI185sXxGvpS2SF5ngi06DjxoIVtNpnfSppqsG59W4VH0bVApKs440E14zAEWDGiqhFA01sL2AR/X6VTbDG0RXqSINeKmRq5aaa6BMs3UV6CgAUtNTlYHQUm/t10ifyXy2tOJEx9HIkSPdjN7glRJKXGgGv1ZXBAaZwftNM1N1vAaXj0La0koJJSJUIk6JucDXTwk9NUJWmS/Rihol9NQjJ5CSfeon4G0XyHudNbDq1X9H8tS7QYnRwMRQIH1Ga0apN6teA/JeH4dITTQHfi4Efo95z0fJdA3Gq1G86HNXq7c0WKyVbzNmzHCrLPR/nRx6q7w0MKVeK2pC6d2fjsdI+8z+4IMPXK+qYPrMVH12JRjVa0ZNZ73EoGZV6jgKLPWogT6VUlECg3J8p3fgwAFXP//FF190vytB5CXCgo9RfbapTJnOHwI/5/RvJdp0LpGUSH3PAhktkr8riddSh3gtNIjXwh/nHemD2PfMEK+dGvFaxiF5EUGCB2Jef/11t7JCNBh5/vnnu7qvooEeBeKaJe2tyHjooYfcrHmPmk1H075TEkKlozxqwq3Bdq0UUBJH12n/1K1b1w2uqwEq9cH/R83dNZAYWCIokAbTVEZIs/Z1UhZIZTVUh5iZpxlH5Xbq1avnetqoPrsSd4EDnkrUKcHpnbCoAaZWyGgwTqVoFAyp3rsGCbzVMt5nUkYPEEQSzQbVILtmiy5cuDDRKgFvn2rwRQlUvee8Ae2kSmhEwr4PfIz6/NCqLT03NUsNXO2mz2gdo15SXskzHa/aXp8dSiyr7KESaxqY17GoZJw+b6644go3qBzJzUmVmFFyODCxqNJZ+l5SLw/tEzWjPffcc30dOnRwSXYNmqtElBIagZ+vU6dOdQPykd4DJT1oMoP2p1Zj6hjSeYFKzQTz3ptKvCvJptfKm/2tZIZWJAaX8QQQfd+VxGtnt++I184O8Vr447wjfRD7pg7x2ukRr2UskhcRSEkLDdio5E5grWv9rrr0gaWgPBr0UXCuwaLkShpkVl4Q8dJLL7kBHs1KVWJCNXE1+KCgRwNfGihTsDRmzBhWBSRBfSnUINajEiSq892vXz83wK0AUrOA1dPCK0+iYFNJMw0GqZ+KjsNImw2dmah0nFZi9ejRwzd8+HC32kIrZpSk++mnn9zMbm91kj5H9P5QCTpvkFgz3Hn9UiapwRO9RzTwrh+9LySpz+PAkkhKIOn1ygyUeFApPh2DShYrWabvJa83g0ry3Hbbba6OufaRejd89913ie7no48+crNxdX/q/SAaTNbqw0jkHQN6/HqvLV26NMEghC5TksfbTtcrwa4yUl6pNh0n6lWDlPHeY94+1feYN5nBa/6e3G10vGqFYdOmTV1Dbq1iVc+nwP5OAFL+Xsys35XEa6lDvBYaxGvhifOOjEHsm3rEa0kjXst4JC8ijAZtNOtSTaY1mKF+DYG1wtWQ01tRoZN/LWvSDBYNKKspdVIlKaKFymdoZqsGKDSTS+W1RINfmqWqQTU15EbSPvvsM7fv1M9AM4G1jF8z3dS8tGLFiu7/ohnRd911lxuIVMNmleOiyXnaOl1CwbteK7JUTkY18lXeSZ8ner00Y3j06NEuwafXOHDwTjO7VUYlsH9FtCVAUytwBnzwvnrllVfc59CQIUNSdF9ayaTP8Uim4+6yyy5zpY+8VTsaANZnhI43rRD0yiMpoabvuA8//DDBPlQpqcCVQoF0nT6DtEoh0gQeH1oloVKPSlhon4lWnWhiQvCxpcEJzfb3ZvCp14L6hHjlUpD8Z2Hwe1L7TIkfJcv0/eatVk3qc84bZFVpPSU6tM+XLVuW5OsJIHq/K4nXzhzx2tkhXgsvnHek3X5NyfXEvilHvJY84rXwQPIiTCUXAGt2n34Ctwn88G7Tpo0b1NAsag2EDB061A0aec26o5kSNxpo0MqKpHhNUJE8BYYDBgxwM/I1+3fz5s3uctUi1sz8BQsWuIBNA5KqQT9x4kR2ZzoK7kMSyPuc0ACwZnKr1JwoCaoVWaql36RJE1+WLFn8g6LB9JkTCWWKwoX2scrQaDB6+fLl/su1SkAJ1J9//jnZE/DMtJ+1skdNVKtXr57gch13Shp7SQn1sVAiTbPZtULOM2vWLLdqLrAB9Y4dO/z9HtQTIzDZEYm0ilKfl3qe6i00Z84cd/n777/v3psajBCtXpNBgwa5mcbe7xs3biRxcRqB76lt27a57zGVo1E5Lq/3j/qFBc7ePlVwrKXjgfedmd6zQHqK5O9K4rXQI147e8Rr4YHzjrRH7Bs6xGunR7yWsUhehJngk3CtCghshNu8eXN/0+2kTuS1mkCz3ZW00IwmlTHI6BP7cKIVKJrtK8yQDB2trFCyYu7cue53NdRF+tF7XSusvM8Gve81Cz2pxunatlevXm6QNLA8jVYdaVWGEk/6CVxpgcQCP1e9f3v7WL2ItBJJfYg0G1QD7CrJpZUtooFpfU5rZmlKPp8zQ6kuleTTykAvoanyZDrOVHJn5cqV/pI76ieg1UAlSpRwZcr0nXfOOeckKJEoOrY18KxeOpFKr6tm/av/TJkyZVwfJr0H9Xzbt2/vVlRo5VPHjh1d4j3wONAgu44tpJ6OMR13eo9qvwcma7VPdfx5yaOUvD85lwCi77uSeC1tEa+lDeK1jMF5R+gR+6YN4rXEiNfCRxZDWMmS5b8vyfTp06127drWoUMHa9u2rf3666+WP39+O3nypP3888+2d+9et50SULJz5047ePCgu80VV1xhcXFxbtuCBQv67xNmjRo1slmzZrldkTVrVnZJCBw+fNg+/vhjq1Onjl100UXuso4dO7Jv05GOZX0GLFu2zO644w4rXLiwvf/++wm2iYmJcZ8J2bJls5tuusly5MhhU6ZM8V9ft25de+utt2zRokX2119/WYkSJXgNT0Gfq7t373afzd5nrPaxzJ071/LmzWuLFy+2YcOGuf9fc8019u9//9v+/vtva9eundWrV8/efvttW79+/Wn3s3e/kUyfDbfffrsNGDDAYmNj3fGq5//www/b8OHDrXHjxrZq1Srr3LmzffTRR9a9e3fLmTOn1axZ07Zv3279+/dP8J2nY/7yyy+3Ll26WKQ4ceJEgueg13XPnj327bff2ssvv2z33HOPew9OnjzZFi5c6PZDyZIl3XETHx9vVatWde/vSy65xLZt2+bODZBy8+fPt65du9rWrVvde1T7/amnnnLH3eOPP+626dSpk/vsmzp1qvtu03t7wYIFdujQoWTvl3MJIPq+K4nX0hbxWugRr6U/zjvSDrFv2iBeI14LaxmdPYlG3syg4Fk7ulw/apKjMhGq463Gx+or0LhxY1d3XnWWNSszeLapym9o5nVwDVkkpNq5qqueGWYyZyT1RFCfEJVtUd1vlTnx6tYjfQSXKdHMRK9cl1di5lTUFFmfK17T3+DPIzVbR/JUF79o0aK+6dOnu9nzakLtlS5SM1/N3g5+z6j/S9++fd3v+jzX5/zAgQN9f/31V6Zsuhrs22+/dT0FgveNSpepNIg+R1ReSqsNkprdHqmf26faL3r/FS9ePEH/KtH3ft26df19qlQmS2WObr31Vvd9j9TVl9bv6hWmFRfq/3XgwAF/uQGVrMmZM6f/sldffdWVL1NDbr1Ha9WqRTNuIAq/K4nXMg7xWmgQr6UPzjvSB7Hv2SNeO/XxlRzitfBA8iKD3hDBgbV3gqya3+pRoRrfHtWBjY2N9Zcx0OCFAuurr77aDR6r+a5O7N99990E94VTvwY4u1qqCjgbNWrkmzBhArsynQUmKFXeSYmGl19+2dehQwf3usyePfu0DWc3bdrkSkephBRlT87sM+T66693gyxqMt2wYUN/D5h+/fq53kMqiRF4u/vuu893ww03+AdgNDijJFKkfy4FHj8q/+R9BwV/F+k4VZItX758vq+//trfuFs0cKzvOCVDleQIFKn7x5uQ4NF7VAN3Dz74oCvxKDpGlHScN2+eP5Ej8+fP92XPnt0lLLxBdeG9emqBx8r+/ft9O3fudOdVXhPYTp06uYbwgVRPX4kz9VrxynVq2fzdd9+doM8KgOj4riRey3iR+r0fbojX0h7nHemD2PfsEa8ljXgtcpC8SAfBAzia/afZpaqz3Lp1azcDyWsWrZUVFStWdP/WyosCBQr4rrzySlcT3KOZSxrkadWqlat73a1bN5pNI92pWSmrfDKOBn3vuusu16zYa3i8Z88e33XXXedq6HtNaE8VAK5bty7dHm+k034MHjjWzHg1nO7SpUuCy9977z1Xwzt44FOz6ZV89kRyojn4va/n0qdPH9eU+/XXX0/2dtu3b3fffUp8Bt42M1PvCvX6KF++vOtLoxru+v72Ejga2FPd90BPPvmkL0+ePC6Zo340SJo3CBpMDc1LlizpBkq1b5ctW+YuX7BggZsM8uKLLyZ4b6setZJI3msSjO86IPN/VxKvITMiXgstzjsyDrFv6hGvpRzxWvgjeZGOlHBQw1LN8Bs+fLive/fuLjGRO3duN/tIdu3a5StSpIivcOHC7oRey6w9mjWo2YBHjx51vys48GYUAogeGojTAKg+P5T8/Oabb/xJCg0CaPXFmDFjUhz0M8Mt5ftHM0SfeOIJV27mxx9/dDNC1UxZTRADaYb3JZdc4lYm6WRIM+v1mZ5Ug+lI2f8a+L3ooosSXa6yHmqyquerVT9aNXAqH330ka9YsWL+pqzBzz+zrC7Qe0+D5Co/pAbcq1atcpd/9dVXbuKCjhHR5ZqooIG9jz/+2K3KUEJD+1KDe0i8X7UaRZ9/mo0deLwoSFMpGpWG0nGmlRe33367S2DMnTvXXa8kmxp1B5bG++2339xKtH//+98R+d4EwkFm+a4kXgMQiPOOjEfsm3LEa6lDvBY5SF6kA5Uu0Mm5ZvVp1YVXFsKjlROqea2SEqJVGUpyBCcmhg4d6pIcmaE+OoAzq0upyzTA1rVr1yRvo1Vcd9xxh6958+a+9evXu8sWLlzoBudw5ryVBSp7oUFTzdT2VsJVrVrVlbkI3McqRaPeBCr9o4FUJakfeuihiH4JNOj+zjvvuH8HHpfqGaDSH/quS4nff//dd8stt7gVQplFcgkX9U9QuRQdA4E0UKdE0Jtvvul+V5+a+vXru5VUOsb0Hs7sK1LOhCZx6D0nStoG0+oz7WtN9PDqfWs/V65c2X0OivozKdnmJSq8/ZzS4xdA5vyuJF4DEIzzjvRF7Hv2iNeSR7wW2UhepIPvvvvOnZB7syyDl1Vr+aH6VmhmoBITmrVaoUIFt71mXqqMgWZtalDDa64LIHML/HL1Bus8Kjmj2dyapfj888+7wWMNBKtcj076NDtFzbjVaFblGlR+Rj0ucOY02Kz9qUFRfX57K+BEvYdU7s/rSxTcrFQD03qtPJEwKB2YnAh+vEo+qC+At4Rb5QsDS3ykZPVEcIPqzBJkaRWKAl2PZh337NnTlYzy+lx4Dbg1UUFJRm9f6H2ufh+6Donpc03vQc3m9mgyiFabKUkhWrmi0mU6LpXgVX+Ve+65xyU1PFp9obKcmlCigdNgmWXlD5ARIvm7kngNQCDOO9IXsW/qEa+lDPFa5pDFkOYuuOAC69Kli23fvt3eeOMN/+VZs2Z1/z/vvPPsqquust27d9vChQutefPmNmXKFNu8ebM9+uijduutt7rtVqxYYZ06deIVA6KAPh+UYO7Xr59deeWVdv3119vDDz/srnvooYfs559/tgoVKthHH31k69evd9sPHDjQ5syZYw0bNrSJEyday5YtrUOHDvbXX39Z5cqVM/ophT3t7xMnTiS6/PDhw/bCCy9YixYt7NJLL3Xb5ciRw44fP+6u79Gjh5UvX95eeeUVW7p0qb333nvu9ZILL7zQvQ5FixZ1963bxsTEWLjLkuW/pwcbN25M8Hh1LOk76pZbbnG/ax/oJzY21u0n0XP0vt+SU6RIEff/pPZ3uNLzCqZ9o32l92CjRo3c+03/Hzx4sPsOz5kzpzsWKlasaK+99pr/dmXKlLF27drZvn37bNSoUe6yfPnyWa1atdx1SKxKlSpu/yxZssTtW5k9e7Y98sgj7v9yySWX2M6dOy1PnjwWFxfnzqmef/55K168uH3//ffuvanXTPt+3Lhxbl8Hv66nO3aBaJdZvyuJ1wAE4rwjfRH7ph7xWmLEa5lYRmdPooV6Wdx4442+Nm3a+Hbv3p1o9YWamKqZ3dSpU/230cxBzUBS3VgAmZs+DwJnGWr2tsrIqH+FVlyprFyhQoV8AwcOdNdrprFmDeszwitFV6pUKd+zzz7rv4/A+6PhbOL9HSiw/r3q6av8lneZ6uZr9dxzzz2X7OunWaZNmjRxM+yLFi3qGzlyZKLXINJoxV+7du3cvlD5o44dO7rLtdpHx+Ly5cvd7wMGDHDPO7jZ8YwZM9xM2kjfD8nVWfeek8qiqLG2ei3oPanftZpSJSE9Kouiuu7qUePRSgvtO68UF5Lf/97s7U8//dSVovH6hEnnzp1dDxGvp4heBx2fgceczqd69erlbuetGgKQ+s+/zP5dSbwGgPOO9EHsGxrEa/87npJCvJZ5sPIinZQqVcrat29vf/zxh02ePNmfKfVm+B06dMhy5cpl2bNn999Gv2sGkmZXA8i8NENAnweaZbhp0yZ32VdffWUFCxZ0sxO14uqyyy6zkydP2jfffGN79+51M7nPPfdcN+M9d+7c9vrrr1uJEiWsXr16/vvV/f1/eUDLli1bBj7D8J2pov0s3mfvgAED7KKLLrJrrrnGrr76atu1a5eVLl3ajh07ZmvXrrX9+/e77bxZp7rsn3/+cbNMp0+f7l6H3377za2CkUhYZRFMx5n079/fHW+ajfrggw9a48aN3eWtW7d2q3t0vWjlgI7Bxx9/3GbOnOn22QcffGDDhw93M98jZbVJcjN3vGNl6tSp9swzz7jnpOPBe07aX1qJ8txzz7n3pFZT6H376aef2ttvv+226dixoxUrVszdh1aveCstRo4caTfeeGOGPcdIoP2v2dtavapzKK2i+PLLL92PdO/e3a1c1eoLvRb33nuvW3mhFWuPPfaY2+f6XPziiy/cypi8efOecnYWgITvv2j6riReA8B5R9oj9j17xGv/O5aEeC0KZHT2JJpo5l+PHj1crXrVtRatvNDlahx56aWXun8DiD7qd9OlSxdXD1qrs9TU0mvaqxkV+fPnd7O0//zzT/9tVq5c6VZi6LOjYMGCbnY8Uu7mm292s7g1q1uz4NVnqE6dOr6PPvrIfUarl4N6h6gHgVbFFSlSxN981OtnoMbTSe33SFzpEvyYX3rpJddEtUyZMv5VFp7333/fzW6fPHmy+13NkNVjwGu6quN11KhRvsxAvafKli3rq1Gjhu/iiy92z/v+++9PsN90/Kxfv971mDn//PPdCqhrrrnGvTd1nIj6LKhxdODqC5yePgMfeeQRX5YsWdwxphUs6lehz0dvlpUaBOu96q30Wbdunesp0qxZM1+9evXcyhcAZybaviuJ14DoxnlH+iD2PTPEa0kjXsv8SF6kMw3wKHmh8gWeRx991HfBBRf4m3GHy9JpAOlDTWZHjBjhBtt+/PFHd1IybNgwN9CZN29e3/XXX+8GRj0aoFOpKA0UaBB16NChCU5k+Aw5NW/Ac/jw4b4KFSq4f2u/a9Bd//fKdqnxb82aNV2SSFT6T5dpQFSf2yoVpMFsLxkdiXSsBB8v06ZN861Zs8Y15p4/f76vXLly7vgMbByv6+6++27//vOS8Wp4Om/ePBeQnG4Zb7jbv3+/G6TTQPmkSZPcgJbec2oArcs2b96c4DlqYF0D6r/++qu/fFHOnDl9Tz75pPtdjbm9Ywkpt3HjRt+5557rmzlzpv8yTQS58MILfW+88Yb7/aeffvI1atTI7fPAhr96zbyyekIzbiDlovm7kngNiF6cd6Q9Yt/UIV5LHvFa9KBsVDq7/PLLrUmTJvbdd9+5MhxVq1a1adOm2bPPPutvxh0uS6cBpM3yzkAqpXD33Xfb2LFjXSkefSaoxJMa06rcwk033WSzZs2yGjVquO337NnjSteoLI+azY4YMcKGDBnibuM1xeQz5NS8ZaVqYq4SGNu2bbM1a9a4y7T/VQJI+1tlZ1QiqE6dOu66V1991UaPHm1ly5Z126s8zapVq9xrFUk+/vhjmzJliju+dKx4x4uOKTVT1XPUNirVo+bcKnmk8kcrV67030fhwoWtS5cubpv777/fXaYyiCoxpWatKtvjHY/e/o40O3bscGXc9Pz1HlUpR73nVM5N/9b1HpU/mT9/vjsWSpYs6UqnqDxU9erVbcaMGa6EipqUe8cSTt8A2FsGvnXrVjty5IhVqlTJf51K1uh9qDJlKtOl61QSSu9XNQH2qGG6SprpszcljeQB/E80f1cSrwGZG+cd6YPY98wRr6UM8Vr0iMwRhQinwUgNakyaNMnuuOMO27x5szVr1iyjHxaANKSBOW8gIPBETsG8BkY1OBd4ebt27VzwvHz5ctdTQPWmNVB3xRVXuO28QQINHtPX4tRefvllN8Dp8QbVVTtfyaC///7bDc789NNPbn8ePnzYFi9ebBMmTHB9hzRov2TJEjcIqvreGvifM2eO9evXz//aRpJ3333XDURpINcbIP7www9dD4tevXq5Y07/V08GGTp0qB09etQ9Z/Vb8aiPgHo5qZeArg8W6X1WlIhRgka9FvTcZeLEiW6ygZIzSmR49P7Ve1L7UX1CHn30UdefYdy4ce7YUcIDSfOSaDoedXypX0jgcaZjS+/ZwM9P9RZR7Xwde15fkbvuusu9BnrdPF5izuspBCB5fFcmRLwGZE6cd6Tffib2PXPEaylDvBZFMnrpR7RS/XDVjgUQPVR2p3///q7HzSuvvOKLi4tzl6vMjGrjd+7c2V9yRrZt2+bq5BcvXtzVl1bdfZXvQcqpTEWBAgXc/vNK83mlMFRSpnDhwr4333zTd+DAAddbRH0NAh08eNDXrVs332OPPZaoxmiklUPySuZ4ZaL0+L0+S+oJoJrloue5Z88etwxX/5cXX3zRlf4YN26cb/v27b6rr77alTLz+jlkVrt27XIlUBo2bOirUqWK2wcqWXTnnXe6Ou8qU+Ttg1mzZrl+DKVLl3Z9L7755puMfvgRRZ+N6ieiclDazxMmTPBfp74rvXv39h07dsx/2euvv+6LjY115WpWrVqVQY8ayBz4rkwa8RqQeXHekfaIfVOPeC31iNeiA8kLAEgHL7/8shsoV88b1cUvWbKkr2/fvv5khQbqNMCuJsnBlOTYtGmTf6BZqN2ectrHSkyoqfmUKVP8/RjUv+Cyyy7zDRkyxP2umvolSpTw3XTTTS65NGPGDJfMUBPmFStW+CJZYKJFyQs9HyUr1HBVlJQoX768awrfoUMH37XXXuuarmogeevWrW4bNZS/6KKLXDJIyTYlN8K56WqoKOmlxIWOleDGcOpX1aRJE99rr73mLtOxtXbt2gx6pJFBx1/g8fjnn3+64037V3XmtQ+VLNS+nT59uttGzX/VDF6fj3o/K2Gk3iN33XWX75lnnvEngiMxqQiEC74rAWRGnHdkDGLf1CNeO3PEa5kfyQsACKGkmmWr8duVV17pby4r/fr1c7OJR44c6U9GtG3b1jXn/v777/2XBdNlNOT2JTtQGbxvvOvVxHfgwIG+okWLuhnc3nZqKKoVL6IB0S+++MINomoGvRIXXmIjszR4++233/zPVQ1Y1XRbs6K0wkJN4uvXr+975JFHXINqrRzQap/77rvP3UarUzQ71zs+o4X2lVZb6FgJbjir/abrcuTIQTPuVA4eaEazmsPrMs1+/OGHH9zl69atc0mzfPny+Ro0aOBPTOg4rFy5sq9q1apuNZpWw6hZMIDT47sSQLThvCP99nMwYt/U70PitbNDvJb5kbwAgBBJbvb54cOHfR9//LH/ZE4ld7QKQAPkmv3uzer/8MMPXbkZDbIjdZJK9CQ1A3vUqFFuQF4zvbXyYuLEiW5WffCJt2aDeys0krv/cBf4mHVCpxJket4bNmxwl02ePNlXrlw5fzmtpLRp08bNgk9q30biPjlTWhGgVVNeIifw/a73t44X+FK0+kHHjWbjKTkxduxYt623/x588EFfsWLFXGm9V1991VexYkXf8OHD3XVaefbjjz+69+zUqVMT3CcJXSBl+K4EkBlx3pExiH3PHvFa6BCvZW4x+k9G990AgEiij83kmr8eO3bMHn/8cTvnnHOsdOnSdsstt/iv+/HHH+3WW2+16tWru2bQa9eudY25b7/9dnv66afdNmrerabcHTt2TLfnE8n++usv10S7WbNmNmTIEPvss8/cfu7Tp0+C7dTkV03j1DxuzZo11qFDBzvvvPMsNjbW3ccLL7xgFSpUSPQae83mIrnZr/aFnocaSe/evdseeOAB6927t7tOx5oacz/11FNWpUoV97y3bdvm9snIkSPt66+/dg3jLr74Yot2asK9aNEit/+uvfZa/zGF5D8bdbyp6b3XvF3NtV999VUrV66cXXfdde696/nyyy+tX79+7vPzqquust9//91q1arlmqOrYXqNGjUS7Wod12r0DeDU+K4EkBlx3pEx+zkQsW9oEK+FBvFa5kXUDQCpFHzypkFM+eCDD1zCYv78+bZ582br37+/+/n555/d9R999JE7wRs3bpwbNM+bN6/lyJHD3nvvPTeoJ88//zyJi1ScSGsfKhExZswYa9SokbVt29by58+f+Mvu/weZ9drVrVvX3nzzTZe8mD17ts2bN89y5syZ5GusgdFITVzExcXZ1VdfbV988YUbDL7pppvc8TZt2jRbtmyZ22bYsGG2atUql/TRQPBXX31lo0aNctsfOHDAFi9eTOLi/2n//fPPP+597iW1kHRgO2vWLGvRooULxAYPHmw7d+50l+u9t2DBAnv//fddEle0L0XJ3F9//dUaN27sfv/uu++sUqVK7v386aefJtjV3rwbEhfA6fFdCSAz4rwj/RD7ph3itdAiXsu8/jsVDgCQYhs2bLDXX3/dunbtajVr1nSDmEpgvPjii27m8EMPPeS2K1asmI0fP96qVavmBuH27t1rxYsXt/3791uhQoXs448/djO4NeP/kksucbfRfZ1qdgv+x1sZsWnTJjerdN++fXb48GH/LO+keAPOl112mV166aXu34ULF7aSJUtG7K79/xKQiY4dzVxfv369S4h5M9wbNmxo3bt3dwPwWk2h/dCyZUubMWOG2x86DrUve/ToYbVr13a3YXb7f51//vluhVT9+vUZNE+CjrstW7ZYt27dbOPGjfbvf//brebRyosyZcq4Y1MJwwEDBtjEiRPd8anPRS8Boc9EfT7q81PHpRKS119/vXXp0sVKlSqV6G8BSBm+KwFkRpx3pB9i37NHvJY+iNcysYyuWwUAkVZDVf0rVJf9mWee8V//1Vdf+WrVquXqVm7ZssX1FoiNjXX9AtQQWd577z3fBRdc4Ktevbrbtnz58okaACPlr4caoNepU8d3//33u8bnMTEx/qbJp6p9G1hfNNJr5QfWST169Gii47REiRKuz0rgc73nnntc42OvD4t6f+TKlcv1Fgi8P20fTX0tcHYOHjzoa9eune+mm25K1EhbfUH+85//+N+b+mxUXwtd7vn9999dTxo169Zno9frwnO69zSApN8vfFcCyIw470gbxL6hR7wGnD2SFwCQQoED3XfccYevWbNmvi+//NL9vmbNGl+2bNl8vXr1cgNzHTt29P3888/+7bdv3+7+/8033/iGDh3qBtsDMTCXcmvXrnX7vXXr1r6XXnrJnRCqIbWaS9erV++MXtdIT2I8+uijvhYtWvi6d+/umzlzpj+ZkTt3bt+LL76YoKme9p+OVR3Dv/76q7ts/vz5yTbdA1JCTbTVhHvJkiUJ3k9PPvmkr0iRIr7mzZv71q1b5y5T0+28efO6pG+w3bt3u+bcHj4bgTPDdyWAzIzzjrRH7BtaxGvAmSN5AQCn8Pbbb/vKlSvnmzJlim/nzp3+y3/88Uff+eef73vwwQd9Bw4c8B07dsx35ZVXugE5b4DOM336dJes0HbBGDA+taQGLkuVKuXLmjWr7/bbb09w+fLly305c+b0vfnmm1FzTO/atcslbGrWrOkbM2aMr2nTpr7ChQv7nnrqKXe9ZreXLFnSt3fvXv9tlMyoVq2ar1GjRu74DsRAMc5U79693WdiIK3y0SqK/v37u1VSgUnbGjVq+Dp16uRWXEhwAlFJyUhPKgLphe9KANGG8460QewbesRrwNmj2yQAnMLcuXNtx44d9uSTT7q+AevWrbMjR45Y1apVXT12NTpeunSpZc+e3Tp16uR6LqhB9+7du11z3+nTp9vjjz/ubpMrV67gsn2n7M8Qzbwmvkk1RX7nnXdcj5F8+fIluLxOnTp277332gMPPGB79uxxDaefeeYZ+/777y0SeU2Jk/tddOzpOFMz+Pvvv98++eQTGzRokA0ZMsQdh/p/7ty5XVNz9WtQg/K33nrLnnjiCYuPj3fHc+B904QaZ2r79u3uM05Ntz06zn744Qd37KmHihrAL1y40F337LPPuvfyihUrkuxjoV4Y9LYATo3vSgDRivOOtEHsmzrEa0A6CUECBAAy1YzFwNm+6l+hkic9e/b0tW/f3s0svvnmm92sYK22uOSSS3xdu3b17dmzx20/YMAAX/HixX1Vq1b1NWzY0Jc/f35XIgVnZtq0aW7/PvTQQ74NGzb4+zqoZJT6hmzbti3B9lphUKVKFVc3X30cVErJm9kdiVQOa+HChcle/8gjj7j+FcG30b7RfhPtN61SUa8VrcLQbURlfK6++uo0fgaIFvqc08qnRYsWJfhs9er8rlq1yvVgGThwoP99PGvWrAx7vEBmEu3flQCiD+cdZ47YN7SI14C0R/ICAP5fcs2zH374Yd+5557r27p1q++zzz5zZaTq16/vmz17tmuEWbduXdd7waPGtOo78Morr7gEh4eSPCmnEltqeq7E0X333eerVKmS76KLLvI38dVATJYsWXzPPvusfx97SSc1C3711VcTDKJGIpUUU9kdDS798MMPSR5Dahp/8cUXu9rmgdePGDHCXe41i5d9+/a5k2vZtGmTS8S9++676fiMkJmpf4pKRHXo0MEtjw+m5IUSuuqvEozyUMCZ4bsSQLTivOPsEfuePeI1IH1QNgpA1Pv777/toosusldffdVbkZbg/w8++KAdPXrUlT5p2bKlffHFF3bttdfabbfdZp9//rnt27fPlUJZs2aN275+/fp2ww032B133OHKSR0/ftxdTkmeZFcAJlkOSWWPvvzyS1deZtWqVa5s10svveTKzJQvX9569uxpTz31lP3000/uNioxo/sqW7as3X777dasWbMEZTUijUqKtWnTxgoXLmyvvfZagmPI22e1atVyZaHee++9BNevX7/eypUr50prqcSWqKTP6tWrbdiwYW7fVKpUyb+PgLNVsmRJV6Zs1qxZ7hhT2TaV0du/f7/7bFVZvQsvvNDq1q2b6LaUhwJOj+9KAOC8IxSIfUOHeA1IHyQvAFi0B/+bNm2y3377zXr16uW/TAPe3oDaOeec42q3v/jii27wt2LFijZ48GB78803LWfOnPbLL7/YjBkz3HVJ/T36WiTNSyoEDlx6A+16TXRiXaFCBfd7bGys3XLLLXbBBRe4hIUoqaHB0bFjx9pff/2V6L6811q18yOVkhf16tWzr776yhYsWODfR97zvPzyy61Ro0Y2c+ZMGzp0qEvkaLtvv/3Wn5jwEhra3+pxoVq22ocffPCBFSlSJAOfHTKbbt262YABA1xvleLFi9tll13mEr5KAKsXzQsvvGAFChTI6IcJRBS+KwEgaZx3nB6xb9ojXgPSXoyWX6TD3wGAsKFVFMuXL/cP7iopoUSEVlQEJhoOHTpkjz32mA0cONAKFixol156qRtE1yx3JS08EyZMcLPf77zzzgx5PpFGg++Bq1DU9FyD6g0bNrTGjRu7y4YPH26ffvqpTZkyxc477zz/tg899JCtXbvWvV6FChWy559/3m2n5JFeg8xIiQgdg8WKFXMrMHSMekke7Ucl3nRMaoBYK1LUwPC+++5zCbdgSvLkzZs3A54FooVOK3ft2uWayGvQNUeOHNa9e/dk3/8AksZ3JQBw3hEKxL5pj3gNSFskLwBEFZVw6t27t5vJ/tZbb1nNmjVdUqJBgwauLJRHM9NHjBhhderUsTfeeMNKly7tT3i8/fbbdt1117lBuuByJwzMpdw///xjXbp0cSsBNOiuAc8WLVrY9OnT3QoC7ftx48a5bbyk0j333GMrV660//znP1E1AKrVJe+8847de++9bn8EHnt79+51CQkd2xs2bLBq1aq5xI5wPCK9JfW5KDo+WYUGpB7flQDAeceZIvZNP8RrQNqJnpEfAAioS6mVFNOmTbOdO3e6Wf8dOnTw7x/1Wfjkk0/s5Zdfdj0tlLgQrQxo3769G0DXDPbgAToN2kXTgPrZUE181cdXPwclKrTPNVP7ww8/tEcffdQqV67s+lYooaQ+F6qfr4F5zWrp2LFjov0cqX0tUuqmm25yPSyUwNBKCx17cXFx7iRZZaV0rGpVkEpIKXGh/cHxiIyQVOKC8nnAmeG7EgA47zgbxL7ph3gNSDusvAAQlVRiRwPhpUqVst27d7vyRCrL4zl27JgrdxJMA8ea+a8ECE5Pg+hKNAQOaP7+++/Wv39/mzp1qnXt2tWVQvIG2kePHu3KcKlvgwbrBw0aZK+//rprLv3jjz9a69at3fbqQxJtlGx77rnnrG3btnbJJZe40lDqt6IVQmpeDgCITHxXAgDSErFv+iBeA9IGyQsAUUnNtdU/Yd68ee73KlWq2MUXX2xXX321m8mu0jsIXfkYDbKXKFHCnxDSSovbbrvNmjdv7nqOqDl3rly53HVqIq3VFyrvpSTS5s2bbePGjS6BUatWrUT3HU31avv06WOTJ092ZURUQmrixIn+6ykRBQCRh+9KAEBaI/ZNH8RrQNogeQEgaqmfgsrw1KhRw/Va0Iz+VatWuYH0smXLup4LV155pRtkR8oFDqJrVYvKP6nJtlZSqOyWZv5olqlWDOhn27ZtLrHhlX5S6SM17lZJpKTuW6K1PNfChQtdwk2JC+1PoZcAAEQevisBAOmJ2Dd9EK8BoRedoz8AYGY33nijlSlTxvbs2eOSF59++qkrTfTxxx+7hMUff/zhn+mPlPMSC+pR8cILL7geDOpboX08fPhw1+tCs1LUeForXpTcUCmprFmzutv8+uuv1qpVq0T365WWitbEhVxxxRX25JNPusSF19eCJsgAEHn4rgQApCdi3/RBvAaEHisvAFi016VU6R31EVB/hWgtSXS2gksWDR482EaOHOl6M0yfPt3Kly/vLtfA+8yZM+3hhx92qzDUz0IN0NW4W03TleS45pproravRUpRIgoAIg/flQCAjETsm36I14DQid7pqwBgZjfccINdeOGF7kRODbxFiQslMMQrZYRTU+Liu+++cyWg5JZbbnGrVrTCQiWhvP3Zt29ft+3nn3/ufm/atKl17NjRrR5Q824ts1UpLxIXp9/fAIDIwnclACAjEfumH+I1IHQY/QAQ1XLmzOlO4vRTsWJF/+XeyguVMkJiSSV1VOrp3//+t2smXb16dVd6a926dbZ9+3a3P9WbQU25r7rqKpekEO1zJS+OHDlia9ascSs11KSbpBEAINLxXQkACCfEvgAiEWWjAADJSkkJLW+bDz74wDp16mQfffSRa3S+b98+l9BQf4b33nvPP/vkjjvusP3797tyUjqB1r/VC2PWrFn2008/WY4cOXhFAAARg+9KAAAAIG2w8gIAAupSIuH+8BIXX331lX3xxRd26NAh97saa1922WW2e/du/zbXXnutu2zYsGEWFxdnRYsWdc25lcxQgziV5hozZozNmDHDJTWUuJCCBQu66//++2976623eAkAABGD70oAQCQi9gUQKUheAID3gUgfgYRfEFmy2Nq1a61JkyauBJRWRmzevNldpz4WK1eutOeeey7BbcaPH+8SHdpWmjdv7m47e/Zs1w9DqzPefPNN69Gjh7ve64VRp04dW7FihXXr1o3jEQAQMfiuBABEImJfAJGC5AUAIAEvoTBx4kRr0aKFa2j+4YcfWu/eva127druusKFC9uECRNs7Nixtn79ev/sHfW6UONtrbBQr4u8efO6REXu3LldwmPJkiV23XXXub8ROFtVqzDKly/PKwEAiAh8VwIAAABpj+QFACABJRQOHjxoM2fOtIcfftglMapVq2aVK1dOsJ16V+hy9atQM25v9k7x4sXtxx9/tEmTJrkExcUXX2z33nuvu6+jR4/+7wuIlS4AgAjFdyUAAACQ9kheAAAS+frrr92KiqZNm/ov27Jli/3www+uvNNvv/3mBm5Gjx7tkhxz5sxxPSvkxIkT9q9//cvd/p9//rGsWbO65MXhw4fd6g05XRNwAADCHd+VAAAAQNqK8XlrngEA+H9HjhxxDbc7dOhgrVu3dr0qdu3aZXv37nWrKurXr28vvviiKyl19913uybcjRs3dtvExsba3LlzLU+ePP79qa8aNezOly+fa+wNAECk47sSAAAASFskLwAASXrnnXfs+eeft9WrV7sVGC1btrSqVau664YNG+b6WcybN88lJqZMmWJffvmlVahQwZWH8qicVLZs2djDAIBMie9KAAAAIO2QvAAAJCs+Pt6VfVKiIjAR0bNnT1u5cqVr5F2sWDF3mfpbeH0sVDpKtwMAILPjuxIAAABIG0yHBQAkK3/+/P/7wvj/xMWhQ4dc/4vmzZv7ExeixIVXiZDEBQAgWvBdCQAAAKQNGnYDAE7r4MGDtm/fPluwYIG1atXKNezu2LFjou3UiJtm3ACAaMR3JQAAABBarLwAAJzSgQMHrFOnTu7f3333nfv3uHHj2GsAAPBdCQAAAKQZel4AAE5LjblVKuraa6+1UqVKucvoawEAAN+VAAAAQFoheQEASBUlLdTfgvJQAADwXQkAAACkFZIXAIAUU0NukhYAAPBdCQAAAKQ1khcAAAAAAAAAACCsZMnoBwAAAAAAAAAAABCI5AUAAAAAAAAAAAgrJC8AAAAAAAAAAEBYIXkBAAAAAAAAAADCCskLAAAAAAAAAAAQVkheAAAAAAAAAACAsELyAgAAAAAAAAAAhBWSFwAAAAAAAAAAIKyQvAAAAAAAAAAAAGGF5AUAAAAAAAAAAAgrJC8AAAAAAAAAAEBYIXkBAAAAAAAAAADCCskLAAAAAAAAAAAQVkheAAAAAAAAAACAsELyAgAAAAAAAAAAhBWSFwAyvddff91iYmL8P9myZbMyZcpYt27dbNeuXen+eG677TarUKFCqm6zbds299j1XDLKp59+am3atLGiRYtazpw5rWzZsta1a1f7/vvvLaNNmDDBzjvvPMuRI4fbTwcOHEhyP48YMcLmzJmT6PZ6DkOHDnX7ORSvV6job59zzjlp8n5I6rkCAAAg/WKSkiVL2k033WSbN28Oi92uc16df55pDLJjxw7r1auXVapUyXLlymUFCxa0Zs2a2VtvvWU+n88y0po1a6xp06YWGxvrntO4cePsiy++cP/W/z1z5851cUFSkoslkrqf9OL97ZkzZ4b0fnWfye0HAEhPJC8ARI3Jkyfb8uXLbf78+da9e3ebPn26XXbZZfbXX3+l6+N45JFHbPbs2am6jQIbPXYlDzLCgAED7Oqrr7aTJ0/a888/7/bhkCFDbMWKFXbxxRfbe++9Zxnl22+/td69e9vll19uCxcudPspX758Se7nUyUvhg0bluSA/pm8XgAAAMCpYpLPP//cDfR/8MEHdumll9r+/fsjeod99dVXduGFF9r7779vffr0cROflPQoXbq0/etf/7Kbb77ZxRIZ5fbbb7fdu3fb22+/7fa/kkaKY/Rv/T8weaG4ICnJxRJJ3Q8AIDSyheh+ACDs1axZ0+rWrev+rYHuEydO2GOPPeZOQG+55ZYkb3P48GHLkydPSB+HZiKlllY6XHLJJZYRlOR56qmn7J577nGJC0+TJk1cEKIZTLfeeqtddNFFdu6556bb4/Jemw0bNrjflZCqX7/+We3npITqfgAAAIDAmESrEhSTaFKQYhKtDI9EWvV8/fXXu1UN//nPf6x48eL+69q1a+eSGgMHDnTxgv6fXrRvjx8/7mKp9evXu3hBE7IChSLGyp8/f4bFagCQ2bHyAkDU8k4wt2/fnqBEz7p166xly5Zu9v6VV17prjt27Jg9/vjjVq1aNXfyq9JJCi727duX6H6nTZtmDRs2dPelH52kv/rqq6csQ/Tuu+9agwYN3Am/BuSVBNDsoNMt2V66dKl7jHqsul2jRo3s448/TnKJ+qJFi1wCokiRIla4cGEXYPz666+n3U9PPPGEW/I9ZsyYRNflzZvXlWxSIuGZZ55xl2kJtv7eTz/9lGj7Bx980JV2+v333/2XadaZnoNO+vUcGjdubAsWLEhwOy1Z1n2uXr3aOnTo4B6PkgoK+DSTS7T/tI231D14P+s6rbJ54403/Mv1dXvtnxtvvNGf1PKu8/Z1Uq+XrtdMuTfffNOqV6/uHnetWrXso48+SvScNftMAZuOG72u48eP9z+fM6HHcs0117jZbJrdlTt3bndcvvbaa4m2/frrr93+1LL9UqVK2aBBg+yff/5J8n5nzJjhjlu9pjpuW7Vq5ZbXBx5r2bNnt3//+99JHl+BxzgAAABSxktk/PbbbwkuX7lypV177bVWqFAhdy5Xu3Zte+eddxLdXmVw77rrLlfSVefZOufT+bJ3f3///bfdf//9LiZRrKH70zmfzlFD5ZVXXrG9e/fak08+mSBxEbiKW+ermhClc1HFUHqsWuEc7Mcff3Tnls8++6z/sj179liPHj1c6V/drmLFim51hBITwfHS6NGjXdymbXT+rZUuulzbTpo0yX+un1S5J533P/fcc+7fgSW+vPtOKpZI6n68+9I5tWKi1q1bu3/rNdJrcfTo0QTPeefOne41U0xXoEABN7FOK9zPtGywF2tokpcmm+l11+ui+DIuLi7BtvHx8S6po/hQj/Gqq66yTZs2JXm/Km/WuXNnK1asmNu3ioO8/eUdazpOVc438O/o9StRooQ/WQcAqUHyAkDU8gbXlYjwKEmhIOGKK65wJ/Q6KdbyZs0Y0sm4TtaUHNC/VTpJJ2BHjhzx3/7RRx91J5sKGnSiqXJD6gvhJUiSoiXGnTp1cgPbWsas+9f9BJ6MJ2Xx4sXucerEUAPHWiGhE962bdu6gehgd955pxt8VnJFJ/U6ufYG/pOjpdU66VUyJ7kVKAp+dAKr/SG6TwUVwSfaOlGdOnWqe3xKoIh+130rcaFAQAGZAioNnAcnMEQJF50MK9nzwgsvuJUgDz/8cIIl+EkFQaLrNNCv4EH/1o9ur1JcWgIuOvn2rjtdiS69ThMnTrThw4fbrFmz3OO+7rrrbMuWLf5tlGDQY1YwoNdE+12vk57r2Vi7dq0LfPr16+dPjtxxxx22ZMmSBKWwlBTSTDi9FtpfSkYomAum56/A5vzzz3evgZIyBw8edGXVvJ4mKmeg2z799NOuvIHo2OjZs6d7zfX3AQAAkDpbt251/69SpYr/Mk060gQUncfpHE7ne0o+KGYIPMdW4qJevXou5ujfv7998sknbiKRBqu9MlQaKP/zzz/dBBSt7tC5qM7rdI46ZcqUkLxcigOyZs3qzvOTooF0xVh6HKtWrXLxlybj6Jw4uJSUzukVS3gr4zXwrdXVn332mYuR9Bx13jly5Eg36B5MSQ+VktXEK21bp04dd24vShB45/pJURyhbcTbTj9eCd+kYolTUaJGz1vn5HoNlTzQhK9Ro0b5t1FCRBOo9Jrrcp2LK9Gg1/ps3XDDDe64UqyiFS+KAxU/eNSHpH379u7cX7GFjiNN8AtenSKKCXSsaQWL4gFN2lK8pPK9XpktJdn0+JXI8ibi6fXVa6m/pWNPxwkApIoPADK5yZMnqzuc7+uvv/b9888/voMHD/o++ugjX9GiRX358uXz7dmzx23XtWtXt91rr72W4PbTp093l8+aNSvB5StWrHCXP//88+73LVu2+LJmzeq75ZZbTvl49HfKly/v/33MmDHufg4cOJDsbbZu3eq20XPxXHLJJb5ixYq55+M5fvy4r2bNmr4yZcr4Tp48meD533vvvQnuc/To0e7y3bt3J/t3tc+0zcCBA0/5nBo0aODLnTu3//frr7/ePYYTJ074L5s7d667rw8//ND9/tdff/kKFSrka9u2bYL70m1q1arlq1+/vv+yIUOGuNs++uijif629/z0epxqP0vevHnd5cHeffdddx+LFi1KdF1S96Ntixcv7ouPj/dfpuMoS5YsvpEjR/ovq1evnq9s2bK+o0eP+i/T61W4cGF3H6ejv63HHEiPJVeuXL7t27f7Lzty5Ijblz169PBf1qlTJ/eaeMe3d3xUq1bN/W0dU/LLL7/4smXL5rvvvvsS/B09zhIlSvg6duzov0zHVOvWrX0FChTwrV+/3nf++ee7+zt06NBpnwsAAEA0Syom+fTTT935VpMmTdxlHp1f1a5dO8Flcs011/hKlizpP8e+/fbbfdmzZ/d9//33KX4cOh/U/d5xxx3ubwSfZwaeKycVgyRFj1fP41QmTZrk7mvGjBnu9w8++MD9Pm/evASPrVSpUr4bbrjBf5nOb88555wE576BMdSGDRsSPNZKlSr5jh07lujv67qePXsmuEzn/sExgLZJ7jw9uVgiqfvxYst33nknwbY6l65atar/9+eee85t98knnyTYTs87Jfve+9uKZ4JjJ8V7gRQPKo7w4kT9TW03fvz4BNs98cQT7nLdj6dVq1YuvouLi0uwba9evdx9/vnnn/7L9Brr9uPGjXPxm2KkwNcZAFKDlRcAooZmkWjlgVYnaKaPlq5qNk7w0mbNUAmkWSVavquZRFoN4f1o9pPuw1serBlHWl2gmeipoRks0rFjRzdTRTOoTkczdFRPVjODtLzXo5ks6j+hpccbN25McBvN+gmk2fpyqlUhKaV4ILAMkkpq6TGoJFTgLCrtL28mz7Jly9zsK61MCdyvmp2j5cpaKh3cTD34tclImiGlY8mj40grULz9qceu5f6azaTZYx69XsnNSkspHXvlypXz/65ZTppVFfhaavaWZnkFHt86PoJncWkWm/Z7ly5dErwOuk/1Mwlc/q7XWDP09LxV4kAzBXXMqtQUAAAAUheT6JxX5VA1Kz9btmz+1eEqneStPAg8P9Osf62M9s7zFcvonFTle05Fq5a1kkPnofo7+vtauf3DDz+k20v23/zBf88nRTGBYgPFCIHnpSprG1g+V7GYnqNWtgfuCy+m0Gr04JhHzy8c6LkGn/crBgs8Z9fj946FQFoVfbaSiv9U2kkrI7x4QYL7P6raQCDdRqvitcpcq/GDj0ldr3K1HsW1Klf8wAMPuJXbDz30kLVo0eKsnw+A6ETyAkDU0KCrBsRVOkcnxd999507iQ+kkzGVMAqkerFasq0BaJ0IB/5oGbPXv8Hrf6FarKmhxtdawu0NIOv2auSnZbXJ0TJwBQBawhxMJ/byxx9/JLhcpYsCqU6pBJa9CuYNkHvL2ZOjE3DVcPUomNBj84IRPV6VGtLz85YKe3V4lYAJ3q9aMq3np+RGoKSeb0YJ3p/ePvX2p/caJVX3N6nLQvm3vddfAWGw4Mu810FJtODXQaWuAvuTeH9bgZCCFAVZF1xwwVk9FwAAgGiMSVTaSH0clEAIHKj2zs1U5in43Ozee+911wXGH6eLPd577z03mFy6dGlXslXljvT3lSDQ+VwoKGbQYwmeeBRIfSPEixmURNGkK5UqUqwlKoml832VkA3cHx9++GGifVGjRg13ffC5ajjFC4otNSEo+Jw9cL/rnD0t4oWUxH/623odgrcLjhe0nWJV9ToMfh2UvEjqddDxpbJZun+VlgKAM/Xf1D4ARAHNSPIa4iUnqSbKXoNr9S9Iijf73uudoRUHgQP5KaGeGvpRTVrNWlENV814UXNm9ZQIphlaWbJkcTOvgnlNuL2+EmdDJ/8KDObNm+eacifV90IBkIIKr+l14AoQ1ZxVMKL6qnpuWpHh8R6fToK95umnO2k/0ybXGUGvkR5vcPNFUdIrremYTervBF/mvQ4zZ8608uXLn/Z+tcJIzQ5Ve1jBpmrohtOKGAAAgEiJSbSiQCu31fBa52Ka1OOdmw0aNMj1pUhK1apV/fGHYo9TUcJCzas1KSXwXDq4afTZ0Kx6xQtKMtx0002JrteEHk1kUo849aDwKDZQE2/1/dPqYG3Tt2/fBH0RtD+0YuCJJ55I8m97E7ciMV7wztm/+eabDIsXlJRQciIwgRH8txXXePFdclUGdIx5lMTStloZrlhIvRdD2SAeQHRh5QUAnIZKTOmEToGFAo3gHy94UONpndRpYPdMaTaMSvV4Tdy0SiQpKtPToEEDN5MqcLa9Si4pQNEMrMCmf2dj8ODBbhWBZn8F04mpZtIoqRHY/M0LRjSrSCtINItKSZhq1ar5r9eqF5XjUvO3pParfgLLLYVC8OqEwMtPtwoltfQa6TloVY0awXsOHTrklr+nNQXDWt4dmDzRMRzczF0z2zQj6ueff072dfAoWabm3DpGVfZLKzDUMPF0K3MAAACQtNGjR7vBYTWj1rm8YovKlSvb2rVrkz038yZPabWzSv8El4sNHszXOXXgoL4Gp0M5mKzBaZVPVcLFK0kU/BxVCmvAgAEJSjopkaOYRqu1k5rs5MViahJdqVKlJPdFcPLibJ0qLkguljgbOq8+ePCgKwEWSAmd9IgX5K233kpwuV6LQIr1tK1iUyWSknodApMfd999t/3yyy8uVlV5MiWl1KgcAM4EKy8A4DQ0e0gndFoS26dPHzfjXCfdmuWkYEErJlT/U6skVM/zsccecye1Wv4dGxvrBue1jHbYsGFJ3r8CFd2X+hMo6aCVCuPHj3d/QyezydHqDM1y0omkEgsKSp5//nl3cq+EQahmHel5rF692saMGeOWe2sJsFZEKEjSSagGvXWCe+655ya4nRIVSljoce7YscNeeumlBNer5q5WXajnhcpDaaaZgh4tOVewpv+fTSIoKSpxpB4OmhWmVSUK/BQgqkyX6DHqMi3v1uyhpMozpcbw4cOtTZs2LkGgY0fJA80u03MPLokVag8//LALFK644gp3jCnoeO655xIt59dxq8epJNWWLVv8tZeV9NAsMCVhdOzqsetY0HGl11uJOiWl1H9DM+WWLl0a8mQTAABAZqfzLg36a2Bf51iaKPLiiy+6xITOIW+77TZX8knnjioxpfNy9bAQncNp0FtlaBWH6FxXsYRWjPfv39+dj2vwX4PIKjml822dlyte0bnw5s2bQ/IcNCFJf0N/Sysr1OugVq1aFh8f7ybOKJbS+aIuD6bYQuWztHq8UaNG/olhHj1HrfzVdZo0pes1QUpxydy5c+2FF15IddneU/FKomoymV4DnfNqwF7nucnFEmdDsZBiKr3u6g9x3nnnuddU/T9Eq+3Tiibf6djRsacYQUmIr776yt58881E2yo+vfTSS+2yyy5z/SwUQyjpoh4t2h8qgyZaRaTJdEpIaQW/fnr16mUPPvigm7ymWBoAUiVV7b0BIAJNnjxZ3eF8K1asOOV2Xbt29eXNmzfJ6/755x/fmDFjfLVq1fLlypXLd8455/iqVavm69Gjh2/z5s0Jtp0yZYqvXr16/u1q167tHkPg3ylfvrz/948++sh39dVX+0qXLu3LkSOHr1ixYr7WrVv7vvzyS/82W7dudc8h8H5E21xxxRXucefOndt3ySWX+D788MMUPf9Fixa5y/X/lJg7d657XIULF/Zlz57dPd5bb73Vt2HDhmRv89JLL7m/occWFxeX5DaLFy/2tWnTxleoUCH//er3d99917/NkCFD3P3s27cv0e2Te37B+1m+/fZbX+PGjX158uRxt2natKn/unHjxvkqVqzoy5o1a4J9ndT96PqePXsmeizaTtsHmj17tu+CCy5wr225cuV8Tz75pK93796+ggULJrvfTnVM6m9o/wTTcwl8PvLVV1+5YyJnzpy+EiVK+B544AH/a6JjKtCcOXN8l19+uS9//vxue/2dDh06+D7//HN3/eDBg31ZsmTxLViwIMHtli1b5suWLZuvT58+p30+AAAA0epUMcmRI0fceWLlypV9x48fd5etXbvW17FjRxcb6BxZ53I673/hhRcS3HbHjh2+22+/3V2v7UqVKuVu99tvv/m30flnhQoV3Dle9erVfS+//LL//PpU57LJxSDJ+eWXX9w58rnnnuvOfWNjY31NmjTxTZ061Xfy5Mkkb6MYQbGC/o4eV1IUA+j8Wefqeo6KG+rUqePOTw8dOpTgsT711FNJ3kdS5+9JxUNHjx713Xnnnb6iRYv6YmJiEpw3JxdLJHU/ycWWSe137bfrr7/exY758uXz3XDDDS720nbvv/9+svs78G+nJHbyjsHAOODAgQPu+ClQoIB7Xi1atPD9+OOPbjvdTyDdTtsqXtProH3UqFEj3+OPP+6u/+6779xrGRwP/f333+710jG4f//+Uz4fAAgWo/+kLt0BAADOlBrXabWCZtCpNjAAAAAABBoxYoRbSa3yS6FcWQIAkYayUQAApCH1hFB5Ly0tV31hLW3Xkn8tvQYAAAAQ3SZOnOj+rzJfmuikEkzPPvusKyVF4gJAtCN5AQBAGlItWPUkUQ8P9TG5+OKLXX3e5s2bs98BAACAKKfedOp7oT4ealperlw51yNCKy8AINqlXeefFFiyZIm1bdvWSpUq5RqAzpkzJ8H1qmg1dOhQd33u3LmtWbNmtmHDhgTb6IP9vvvusyJFirimotdee61rfAsAQDh455133PeSvq8OHTrkvvvUFBsAkDaIMQAAkURNy9etW+cmPR07dsw1wVajcjUJB4Bol6HJi7/++stq1arlXyIXbPTo0TZ27Fh3/YoVK6xEiRKu9IY+0D19+/a12bNn29tvv21Lly51A0PXXHONnThxIh2fCQAAAIBwQIwBAAAAZA5h07BbKy+UhGjfvr37XQ9LKy6UnNByOdGs1eLFi9uoUaOsR48eFhcXZ0WLFrU333zTOnXq5Lb59ddfrWzZsq4kR6tWrTL0OQEAAADIOMQYAAAAQOTK0JUXp7J161bX2LRly5b+y3LmzGlNmza1ZcuWud9XrVrlmhkFbqOER82aNf3bAAAAAAAxBgAAABBZwrZhtxIXopUWgfT79u3b/duoBmDBggUTbePdPilawaEfz8mTJ+3PP/+0woULu9lZAAAAAMy/IlplWzVJKEuWsJ37lKExBvEFAAAAEPoYI2yTF57gZIKe2OkSDKfbZuTIkTZs2LCQPUYAAAAgs9uxY4eVKVPGMoNQxxjEFwAAAEDoY4ywTV6oObdodlPJkiX9l+/du9c/U0rbHDt2zPbv359gZpS2adSoUbL3PWjQIOvfv7//d/XOKFeunNtZ+fPnT6NnBAAAAESe+Ph411MuX758FunSKsYgvgAAAABCH2OEbfKiYsWKLnCYP3++1a5d212mIGLx4sWuYbfUqVPHsmfP7rbp2LGju2z37t22fv16Gz16dLL3rd4Z+gmmxAXJCwAAACCxzFBeNa1iDOILAAAAIPQxRoYmLw4dOmQ//fRTgibd3377rRUqVMithOjbt6+NGDHCKleu7H707zx58ljnzp3d9rGxsXbHHXfY/fff7/pV6Hb//ve/7YILLrDmzZtn4DMDAAAAkBGIMQAAAIDMIUOTFytXrrTLL7/c/7tXyqlr1672+uuv24ABA+zIkSN27733umXbDRo0sHnz5iVYTvLMM89YtmzZ3KwobXvllVe622bNmjVDnhMAAACAjEOMAQAAAGQOMT51notyqrGlVRzqfUHZKAAAAIBzZeILAAAAIGPH47Ok0d8HAAAAAAAAAAA4IyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCshHXy4vjx4/bwww9bxYoVLXfu3Hbuuefa8OHD7eTJk/5tfD6fDR061EqVKuW2adasmW3YsCFDHzcAAACA8ESMAQAAAESGsE5ejBo1yl544QWbOHGi/fDDDzZ69Gh76qmnbMKECf5tdNnYsWPdNitWrLASJUpYixYt7ODBgxn62AEAAACEH2IMAAAAIDKEdfJi+fLl1q5dO2vTpo1VqFDBOnToYC1btrSVK1f6V12MGzfOBg8ebNdff73VrFnT3njjDTt8+LBNmzYtox8+AAAAgDBDjAEAAABEhrBOXlx66aW2YMEC27Rpk/t97dq1tnTpUmvdurX7fevWrbZnzx6X0PDkzJnTmjZtasuWLcuwxw0AAAAgPBFjAAAAAJEhm4WxBx980OLi4qxatWqWNWtWO3HihD3xxBN28803u+uVuJDixYsnuJ1+3759e7L3e/ToUffjiY+PT7PnAAAAACBzxxjEFwAAAECUrbyYMWOGTZ061ZWAWr16tSsJNWbMGPf/QDExMQl+Vzmp4MsCjRw50mJjY/0/ZcuWTbPnAAAAACBzxxjEFwAAAECUJS8eeOABGzhwoN100012wQUX2K233mr9+vVzwYGoOXfg7CjP3r17E82UCjRo0CA328r72bFjRxo/EwAAAACZNcYgvgAAAACiLHmhxttZsiR8iFraffLkSffvihUruuBi/vz5/uuPHTtmixcvtkaNGiV7v+qLkT9//gQ/AAAAADK/tIgxiC8AAACAKOt50bZtW1d/tly5clajRg1bs2aNjR071m6//XZ3vZZt9+3b10aMGGGVK1d2P/p3njx5rHPnzhn98AEAAACEGWIMAAAAIDKEdfJiwoQJ9sgjj9i9997rlmmXKlXKevToYY8++qh/mwEDBtiRI0fcNvv377cGDRrYvHnzLF++fBn62AEAAACEH2IMAAAAIDLE+NR5LsrFx8e7xt3qf0EJKQAAAIBzZeILAAAAIGPH48O65wUAAAAAAAAAAIg+JC8AAAAAAAAAAEBYIXkBAAAAAAAAAADCCskLAAAAAAAAAAAQVkheAAAAAAAAAACAsELyAgAAAAAAAAAAhBWSFwAAAAAAAAAAIKyQvAAAAAAAAAAAAGGF5AUAAAAAAAAAAAgrJC8AAAAAAAAAAEBYIXkBAAAAAAAAAADCCskLAAAAAAAAAAAQVkheAAAAAAAAAACAsELyAgAAAAAAAAAAhBWSFwAAAAAAAAAAIKyQvAAAAAAAAAAAAGGF5AUAAAAAAAAAAAgrJC8AAAAAAAAAAEBYIXkBAAAAAAAAAADCCskLAAAAAAAAAAAQVkheAAAAAAAAAACAsELyAgAAAAAAAAAAhBWSFwAAAAAAAAAAIKyQvAAAAAAAAAAAAGGF5AUAAAAAAAAAAAgrJC8AAAAAAAAAAEBYIXkBAAAAAAAAAADCCskLAAAAAAAAAAAQVkheAAAAAAAAAACAsELyAgAAAAAAAAAAhBWSFwAAAAAAAAAAIKyQvAAAAAAAAAAAAGGF5AUAAAAAAAAAAAgrJC8AAAAAAAAAAEBYIXkBAAAAAAAAAADCCskLAAAAAAAAAAAQVkheAAAAAAAAAACAsELyAgAAAAAAAAAAhBWSFwAAAAAAAAAAIKyQvAAAAAAAAAAAAGGF5AUAAAAAAAAAAAgrJC8AAAAAAAAAAEBYIXkBAAAAAAAAAADCCskLAAAAAAAAAAAQVkheAAAAAAAAAACAsJIttTc4evSoffPNN7Zt2zY7fPiwFS1a1GrXrm0VK1ZMm0cIAAAAINMivgAAAABwVsmLZcuW2YQJE2zOnDl27NgxK1CggOXOndv+/PNPF3Cce+65dtddd9ndd99t+fLlS+ndAgAAAIhCxBcAAAAAzrpsVLt27axDhw5WunRp++yzz+zgwYP2xx9/2M6dO93qi82bN9vDDz9sCxYssCpVqtj8+fNTcrcAAAAAohDxBQAAAICQrLxo2bKlvfvuu5YjR44kr9eqC/107drVNmzYYL/++mtK7hYAAABAFCK+AAAAAHA6MT6fz2dRLj4+3mJjYy0uLs7y58+f0Q8HAAAACBucK7PPAAAAgIyIMVLdsDvQ+vXrbfHixXbixAlr1KiR1a1b92zuDgAAAEAUI74AAAAAkKqeF0l57rnn7Morr3TJi0WLFrl/P/HEE2d6dwAAAACiGPEFAAAAgDMqG6Xm3GXKlPH/Xr16dfvyyy+tSJEi7vfly5fbtddea/v27bNIw1J4AAAAIH3PlYkvAAAAgOgUn8IYI8UrL7SyYvz48eblOgoXLmyfffaZHT161A4ePGiff/65FS1aNDSPHgAAAECmRnwBAAAA4FRSnLxYsWKF/fjjj9agQQNbs2aNb2ox0AAAnzFJREFUvfTSSzZ27FjLnTu3FShQwGbMmGFvvPFGSu8OAAAAQBQjvgAAAABwKilu2K3lG5MmTbKvvvrKbrvtNmvevLkrG6Vm3fpRAgMAAAAAiC8AAAAApHvD7saNG9vKlStdTaratWvbkiVLSFwAAAAAOCPEFwAAAADOqmH38ePH7eWXX7bvv//eatWqZd26dbOff/7ZevTo4Zp2T5gwwUqUKGGRiIbdAAAAQPqeKxNfAAAAANEpPtQNu7t37+4SFHnz5rXJkydbv379rEqVKrZo0SJr1aqVNWzY0JWVAgAAAADiCwAAAADpsvKiYMGCtmzZMqtevbodOXLEatas6VZeePbu3Wt9+/a1adOmWaRh5QUAAACQvufKxBcAAABAdIoP9cqLYsWK2bx58+zYsWO2YMECK1y4cKLrIzFxAQAAACD9EV8AAAAAOJVslkITJ060f/3rX9a/f38rWbKkvfPOOym9KQAAAAAQXwAAAAAIffKiRYsWtmfPHvv999+taNGiKf8LAAAAAEB8AQAAACAVUlw2SmJiYkhcAAAAAAgJ4gsAAAAAZ5W8uOqqq1yz7tM5ePCgjRo1yp577rmU3C0AAACAKER8AQAAACAkZaNuvPFG69ixo+XLl8+uvfZaq1u3rpUqVcpy5cpl+/fvt++//96WLl1qc+fOtWuuucaeeuqplNwtAAAAgChEfAEAAADgdGJ8Pp/vtFuZ2bFjx2zmzJk2Y8YM+/LLL+3AgQP/vYOYGDv//POtVatW1r17d6tatapFmvj4eIuNjbW4uDjLnz9/Rj8cAAAAINOfKxNfAAAAANEpPoUxRoqTF8F0x0eOHLHChQtb9uzZLZKRvAAAAAAy9lyZ+AIAAACIDvEpjDFSVDYqKbpz/QAAAADA2SK+AAAAAJDqht0AAAAAAAAAAADpheQFAAAAAAAAAAAIK2GfvNi1a5f961//cr018uTJYxdddJGtWrXKf71adgwdOtRKlSpluXPntmbNmtmGDRsy9DEDAAAACF/EGAAAAED4C+vkxf79+61x48auIfgnn3xi33//vT399NNWoEAB/zajR4+2sWPH2sSJE23FihVWokQJa9GihR08eDBDHzsAAACA8EOMAQAAAGTS5MXnn3+e7HUvvviihdKoUaOsbNmyNnnyZKtfv75VqFDBrrzySqtUqZJ/1cW4ceNs8ODBdv3111vNmjXtjTfesMOHD9u0adNC+lgAAAAAhF56xhdCjAEAAABk0uRFmzZt7P7777djx475L9u3b5+1bdvWBg0aFNIH98EHH1jdunXtxhtvtGLFilnt2rXt5Zdf9l+/detW27Nnj7Vs2dJ/Wc6cOa1p06a2bNmykD4WAAAAAKGXnvGFEGMAAAAAmTR5sWTJEvvwww+tXr16rrfExx9/7FY8HDp0yNauXRvSB7dlyxabNGmSVa5c2T777DO7++67rXfv3jZlyhR3vRIXUrx48QS30+/edUk5evSoxcfHJ/gBAAAAkP7SM75IqxiD+AIAAAAIvWypvUGDBg1szZo17iS/Tp06dvLkSXv88cftgQcesJiYmJA+ON23Vl6MGDHC/a6VFwpoFGx06dLFv13w31U5qVM9lpEjR9qwYcNC+lgBAAAApF56xhdpFWMQXwAAAABh0rB748aNrjl2mTJlLFu2bPbjjz+6PhOhVrJkSTv//PMTXFa9enX75Zdf3L/VnFuCZ0Dt3bs30UypQFp+HhcX5//ZsWNHyB87AAAAgPCKL9IqxiC+AAAAAMIgefHkk09aw4YNrUWLFrZ+/XoXZGim1IUXXmjLly8P6YNr3LixC2QCbdq0ycqXL+/+XbFiRRdczJ8/33+9auUuXrzYGjVqlOz9qi9G/vz5E/wAAAAASH/pGV+kVYxBfAEAAACEQdmo8ePH25w5c+zqq692v9eoUcO++eYbe+ihh6xZs2au3muo9OvXzwUIWtLdsWNH93deeukl9yNatt23b193vWrW6kf/zpMnj3Xu3DlkjwMAAABA2kjP+EKIMQAAAIDIEONT8dZU+P33361IkSJJXqfZSE2bNrVQ+uijj9wy7M2bN7tZUP3797fu3bv7r9fDV/+KF1980fbv3+9q5j733HOuyV9KqWF3bGysKyHFKgwAAAAg/c6V0zu+SI8Yg/gCAAAAOPvz5VQnL+TAgQM2c+ZM+/nnn10jvUKFCtnq1atdDdjSpUtbpCG4AAAAADLuXJn4AgAAAIge8SmMMVJdNuq7776z5s2buzvftm2bm6Gk5MXs2bNt+/btNmXKlLN97AAAAACiBPEFAAAAgJA07NaS6ttuu80tsc6VK5f/ctWoXbJkSWrvDgAAAEAUI74AAAAAEJLkxYoVK6xHjx6JLle5qD179qT27gAAAABEMeILAAAAACFJXmi1hWpSBdu4caMVLVo0tXcHAAAAIIoRXwAAAAAISfKiXbt2Nnz4cPvnn3/c7zExMfbLL7/YwIED7YYbbkjt3QEAAACIYsQXAAAAAEKSvBgzZozt27fPihUrZkeOHLGmTZvaeeedZ/ny5bMnnngitXcHAAAAIIoRXwAAAABISjZLpfz589vSpUtt4cKFtnr1ajt58qRdfPHF1rx589TeFQAAAIAoR3wBAAAAICkxPp/PZ1FOPTxiY2MtLi7OBU8AAAAAOFcmvgAAAAAybjw+RSsvnn322RT/4d69e6d4WwAAAADRh/gCAAAAQEhWXlSsWDHB7+p5cfjwYStQoID7/cCBA5YnTx7XB2PLli0WaVh5AQAAAKTfuTLxBQAAABC94lMYY6SoYffWrVv9P2rKfdFFF9kPP/xgf/75p/vRv9X34rHHHgvlcwAAAACQCRFfAAAAAAh5z4tKlSrZzJkzrXbt2gkuX7VqlXXo0MEFIpGGlRcAAABAxpwrE18AAAAA0SU+lCsvAu3evdv++eefRJefOHHCfvvtt9Q/UgAAAABRi/gCAAAAQEiSF1deeaV1797dVq5cad6iDf27R48e1rx589TeHQAAAIAoRnwBAAAAICTJi9dee81Kly5t9evXt1y5clnOnDmtQYMGVrJkSXvllVdSe3cAAAAAohjxBQAAAICkZLNUKlq0qM2dO9c2bdpkP/74o1t9Ub16datSpUpq7woAAABAlCO+AAAAABCS5IVHyQoSFgAAAABCgfgCAAAAwFklL9SY+/XXX7cFCxbY3r177eTJkwmuX7hwYWrvEgAAAECUIr4AAAAAEJLkRZ8+fVzyok2bNlazZk2LiYlJ7V0AAAAAAPEFAAAAgNAlL95++2175513rHXr1qm9KQAAAAAQXwAAAAA4rSyWSjly5LDzzjsvtTcDAAAAAOILAAAAAGmTvLj//vtt/Pjx5vP5UntTAAAAACC+AAAAABD6slFLly61RYsW2SeffGI1atSw7NmzJ7j+vffeS+1dAgAAAIhSxBcAAAAAQpK8KFCggF133XWpvRkAAAAAEF8AAAAASJvkxeTJk1N7EwAAAAAgvgAAAACQdj0vAAAAAAAAAAAAwmLlRe3atS0mJua0261evfpsHxMAAACATI74AgAAAEBIkhft27dP6aYAAAAAQHwBAAAA4IzF+Hw+n0W5+Ph4i42Ntbi4OMufP39GPxwAAAAgbHCuzD4DAAAAMiLGoOcFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLCSLbU3ePbZZ5O8PCYmxnLlymXnnXeeNWnSxLJmzRqKxwcAAAAgEyO+AAAAABCS5MUzzzxj+/bts8OHD1vBggXN5/PZgQMHLE+ePHbOOefY3r177dxzz7VFixZZ2bJlU3v3AAAAAKII8QUAAACAkJSNGjFihNWrV882b95sf/zxh/3555+2adMma9CggY0fP95++eUXK1GihPXr1y+1dw0AAAAgyhBfAAAAAEhKjE9LJ1KhUqVKNmvWLLvooosSXL5mzRq74YYbbMuWLbZs2TL37927d1skiI+Pt9jYWIuLi7P8+fNn9MMBAAAAouZcmfgCAAAAiC7xKYwxUr3yQgmJ48ePJ7pcl+3Zs8f9u1SpUnbw4MHU3jUAAACAKEN8AQAAACAkyYvLL7/cevTo4VZaePTve+65x6644gr3+7p166xixYqpvWsAAAAAUYb4AgAAAEBIkhevvvqqFSpUyOrUqWM5c+Z0P3Xr1nWX6TpR4+6nn346tXcNAAAAIMoQXwAAAAAISc8Lz48//ugadevm1apVs6pVq1qkoucFAAAAkLHnysQXAAAAQHSIT2GMke1M/4ASFvoBAAAAgLNFfAEAAADgrJIXJ06csNdff90WLFhge/futZMnTya4fuHCham9SwAAAABRivgCAAAAQEiSF3369HHJizZt2ljNmjUtJiYmtXcBAAAAAMQXAAAAAEKXvHj77bftnXfesdatW6f2pgAAAABAfAEAAADgtLJYKuXIkcPOO++81N4MAAAAAIgvAAAAAKRN8uL++++38ePHm8/nS+1NAQAAAID4AgAAAEDoy0YtXbrUFi1aZJ988onVqFHDsmfPnuD69957L7V3CQAAACBKEV8AAAAACEnyokCBAnbdddel9mYAAAAAQHwBAAAAIG2SF5MnT07tTQAAAACA+AIAAABA2vW8AAAAAAAAAAAAyPCVFxdffLEtWLDAChYsaLVr17aYmJhkt129enUoHx8AAACATIb4AgAAAEBIkhft2rWznDlz+v99quQFAAAAABBfAAAAADgbMT6fz2dRLj4+3mJjYy0uLs7y58+f0Q8HAAAACBucK7PPAAAAgIyIMVLd8+Lcc8+1P/74I9HlBw4ccNcBAAAAAPEFAAAAgLOR6uTFtm3b7MSJE4kuP3r0qO3cufOsHgwAAACA6EJ8AQAAAOCMe17IBx984P/3Z5995pZ1eJTMUEPvihUrpvTuAAAAAEQx4gsAAAAAIUletG/f3v/vrl27Jrgue/bsVqFCBXv66adTencAAAAAohjxBQAAAICQJC9Onjzp/q/VFStWrLAiRYqk9KYAAAAAQHwBAAAAIO16XgwbNszy5cuX6PJjx47ZlClTUnt3AAAAAKIY8QUAAACApMT4fD6fpULWrFlt9+7dVqxYsQSX//HHH+6ypJp5h7v4+HjXwyMuLs7y58+f0Q8HAAAAiJpzZeILAAAAILrEpzDGSPXKC+U6YmJiEl2+c+fOBE28AQAAAID4AgAAAECa9ryoXbu2S1ro58orr7Rs2f53U6222Lp1q1111VVn9CAAAAAARBfiCwAAAAAhSV60b9/e/f/bb7+1Vq1a2TnnnOO/LkeOHFahQgW74YYbUnp3AAAAAKIY8QUAAACAkCQvhgwZ4v6vJEWnTp0sV65cKb0pAAAAABBfAAAAAAh98sLTtWvX1N4EAAAAAIgvAAAAAIQ2eVGoUCHbtGmTFSlSxAoWLJhkw27Pn3/+mfK/DgAAACDqEF8AAAAACEny4plnnrF8+fK5f48bNy4lNwEAAAAA4gsAAAAAaZe8WLt2rXXo0MFy5sxpFStWtEaNGlm2bKmuOAUAAAAAxBcAAAAATivL6TcxmzBhgh06dMj9+/LLL6c0FAAAAIAzRnwBAAAAICTJiwoVKtizzz5rixcvNp/PZ8uXL7clS5Yk+ZOWRo4c6fpt9O3b13+ZHs/QoUOtVKlSljt3bmvWrJlt2LAhTR8HAAAAgDMXLvGFEGMAAAAA4SlFtZ+eeuopu/vuu/0n9tddd12S2+m6EydOWFpYsWKFvfTSS3bhhRcmuHz06NE2duxYe/31161KlSr2+OOPW4sWLWzjxo3+Ph0AAAAAwkc4xBdCjAEAAABE+MqL9u3b2549eyw+Pt7NjNq0aZPt378/0c+ff/6ZJg9SJatuueUWe/nll61gwYL+y/VY1EB88ODBdv3111vNmjXtjTfesMOHD9u0adPS5LEAAAAAODsZHV8IMQYAAACQCZIXnly5ctlrr73m/h8bG5vkT1ro2bOntWnTxpo3b57g8q1bt7qgp2XLlv7L1FS8adOmtmzZsmTv7+jRoy5QCvwBAAAAkL4yKr4IdYxBfAEAAABkcPIiW7Zsdu+996bp0u1gb7/9tq1evdotKQ+moEKKFy+e4HL97l2XFN1XYEBUtmzZNHjkAAAAAMItvkiLGIP4AgAAAMjg5IU0aNDAvv32W0sPO3bssD59+tjUqVPdbKzkqBZuIC09D74s0KBBgywuLs7/o78DAAAAIP2lZ3yRVjEG8QUAAACQQQ27A2lmVP/+/d1Jf506dSxv3rwJrg9uqH02Vq1aZXv37nV/x6NZWUuWLLGJEye6ptyiGVAlS5b0b6PbBM+UCqRl3/oBAAAAkLHSM75IqxiD+AIAAAAIg+RFp06d3P979+7tv0wzkLyZSKFc8n3llVfaunXrElzWrVs3q1atmj344IN27rnnWokSJWz+/PlWu3Ztd/2xY8ds8eLFNmrUqJA9DgAAAABpIz3jCyHGAAAAADJp8kIN7NJLvnz5rGbNmgku00yswoUL+y/v27evjRgxwipXrux+9O88efJY586d0+1xAgAAADgz6RlfCDEGAAAAkEmTF+XLl7dwMmDAADty5Ihbbr5//35XM3fevHkuKAEAAAAQ3sItvhBiDAAAACDjxfi0HjuV3nzzTXvhhRfcLKnly5e7gGPcuHFWsWJFa9eunUWa+Ph4i42Ndc278+fPn9EPBwAAAIiqc2XiCwAAACB6xKcwxsiS2jueNGmSa6jXunVrO3DggL8GbYECBVwCAwAAAACILwAAAACcjVQnLyZMmGAvv/yyDR482LJmzeq/vG7duomaawMAAAAA8QUAAACANE9eqFRU7dq1E12eM2dO++uvv1L9AAAAAABEL+ILAAAAACFJXqivxbfffpvo8k8++cTOP//81N4dAAAAgChGfAEAAAAgKdkslR544AHr2bOn/f3336Ze3998841Nnz7dRo4caa+88kpq7w4AAABAFCO+AAAAABCS5EW3bt3s+PHjNmDAADt8+LB17tzZSpcubePHj7ebbroptXcHAAAAIIoRXwAAAABISoxPyyfO0O+//24nT560YsWKWSSLj4+32NhYi4uLs/z582f0wwEAAACi8lyZ+AIAAADI/OJTGGOkuufFsGHD7Oeff3b/LlKkSMQnLgAAAABkHOILAAAAACFJXsyaNcuqVKlil1xyiU2cONH27duX2rsAAAAAAOILAAAAAKFLXnz33Xfu54orrrCxY8e6fhetW7e2adOmuR4YAAAAAEB8AQAAACDDel7IV1995RIX7777rv3999+uXlWkoecFAAAAEB7nysQXAAAAQOaWZj0vguXNm9dy585tOXLksH/++eds7w4AAABAFCO+AAAAAHDGyYutW7faE088Yeeff77VrVvXVq9ebUOHDrU9e/awVwEAAAAQXwAAAAA4K9lSe4OGDRvaN998YxdccIF169bNOnfu7PpeAAAAAADxBQAAAIAMSV5cfvnl9sorr1iNGjVC8gAAAAAARC/iCwAAAAAhbdj9+++/W0xMjBUuXNgiHQ27AQAAgIw9Vya+AAAAAKJDfFo07D5w4ID17NnTihQpYsWLF7dixYq5f/fq1ctdBwAAAADEFwAAAADSrWzUn3/+6fpd7Nq1y2655RarXr26adHGDz/8YK+//rotWLDAli1bZgULFjzrBwUAAAAgcyO+AAAAABCS5MXw4cMtR44c9vPPP7tVF8HXtWzZ0v3/mWeeSeldAgAAAIhSxBcAAAAATiXFZaPmzJljY8aMSZS4kBIlStjo0aNt9uzZKb07AAAAAFGM+AIAAABASJIXu3fvtho1aiR7fc2aNW3Pnj0pvTsAAAAAUYz4AgAAAEBIkhdqzL1t27Zkr9+6dasVLlw4pXcHAAAAIIoRXwAAAAAISfLiqquussGDB9uxY8cSXXf06FF75JFH3DYAAAAAQHwBAAAA4GzE+Hw+X0o23Llzp9WtW9dy5sxpPXv2tGrVqrnLv//+e3v++eddAmPlypVWtmxZizTx8fEWGxtrcXFxlj9//ox+OAAAAECmP1cmvgAAAACiU3wKY4xsKb3DMmXK2PLly+3ee++1QYMGmZfziImJsRYtWtjEiRMjMnEBAAAAIP0RXwAAAAA4lRQnL6RixYr2ySef2P79+23z5s3usvPOO88KFSqUmrsBAAAAAOILAAAAAKFJXngKFixo9evXP5ObAgAAAADxBQAAAIDQNOwGAAAAAAAAAABIDyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAPiNHDnS6tWrZ/ny5bNixYpZ+/btbePGjcnuoR49elhMTIyNGzfutHvxwIED1rNnTytZsqTlypXLqlevbnPnzvVfX6FCBXdfwT+6DQAAAKJLtox+AAAAAACA8LF48WKXLFAC4/jx4zZ48GBr2bKlff/995Y3b94E286ZM8f+85//WKlSpU57v8eOHbMWLVq4hMjMmTOtTJkytmPHDpck8axYscJOnDjh/339+vXuNjfeeGOInyUAAADCHckLAAAAAIDfp59+mmBvTJ482SUcVq1aZU2aNPFfvmvXLuvVq5d99tln1qZNm9Puwddee83+/PNPW7ZsmWXPnt1dVr58+QTbFC1aNMHvTz75pFWqVMmaNm3KKwQAABBlKBsFAAAAAEhWXFyc+3+hQoX8l508edJuvfVWe+CBB6xGjRop2nsffPCBNWzY0K3qKF68uNWsWdNGjBiRYKVF8EqNqVOn2u233+5KRwEAACC6sPICAAAAAJAkn89n/fv3t0svvdQlGzyjRo2ybNmyWe/evVO857Zs2WILFy60W265xfW52Lx5s0tkqDTVo48+mmh7laRSj4zbbruNVwcAACAKkbwAAAAAACRJZaG+++47W7p0qf8ylY8aP368rV69OlUrIrRaQ+WnXnrpJcuaNavVqVPHfv31V3vqqaeSTF68+uqrdvXVV6eonwYAAAAyH8pGAQAAAAASue+++1ypp0WLFrnm2p4vv/zS9u7da+XKlXOrL/Szfft2u//++61ChQrJ7smSJUtalSpVXOLCU716dduzZ48rERVI9/f555/bnXfeySsDAAAQpVh5AQAAAABIUCpKiYvZs2fbF198YRUrVkywd9Tronnz5gkua9Wqlbu8W7duye7Jxo0b27Rp09wKjCxZ/juPbtOmTS6pkSNHjiSbhKekETgAAAAyJ5IXAAAAAAA/9aFQkuH999+3fPnyuZUREhsba7lz57bChQu7n0DZs2e3EiVKWNWqVf2XdenSxUqXLm0jR450v99zzz02YcIE69Onj0uOqOeFGnYH981QckPJi65du7pVHQAAAIhOnAkCAAAAAPwmTZrk/t+sWbMEe0UJhdQ0z/7ll1/8KyykbNmyNm/ePOvXr59deOGFLrGhRMaDDz6Y4HYqF6Xb3n777bwqAAAAUSzGpzXBUS4+Pt7NIoqLi7P8+fNn9MMBAAAAwgbnyuwzAAAAICNiDBp2ZwJahl2vXj23pFt1Ydu3b28bN25MsM17773n6tAWKVLEYmJi7Ntvv03RfY8bN84t/dbycM2U0iypv//+23/9wYMHrW/fvla+fHm3TaNGjWzFihUhf44AAAAAAAAAgOhB8iITWLx4satL+/XXX9v8+fPt+PHj1rJlS/vrr7/82+jfapD35JNPpvh+33rrLRs4cKANGTLEfvjhB3v11VdtxowZNmjQIP82d955p/ubb775pq1bt879XTXv27VrV8ifJwAAAAAAAAAgOlA2KhMuhd+3b59bgaGkRpMmTRJct23bNqtYsaKtWbPGLrroolPeT69evVzSYsGCBf7L7r//fvvmm2/syy+/tCNHjrjVHmrk16ZNG/82ut9rrrnGHn/88TR4dgAAAEhPme1cOT2wzwAAAICzP1+mYXcmpBddChUqdFb3c+mll9rUqVNdsqJ+/fq2ZcsWmzt3rnXt2tVdrxUeJ06csFy5ciW4ncpHLV269Kz+NgAAAICzU2Hgx+zC/7ftyf9NtgIAAEBkIHmRyaj/ev/+/V3ioWbNmmd1XzfddJNbxaH70v0qWXHPPfe4UlKiVRcNGza0xx57zKpXr27Fixe36dOn23/+8x+rXLlyiJ4RAAAAAAAAACDa0PMik1Gpp++++84lEc7WF198YU888YQ9//zztnr1atf0+6OPPnLJCo96XSixUbp0acuZM6c9++yz1rlzZ8uaNetZ/30AAAAAAAAAQHRi5UUmct9999kHH3xgS5YssTJlypz1/T3yyCN26623uqbccsEFF7jG33fddZcNHjzYsmTJYpUqVXK9NXS5apWVLFnSOnXq5PpqAAAAAAAAAABwJlh5kQlo5YNWXGhlxMKFC0OWODh8+LBLUATSigr9Pf0Eyps3r0tc7N+/3z777DNr165dSB4DAAAAAAAAACD6sPIiE+jZs6dNmzbN3n//fdeHYs+ePe5ydWxX82z5888/7ZdffrFff/3V/b5x40b3/xIlSrgf6dKliyv/NHLkSPd727ZtbezYsVa7dm1r0KCB/fTTT241xrXXXusvC6VEhRIZVatWddc/8MAD7t/dunXLkH0BAAAAAAAAAIh8JC8ygUmTJrn/N2vWLMHlkydPtttuu839W+WkAhMKasYtQ4YMsaFDh7p/K7kRuNLi4YcftpiYGPf/Xbt2WdGiRV1CQ30wPHFxcTZo0CDbuXOnFSpUyG644QZ3ffbs2dP4WQMAAAAAAAAAMqsYX3D9nyikXg1apaCB+Pz582f0wwEAAADCBufKkbvPKgz8OMP+drjZ9mSbjH4IAAAASOX5Mj0vAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLCSLaMfAP6LZnr/QzM9AAAAAAAAAIhurLwAAAAAAAAAAABhheQFAAAAAAAAAAAIK2GdvBg5cqTVq1fP8uXLZ8WKFbP27dvbxo0bE2zj8/ls6NChVqpUKcudO7c1a9bMNmzYkGGPGQAAAED4IsYAAAAAIkNYJy8WL15sPXv2tK+//trmz59vx48ft5YtW9pff/3l32b06NE2duxYmzhxoq1YscJKlChhLVq0sIMHD2boYwcAAAAQfogxAAAAgMgQ1g27P/300wS/T5482a3AWLVqlTVp0sStuhg3bpwNHjzYrr/+erfNG2+8YcWLF7dp06ZZjx49MuiRAwAAAAhHxBgAAABAZAjrlRfB4uLi3P8LFSrk/r9161bbs2ePW43hyZkzpzVt2tSWLVuW7P0cPXrU4uPjE/wAAAAAiD6hiDGILwAAAIAoTl5olUX//v3t0ksvtZo1a7rLFFSIVloE0u/edcnVuY2NjfX/lC1bNo0fPQAAAIDMGmMQXwAAAABRnLzo1auXfffddzZ9+vRE18XExCQKQoIvCzRo0CA3w8r72bFjR5o8ZgAAAACZP8YgvgAAAACirOeF57777rMPPvjAlixZYmXKlPFfrubcohlQJUuW9F++d+/eRDOlAmnZt34AAAAARKdQxhjEFwAAAECUrbzQ7CbNhnrvvfds4cKFVrFixQTX63cFF/Pnz/dfduzYMVu8eLE1atQoAx4xAAAAgHBGjAEAAABEhrBeedGzZ0+bNm2avf/++5YvXz5/jVn1qcidO7dbtt23b18bMWKEVa5c2f3o33ny5LHOnTtn9MMHAAAAEGaIMQAAAIDIENbJi0mTJrn/N2vWLMHlkydPtttuu839e8CAAXbkyBG79957bf/+/dagQQObN2+eS3YAAAAAADEGAAAAEHnCvmxUUj9e4kK0+mLo0KG2e/du+/vvv13JqJo1a2bo4wYAAAAQnogxkN7UV6Vt27ZWqlQpF7/OmTMnwfWKb3V54M8ll1xy2vudNWuWnX/++a7niv4/e/bsBNcfPHjQVSooX768q1yg0sorVqwI+fMDAACIyuQFAAAAAACR7K+//rJatWrZxIkTk93mqquuchPyvJ+5c+ee8j6XL19unTp1sltvvdXWrl3r/t+xY0f7z3/+49/mzjvvdP0h33zzTVu3bp21bNnSmjdvbrt27Qrp8wMAAIjKslEAAAAAAESyq6++2v2cilZPlChRIsX3OW7cOGvRooUNGjTI/a7/qwqBLp8+fborrayVGeof2aRJE7eNKhZo1YfKMz/++ONn+awAAADSHisvAAAAAADIQF988YUVK1bMqlSpYt27d7e9e/eeduWFVlIEatWqlS1btsz9+/jx43bixAnLlStXgm1UPmrp0qVp8AwAAABCj+QFAAAAAAAZRKsy3nrrLVu4cKE9/fTTri/FFVdcYUePHk32Nnv27LHixYsnuEy/63LJly+fNWzY0B577DH79ddfXSJj6tSprqyUylIBAABEAspGAQAAAACQQdS7wlOzZk2rW7eua7L98ccf2/XXX5/s7dTYO7gZfeBl6nVx++23W+nSpS1r1qx28cUXW+fOnW316tVp9EwAAABCi5UXAAAAAACEiZIlS7rkxebNm5PdRv0xvFUWHpWaClyNUalSJdcH49ChQ7Zjxw775ptv7J9//rGKFSum6eMHAAAIFZIXAAAAAACEiT/++MMlG5TESI5KQs2fPz/BZfPmzbNGjRol2jZv3rzuvvbv32+fffaZtWvXLk0eNwAAQKhRNgoAAAAAgDSilQ8//fST//etW7fat99+a4UKFXI/Q4cOtRtuuMElGLZt22YPPfSQFSlSxK677jr/bbp06eLKP40cOdL93qdPH2vSpImNGjXKJSPef/99+/zzzxM041aiQqWkqlat6v7+Aw884P7drVs3XmsAABARSF4AAAAAAJBGVq5caZdffrn/9/79+7v/d+3a1SZNmmTr1q2zKVOm2IEDB1wCQ9vOmDHDNd32/PLLL5Yly/8KJ2iFxdtvv20PP/ywPfLII65ElG7ToEED/zZxcXE2aNAg27lzp0uSKEHyxBNPWPbs2XmtAQBARIjxaSpGlIuPj7fY2Fh3cpc/f/4MeQwVBn6cIX83HG17sk1GPwQAAACE0blypAmXfUaM8T/EGAAAAJF3vkzPCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVGnYDAAAAAHAK9A/5H/qHAACA9MLKCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAAAAAACCskLwAAAAAAAAAAABhheQFAAAAAAAAAAAIKyQvAAAAAAAAAABAWCF5AQAAAAAAAAAAwgrJCwAAAAAAAAAAEFZIXgAAAAAAAAAAgLBC8gIAAAAAAAAAAIQVkhcAAAAAACAiHT9+3B5++GGrWLGi5c6d284991wbPny4nTx58pS3e+utt6xWrVqWJ08eK1mypHXr1s3++OMP//XNmjWzmJiYRD9t2rRJh2cFAAAkG7sBAAAAAABEolGjRtkLL7xgb7zxhtWoUcNWrlzpEhGxsbHWp0+fJG+zdOlS69Kliz3zzDPWtm1b27Vrl919991255132uzZs9027733nh07dsx/GyU2lOy48cYb0+25AQAQ7UheAAAAAACAiLR8+XJr166df0VEhQoVbPr06S6JkZyvv/7abde7d2/3u1Zt9OjRw0aPHu3fplChQglu8/bbb7tVGiQvAABIP5SNAgAAAAAAEenSSy+1BQsW2KZNm9zva9eudSsrWrdunextGjVqZDt37rS5c+eaz+ez3377zWbOnHnKklCvvvqq3XTTTZY3b940eR4AACAxkhfAaWhGTlK1Tnv27Jnk9rfddluS22sJc6Bx48ZZ1apVXV3WsmXLWr9+/ezvv//m9QAAAACAFHrwwQft5ptvtmrVqln27Nmtdu3a1rdvX3fZqZIX6nnRqVMny5Ejh5UoUcIKFChgEyZMSHL7b775xtavX+/KSgEAgPRD8gI4jRUrVtju3bv9P/Pnz3eXJ7dcePz48Qm237Fjh1tyHLi9TpQHDhxoQ4YMsR9++MHN4pkxY4YNGjSI1wMAAAAAUkhx1NSpU23atGm2evVq1/tizJgx7v/J+f77713JqEcffdRWrVpln376qW3dutX1vUiK4rWaNWta/fr1M/XrktqJe4G++uory5Ytm1100UUJLqfxOQDgbNDzAjiNokWLJvj9ySeftEqVKlnTpk2T3F6N4fTjmTNnju3fv981jQusy9q4cWPr3Lmz/yRRM4M0owcAAAAAkDIPPPCAmximkk5ywQUX2Pbt223kyJHWtWvXJG+j6xSP6bZy4YUXunJQl112mT3++ONWsmRJ/7aHDx92/S6GDx8eFRP3Tpw44f9dq01atGhx2j4fcXFxrgH6lVde6UpwBaLxOQDgbLDyAkiFY8eOuVk9t99+u5uBkhKapdO8eXMrX758grqsmuHjJSu2bNni6q2eqsYqAAAAACAhJReyZEk4tJE1a1Y7efJkqm8j6oER6J133rGjR4/av/71r6iYuKcSWt7PRx99dMqJex41O9fEvIYNGya6TlUIAu9TlQxofA4ASClWXgCpoFUUBw4ccH0tUkJloz755BO3hDmQZgXt27fPJTF0cnz8+HG755573IwhAAAAAEDKtG3b1p544gkrV66c6zO4Zs0aGzt2rJtw5lF53l27dtmUKVP8t+nevbtNmjTJWrVq5eI29clQWahSpUolmozWvn17K1y4cFRO3Ovfv/8pJ+5NnjzZfv75Z7etVq2cDo3PAQCpQfICSAWdaF199dWJTmiT8/rrr7vGbzrZDfTFF1+4E+znn3/eGjRoYD/99JP16dPHLU9+5JFHeE0AAAAAIAXUZFsx1L333mt79+51sZpWAqifhUfJiV9++cX/uyajHTx40CZOnGj333+/i9muuOIKGzVqVIL73rRpky1dutTmzZsXda9FSibubd682U3A+/LLL12/i9PxGp8rrgYAICUoGwWkkOqmfv7553bnnXemaHutqHjttdfs1ltvtRw5ciS4TifXulz3pZqs1113nY0YMcLVXj3V8mYAAAAAwP/ky5fPxo0b5+K1I0eOuFUAWgEQGINpUpkmkAW67777bMOGDa6E1K+//upWDpQuXTrBNlWqVHFxnfo+RJvTTdxTbwyViho2bJjbTym9z2hofO7Rah+VG9OqHZXKUjNzlY9OjhJl6sWi7XPnzm3VqlWzZ555JsE2L7/8suvNUrBgQfejEtXR0juT/QlEJ1ZeACmk5bDFihVLcV+KxYsXuxUVd9xxR4prrOrEOLjGKgAAAAAA6T1xT822k6OVKytXrnRlunr16uUu00Q8xbNahaHVKlrNEo2Nz2X//v0uEXH55Ze7UtIaS1BiTat8kqOm8dqXXgN5JTO0ikj/vuuuu9w2SsLdfPPN1qhRI8uVK5eNHj3aWrZs6RJxwcm3zIT9CUQvkhdACugkTMmLrl27JloOG1w/NXBWiUpCaWZJMNVYVR3W2rVr+8tGaTXGtdde628UBwAAAABAOE7cy58/v61bty7BZSqLvHDhQps5c6ZVrFgxahufi0qQlS1b1u1LT4UKFU55G40P6CdweyWQVJbLS1689dZbiVZiaH8vWLDAunTpYpkV+xOIXpSNAlJAs05UIzWw6Vty9VMlLi7OZs2aleSqC3n44YddbVX9//zzz3fbqVHciy++yOsBAAAAAAjLiXveALkqCWiiXuCPEh5aDaB/a7VANDc+/+CDD6xu3bp24403uv2ipIQSDamhVS3Lli2zpk2bJruNVrT8888/VqhQIcvM2J9A9GLlBZACWoaZXDkn1U8NFhsb604ikn3jZctmQ4YMcT8AAAAAEE0qDPw4ox9CWNj2ZMpKEofzxL2UiMbG51u2bLFJkyZZ//797aGHHnJ9KXr37m05c+Y87QqJMmXK2L59++z48eM2dOjQU/bdVMN0lYtS74vMjP0JRC+SFwAAAAAAAEj1xL1AGmjXTzCv8Xm0rWDRyosRI0a437XyQn0plNA4XfJCZaIOHTpkX3/9tUtOnHfeea7PRTD1u5g+fbrrg6EVL5kZ+xOIXpSNApBhRo4caTExMda3b99Tbqe6nrVq1bI8efJYyZIlrVu3bvbHH3/4r9cyWTV+q1Spkjtp07affvppOjwDAAAAAAASUtyqEtGBqlevnqKVK+oXcsEFF1j37t2tX79+SSaExowZ4xIjWs2iBt+ZHfsTiF4kLwBkiBUrVthLL7102hMtLS/WzBT1BdFMlXfffdfdNnDprHqHqF/IhAkT7Pvvv7e7777brrvuOlcjFAAAAACA9NS4cWPbuHFjovJZ5cuXT9X9aMWKGp0Heuqpp+yxxx5zE/a0uiMasD+B6EXZKGRK1FAN7zqqWgJ7yy23uIZljz/++Cm31VLZChUquPqg3iyUHj16uCWynjfffNMGDx5srVu3dr/fc8899tlnn9nTTz9tU6dOTeNnAwAAAADA/2jFRKNGjdzqiI4dO7qeF5q8p5/ABui7du2yKVOmuN+fe+45K1eunFWrVs0/kU8rLO677z7/bRQHP/LIIzZt2jQXJ+/Zs8ddfs4557ifzIr9CUQvVl4ASHc9e/a0Nm3apKipmE74du7caXPnznWzTn777TebOXOmu71HM1GCa3zmzp3bnewBAAAAAJCe6tWrZ7Nnz3Y9KWrWrOlWSowbN85N4kuuAbr6OiihcdFFF7kVFaos8OSTT7oSyZ7nn3/ejh07Zh06dHCllLwfJTkyM/YnEL1YeQEgXb399tu2evVqV/opJZS8UM+LTp062d9//23Hjx+3a6+91p3IeVq1amVjx461Jk2auL4XCxYssPfff99OnDiRhs8EAAAAADIWVQfCt+rANddc436SE9wAXSssAldZJGXbtm0WrdifadeL9KGHHrI+ffq4BFtyFi9ebP3793flvEuVKmUDBgxwJbs9qqyhVUTr1693v9epU8etPKpfv34aPXJEC1ZeAEg3O3bscF+IKuUUvFIiOephoZJRjz76qK1atcrV9dy6dWuCL8nx48db5cqV3fLaHDlyWK9evVxT76xZs6bhswEAAAAAAMjcvUg1BqMy3ZdddpnrLapkh8ZpZs2a5d/miy++sJtvvtkWLVpky5cvdyXQWrZs6UqjZWaTJk1y+y9//vzup2HDhvbJJ5+c8jaqHqLS5+qBkzNnTjcJ97XXXvNf/88//7gVV7o8V67/a+9MwG2s2j+8yJixJEMKzYWKIkNJH2XoExoQaRIpISpThTRqQAOigdSnjyQhlUqDNJKkZKpQKtMnDSrF+7/up//avWfbh3M45+zpd1/Xuc7Z7x7O3muvd73rmX5PEXfiiSeaLyxdUfBCCJFnEHzYsGGDReALFChgP0TvH3zwQfs7VqUEWQA057rxxhvtgkCVBaWyLOyU2ULZsmXd9OnT3a+//urWrFnjli1bZnqf9MdIZbJ7kURGi7EsU6aMyWoR7BkxYsQu2T/58uXb5YeqFyGEEEIIIYQQQiQ/4V6kBxxwwG4f+8gjj1gwgsqM4447zl155ZXuiiuuyCBXhmLGNddcY7Jn+Bp4XaTQUMZIZSpVqmTybgsWLLCff/3rX65Vq1ZWoZIZ9MFhXB5//HG3fPlyk5fzvW7g5ptvdmPHjjXFkaVLl1rybps2bSxwlI4oeCGEyDMaN27slixZ4j755JPID1qeXDD5O1alxLZt21z+/BmXKv84emCEISJ9yCGHmLQUGQBcMFKZ7F4kixUrZlUpb7/9tvviiy/sgshPuGkcEAghMBT+yWqlTLoEghiTDh06uGOOOcbm53XXXRfzcczD448/3rIp+I3ubaqzN5knBDEJajLPDj/8cNsch1HmiRBCCCGEEELEpxcplRRUUYQhsRQ/BLZaLPDlcN+BBx7oUpmWLVtaVcrRRx9tP3fccYcl077//vsxH08FBfYvfV0Z+ypVqpi0FpLpnqeeesqqW3jdww8/3F199dU23vfff38efrLEQT0vhBB5RokSJaxZWbRDnUoAf5wGZZQVopXoLwRdunQxhyiLNU5jHMUs7ugswgcffGDPIcLP7yFDhliEHw3GVIaxCcNFknHiIlmtWrVdHl+zZk378XCRnDZtmps3b57r2rVr5DiVFuXLl3fphA8EHXnkkXb7ySeftEAQmQ2xxpIyTyp+KPWMrl4Jb/Do1UJzPrIkCFyQYUEFzKmnnupSleyOpS9B5jxHUm7+/PmWscP4nn/++fYYgmzcR/YOGSmvvPKKjem7776bYU4LIYQQQgixL6iHSA72DxlSSpMxMhZbk7oX6Q8//ODKlSuX4Ri3SRzdtGmTNY2Ppn///pZcmpXgSKqAmsizzz5rqiAk8cVixowZlsR7zz33WJACnxh9XfEboJDh/Q3RCaRFixY1X0I6osoLIURCQXBi7dq1kduXXXaZNeN++OGHLcBx4YUXWrY7TncPkkY4N8lsx6HJBZJFvXTp0i6dLpJsQHZ3kYwGZzLO3zPOOGOX8lG0F3FC0xQtHUoTs5stQeCHXiuXXHKJK1Uq9qacktqzzjrLAnI43PlN9dHumqCl41hmpQQ5nTNPkM6rXbu2BX8PPvhg17p1ayst3h2sm7Hk38LBo0aNGsV8DNlXQgghhBBCiNRkb3qRArZCGK+EEX0ccMwjhYTfJtVVHACFEWxeFBeQeCJxEf9ULL766ivzV9HYnMdhB0+dOtUqYTzYuvjBVq5caYm5r776qnvhhRci0unphiovhBBxhaZO0T0XounRo4f9ZAbOd3QA0xEukgQrCOBwsdzdRdJDUGLjxo2WJUGVCs5iD052voMaNWq4n376yRz09MlYvHixNUVPB7KSLZEVqLzo3bt3hmNsQlI9eJHdscysBBn9T8qMCxYsmNaZJ5QUs5ElgME5S7UP48WaR5ZOLDhvqX7x8DyavBH89WBIbN++PXJ78+bNuzxGCCGEEEIIkbq9SMN2G/LSJI1ie0VLeqPMQPVFGF6D3qUoaYQhCe3OO+90r7322h4bgacKJNgihf7jjz+adPSll15qdlws3wzBCAI+9AjxiZAEKi644AI3atQos3Ox51AmwD+TL18+a9x9+eWXu/Hjx7t0RMELIYRIk4ukB5koqivIhKeUE3mfiy66yO6rW7eu/XgIXNSqVcsaRdFYPZXZm0DQ3pTWRm/60n0ss1KC7DNPGjZsaBs3mpuRecImO9VBEzUMG1YqMDA6GI9YsAkOVwRNnz7dbdmyxTa8nmjtWSq39t9/fwUvhBBCCCGESINepGGwE3CU9+vXL2YvUmy7mTNnZjg2Z84ckz8i2cxz7733uttvv91kfrkvXShUqFBENpnPjRwXAQiabkeDfYtaSNheQ4GASpZvv/3WkkaRUMaGw57evHmzSabju6latapLRxS8EEKINLlIevwFj+qK9evXW/WFD15EQzNqMr4pV0x19iYQtDeltbHKatN9LPdUgqzMk3/YuvVvvdzsNL6jigWtWeTgdveY9u3bZ1rNIYQQQgghhEjPXqRIIVGV0adPH6sIoHoe+wFpqLBU1C233OImTZpkMss+aY9kNn7SCexZKlhiQYIo6gQklPpxWbFihfleUMkIg/rAIYccYooE2NX00ExH1PNCCCHS5CK5N4/nfpzQsRpwpWogiCAQfQaQ0MFpvrdkVlobXWWQ7mOZlRJkn3mC/NSaNWvcsmXLbKOXbpknnI8YDKeddtouBkdmoIv60ksvZZCHi+bDDz80zdXdPUYIIYQQQgiRnr1Isbtmz55tst8nnXSSNZdGmeH888+PPGb06NEmS4v8Ef4D/xPuZZiK0JsRdYvVq1dbRQsyv4xTx44dI4EgemV6OnToYHYu1S5IASPXdeONN1rfR9+w+4MPPjCZX/pjzJs3zzVr1szkpvr27evSEVVeCCF2S5X+L2qE/p/Vd5+TcBfJ5s2bu0MPPdT9/PPPJvvCRdLLzERnS6CfSGNkykGBfgFsJML9RG699VaTjaJUkZ4XbEgIXvDcdCO7gaBYpbU01gr3vaC0tn79+i7d2N1YZrUEGdI98+Taa691n376abZ6fdDDpnTp0tboOzPImiIYUqdOnRx6p0IIIYQQQohU6kVKr9GPP/4409fAeZ+OoGbRqVMnC/ggBUWfD3wyZ511VsxAEEl4+Anww2DzEsjArkVuy4Nc1M0332zBi+LFi7sWLVq4p556yuy6dETBCyGESJOLJJF6Ahpff/21ZbXTO4CmvldddVXkMcj8dO3a1TLhec2aNWtaJkCqOzWzGwgCgjpAuScN0LlNxYGXRurVq5f1JBg2bJhr1aqV9WigaVmqN5nO7lhmpQSZzBOeQ5YPv5E6S7fMEza3M2bMsPMxupx4d0GjJ554wtYJ5mYstm3bZt/R0KFDXTrA+KHFS88Q1kj6sewusEPG05gxY+z8JgBXrVo1m3/0YYkFY4kMH+c81UJCCCGEEEKI1AXbdXfECgSRUEoAIzMIFFGVIf5GwQshhEiTiyTOz3CVRSxGjBhhP+lGdgNBQGDHgyMUbU96CviMEyoscGSSMYH2J8GiyZMnu1NPPdWlMtkdS1+CTIUKFT40I4suQU7nzBMCEJy3ONkJAmVHKos+I6tWrXKdO3fO9DFTpkwxp/zFF1/s0gGkx5Axo0w7PMd2F+xg7t55550232iY3rJlSwuohdcAQNLshhtucKeffnoufgIhhBBCCCGESB8UvBBCCJH27E22hG8qvTvQ++QnndibsdxTCXI6Z550797dAmNU7tBcz/cHITDkNVFjVQb574Jg2e76Y/AYKg98f5FUh6ogfrLKyJEjM9wmiMF3gdRZOHixY8cO07VFeg9dWqrYhBBCCCGEEELsGwpeCCGEEEIkKEgWQaNGjTIcpwLgsssuy7QyaOvWrdYXZHdN51esWGEyZvQYEVkDuTLk0A488MAMx5HdorE8VS4EL4QQQgghhMgp1Is0cXuRitxHwQshhBBCiAQlKxU+sapZqMygn8XuOProo7P0+uIf7r//fpOeCjeLnz9/vlWw+D44QgghhBBCiMRFwaDkCgQpeCGEEHmILpLJdZEUQggPTeRp1o1s1MEHH2zHqMKgX8ijjz7qDjroIA2WEEIIIYQQQuQgCl4IIYRIShQIysFg0JBS+/p1pA5Dtsb7HYgEZPLkySYJ9eyzz7omTZpEjn/55Zdu9erV1sQ7LC0FBQoUcMuXL3dHHHFEXN6zEEIIIYQQQiQ7Cl4IIYQQQgixm4qLK664wn6fc07GQOGxxx7rlixZkuHYzTffbBUZ9Bs59NBDNa5CCCGEEEIIsZcoeCGEEEIIkYOoKihxJeJ++eUXt2rVqsjtr7/+2npV0ID7sMMOcwMGDHDr1q1zEydOtPsJWFxyySUWiKhbt6774Ycf7HjRokWtr0iRIkVc9erVM/yP0qVL2+/o40IIIYQQQgghskf+bD5eCCGEEEKIpGTBggWuZs2a9gN9+vSxvwcNGmS3v//+e7d27drI48eOHev++usv1717d1ehQoXIT69eveL2GYQQQgghhBAiXVDlhRBCCCGESAsaNWrkgiDI9P4JEyZkuP3mm29m+39Ev4YQQgghhBBCiL1DlRdCCCGEEEIIIYQQQgghhEgoFLwQQgghhBBCCCGEEEIIIURCoeCFEEIIIYQQQgghhBBCCCESCvW8EEIIIYQQCUmV/i/G+y0kDKvvPifeb0EIIYQQQggh8pSUqbwYPXq0q1q1qitSpIg7+eST3bx58+L9loQQQgghhBBJjGwMIYQQQggh4kdKBC8mT57srrvuOnfTTTe5RYsWudNPP901b97crV27Nt5vTQghhBBCCJGEyMYQQgghhBAivqRE8GL48OGuc+fO7sorr3THHXecGzlypDv00EPdmDFj4v3WhBBCCCGEEEmIbAwhhBBCCCHiS9L3vNi+fbtbuHCh69+/f4bjZ599tnv33XdjPuePP/6wH8/WrVvt908//eTixc4/tsXtfycaOfE9aDxzbjw1ljk3lhpPjWXCzs0/gpx6K8mPzvMcHk5dgxJlLHPifwdB+qwV2bUxEtG+AO3j/kHrUc6hPbHGMlHR3EyssZSNkWFA92kodT0PD6X8MjlFvPepWbYxgiRn3bp1fMJg/vz5GY7fcccdwdFHHx3zOYMHD7bn6EdjoDmgOaA5oDmgOaA5oDmgOaA5kLU58M033wTpQnZtDNkXWke0jmgOaA5oDmgOaA5oDmgOaA64HLcxkr7ywpMvX74Mt4naRB/zDBgwwPXp0ydye+fOne5///ufK1OmTKbPSQeIeCG39c0337iSJUvG++0kNRpLjWeiormpsUxUNDc1lomK5ubf++qff/7ZVaxY0aUbWbUxZF/ERudPzqLx1FgmIpqXGs9ERXNT45moaG5mz8ZI+uDFQQcd5Pbbbz/3ww8/ZDi+YcMGV65cuZjPKVy4sP2EKV26dK6+z2SCwIWCFxrLRERzU2OZiGheajwTFc1NjWdOUqpUKZdOZNfGkH2xe7Qe5SwaT41lIqJ5qfFMVDQ3NZ6Jiuamy5KNkfQNuwsVKuROPvlk9+qrr2Y4zu369evH7X0JIYQQQgghkhPZGEIIIYQQQsSfpK+8ACSgOnXq5E455RRXr149N27cOLd27VrXrVu3eL81IYQQQgghRBIiG0MIIYQQQoj4khLBi3bt2rnNmze7oUOHuu+//95Vr17dzZ4921WuXDneby2poNx98ODBu0hqCY1lvNHc1FgmIpqXGs9ERXNT4ylyBtkY+47Wo5xF46mxTEQ0LzWeiYrmpsYzUdHczB756NqdzecIIYQQQgghhBBCCCGEEELkGknf80IIIYQQQgghhBBCCCGEEKmFghdCCCGEEEIIIYQQQgghhEgoFLwQQgghhBBCCCGEEEIIIURCoeCFEEIIIYQQQgghhBBCCCESCgUvhEhj/vrrr3i/BSH2mSAINIpCiKRh586dGf7WGiaEiBdaj0Q6Ids3fmivI4TYFxS8EAmJLm65y/z58+13gQIF7Pf27dtz+T8KzemcZ8eOHfY7X758mmC5hIw8kezrbtgxlyjkz5/fffnll+7999+3v1nDfvzxx3i/LSFELqL1SOxpfojcQ7Zv/JC9JpIJ2b6Je+1S8EIk3MWNE0DOyNzjhRdecBdccIGbMWOG++yzz1yzZs3cu+++m4v/Mb2J3rAx7itWrIjzu0puvDNyv/32s99Tp051Y8aMcZ9//nmc31nqzVsCnAQ358yZ4zZs2BDvtyVEtuYw6y7BAQIDiWSM/PHHH27IkCGuZcuWdn5dfPHF9rN58+Z4vzUhRC6g9Ujsbm7I9s1dZPvGB9lrIpmQ7Zv4Pi4FL0RCgTOSE+CVV15xgwcPdmPHjnU//PBDvN9WSm0gGjZs6Bo1auS6du3qTj75ZFe9enVXr169eL+9lARjxDvYP/30Uzdp0iR34YUXupdeeimhHGnJBs5I2LZtm83lXr16ueHDh7vWrVu7p59+OsMFVewdft6OGDHCVaxY0T3yyCPu448/Tsrh5Hry2muvKasxDecwazDrQ4MGDVyLFi1cly5d4lpp6K/DhQsXdrfeeqv79ddf3YEHHujWrVvnhg0b5sqUKRO39yaEyD20HondzQ3ZvrmDbN/4kg72mmyM1CGVbN9U9XH9rRkjRIKwdetWd/nll7u5c+faCTBhwgS7KLRt29a1b98+3m8vKWFTwOLiNxCM8aJFi9yWLVtcjx493H333Rfvt5iyYIysXr3a5u6mTZtc3bp1LZP9P//5jwWRatasGe+3mJTgfOzTp4+rWrWqBd5ef/11i/Q/+uijNqepLCpSpIgy2fZyrfCbkmuvvdYqLh5++GHXpEkTc7j6+5KpOu62226zjPZXX33VVapUKd5vR+QRrLnsI1gv7r77blt7r776agtgMCcOO+ywPJeL8ecXsG79/vvvrmjRou7ll1+284vH+Gu1ECJ10HokMkO2b84j2zcxSAd7TTZGcpOqtm+q+rhkIYmEgnKj//3vfyb/woWNixyO9oceesj99ttv8X57SUfYWTJr1iw3fvx4V6xYMZPZufHGGy0w5Mu7kj3zIVFh7sInn3xikXzGHLmu5557zv3888/xfnsJT6x5+f3339u8ZQ6TGcEcP+6448wxWbZsWde9e3d7XCJq3SfyGDOOa9eudePGjXPfffedW758ubv++uttY4KDdf/997dMcT+uiarPjEN4ypQpbv369Xabv7/++ms75/788894vz2RwzAPY81F9g5832QBIc907LHH2txYs2ZNnl7vvMHD+cX/vuGGG9yLL77oOnToYBUXVapUcddcc02evR8hRO6h9UhkF9m+OYts3/iQLvaabIzUINVs33TxcSl4IeKm7Rl9DCcDkU56MBxyyCFu9OjRFrmrXLmyu//++20BEdmDDM5ly5a5+vXrW7YppW8//fSTSUU1bdrU5CruueeeDCXtYu/mdDRc5BjrefPmuTPPPNMVL17cJEFOO+00y0KhXPaDDz7QcGcxU5kNhZ+frAmUHpcoUSLSdJ7HHn744W7AgAEWpFu6dKk9N5k2xPHCjzEVb0jJrVq1ypyszF9KQclaZ86yNp966qmm1Z+oUGGBQcSm85133rGsLwwmMrzuvfde25SK1NOR5yd6HX777bdtzS1ZsqRr06aNZQF16tTJPf/885YFmFf4TK2+ffu6atWquZUrV0b2PBUqVHADBw60NYtgC9dsSQoKkZxoPRK7mxuyffMG2b55SzrZa7IxUodUsn3TyscVCJGH7NixI/L3okWLghdffDH4+uuvI8dOPvnk4PLLLw9OPfXU4LDDDgueeOKJYOfOnXbf+vXrgy1btuj7ygb/+9//gjPOOCPo2LFj8NNPPwXbtm2L3PfXX38F9957b3DMMccEc+fOjRz/448/NMa7wc9H/3f49jvvvBM899xzGebpSSedFFx33XX2tx9/nlO6dOngsssuC9atW6fxDoLgm2++yTA/PZ988knQoEGDoEaNGsHpp58ePPnkk3b8119/Dbp27RpUqlQpw3fAOtGsWbOgVq1aGtcswlpct27d4JprrgkeeuihyPEJEyYE//rXv2xdHjhwYHDXXXcFw4YNC/bbbz97TqJy9tlnB4UKFQrq168frF27NnK8TJkyQc+ePYNffvnFbofnjUiufQTXrzC33HJLcOmllwb3339/5BrG/C1btmxQpEiR4MILLww+++yzyOPfeOON4Msvv8yV9xdrXk2cODE49thjg/fff3+Xx2zdujU466yzgkaNGmV4zm+//ZYr708IkXNoPRJZmSMe2b65j2zf3CXd7TXZGKlBqtm+6eLjUvBC5DmbNm0Kzj333KBcuXI26atWrRoMGjTI7hszZkyQL1++oE+fPsHPP/8cec7q1auDIUOGBG+//ba+sRhEO3I8BCUY56+++spu46xhs+CdONxu06ZNcMopp5iTj3EfMGCABTrErjCO33777S7GCOPFnD7ggAOCChUqmBOKwBzcd999QYkSJSJjynfFAn/88ccHhx9+ePDMM8+k/VA/++yztoH4+OOPd5m/bHZ79eoVTJkyJbj66quD4sWLBw8++KCN48KFC2396N+/vz3eX2RnzJhhF87cck4mK4xPZmsF48Xa+8orr2Q4jmM17Eh98803g5o1a2ZwBMeT6GAr1xc2TDixmSt33HFH5L2PHz/eHNk4rsP8+eefwbvvvhv88MMPefreRdZ54YUXzHiIZUS3bds2qF69uhnHzGHWCzbXrA9c284555wMz9m4caNd9x599NFcP7+4Tmzfvt3WrvPPP9+Off/998HixYuD119/Pfjiiy/s2Pz58+29sxciaYMEjkmTJuXo+xNC5Axaj0R2ke2b88j2zXvSzV6TjZH8pKLtm84+LgUvRK5mHGK0R9OjRw/LMvTROIwAFo5p06YFK1asCI4++mirFKAig+fjnOjQoUNw2mmnpfSikRNjPm/ePNtY+E0Fiy6R4ksuucQyBXDYVKlSxQIad955pz0XR17t2rVt00EVBpkTYleYm1SxPPbYYxnGnsySW2+9Nbj22muDDRs2mBO0ZcuWQZMmTSxQ9N133wXVqlULWrduHfz444/2PLJvcbQR1b/gggtiZrCkE2wS1qxZs8txApb16tXLsI4wzqwFzHXGn4yIgw46KMPzf//9d1UQRRHeiODYJXsEY9qDscE6zO/odZx1hLn74YcfBg0bNrR1hEyqeOHfH+cQ2V3Rm06c1TiByZ4pVapUhusGAXPOT//ZMaiaNm1qn51zVyQmvXv3Dp5//vnIXOYcv+iii6zagnngN87//e9/gyOOOCIYN26c3WZ9YLN94403BjNnzrT7qYBg8+0DBzlB+JzhOsB14r333osYQMzHE044wdZ8/jfXh8KFC5sxxB4IMPLJQKxcuXIwYsSIHHtvQoicReuRCCPbN++R7Rsf0sFek42ROqSS7ZubrEgiH5eCFyJHYIKHF4jJkyfvIpmA44FSzkMOOSTiNCAT9sgjjzSH0pIlSyIZiETncbDjhCIqSrCDIIaIDZmcBCfKly9vmwfkUaiggNdee80kM2644QbL6CQ4QWYEY+7H1GepisxhfrNQh2ERZxwZb+ayB2cU38PNN98ceRwbNpxmOEoLFixo0ejp06ebvE2qXgz3hN8o+LWDC14425g53blzZ/vbb27JCmDNuPvuu+320qVLrUS5cePGu7x+ZpkW6cxNN91kDn0cqWRFeCcvMJdZc8lM93iD47zzzrO1mA0JlQrxhk0SG05+2CCFnb1stpo3b25G0VFHHWVzyDu3mWMFChQIRo8ebYF0/m7RokUGeSmROIT3FcB36tdLNtN8/36N8HC9Y8+wbNkym6uszcwDqjAIbDCfcwuSAghKsCaxhyE4wRrF52Bt49rLXogq0s8//9wCGVdddVXk+Rj10Z9ZCJEYaD0SYWT7xhfZvnlHutlrsjFSi1SxfXOLZPJxKXgh9pnwBeeDDz4ITjzxRHMoEI3bvHmzRewIWDz99NN2IatTp46dBBjtFStWDB5++OHIguDLs3A6UEqIBl20xEe6E8uxgY47DjivQ0c5F9/B2LFjY24+GFfGP5UX4pwc7/CYs/nCaeahZI5SurAECfO4b9++5lT1GucfffSRXSwppSULxT+XSiOi2emmvx9r7uFwJPLvA2no2JM1Hf0cIvlE/oEsH5yBvoRRZA5SSlRXkYFOsLhbt25W2nnbbbdFNiCsG2w6ojWaWae9/Fy8DI0FCxYEL730UsQwQkaITSXvnx5JXGs4l6ZOnWo6uoA+J9VnlLT7z8T84XOSLUJwVyQm0WsiayjZT97ooHfJcccdF7Rr1y6D5BfzhHnOvPCbZtZk9h8EP3JrDrOuExyZPXu2yV5yvrAfIiOJ60Y0vCfkoagGEUIkNlqPRBjZvnmLbN/4kS72mmyM1CTZbd/cZEcS+rgUvBB7TXiyU0ZIo22cRMgzYLgziZF1wHD3DW44KdBKJDORCR5u+kKQwve+ELsSfeIPHz7cKlzIKCaKTBYnsNDiyENOxR8DFmzGn4oMoqgjR47cpRmP+GesmZuMFUE44DcXLaqIyKj1gSF0OtEC5IdgnYcFnexvHGux4GJJBgoXgHQiPN/Y3DIPaQIFOJKRMBs8eLA97tNPP7WGu7fffnvkOTgfydph3DR3d4Ux9Zur8PiwXuMopdrAwzpNqTcyNb6Mm6x1ssUz05/lteOVGd6pUydbu8Il58wPPgPVFsgLkvVBEJ3Nlj8fabyGocUGyl+v/vOf/8TlM4jMCWsox5KcpHITCQJkEFetWmXHqKChUpMgVRgqDQlOYaxEsy/GR2Z9LYB5SJYS1w7/GPY1rPNIQvE4ytVZ55h/bOq5TiORKYRILLQeiVjI9s1bZPvGj3Sz12RjJC+pbPvmNDuT3Mel4IXIkVIsSoSIWoalO5BPICuWi1sYmkKj60w5Ubj0k+AHjTdxUIjMIcOUKDLVLJRsspggiUGzcwJDLMbIQ3nQmiP7lA0FzhIipTQeErsHRydzmshx9+7d7W+yvhl/Am9IkPi5SqCOiyMBpTDemeWzbolW8xoE9Pbff39zsKUro0aNMkc0pYeMsYcNBg49P0fZLDP2/fr1s7EbOHCgyaOpIuufTQjzLHqDgNFAZrqHclCypKIlc9iAMJf9d8Cc9vM+eqMWL+PDZ3ARdGDO8Hm9hiZO4KJFiwZz5syx8wvnNuXr/nwFgrjcZl1Mlc1nqvHqq69a1t4jjzwSObZy5UpbJ+hZ4ntHsLHGwAjvNRo0aGDNsMNGB3sKsv28HGVOEJ47XFNpus089OcF6zmbdf9YfxydXDb+wHPQiqViJDflq4QQe4/WI7EnZPvmLbJ940eq22uyMZKPdLB9c5MNSezjUvBC7DWUBR188MHmOKePAtmQOBVo+uIzJ5nAlGaFKwBwMJAhS2CDiB3lSWilYdArAzFzWDyRe2IRJtrps8JWr15t2cZUvbBhIKLsYUPBgs1ziS6jsy0yx1+wfNYvUlzo9TGHab7qoeSVhZ3xBiLYBN+8zrqHi0B0MI7zg4h2umjshzWB/QaAoBuBNByR4PsR+PHhInnNNddEmj8xh5n36ClyoaQvjvgbnKf9+/cPSpQoEZHOYUNB9RWOfPT0vVQOGVAEiMMSO2w2kLoJl4Sy+Yh3HxZKy7k24IQOg3FUsmRJu+Z4kCKkuoLzlo0q84UABp/TzznOOWSDRGLC9enKK68045hAxQMPPGBJEZzzBOSp6PSQIcU10Jcr07Cdx1CFkRNSiHsyVO644w7bs1DZQTIA1Y7ANYIeKt5Q99cRMhNZ7/w6SCWql8gUQiQeWo9EZsj2zVtk++btWKeLvSYbI7lJVds3N9mRIj4uBS/EXoNO84QJEyK3kUPA2UDFhY960rcCzefoiCf342i4/vrrLYAxbdo0fRNZkLVgzHyD8zDo9uFIQa/Pw8KBbBcLNt+NyLoUCJswLmxUsnBhJLskHIln/pJ1RfYsmbQwa9Ysc2SFm696wlm46UTYkUhQzY8xgU6ficxY0zieIJy/CJIJwIWTPjlhvFQMSPLsH7744ougfv365tSlVJPKNgwNnKaHHnqobVCYz2+99ZbN58cffzyDkwYtUDby0cSrSgHnLoFxMkEIavtmfx4C5hdffHEkG59ABo/lehR9nqXjeZdMhOcY+wUCURjCNLZGfxhDmV4mGM9PPfWUPe7111+3Oc4aHN6Es2aEJcWyKxEVSxIqfB8QVEGmij0Lm30ylghkeMMefWfu55rLZ2MNZA6jBy2ESGy0Hok9Ids395DtGz/SyV6TjZEapJrtm1vsTDEfl4IXItvEmqC+gSpRTzQPw1qxROuIenqdxFRbFPaFWBf08G0qJT788MNg48aNkQWlS5cu1ugcfUkPGwmadhNBpQqDMS9VqlTw73//O6JnJ/YMElydO3c2xyhjClzYGFdkBMKQ9YtTCo1MDw4qHHAiI0TvycShkXK4ARQOynPOOcfWB0oMkZhjw0vmAxF+5nIs/clUa5i1r+sG40HPhwMPPDCoXr16BiMC2RzGGqk56Nq1qz2GsUVqjqAnZd9ULMQTvnN/jaCclYA3axibKrJjkN7xTf7IjiFYQca9nwuch0j2RBtMIjGJFSjAYCaTCpmBVq1aRY6vW7fO1uUTTjgh8hzWjkaNGkUMD6pqkJfaW8LvhcwhAiZIkvmNO++XfQ7GUbgKhPfM+kYAg8dwHpFxSB8qpKyYkwTbfN8vIUTiofVIZGWORCPbd+/PN9m+iUmq2muyMZKfVLR985LNKeLjUvBC5AjhxQTHOouEj8ovXLjQonton6VyOVZ2iY6ChscQJwzVFZUqVbLoMdHOl19+2e6bO3euRZqvu+66XV6TiDNOF+Q3cOyJrEPpIBFoIvUs5mGtdDZpXPB8w1/g+yILl4ujKocyL6/385dsNS9bxjjefPPNNtZo15NRTRYEvQt8lRZZ9Gyiw9qV6QoB32effTbydyy++uqr4LLLLrNNiHfg+0wqssPJoAAy2ZnfOIfZuKFJmwjlv71797ZzyX/fH330kV03unXrZs7r9u3b2/xAsof1ks0XvQ68rBTPI6DBvMoJ6SCRN3DeMz8nT55sayrVFmTxIQMWhusfc3jQoEGRAANViAQ7cCD56+e+BKx4nUsvvTQoUqSIrfdVqlSxylEyDf08bdiwYeQ9+P/H9RrZKmQdfdUj/VXQjR02bNhevx8hRN6i9UhkB9m+2Ue2b2KSyvaabIzkJNVt37zk0RTycSl4IbKsf7gn/GLBQoPuM87zcCNLZB/UcyHjAkyAh8gmvUG8BAoXWRw3OOe4H4mMK664whYQSuQAhw3a4DSpDY+92DOxnFtUtqDbGdY+DINDDcdoOKpP1JooNs5UnKu7e/101EkF5m2sEsPMwDEYbtgr/mb27Nk2/yh99dBAi82Xz47yFQnFixe3vhDgdfWXL19ukn6+qZZfM7weaCJkR7322muW1e6br7EOoptZrFixSH8LmoVxnpKBz9/0+cGQ8kFxHOC+55JIfJA7xABGkgBjmesd6wcGMpULvuE6cH0kaICerTdQKBPPKSgnZ2PPGuSrGrn2Erzw5xMSVWz8CXCE9Vx53/T78sGLdL4WCJGsaD0SHtm+OY9s38QgXe012RjJRzrYvjnNzjTwcSl4IbK00cCRlB1oltOsWbNIg1ROHJpHi39AT45IMY1Hw6WWSKcQqCDzOAzRY7QnAQkKyjc7duwYKVtOpIUlUcksyMPCjbOMwBvReS6KXCDR2vca6pTOkV1LIA5ZEIJHkkDLeOH3+vPAvPRBOKAfC87oPn362CbSPx5HIXMeCRgkVlauXJlhHmuM/wYJOEq50dJv2bKlzcUzzzzTAsXI9QFzF5kl1g/kbDzI35ClzmYken2IRz8WnM9kcoSbcfN+b7/9dqs28xtNHsc6R6WZh89ILx+uMWy2kJT6+uuv8/T9i32HNZd1dPr06buc5zSEQ3KJwH4YekwQuPINsj05sUawnlNGHp5LBMUIShA88+fI+PHjrbndqFGjIo+jMoM+Fy+88MI+vw8hRN6j9Uh4ZPvmLrJ940e62GuyMVKHVLJ9c5s/08THpeCF2IXwZOXERs6DEisWCd/LIrMJ7S+MyCjgWMLQT9TJHy+onqAKhQxSr/EehrFDtsIHNHwEecqUKRZBRjIFaIzO6/jqC5E1cEhRuTJ06FDL1IYffvjBAkE0CT7kkEPsAomTjGZOZIP75xHtx6GGkzVMql0A9zZrkXJMZH68Dj2ZyDijyWhGE5UNB2sJt9n0UonFBbNChQomdRbOhhAZDQ2096k0QBYO7VkCyqwNyNOwifOZKcj0sbaw2WP833jjDTMy+G6iA53xgM/BOsb1AXkg3q+vnOBvjCKaHvvzCuc2eqa+WTPweC9HSFaISEx21wCbptzIE2AQ+8eE9wp838zbcGYfjwsHvHIC/7/nz59v540PStAryms7EzwjycDLR7FWcW0gwEImE58DCTOfrCGESDy0HondIds3d5Htmziksr0mGyP5SUXbN6/4NQ18XApeiEwhGkcEDsOdE4FJjmPJ97LYUwCDqB6RUrFrGRyZm2Q0hCHblB8cJDhCGPtoPUoWHZwsgDadmoBmDb/wkhlbunRpiygjVcKFj1JZFnYeQ7YJFS9oAXJxRPqscOHCEbku5nY4sp2Ocl3R2QpkNHDxozKIjGi0J1krvNOR+UrjJ+R8KEHkuZR3MtaMMRVZPvKfiiWce0P02urHhEbBOP3JMAmDkcEPmw+cwehU4nTF4dqhQwczUBKJCy+80By+ZMTUqVPH+ln4bBnke+ibNHPmTLuNs5r3T9Pj6IyxdDz/koXweYwOMnMzvG7Qs4k5kNnmmL1Dly5dzJj2e44w+5IUEb3G+P/N2kVAjHOmZMmSNk8xjFjLqKxgU8/c27Jli2UwoRGLViwJHkKIxEXrkcgqsn1zB9m+eU+62muyMZKTVLd9c4udaebjUvBC7AITesCAAeYswqnkAxBk+ONoogHO7iJxiRahSxT8uDC+ZAtTluU3ASwuaH+TxcnizfizwaA5twctP8bfV2KIPY91GC5sXNBoKuZhISc45+d0NDjY2rZtm6G8NlXLDbNC+DP7xk7MWTIbwuWJOP6Yv+FsB/9cGruhvRjdm4AxTfcqregx+Pzzz20cP/zww4j8HgFMP1/9Y9mI5M+fP5g4caLdZiPCGLPOhOduvA0N//9fffVVk31inUOrlGsNjuwnn3zSZHsuv/xyq8rwUKFWtmxZOx9FYrGndZBGj1zrSHzAUPZQ4VC9evXgxRdfzDA32GQTqPdNusmg4n/kxHobfX6xtwm/LtUWlE2TWThjxowMz6XyEeMpvG5xbmVXUlMIkXtoPdJ6tLfI9s0dZPvGh3S012RjJCepbvvmNDvT3MeV34m05q+//trlWJEiRVyFChXcn3/+abfLlCljv08//XTXtm1bN336dLdw4UKXL18+t2PHjl2ez3HhYo4LAUPGt3nz5q5q1ar2++CDD3Zr1qxxb7zxhrvyyitd/vz53cUXX+yOP/5416JFC9elSxfXtWtXd/PNN7vzzz/fFS5c2F5HZD6nY83B7777zi1fvtwdeeSRkWOMZ8uWLd2HH35oPzBz5kz3yCOPuFq1arlp06bZ+BcsWDDDa/EdpdM89/ONz8y6cMUVV7jLLrvM5u17773nTjjhBLdz50473qhRI9epUyc3Y8YMV6hQIXve/Pnz3dixY13Tpk1djx49bH4fddRRu4wpP+nE+vXrM6yhfgwY08svv9y98847btGiRbbmbt261R100EGuf//+bvz48e6LL76wx/LdVK9e3XXr1s3169fPrVu3zh177LFu1qxZbuDAgTZ3/z9Rwe23335x/bz+/zdp0sTVqFHD5kXFihXt85533nmuZ8+e9vkOO+ww9+uvv9qcgWrVqrlbbrnFNWzYMK7vX+yKXweZpz/99FPk+IoVK1yDBg1sHg4aNMhdffXV7vXXX3fdu3e3Od+4cWNbA+666y7322+/Rebo8OHD3aRJk9y2bdtsvbj22mvtf+zNert69erI37x2+PxiLrVq1cquwUuXLrX3xL6H91myZEm7Tvvn+XO1XLlykX0RcG4VLVpU00KIBEHrkdajrCDbN++Q7Zu3pLO9JhsjOUg32zcn+Us+LlvkRJoRK5r23HPPWQSezENAuoimqDRD9XrkPhpKZI9yJLFvUKYZjiTHgmY6SGeQKUGzUpE1iBo//fTTlsG7bt06O0aVC9nbNHDyjwHmPb1DfEN5KlyY474RlPhnzWCMyMRp0aKFNW5D87RNmzami8rYohHvMyWA8mMyk9FKJev62muvjfRsSXfuu+8+0+aM1sknM4qyV2TjRowYYRUKxYoVizTN47tAq7Jdu3YZMlUYV/Q+mc9hEik7ihJU/36QyKOSjDmBDA+Qhc91h89LuSu9LrZu3Rrndy12B3JffGeFChWyKgk/R/kuqayhOZzfU1CBUapUKWvWDszpk046yXRYaczOOsyew6/Fnr3JAHr99ddNcoqKCWDeMf9Y1/l/nF/cx/p14oknZug/xXu65JJLIvshGnYjJ9W5c+eELaMWQmg9Epkj2zcxkO2bu6SzvSYbI/FJR9s3p9mR5j4uBS/SBHTQvBRDGJqhMtlxGBx66KGmfeibcuN8wIin6UsYThgaOPFb7MqenBt+Y4E8Cs2v2Ej4ck2/2KTyoruv7MmRRfkgZbBIkqCdz282ZUCDVZxQYQ11HFQ0g5o1a5bdxlkalgJJV2dV9BykPBPZFAJulCKGG+tyfPDgwRke/9VXX5n8j28o752YvoQzkUsScxP/uenlsHbt2gz3MddoVs24hceKdbhZs2YmqePldHAWI78Ufs14rxuZnSu8v/B7+/LLLyPBWXoGhJtxw+jRo02Tlw0WzvF0nSuJRqzvgTmJzNLhhx9uOsOsE/47Rl+ZcmRKkwlaoFuLfBSSYH7DzXpLfyz6avG95xRLly41I4c+Ff59Yyz17dvX9j2eO++809YvDHXfkPu///2v7YnGjBljjSm5/+qrr07ba4EQiYjWI61He0K2b94h2zd+pIu9JhsjeUll2zcnkY9rzyh4kQbgiMVZQDQ9DIZ6tWrVgrvuusuqK8gupAEliwW6ceh/YujTXHrlypWR5xHdQ8c6HLEXu/LBBx9EMoozY+rUqZb1yXeQagtwbhAen/AmxusZ4ixjvhK1536+g/POOy+oUqWKXTCZuzQnQhOQ+c5FgrEnoOGzbMP/K1E2bHlJeFwZE7Tf/UaWKiE2vmwgwtSsWTM4++yzLeLPpoQmUKw5HPOOao/m+N/4ufXGG29kyPom4OYz2H1QkyZ6jDuGh/9+cMrSK4JsqjDx0PbkPZ111lm7GETR8DnJAOGc5PPjuOZzdOzYMUMTQPANvEXi4ucalRfsG6jIvOmmmzI8hrlMgIrG1z4pAuODwACNvGOxL0EC3pNfY6isoJfKPffcE5lTixYtsr8xfmgYz/00ATzggAMsaOH517/+ZeccyQUEQoQQiY3WIxFGtm98kO2bd6SLvSYbI3VIJds3p5GPK2soeJHi+JPZnxDhk5sMdWQVcPj6xYSMdBYQ74RiYaG08NJLL43L+08G/Nj6MUSCC7kTMjcJTPis/zDh8aZEjseR+RC+T/xDeN6yQbvqqqssQj9o0KAMwzR27FjLAmZcw03ikAkh4AZk+eKwKleunG3iSpcuHUyaNEnDHTWnydxBrozKFV9uSHlmkSJFzEEZrk5ZvHixSarglKxXr545AsNNo0TstYLNGPP14osvjpTQkr1Odnr0WkFQjlLb5cuXRyq3fPZJvMBI8hkxzIkyZcpE1rFoKF9nfrDe0XzNQ1ZYjRo1gttvvz3P3rfYO5hvVCB4CUPmM0YG6zASUUgcMkf9ekHwnsDw9ddfHzE8eGzRokWtOo45HCYnr33sax577DE7tyg1X79+feQ+5ihN/W699dZIAKV8+fJ27rGWAefZ3Llzc+z9CCFyFq1HIjNk++Y+sn0Tg1S212RjpAapZvvmNPJxZQ8FL1KY6Ij5s88+G3To0MH6VsDkyZNN/smDk9c7F6pWrRpZYDDwK1eubBrlIvMx9osPUlDjx483jUmyGdCb9AGMWM4ZtLlZnH31hcicXr16mcQT8k/IeeAE69OnT+R+tNRxoPo+LX5OM7YE5TxIljz//PP2PSVKZkmiQCAHncm2bdtacIfNb+/evYMNGzbY/cjIMcZeXs7DOK5YscICnps2bUqpbIh9JTwGrKnhdYA5iOSOz/rGmU9GeDighrOVzPb8+fMH999/f5AIMCfYfPoyc8413jfnZSy47oSzusJjQLnw448/ngfvWuwtCxcutIAvWVAE5glg+PWV4AQJDlTPNGjQwAIc/j50ayn7xmAm06ply5ZW2RmdDZgddrdmc6717NnT1i36VnDe8J7DxjkBbK65vA+vCYtsZsGCBa0iRGuWEImN1iORGbJ9cx/ZvolBKttrsjGSn1S0fXMT+biyhoIXKQgXpfCC4RueoulPhJ1mWdxPpJ6F4t5777X7fWYklQNkIXoZD8oKvT61+Jvw+JJ5TPQYKRQ2ClQE+JI3pIkIYJBt7J050QEMxv2zzz7T0O7BUCWgxo/PjGXcaPyEAxVddaCxE02AvUyIH2uvoe81zaORlvnfULGClBwBy7BGPJUraAd70FHFSe3Lk2MF5RJJJzWv8J83s8/NWnvmmWcG7du3t34PYYkaGhaz1vId4PxlraavEDI3bGiY6zhgKZeNJ5TvYgxRLeEbqXm4dhBcpNQ3q45miC7/FYkH3yO9KwhEULmG1BdrAyAhSUCD7D7WXqotfNM4jGb6arF204zPV8DlBLHknDDG2dcwNzkPqbhA1orzxleMcD3gukEAm+s3slE0C6Qa1V+nhRCJi9YjEWtOyPbNXWT7Jg6paq/Jxkg+0sH2zU3k48oeCl6kAD44Eb1wkFXIQoHDwTvTqQogM5LABUY6TvXDDjvMJBY8SPKQCSv2zKpVq6ypLD9kPpDhiR5fGEo2Kc3EUSL2DnTSKYf1zrJwZgYXN9+vAk1zGq8SqafyxXPFFVfYuRCLRNmw5SWZBWvIoidwiWZtGDbIlHR6SSAqXJjr4Q2y+AcfTPOGHvI56MmSZYKTdMiQIdb7AZkdePfdd60y6IEHHjADHCcwmew8Bgk6ZOXoO0SGCjJn0bq0eQGluvXr1ze5H+R4MoP1j01qrICEqpySE/+9EZRCmoAKTsq2CUrQ8PrJJ5+0AAH7CBIdqDbktg8WM3eQMghn+O0LGOFcD5A94JwIO1TI2jrooIMicmbAeob8JQkGHvZBBFyYz1wvwnsgIUTiovVIgGzf+CHbN+9IF3tNNkbyk4q2b14gH1f2UPAiyRk2bJg1yQwb6jhj0Z+mfPCyyy6zUixvmPObYMUtt9xiiwwXN4x6IvU4G/79738HpUqVskbSInMHNyWZ7dq1My1tsjY9RIc5Nnv27MgxGkWj44fGpCpY9p7+/fub89RXXjBf2ZAx3shHIV2yefNm00XknGD+E7Cg4SrOrJdeeinmd5nOICX39ttvR6qsGFvKM71EnJffYuNARv0TTzwR2ZQQkJPUT0bYfBFgQ58zPNdw9LIGeOctTt1jjz3WGsl7By8BNjLWvcQcr8XGj0Czh8eEHbB5gf++mQOcbziqox3JNFljnfPVZgUKFIhk3ntwXiMZRIaNSFyYs7sLMtGbhOo2vk+MZqoOMTAKFy4caYZNOTgG9G233ZYrGX5cf5GE4nygdwXXXR8sQ/YJ+YTweQNcpzF+fBIBe6aPPvrIpKyEEImJ1iMRC9m+eXf+hZHtGz9S1V6TjZH8pKLtm9fIx5V1FLxIUvzCwMUrWnKI7EicCVzkYkElAIuHl/zgwjF8+PCgW7duVrLltRLF3+McK+uBJp8EiChvC+vwsdj6rNOw/MSoUaNMU5vNh4g9lzPDO9JwjDVt2tSCFWTLkgGMVjmlsiNGjDCHKfPY8+CDD1o/jBtvvDFDs7J0YE9jOmXKFNOvr1WrlmU4hBvLs8mlp0j4ddCnRw+eoBDO6XCGRboSy8HLeOG0x8n/1ltvRY7fcccdQevWrSNO1OLFi1t2STiLhMAmvYW6d+9uGzcPAWccxTyf8m+kmfIKJAbZNPprBRk0bdq0sSAhUP5L36SzzjrLSn4911xzjWW18zn4jHxW5g+SQ5KISo51A7mlcEWDn+8kPLD2Mh8xljFKCGAQLJ43b549hkpP5rFvHJnTsJ6zZvH67Heo9OHawBykGTxBCjK5wus+gRSuEcccc4zmoBBJgNYjkdmckO2b++eebN+8IZ3tNdkYyUc62L45iXxcOY+CFymiL4dj12ekc4Lj3MWQpwxv+vTpVq6FAx3YkHDxI1jhI/ggSY/YY+zliMhmoOmsL1VmzIkW49ALg9OEbFCyHsJj6zP/RbDXfScYWyqHkIaKplKlSuZozazhWLr0tYhukBV9fnPOM299rxscfDifGVeykSdPnmxZO/xm3nsnNRsLyjjRI/WvxzmS7pUsVBKExxzHPhJyBIg9gwYNMsODCiDkasKbO7LXfWUcFXFkkYcNDQKeZK6wgfPVDbkN5ehkxiDNQwDQZ6vzvjnPuHbQV4A+MrECsgTAMbbojUCAF1keND1FcoCGMk7+8DwNw7WN6gsfuGe+ej3l3N5H+HONsnOqGf18o6oHY50mlEhZYeSTaUgghQALvaioziNjlzUv3dctIZIFrUfCI9s395Htm3ekq70mGyP5SUXbNzeRjyvnUPAiBU4AFgwcRD179rQLGw0yyUSkqSoNbpCCQsKBDFmy0L3zAb1o9WH4hxkzZlifkGjI5qfRKAsy2nynnXZaZCElawAnT1hmi4xVNMEJYEgiZc/8+OOP1pdl7NixdpsAkc8Wid7I0dsCLU8cVb7PhT9OQA6nVSzSITAX/oxkL+B0xmFHg9xwBjLOu9q1a0fWDvrgIBXH41lbcPZRnUX2MnMYJyWycnxPNNdi/MXf2SJsxhgbsrrDFQVkgxcrVszklIDKBcaTsQ5DgJlGev5xYbyRQbA0PNdzG2R0uF7cddddVj0WXSlB4ILsGqorwhvXaKOIdZPrUrR8lEhcqJzA2KWyYu7cubtk6/nvmEAFawtGtL9mxpJ3ya11l//FOoZ0lIcm3MxLgmrsa7iPANwpp5xi85C+VJJtFCJ50Hokwsj2zR1k++Y96WyvycZIblLV9s0t5OPKeRS8SCKinUMTJkywygpgATn++ONNXw6IyOMMJrLpKzIGDhxoxrxn4sSJefr+E5mlS5da9gIOu/BCjPQWY0bDKzYOH374oTUeoqE52ZwsrEhEEdAIb6yffvppc8jnVIPSVIasWcYT2Q82Wjig0EzPbP7jDCUThe/Ky5gQzCBLPFpCLR1hI4s8CkFLHHgELRlfL2NG9Qq9cNCuZ1OBzFm4ubln1qxZlvHI6yGTBow7QVIRmM4sRgWGBD1XyPoOBzHJ8mbsvYO/Y8eOVolAgA15OTbw9HDB2PBVCX6OxzPYdsMNN5hTOly+G4bALSW+ZNSwKQuDhBs9MdKlyilZiRVoICDBesAPewWIVcUWliZgPl911VV59K4z/v9x48bZdZdkAQIT9NzgmoADAKMdYwnn53333acAmhAJjNYjsaf5EUa2b84h2ze+pKO9JhsjuUlV2ze3kI8r51HwIglh40bEEymOcL8FbqMlF5aC8hCd54JIVD8zWZ10xY8HF3kW03feeSfDRZZjZEL4x3E/mZzISPnSNhZmtP1E1vAXKj+mvXv3jmTNEozY3XPY1JH1TWMoGnJTQYQOf1hzPx0hYElzcqqE/IaAsWLzy9gSyPQZ8WRGEISbOXNm5Pl8F5QmhzchYbivatWqmfbSSUeQ4sPowIE7dOhQG1cqE8hMWbVqlVVreWkb1mWcq0j6+ewoSrsTpYzbQ1+Kdu3aRW4jd0dPGc5RNp84uak4o6eFl8IjQx+HN/OMvklcbxLtc4m/CQeWovcCjz32mAXxBw8enKXhIoBF1mY8oKqR98qco1KEilPAcCd5AIcADbmFEImL1iORVWT75iyyfeNHOttrsjGSn1S0fXMS+bhyFwUvkgyi61zExowZYw51mlOGmzrRFNpXVOBkwrFA2SGOppo1a8aURUpnws4bqiSQ2SJgwcYCKM0kKBRtaHHxJdvfR1XptYCun9f9Fpkv6NEOM8aMwA8ZJegb+kqhWEE2H5WnFJFAB2P+7rvvxvw+0w02DTTOpQ9BGAKWOPL8JhddVKpUCPyQteyhVw6ZzOFeLd98801EGg2N1fDmOZXZ06bK3886gUQcfW8ocWV9pnSb8b3nnnssOxxDJByQo1oLabSwhmcizdtXXnnF3jPnIlVnfPdUYpxwwglmDPEb+Jxdu3Y1Y4tmavQYIKNGJAdUa1LpxvXuvffeixwnW49ggG+oF+tcSITsKPYyrP9UVsTC96YSQiQ+Wo/E7pDtm7PI9o0v6WyvycZIXNLZ9s0J5OPKGxS8SFAyO6HJMOcn/JjwYnPOOeeYY53IJ874IUOGWHTfN+sWsaGC5eGHH7bNAHrvNDmHF154wfpccLEFMophwIABVm3hby9fvlyBiz0QdnjRpIlIPLrqyHF5rUR6tYRlSHZ3IaXcOfzaieBQizfIpBDAZC4DmQ9sIKhOWbBgQaQ6BektNhrly5e3DIgmTZoExYsXz1DJ5dcYviOkgNKR6H4PYfzcxMggmwTnCxBUxgBh3WjYsGGQP3/+SKAzGsY3EectQe++ffvaOUql2cqVK+04zdbImnn99ddts8rcoimgn28iMQjPKf+3n69ITRKAQmaSygkMXbKkMDaAax/BKKowsjI345k9RVIGwbNUNIKESBW0HomsIts3b5HtGz/S2V6TjZHYpKvtuy/Ix5V3KHiRYESfzEgghJvXcNHyTbdjOQ6QTsDxQNCCKgEufqm2QOQUjB1Z/+j1VapUyRp+EklmU9C6dWurqCBS3LZtW8vwDI81TnYcPyL7sBFjc4YDjXEPX9wYUzZpPniUlbkrp9U/kKWD5AulyJRo0kdk8uTJVtbJPCfLh00xULV1yy23WHUR/Vl8EMmfG+kMaycVa36tZR2l/DpWg2oee+2111rgMyw5h2QN6wnGCD/hbJNkhcoKghWzZ8+228wtkZhw7YrVoJpEhnr16kWqNsmgovqC9cLrLHP9Y6/hq+ASFfpaYCQJIRIbrUdid8j2zTtk+yYGstd2RTZGfJHtu+/Ix5X7KHiRoEyaNMnkiqiioJrCOyFoRHneeedFygf9ho9yQS9ZhEGPPrmvChBBppUqK1assPJKr93ue1jgyPHlmDTpRqIISSnkoXCuI58iPe3sMWfOHGtIRuMxZJ/4Hp555hmL0vvIPSWFSJbQn+XXX3+1YzyWTZ6I3dgymk8++cQkf5inYciKYGypLKJcGWdCrHMk3QMXwBj06NEjaNCggZ3zBB9oQhYdKPPfBUEL1mZklKJ58803beyTHc5H32gv1twRiQNBh7Jly9r6yr4AbVovIUC/oOi1gdJuZL8IYvp1mHW5f//+kXU4ESFQiya01iwhEhetRyKryPbNeWT7xgfZa9lDNkb8ke2798jHlXcoeBEHvKEd7YTkOD833XSTOQ5ouIRTHWcRTjQcCjhyqQyILgukVItM4egGeGL32fs03S5XrlyG3iHAmJ9yyimRHiEEh5BQITDEWIvdz+9oJy+36dNCxQW9V3788cdIaSKBi8KFC0eOPf7446abSENuzoMTTzwx7Ztx+zH0UAng15Foxx3Nk5F8KVGiRPD+++/bMZ9RzRhT1UIwjiBHmHSv0IqWHmMMvSySl43bHQTlWKdZU/zrRX8vyQZObZofo6PLnCHw5RsJisQjPOdIciAgQSM9Ki289BeJDSRFIB8Vfh7BuvPPPz8SrCCQwZxO5HUhkd+bEOmO1iMRRrZv/M6/aGT75i6y17KGbIz4I9s3e8jHFX8UvIjTRiLaues3dWSY06OCZkwemmqWKlUqIqWDAx3nbvPmzc2pRMMcnLxUDIRfK93xwSDPo48+ahmo/fr1M3ktwIGDg5KIKfgM6VdffTUoWLCgBSy8Ux0kUZT1Ob5ly5bg22+/jVRNrF27NmjXrp01nA9DY1icojQk81JpaIF269YtQzOydCQ6EMl87tWrl8k/TZgwIdPnrVmzxuS46tevn+G5Ys/jjLwTgQbWCyqAyFJ//vnn99hEnioupKOQkEqVdQJdWj4/8+ihhx6K99sRmcAcjJ5zBN9p/Ei1W5hp06ZZv4votZWAPXsLj9YLIcTeoPVIRM8Hj2zf3Ee2b3yQvZZ9ZGPEF9m+2UM+rsRAwYs8INoJQAY6si04F1u0aGFyDvSzACorkCQCKi9Kly4dNG7cOKJTD8hAEMhAz57eC5dffnnk+WJX6F1BQ6zKlSubhj09QRg7n5VOhir9F8Lcfffd1jeAbGPJQ2WOz+aNhobmFSpUsIxfxvbdd9+14zT6JRA3duzYDBcDNAIJIvnvJJp0qiZijJCMi4bKKxrr1q1b15zpBNh2Bw2Vaa7sG/FGZ2GlioM9p6A6BdknZORoROb7AbRp08b6hfieILvLZluyZEmQaixdujStzr9kIzwfCcbfcccdVtG2bNkyq56gXxM6wmEIIrOOEJDi+kjwnoBGrEaPqm4QQmg9EtlFtm98ke2b+8he23dkY8QX2b6ZIx9XYqLgRR5CwOHQQw+1LHMa6Hbp0sUCE0WLFjUpB6C3xUEHHRSUKVPGnAloVnvIXCcj3feywPmoXgC73zjjJEd+iAakCxcutOPz58+3oBEOHOA4QSIyVF988UWryiCggYOYLFWx67hSjcLcRVYk7ATHyYmmOtJQOM+pvKBnAAEMmvxyP5UDNOoOy+jQw4WsdTT1091xxvycMmXKLp8feS3kXqhoyQqbNm0KOnbsaI53sXsIrhHUZE4TTKbPjR97MtSpPrjvvvuynJGejvNWxA9fkYVEFHOYYLBPdDjmmGNMEsr3yfLVbsgfUl3IWs0eZODAgXH8BEKIVEHrkQgj2zfvzz/ZvnmD7DWRzMj23RX5uBIfBS/yAJyNOMrJLKfqIrp5K5UT9F1ApgSoyiDIER2YGDJkiAU5ErmBZrzILIuc/gnofuOgCUPGKdntTz31lN1G075OnTqWdY0DqHPnzpLNiAEBNN8YHgdvNGSqM9YE2byeJeNMs/O5c+faMTTzqSDwgQrvDM6qUz6VCDu5o53iBB+Q0PKZEVRZhWVdslI9Ed3LJd2J1UCPY8zFSy+9NOZzqGpjPWjSpEnw2Wef2THmctgZLEQ84XpGbyDWXea3T3AApCWp5vSyk9GNdLn2kaHpkVyUEELrkdhXZPvmPrJ98w7ZayJZke2bNeTjSg4UvMgDPv30U3Po+kz/aE1YypLoW0F2OoEJ5GCqVKlijyf7HykdKgdwrPtmsCL2goy0DouPB/mM7t27m2SU73PhG3ATJMIh6R28OOVpYsx9InaEHgcZsiQeAnFkphOkACpX6MeAsx1nME2jr776agtqeKi+QBKNYB4ZwNGko5wREi9hCFoQ9GnVqlWGXjj0U/DBy+w4GdNxTHc3Bj4A50FGjgotnLijR4+2KhcqVugrwjgz92nGzfynlwCScvS4ECKeTeKA9YBqTh8M9o8JS301atTI+j0R3KCfFlJo0fA8BS6EEFqPRE4g2zf3kO0bP2SviWRCtm/WkI8recjvRK5To0YNd8kll7g1a9a4J598MnJ8v/32s99HHnmka9asmfv+++/d3LlzXZMmTdzEiRPdypUr3aBBg1ynTp3scR999JFr165d2n5jBNuiyZcvn8ufP7/77LPPXP369d0FF1xgv2+66SYbv8KFC7vzzjvPVa1a1T3xxBOR51WqVMm1atXKbdy40Q0bNsyOlShRwp144ol2n9iVo48+2sbn7bfftrGF559/3t1yyy32G+rWreu+/fZbt//++7utW7fafB49erQrV66cW7p0qZs2bZp9Z4z9yJEjbayjv1d/XqQLbdq0cf369XM//fSTzVHO8WLFirmuXbu6efPmuffff98VL17c1atXz82cOdMtWbLEnsc4wpQpU9ycOXMyPUfScUwzGwPGp3fv3q5x48a2Ltx8881238CBA92XX37pqlSp4mbNmmXrCY/v37+/mz59uo39ww8/7M4++2xbY3799Vd31FFHxfsjiRRl586dGW7/+eefdr4zJ1lXWSs4Blu2bHGFChWya1z4XC9QoEDk+bfddps95+KLL3bdunVzderU2WW94Hl+TRFCCK1HYl+Q7ZszyPZNHGSviWRDtm/WkI8riYh39CRdoJfFhRdeGJxzzjnB999/v0v1xZo1a4ICBQoETz/9dOQ5ZK+TCUwTznQmM/14nyWKvjeNtem1QCY/t6lkQY7Lg743DUrRsw9nX/ft2zfSX0BkPv5ehuTll182TXXfowU6dOhgPUR8TxG+hwMPPDBDFi9zmaoBnuelkNIdP6/ffvtta25OZRX9bh544AE7vnr1alsvaHruQW6LDOpnn33W+om88MILlnXdr18/ZU3HGN/wHKQiC2k4+ldQwYZMH/O0f//+dj/VQ6wfrLle2q9ixYrBgw8+GHmN8OupibXIbd55550Mt2+88UaryqQKi3WYNQBYA2g2/7///c9u+30FlYS+txB7EBp3q7pCCKH1SOQFsn33Htm+iYPsNZEsyPbN/njJx5VcqPIij6hYsaJr3bq127x5sxs/frwdo2LAZ0n+8ssvrkiRIq5gwYKR53C7bNmylg2cztkmjBM8/fTTbsSIEZbNv3379kiWKFmqHTt2dKNGjXKHH364VVO888477uWXX3b//e9/7TFt27Z1Bx98sL0GWdO+0uKuu+5yF154Ydw+YzLA+JPZS+UQ85cqCioC+IEuXbpY1RDVF3wX11xzjVVekN1Oxi9jXrt2bffmm29a1jpVBZ7MKgVSmb/++ivDvF62bJnbtGmTjR2VFT179rTjlStXtuqL5cuXuwkTJtgxqljKlCnjOnTo4Fq2bGlVWVR13X333cqaDsG8YnxZI1asWGHH5s+f7w444ABbG6huOf30023MP/zwQ7dhwwbLXGf9KFWqlCtatKiNefny5W3ueni9/5dbzJDZLkROwzk+ePBgu9b9/PPPrn379nbtowLooYcesrnLPKbSbcCAAVbV9tJLL9lz2Vf88ccf7t5773VPPfVUZA/SqFEjm8N+DRJCCK1HIreQ7Zt9ZPsmDrLXRDIh2zf7yMeVhMQ7epJOkH1+1VVXmbY6GZE+Q5Lj6FWfdtpp9rfICH0/aGBOdmmtWrUsW/r666/PkAFNFQXNdNGjP/744y1bmgx1xpS+F0CfBRpHh6svxJ4hU/eWW24J8ufPb30sqGChXwVNjH02Sq9evawnAM1fYcmSJdZTBK312rVrW+VLuo9hdMbzpEmTgkWLFlljbvrcUHlx5513ZujHwH3dunWzbGsPawZawnPmzIn0v9hdlla6wthccskl1qyYarcePXrYnOV7oIdQyZIlrfLKZ6vDggULrBKDdeOAAw4IHn/88bh+BpF++PN46NChkfMejWX6ZnmtZaqI6C1UvXp1m7NAZSfHWHMHDRpk1YhcL/1eQwghtB6JvEa2794h2zc+yF4TyYxs3+whH1fyoeBFHjN37lwLXiCh48HRUKNGjUgzbsk6/M2WLVusaTmO8jFjxtgGmGbaNIDmGI3Oww4fHOs4J7/77ruIfFHhwoWDu+++227TmNs7ekTWWb58eXD44YcHU6dOjRwjCEeD+SeffNJur1q1Kqhfv76NObI7Hr4zL8GTbo2jZ82aZeMT/ZmReiJQQUPu22+/PRKsIIDJmLJGRDeROvroo4M+ffrE/D+SL9oVGscTCCKAhsOXMbr11lsteFmsWLHgvPPOs2Cnh6Ab85T1hcDokCFDMoyr1mSR1zzzzDM2X5GN5G+CF16mr0SJEraHCK+1rCME5jt16hS0bNkyGD58uL40IYTWIxF3ZPtmHdm+eY/sNZEKyPbNPvJxJR8KXsQBstgbNmxoWb84JcmQRItaZITschw2BDDCDBw4MChatGgGJy8Bi7A+Pfp1BDNwEPMa4exqsSs4Z6Od7N5hS58LejJQJeChNwD9GHCSeQcazjJ6MjzyyCO7vEa0BmM6wPyjugL8Z58xY0ZwxBFHBPfcc48Fdn788cfI4+kFcswxxwQ9e/YM1q9fHzmOE521gixqX0UkMq82IdOcSi36h4waNSpyfPr06RaEI8AZhqqMZs2aRYLHXvvSj70Qucm4ceMyBCH8nOP6RpDiiy++sKA7fxcsWNCqhj7++OPI4z/66KPgrbfeyjBXw+dFOgWMhRD7htYjkVvI9s0asn3zHtlrIpmQ7Zs95ONKLdTzIg6gXU3fhTFjxrjOnTu7lStXmha1yEiNGjVMz59eC9OnT7dj6H0/+OCD1lOhUqVKkcf+9ttv7uSTT7aeAWjYDxo0yPozjBw50r399tumdS9is2PHDtNBRycd7X96AvDbg3Y6up++RwNa6/QGOO2006yPhe8rQn8GvgO+N4/vS+L7D6TLeAK9bS666CIbL8YQmJv0UbjxxhutZ8Lvv//ufvzxR7d+/XrrBdKnTx83e/Zs98wzz7i1a9e6Fi1aWM+LoUOHuoULF7rChQvH+dMl1jiH56TnxBNPdN26dbM1IXy8VatW7swzz3TvvfeeGzZsmPXAmDp1qvvXv/5lj2PuAv1d1NdC5AWLFy92ffv2dc2bN3eTJ0+2Y35O16tXz+biggUL3JFHHmk9hI4++mjrLVSzZs1Iryz64HCNC8Nr+Lnv+2oJIYTWIxEvZPtmDdm+eYfsNZFsyPbN/njJx5VixDt6kq689957GTJ8RWzWrVtnWt716tWLVKkgWXTllVcGZ555pskU+Wz05557zvoxHHLIIdb34sMPP9SwZgNkiegngnQR4/zQQw9F7qtUqZJVBGzfvj1ybMKECUGpUqVMd33hwoUa66hsCCL9ZEXTC4SSZBg5cmRQuXJlq6S44IILgnPPPdcqBBhz5GGAPg1UDJUuXdp6L1BC7lElQEaQymHeIrn12GOPBVu3bo1UYjF2SOx4GTlYvXq19b4pV65ccPLJJ1uFBvJSQsQL5ifVFPRYmThxYqSPDRJmp59+ejB48GC7jWxf+fLlg/bt29tcnzx5svWBos8T64wQQmg9EomMbN+sIds395G9JpIV2b7ZRz6u1EHBC5HwIOdC4AJHTnQzM3qFIMH1xBNP2DEcP4sXL47TO00OcKqHN21IauFEZ3yRKmEMb7vtNhtbtNbhP//5j0mWICmAs42AEb1HunbtGowYMSLiNE7XxtHRDd687BPjRNNdmm6z2fjhhx+s90KdOnWshJ5eLgTZcKLTUBqQkkL6aOnSpXH7PMnAo48+GpQpU8Z6CCEFhbTZddddFwlWEHwjQMGcjYb5umLFCpPu8kheR+Q00WthtHSevx/ZKBrFly1b1oLE/nE03yYA59eSN99809ZpgvQELnxgQwghtB4JkTrI9s0dZK+JZEa27+6Rjyv1UfBCJDw4bai2wJGDUzcMzmDuK1SokJpxZ3NBJwOKngwcIyKNtjosWbLEKgHQWD/11FMjgQmc6zSQpS8DmetUw6xduzZId8JOb+Yqmf0Egz7//HM7Nn78eGvQ7XsqxIL+IQSMouG7SXeneqxeKTTYaty4caRhPPTu3dsqhO666y67zbjRk4Xm3D4QFGssOZZu/VhE3hJr3sUK8g4bNswCmawfVF48/PDDFriPnp8EnH2FRmavL4QQWo+ESE5k++Y8stdEsiDbN/vjJR9XeqDghUgKqAggw9pnp4cldLZt26aG3FHsrvqBzRuRe4ITNNnmsb6heb9+/YKDDz7YZHgef/zxoGrVqsHQoUPtPrLUly1bZg61p59+OsNryvkbWMZ09+7dg9q1a5sT/YEHHoiMDxJnOCRxuvvx+uqrryxQRGY1jaQlvbUrmclkcc6/+OKL9jdj2rx5c5PdISMdmS4vozNz5kyTkCOrXYi85pdffrGg+5AhQ+z2yy+/bNJxma3XrM3MXaTlCM4ReGvatGlEUi56vVXgTQih9UiI1ES2b+4ge00kMrJ9d498XOmNghciaUBmBx37F154IW3lifZEdBABCZ3wRRAZqCZNmgRXXHGFOXbDvP322yaz89JLL9ntjRs3BhUrVrT+F5999lnM/6eM379lnpo1a2bVKozp/fffb8EIqlbmz58fGVt6sTz44IM2ZvPmzbOKIY61aNHCsqzTmd0Fv+gNxLlPVnp00IxqITT/O3XqZN/DW2+9Zb1CqCTyMM70BxAiHnOaYG/x4sWtUg3pPS9xGAt/TWO9YN7my5fPfsJ9W4QQQuuREOmBbN+cQ/aaSCRk++7beMnHlZ4UiHfDcCGySvv27d2cOXPcjBkz3DnnnOP2228/DV4IgpH58uWzv5977jn3yCOPuAMOOMBVrVrV9ejRw1WqVMmdcsoprkOHDu7AAw90AwcOtMfu2LHDxnLx4sXuu+++cw0aNLDjn376qTviiCPcr7/+6l5++WVXrVq1Xf5XOn0H/x/sdfnz588w1ps2bXKfffaZGz16tPv3v/9tx+rVq+e6dOlic7VWrVru9NNPd2effbabPHmyO+2001zdunVtXK+66ipXs2bNDN9DOuLH0rNz504bZ8avc+fO7sgjj3TVq1d3999/v1u4cKHr3r27zc1Zs2a57du3u5EjR7pSpUq5YsWKuUKFCrlp06a52rVr25rB98JrCZHXc5pzesWKFXaub9y40W3bts0VKJD5tsvPU9YL1gkoU6aMq1ChQp69byFE6qH1SIjkRLZv9pG9JpIB2b5ZRz4u4ZFHRyQNxx9/vDkvx4wZk7ZO3j1dBL/66it3xhlnmHO3adOm7uKLL3atW7e2wAULP07gvn37ut9//92c7uDHkoBGuXLlLKgxZcoU179/f9eiRQs3c+ZMd/311+/yv9IJnJB8ZpyLOMvDn3/58uXur7/+csccc4zdZpwJXjRs2NCc6HPnzrXjQ4cONcc7Dneez/dD4ILHp3PgAj7//HN34403WhAIGGcCGGPHjnW9e/d27733nnv00UfdlVde6caNG+def/11e9yGDRtszm7ZssVuv/jii+7cc8+1xxEg8q/FGAuR2zBnPRMnTnSnnnqqK1iwoLvzzjvdl19+aQHi6Mftbr3hWnfHHXfk+vsWQqQeWo+ESH5k+2YP2WsiWZDtm3Xk4xIR4l36IYTIGX7++eegVatWQfv27XdppE2PgA8++CAiTVKqVCnra8Fxz6ZNm0yaB/kjNNd9rwuPZLqCYNCgQcFZZ50VdOnSJZg6dWpE1qho0aLB2LFj7baX6Vq8eHFQoECBoHPnzhHZl1dffTVTLct0IdY8on8FvVZGjBgRuR/JrRNPPNFktugPQs8Q5i2NzX/66Sd7zLRp04IaNWoExx13nD2WefvJJ5/k+WcSwsN5jywccnDjxo2z+UvjzXPOOcf64exNmbR6Cgkh9gatR0KIdET2mkgkZPvuG/JxCY+CF0KkCPQDoAk3eulhZ9fdd98dHHTQQdbrggbRXoe9WLFikZ4MYb7//ntrzu1R0CII1q1bZ47H6tWrB/fdd581jy9Tpkxw77332hgRCKpQoUKwYcOGyLgRzDj22GOD+vXrB//9738zjLHG9G/C85QgD82NcfzCokWLLPhz7bXXWtCibdu2wZdffhl5/Jo1a+z3hx9+aA2R77rrLo2xyFNincf0Cdpvv/2sr1CY9957LyhcuHDw1FNP5eE7FEKkC1qPhBDpjuw1kejI9s0+8nEJj4IXQqQIPXv2DI4//vgMx66++mrLRqeBMc24ww7eatWqBe3atbOKC4jO7iVjOB0yfqM/Y6zPTMPnk046KVi9erXdpmKFIMb+++8frFq1yjICaNLdsGFDO05FAH8/99xzFvC46aabMn3tdINAzmGHHRZMnDgx+PbbbyPHly1bZvO3X79+1lRv+/btQePGjS3I5oNu4cbzzGUeF026V7aI3Ie1MTPeeecda7Ldq1evDMeZz7179w7Kly9vAeItW7YEw4cPDz7//PM8eMdCiFRF65EQIh2QvSaSFdm++4Z8XMKjnhdCpAhr1qxxRYoUsabbHvTSv/jiC+sVQn+Ft956K9KD4cEHH7TeFh999FHMPhb0YEiH3hZ8xj/++MO98cYbkdvR0IuBpruVK1e220WLFnXXXnutO+qoo9xtt93mihcvbr1B6Cny+OOPW88Reo+cd955rnz58u7jjz/O9LXTjdmzZ7tvvvnG3X333dbgfMmSJe63336zniGM1yuvvOLeeecd6xXQrl07a3JMv4Dvv//e/fnnn+6ZZ55xt99+uz2H+R6GgPzuGiILkRP4/jTMxcsuu8zddNNNbunSpdYPp0GDBq558+buzTfftDXZw3weMGCAK1mypPW7oQn3Sy+9ZD1bhBBC65EQQmSO7DWRrMj23Tfk4xIRImEMIURSgxQUsiRvvPFGBhkBn5W3cOFCy/rt37+/9WkAKgPSHTL1qVCh18cXX3wRU36BXgy1atUy/ejw/Xfeeacd9z0YYOPGjaZxDytWrLBqgmeffTZIJ6LHL5wtRf8KZMy6d+8etG7d2sbnoosusnlKdnrdunWDSy+9NPjhhx/s8X379g3KlSsXHHPMMUG9evWCkiVL2lwXIl5Q8UMPFuZxjx49giOOOMIqs3yfICq08ufPHzz44IM2p8PnAP2IHn/88QzrtBBCaD0SQojMkb0mEhnZvrmHfFzCo8oLIVIEn+U/atSoSPVF/vz5I1nCULVqVde4cWNXqFChyHN8xnq6Qqb+Oeec48qUKeOeeOKJyLiFx+XEE0+0aotp06ZluJ+KjMMOO8yVKFHC7dy5045RDUClxa233uoaNWrkjjjiCPudTvjxWbx48S4VJ8zBbt26Wdb5iBEj7Gf+/Pmufv367sUXX3RXX321+/zzz92MGTPs8cOGDbO/qSLq3Lmz27Rpk1W2gB9zIXKLWGsjlUFUA82bN88q2BYuXGhVROPGjbNKNiq0mKP33nuvW7VqVeQc4LUOPfRQd8UVV0TWhB07dujLE0JoPRJCiN0ge00kMrJ9cw/5uIRHwQshUgRkSAYPHuyee+45c5z/+OOPJrmzZcsWkzJCgueEE05wp5xyyi7PTXc5I4IXtWvXNif666+/HnGM+3E588wzzbk+depUN2TIEHNI8rhPPvkk4oT0mxackUghUSKK8xLH+0EHHeTSid9//92ddNJJNu/CDmD/u1+/fibVhZzZ2WefbRI75557rknwvPbaa27jxo0mb7Zo0SJ7fJ06ddz5559vwQvkd/76668MYy5ETuODCuG10QfLVqxYYXO8SpUqdrtUqVKuY8eOrkaNGnbOA0EN1t/hw4eb5Fz0a/lzIRxcFkIIrUdCCBEb2WsiUZHtm3vIxyUiRGowhBApAQ2Py5YtGxQqVMgkjU455ZSgTJkywdixY+P91hKaRYsWBU2bNg06deoUafpMCagvA0XGaPTo0UGJEiWsCTe/Bw4cGPO1fvnllyBdiNWEHHktJMqWL18eeUx0U9EJEyYEBQsWNDkzz4wZM4Irr7zSGh7z89hjj2Xp/wmRW2XfL7/8cnDvvfdaI27PrbfeahJmK1euzPDYAQMGBC1atAg2b95st0eNGhW0bNky2LZtm74gIYTWIyGE2Edkr4l4I9s3PsjHJfIxBP+EMoQQyQ6n9Lp169ysWbMsexiJqC5dumTIHlbGemzIkqaJ+TXXXOMuueQSG0ufLb1hwwZXrFgxy/pH1ujYY491Bx54oMbUOauieO+99yJVKGPHjnVPPfWUVVSEG2j/8ssv1uC8f//+7oADDnCnnXaaZa0jx1W4cOHI4x566CGT6bryyitz6SwRYvfQHJ41gAoqZKBYU8866yxr0k3l1cknn+xGjhxpj/FzHMmzBQsWuA8++EBrrBAix9B6JIQQ/yB7TcQb2b55j3xc4h+vkhAiZahUqZL1FQiD0x0nmwIXmdO+fXv3/vvvWwCjadOmrly5cm7r1q0mf/TAAw+43r17u+uuu84kpIDgEOOZzmPKvGJckNz6z3/+46pXr26Bi1NPPTVD4AI5nTvvvNOcvsjpELzgGAEPHMRt2rSJBIt69OgReZ6CbSKvQXYPo4Q+OAQqCAAvXbrUNWnSxA0aNMgCcPStQPaMMvEOHTpYcAMZubZt2+6yHrBOSB5KCKH1SAgh9h3ZayKeyPaNH/JxpTfp63ETIkWJ1b8Cp3DYkSxiU7FiRde6dWvrEzJ+/HirHKA6AGdm3759LXARBodkuvcL8Q30CEZMmjTJffvtt9bz44ILLog8hsbGNOh+9NFHrafFIYccYsfr1atn403GOn0BoseSeZvOgSGRuxBUiC4+pSE8zbjvvvtum5P0qylRooTNVXoKTZgwwXpecD/9Wm666SYLahCsoxk3czkaBS6EEFqPhBAiZ5C9JuKJbN/4IB+XkGyUEEKEIOO6V69eFrxAqgEJqYcffjhyvyoBYkMTbjLPMSi+//57N3HiRHfwwQdH7t++fbtlsEezfv16k9ohACJEXhGWhFu7dq0rX758ZH4SbKN5PEEJJNCorihSpIjdRzCD6ouePXvanF65cqVbvny5O+KII9yJJ564y2sLIYTWIyGEyFlkr4l4I9tXiLxFwQshhIhi7ty5bs6cORa4OOywwzLIbonYfPzxx27gwIE2bnD00Ue7WrVquebNm7vatWtbjxAh4k04+EiQDfmnxYsX23lOFRCGCBUZSJzxs3r1agtscAyQjGvQoIHpLcd6bVC1kBBC65EQQuQustdEPJHtK0TeouCFEELsBt/XQpnUe4YGxvQLqVatmjU3fuKJJ9zChQstcx1JHfpdNG7c2LLahYgnn3/+uc1VelpcdNFF1mSbHhY33HCDBTA2btzozj33XNNWpYqIiotPP/3UKoQee+wx64kTRtUWQgitR0IIER9kr4l4INtXiLxDacRCCJEJZFJLrz7rXHjhhe7dd991P/zwgwUvaF68efNmcxTTCJ0eIl5aR4i8IlrqjT4Vd911l6tbt6575plnXOXKld2///1vV6xYMTd16lSrGKIKo0+fPtbD4qSTTrIeLuPGjbPHUXkRjYKbQgitR0IIkffIXhPxQravEHmHKi+EEELkGDTtpkdIy5Yt3YABA+yYstJFvKFqomTJkq5KlSpu6dKlrmPHjhbQINhGrwuCD1QINWzY0NWpU8fm8Ndff+2GDBni3nrrLff888+bvjIBDyGE0HokhBBCCNm+QuQN/6QiCiGEEPvI+eef70444QTbyNHAG3AME8AA3ztAiNwi1hxD5glJqD///NMdd9xxJl22ZMkSt2bNGpuf9LShKXezZs1MQxmqVq1q1UO//fabW7RokQUuaNKtOSyE0HokhBBCCNm+QuQNCl4IIYTIMQoXLmybOH5w/kbL6kiGS+QUPiAWTXiO+ceMHTvWvfjii+7tt9+2udihQwdXvXp117dvX5MbKFDgbxXNdevWWXN5qix8g24eSwUGgQuqNDSHhRBaj4QQQggh21eIvEGyUUIIIYRI2j4W8+fPt4qKU045xRUvXtx6rHTr1s0acleoUCHynLPPPtukoWbOnOlKlSrlXnjhBQuytWrVyn5/9913FqSgcfdVV10VeR7SUvTAGDZsmLv88svj8nmFEImL1iMhhBBCCCFyD1VeCCGEyDWHjhC5AYGLxYsXW48KJKCee+45t3LlSruvfPnybsGCBW7UqFEZnvPAAw9YoIPHQpMmTey59LNYvXq1mzFjhnvqqacigQtftXHyySe7jz76SIELIYTWIyGEEELERLavELmHghdCCCFy5wLz/5nxQuQUPqBAQ+2zzjrL+qtQSdGzZ09Xs2ZNu69MmTLuoYcecsOHD3efffZZxJig18Wll17q7rvvPut1UaxYMQtUFC1a1AIeSEq1adPG/geP91JnlINXrlxZX6IQQuuREEIIIWT7CpHHyLMkhBBCiKSAgMLPP//spk6d6m6++WYLYtCj4qijjsrwuM6dO9vxoUOHWjNuH0grV66cW7ZsmRszZowFKGrVquWuueYaey3f5wIUeBNCaD0SQgghhBAi/ih4IYQQQoik4f3337eKijPOOCNy7KuvvnJffPGFyTutX7/eghz33HOPBTmmT59uvS5gx44d7uKLL7bn0yeD5tsEL7Zt22bVG+ArLoQQQuuREEIIIYQQ8UUNu4UQQgiRNPz222+ubNmy7oILLnAtWrSwXhXr1q1zGzZssKqKOnXquLFjx5qkFI27J0+e7Bo0aGCPoVH37Nmz3f777x95PWSiJk2a5EqUKOHOPffcuH42IURyofVICCGEEEKI3EXBCyGEEEIkFVOmTHGjR492H3/8sVVgnH322e6YY46x+2699VbrZzFnzhwLTEycONHNmzfPValSxeShPMhJFShQII6fQgiRCmg9EkIIIYQQIvdQ8EIIIYQQScdPP/1ksk8EKsKBiO7du7sFCxZYI++DDz7YjtHfwvexQDqK5wkhhNYjIYQQQgghEhulHAohhBAi6ShZsmTkbx+4+OWXX6z/RZMmTSKBCyBwQRUGKHAhhNB6JIQQQgghRHKght1CCCGESFp+/vlnt3HjRvf666+7pk2bWsPutm3b7vI4GnGrGbcQQuuREEIIIYQQyYMqL4QQQgiRlPz444+uXbt29venn35qf48cOTLeb0sIkYZoPRJCCCGEECLnUc8LIYQQQiQtNOZGKurcc891FStWtGPqayGE0HokhBBCCCFE8qPghRBCCCFSAoIW9LeQPJQQIt5oPRJCCCGEEGLfUfBCCCGEEEkPDbkVtBBCJAJaj4QQQgghhMgZFLwQQgghhBBCCCGEEEIIIURCkT/eb0AIIYQQQgghhBBCCCGEECKMghdCCCGEEEIIIYQQQgghhEgoFLwQQgghhBBCCCGEEEIIIURCoeCFEEIIIYQQQgghhBBCCCESCgUvhBBCCCGEEEIIIYQQQgiRUCh4IYQQQgghhBBCCCGEEEKIhELBCyGEEEIIIYQQQgghhBBCJBQKXgghhBBCCCGEEEIIIYQQIqFQ8EIIIYQQQgghhBBCCCGEEAmFghdCCCGEEEIIIYQQQgghhHCJxP8B0PebIYq0sfoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the selected sampler's models for overfitting index comparison\n",
    "overfitting_index_plot(selected_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating feature importance for TPE...\n",
      "âœ“ Saved TPE feature importance to: ../artifacts/ds2/models/tpe/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for GP...\n",
      "âœ“ Saved GP feature importance to: ../artifacts/ds2/models/gp/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for CMA-ES...\n",
      "âœ“ Saved CMA-ES feature importance to: ../artifacts/ds2/models/cmaes/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for QMC...\n",
      "âœ“ Saved QMC feature importance to: ../artifacts/ds2/models/qmc/sel-nnml_feature_importance.csv\n",
      "\n",
      "All feature importance data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save feature importance results for all samplers\n",
    "import os\n",
    "\n",
    "for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']:\n",
    "    # Set the sampler\n",
    "    temp_sampler = sampler\n",
    "    temp_models = all_models[temp_sampler]\n",
    "    temp_sel_nnml = temp_models['SEL-NNML']\n",
    "    \n",
    "    # Calculate permutation importance for this sampler\n",
    "    print(f\"Calculating feature importance for {temp_sampler}...\")\n",
    "    temp_perm_importance = permutation_importance(\n",
    "        temp_sel_nnml, X_test, y_test,\n",
    "        n_repeats=30, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Create dataframe\n",
    "    temp_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns.tolist(),\n",
    "        'Importance Mean': temp_perm_importance.importances_mean,\n",
    "        'Importance Std': temp_perm_importance.importances_std\n",
    "    }).sort_values('Importance Mean', ascending=False)\n",
    "    \n",
    "    # Save to CSV\n",
    "    sampler_folder = temp_sampler.lower().replace(\"-\", \"\")\n",
    "    os.makedirs(f'../artifacts/ds2/models/{sampler_folder}', exist_ok=True)\n",
    "    importance_save_path = f'../artifacts/ds2/models/{sampler_folder}/sel-nnml_feature_importance.csv'\n",
    "    temp_importance_df.to_csv(importance_save_path, index=False)\n",
    "    print(f\"âœ“ Saved {temp_sampler} feature importance to: {importance_save_path}\")\n",
    "\n",
    "print(\"\\nAll feature importance data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3 Save All Models Metrics (All Samplers)**\n",
    "\n",
    "This section calculates and saves performance metrics for all models across all samplers. This data will be used for cross-sampler comparisons in the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for all models across all samplers + baseline models...\n",
      "\n",
      "Processing BASELINE models...\n",
      "  âœ“ Logistic Regression (Default): Acc=0.8833, AUC=0.9514\n",
      "  âœ“ Decision Tree (Default): Acc=0.8167, AUC=0.8333\n",
      "  âœ“ Random Forest (Default): Acc=0.8667, AUC=0.9572\n",
      "  âœ“ K-Nearest Neighbors (Default): Acc=0.8833, AUC=0.9456\n",
      "  âœ“ Support Vector Machine (Default): Acc=0.9000, AUC=0.9560\n",
      "  âœ“ AdaBoost (Default): Acc=0.8833, AUC=0.9086\n",
      "  âœ“ Gradient Boosting (Default): Acc=0.8333, AUC=0.9051\n",
      "  âœ“ Stacking + Linear Regression: Acc=0.8833, AUC=0.9641\n",
      "  âœ“ Stacking + Default MLP: Acc=0.8833, AUC=0.9606\n",
      "\n",
      "Processing TPE models...\n",
      "  âœ“ Logistic Regression: Acc=0.8833, AUC=0.9641\n",
      "  âœ“ Decision Tree: Acc=0.7333, AUC=0.8449\n",
      "  âœ“ Random Forest: Acc=0.8833, AUC=0.9537\n",
      "  âœ“ K-Nearest Neighbors: Acc=0.8833, AUC=0.9439\n",
      "  âœ“ Support Vector Machine: Acc=0.7833, AUC=0.9514\n",
      "  âœ“ AdaBoost: Acc=0.9167, AUC=0.9514\n",
      "  âœ“ Gradient Boosting: Acc=0.8667, AUC=0.9606\n",
      "  âœ“ SEL-NNML: Acc=0.9167, AUC=0.9549\n",
      "\n",
      "Processing GP models...\n",
      "  âœ“ Logistic Regression: Acc=0.8833, AUC=0.9641\n",
      "  âœ“ Decision Tree: Acc=0.8000, AUC=0.9022\n",
      "  âœ“ Random Forest: Acc=0.8667, AUC=0.9572\n",
      "  âœ“ K-Nearest Neighbors: Acc=0.8667, AUC=0.9439\n",
      "  âœ“ Support Vector Machine: Acc=0.7833, AUC=0.9514\n",
      "  âœ“ AdaBoost: Acc=0.9167, AUC=0.9514\n",
      "  âœ“ Gradient Boosting: Acc=0.8833, AUC=0.9606\n",
      "  âœ“ SEL-NNML: Acc=0.9167, AUC=0.9549\n",
      "\n",
      "Processing CMA-ES models...\n",
      "  âœ“ Logistic Regression: Acc=0.8833, AUC=0.9641\n",
      "  âœ“ Decision Tree: Acc=0.7500, AUC=0.8553\n",
      "  âœ“ Random Forest: Acc=0.8833, AUC=0.9560\n",
      "  âœ“ K-Nearest Neighbors: Acc=0.9167, AUC=0.9520\n",
      "  âœ“ Support Vector Machine: Acc=0.7833, AUC=0.9514\n",
      "  âœ“ AdaBoost: Acc=0.8500, AUC=0.9340\n",
      "  âœ“ Gradient Boosting: Acc=0.8833, AUC=0.9572\n",
      "  âœ“ SEL-NNML: Acc=0.9333, AUC=0.9630\n",
      "\n",
      "Processing QMC models...\n",
      "  âœ“ Logistic Regression: Acc=0.8833, AUC=0.9641\n",
      "  âœ“ Decision Tree: Acc=0.8000, AUC=0.9022\n",
      "  âœ“ Random Forest: Acc=0.8667, AUC=0.9456\n",
      "  âœ“ K-Nearest Neighbors: Acc=0.8667, AUC=0.9439\n",
      "  âœ“ Support Vector Machine: Acc=0.7500, AUC=0.9468\n",
      "  âœ“ AdaBoost: Acc=0.8667, AUC=0.9444\n",
      "  âœ“ Gradient Boosting: Acc=0.9000, AUC=0.9618\n",
      "  âœ“ SEL-NNML: Acc=0.9333, AUC=0.9433\n",
      "\n",
      "âœ… Saved metrics for 41 model configurations\n",
      "   - Metrics: ../artifacts/ds2/models/all_models_metrics.csv\n",
      "   - ROC Data: ../artifacts/ds2/models/all_models_roc_data.csv\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: Top 5 Models by Accuracy\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sampler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AUC",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9f4f225a-3f68-4a19-8a64-015eb42514c5",
       "rows": [
        [
         "32",
         "CMA-ES",
         "SEL-NNML",
         "0.9333333333333333",
         "0.9166666666666666",
         "0.962962962962963"
        ],
        [
         "40",
         "QMC",
         "SEL-NNML",
         "0.9333333333333333",
         "0.92",
         "0.9432870370370371"
        ],
        [
         "14",
         "TPE",
         "AdaBoost",
         "0.9166666666666666",
         "0.8979591836734694",
         "0.951388888888889"
        ],
        [
         "16",
         "TPE",
         "SEL-NNML",
         "0.9166666666666666",
         "0.8936170212765957",
         "0.954861111111111"
        ],
        [
         "22",
         "GP",
         "AdaBoost",
         "0.9166666666666666",
         "0.8979591836734694",
         "0.951388888888889"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>QMC</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.943287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TPE</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.951389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TPE</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.954861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GP</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.951389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sampler     Model  Accuracy  F1-Score       AUC\n",
       "32  CMA-ES  SEL-NNML  0.933333  0.916667  0.962963\n",
       "40     QMC  SEL-NNML  0.933333  0.920000  0.943287\n",
       "14     TPE  AdaBoost  0.916667  0.897959  0.951389\n",
       "16     TPE  SEL-NNML  0.916667  0.893617  0.954861\n",
       "22      GP  AdaBoost  0.916667  0.897959  0.951389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate and save metrics for ALL models from ALL samplers + BASELINE models\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "\n",
    "print(\"Calculating metrics for all models across all samplers + baseline models...\")\n",
    "\n",
    "all_metrics_data = []\n",
    "all_roc_data = []\n",
    "\n",
    "# Process baseline models first\n",
    "print(\"\\nProcessing BASELINE models...\")\n",
    "baseline_models_dict = {\n",
    "    **{f\"{name} (Default)\": model for name, model in default_base_models.items()},\n",
    "    'Stacking + Linear Regression': stacking_lr,\n",
    "    'Stacking + Default MLP': stacking_mlp\n",
    "}\n",
    "\n",
    "for model_name, model in baseline_models_dict.items():\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get probability predictions for AUC and ROC\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_metrics_data.append({\n",
    "        'Sampler': 'Baseline',\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    # Store ROC curve data\n",
    "    for f, t in zip(fpr, tpr):\n",
    "        all_roc_data.append({\n",
    "            'Sampler': 'Baseline',\n",
    "            'Model': model_name,\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "    \n",
    "    print(f\"  âœ“ {model_name}: Acc={accuracy_score(y_test, y_pred):.4f}, AUC={roc_auc:.4f}\")\n",
    "\n",
    "# Process optimized models\n",
    "for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']:\n",
    "    print(f\"\\nProcessing {sampler} models...\")\n",
    "    models = all_models[sampler]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Get probability predictions for AUC and ROC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(X_test)\n",
    "        \n",
    "        # Calculate ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Store metrics\n",
    "        all_metrics_data.append({\n",
    "            'Sampler': sampler,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-Score': f1_score(y_test, y_pred),\n",
    "            'AUC': roc_auc\n",
    "        })\n",
    "        \n",
    "        # Store ROC curve data\n",
    "        for f, t in zip(fpr, tpr):\n",
    "            all_roc_data.append({\n",
    "                'Sampler': sampler,\n",
    "                'Model': model_name,\n",
    "                'FPR': f,\n",
    "                'TPR': t\n",
    "            })\n",
    "        \n",
    "        print(f\"  âœ“ {model_name}: Acc={accuracy_score(y_test, y_pred):.4f}, AUC={roc_auc:.4f}\")\n",
    "\n",
    "# Create DataFrames\n",
    "all_metrics_df = pd.DataFrame(all_metrics_data)\n",
    "all_roc_df = pd.DataFrame(all_roc_data)\n",
    "\n",
    "# Save to CSV files\n",
    "os.makedirs('../artifacts/ds2/models', exist_ok=True)\n",
    "all_metrics_df.to_csv('../artifacts/ds2/models/all_models_metrics.csv', index=False)\n",
    "all_roc_df.to_csv('../artifacts/ds2/models/all_models_roc_data.csv', index=False)\n",
    "\n",
    "print(f\"\\nâœ… Saved metrics for {len(all_metrics_data)} model configurations\")\n",
    "print(f\"   - Metrics: ../artifacts/ds2/models/all_models_metrics.csv\")\n",
    "print(f\"   - ROC Data: ../artifacts/ds2/models/all_models_roc_data.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: Top 5 Models by Accuracy\")\n",
    "print(\"=\"*80)\n",
    "display(all_metrics_df.nlargest(5, 'Accuracy')[['Sampler', 'Model', 'Accuracy', 'F1-Score', 'AUC']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **SECTION 7: Statistical Significance Testing**\n",
    "\n",
    "Perform paired t-tests to compare SEL-NNML (TPE) against all other 12 models using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.1 Prepare All 13 Models for Statistical Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODELS PREPARED FOR PAIRED T-TEST\n",
      "================================================================================\n",
      "Total models: 13\n",
      "\n",
      "Baseline Models (9):\n",
      "  1. Logistic Regression (Default)\n",
      "  2. Decision Tree (Default)\n",
      "  3. Random Forest (Default)\n",
      "  4. K-Nearest Neighbors (Default)\n",
      "  5. Support Vector Machine (Default)\n",
      "  6. AdaBoost (Default)\n",
      "  7. Gradient Boosting (Default)\n",
      "  8. Stacking + Linear Regression\n",
      "  9. Stacking + Default MLP\n",
      "\n",
      "Optimized SEL-NNML Models (4):\n",
      "  10. SEL-NNML (TPE)\n",
      "  11. SEL-NNML (GP)\n",
      "  12. SEL-NNML (CMA-ES)\n",
      "  13. SEL-NNML (QMC)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Collect all 13 models for paired t-test\n",
    "models_for_ttest = {}\n",
    "\n",
    "# Add 9 baseline models (7 base learners + 2 stacking)\n",
    "models_for_ttest.update({\n",
    "    f\"{name} (Default)\": model \n",
    "    for name, model in default_base_models.items()\n",
    "})\n",
    "models_for_ttest['Stacking + Linear Regression'] = stacking_lr\n",
    "models_for_ttest['Stacking + Default MLP'] = stacking_mlp\n",
    "\n",
    "# Add 4 optimized SEL-NNML models\n",
    "for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']:\n",
    "    sel_model = all_models[sampler]['SEL-NNML']\n",
    "    models_for_ttest[f\"SEL-NNML ({sampler})\"] = sel_model\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODELS PREPARED FOR PAIRED T-TEST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total models: {len(models_for_ttest)}\")\n",
    "print(\"\\nBaseline Models (9):\")\n",
    "for i, name in enumerate(list(models_for_ttest.keys())[:9], 1):\n",
    "    print(f\"  {i}. {name}\")\n",
    "print(\"\\nOptimized SEL-NNML Models (4):\")\n",
    "for i, name in enumerate(list(models_for_ttest.keys())[9:], 10):\n",
    "    print(f\"  {i}. {name}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.2 Cross-Validation for All Models (10-Fold)**\n",
    "\n",
    "Run 10-fold stratified cross-validation on all 13 models to generate paired samples for statistical testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RUNNING 10-FOLD CROSS-VALIDATION FOR ALL 13 MODELS\n",
      "================================================================================\n",
      "Metric: accuracy\n",
      "This will generate 10 paired samples for each model...\n",
      "================================================================================\n",
      "\n",
      "[1/13] Evaluating Logistic Regression (Default)... Mean=0.8313, Std=0.0522 (Time: 0.03s)\n",
      "[2/13] Evaluating Decision Tree (Default)... Mean=0.6841, Std=0.0750 (Time: 0.03s)\n",
      "[3/13] Evaluating Random Forest (Default)... Mean=0.7763, Std=0.0632 (Time: 0.25s)\n",
      "[4/13] Evaluating K-Nearest Neighbors (Default)... Mean=0.7937, Std=0.0711 (Time: 0.03s)\n",
      "[5/13] Evaluating Support Vector Machine (Default)... Mean=0.8230, Std=0.0702 (Time: 0.04s)\n",
      "[6/13] Evaluating AdaBoost (Default)... Mean=0.8149, Std=0.0626 (Time: 0.11s)\n",
      "[7/13] Evaluating Gradient Boosting (Default)... Mean=0.7645, Std=0.0851 (Time: 0.15s)\n",
      "[8/13] Evaluating Stacking + Linear Regression... Mean=0.8149, Std=0.0554 (Time: 2.95s)\n",
      "[9/13] Evaluating Stacking + Default MLP... Mean=0.8065, Std=0.0585 (Time: 2.97s)\n",
      "[10/13] Evaluating SEL-NNML (TPE)... Mean=0.8188, Std=0.0862 (Time: 1.49s)\n",
      "[11/13] Evaluating SEL-NNML (GP)... Mean=0.8230, Std=0.0857 (Time: 1.63s)\n",
      "[12/13] Evaluating SEL-NNML (CMA-ES)... Mean=0.8188, Std=0.0816 (Time: 1.12s)\n",
      "[13/13] Evaluating SEL-NNML (QMC)... Mean=0.7980, Std=0.0851 (Time: 0.76s)\n",
      "\n",
      "================================================================================\n",
      "âœ“ Cross-validation completed in 11.55 seconds (0.19 minutes)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import time\n",
    "\n",
    "# Configuration for statistical testing\n",
    "N_FOLDS_TTEST = 10  # Use 10-fold CV for better statistical power\n",
    "METRIC = 'accuracy'  # Primary metric for comparison\n",
    "\n",
    "# Create StratifiedKFold to ensure all models are evaluated on the same folds\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS_TTEST, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"RUNNING {N_FOLDS_TTEST}-FOLD CROSS-VALIDATION FOR ALL 13 MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Metric: {METRIC}\")\n",
    "print(f\"This will generate {N_FOLDS_TTEST} paired samples for each model...\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "cv_scores = {}\n",
    "cv_start_time = time.time()\n",
    "\n",
    "for idx, (name, model) in enumerate(models_for_ttest.items(), 1):\n",
    "    model_start = time.time()\n",
    "    print(f\"[{idx}/13] Evaluating {name}...\", end=\" \", flush=True)\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        model, X_train, y_train, \n",
    "        cv=skf, \n",
    "        scoring=METRIC,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "    \n",
    "    cv_scores[name] = scores\n",
    "    model_time = time.time() - model_start\n",
    "    \n",
    "    print(f\"Mean={scores.mean():.4f}, Std={scores.std(ddof=1):.4f} (Time: {model_time:.2f}s)\")\n",
    "\n",
    "total_cv_time = time.time() - cv_start_time\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ“ Cross-validation completed in {total_cv_time:.2f} seconds ({total_cv_time/60:.2f} minutes)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.3 Perform Paired t-tests**\n",
    "\n",
    "Compare SEL-NNML (TPE) against all other 12 models using paired t-tests with Bonferroni correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PAIRED T-TEST: SEL-NNML (TPE) vs. ALL OTHER MODELS\n",
      "================================================================================\n",
      "Control Model: SEL-NNML (TPE)\n",
      "Control Mean Accuracy: 0.8188 Â± 0.0862\n",
      "Number of Comparisons: 12\n",
      "Significance Level (Î±): 0.05\n",
      "Multiple Testing Correction: Bonferroni (adjusted Î± = 0.0042)\n",
      "================================================================================\n",
      "\n",
      "Model                                    Mean Diff    t-stat     p-value      p (Bonf.)    Sig?    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Decision Tree (Default)                       0.1348      4.412      0.0017      0.0203        âœ“\n",
      "Logistic Regression (Default)                -0.0125     -0.812      0.4376      1.0000        âœ—\n",
      "Random Forest (Default)                       0.0426      1.749      0.1142      1.0000        âœ—\n",
      "K-Nearest Neighbors (Default)                 0.0252      1.934      0.0852      1.0000        âœ—\n",
      "Support Vector Machine (Default)             -0.0042     -0.421      0.6836      1.0000        âœ—\n",
      "AdaBoost (Default)                            0.0040      0.220      0.8307      1.0000        âœ—\n",
      "Gradient Boosting (Default)                   0.0543      1.781      0.1085      1.0000        âœ—\n",
      "Stacking + Linear Regression                  0.0040      0.248      0.8095      1.0000        âœ—\n",
      "Stacking + Default MLP                        0.0123      0.735      0.4812      1.0000        âœ—\n",
      "SEL-NNML (GP)                                -0.0042     -1.000      0.3434      1.0000        âœ—\n",
      "SEL-NNML (CMA-ES)                             0.0000      0.000      1.0000      1.0000        âœ—\n",
      "SEL-NNML (QMC)                                0.0208      1.861      0.0957      1.0000        âœ—\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Define the control/proposed method\n",
    "CONTROL_MODEL = 'SEL-NNML (TPE)'\n",
    "ALPHA = 0.05\n",
    "\n",
    "if CONTROL_MODEL not in cv_scores:\n",
    "    raise ValueError(f\"Control model '{CONTROL_MODEL}' not found in cv_scores\")\n",
    "\n",
    "control_scores = cv_scores[CONTROL_MODEL]\n",
    "n_comparisons = len(models_for_ttest) - 1  # Exclude comparison with itself\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"PAIRED T-TEST: {CONTROL_MODEL} vs. ALL OTHER MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Control Model: {CONTROL_MODEL}\")\n",
    "print(f\"Control Mean Accuracy: {control_scores.mean():.4f} Â± {control_scores.std(ddof=1):.4f}\")\n",
    "print(f\"Number of Comparisons: {n_comparisons}\")\n",
    "print(f\"Significance Level (Î±): {ALPHA}\")\n",
    "print(f\"Multiple Testing Correction: Bonferroni (adjusted Î± = {ALPHA/n_comparisons:.4f})\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Perform paired t-tests\n",
    "results = []\n",
    "\n",
    "for name, scores in cv_scores.items():\n",
    "    if name == CONTROL_MODEL:\n",
    "        continue  # Skip comparing with itself\n",
    "    \n",
    "    # Calculate differences (control - other)\n",
    "    diff = control_scores - scores\n",
    "    \n",
    "    # Paired t-test\n",
    "    t_stat, p_val = stats.ttest_rel(control_scores, scores)\n",
    "    \n",
    "    # Cohen's d for paired samples (effect size)\n",
    "    d = diff.mean() / (diff.std(ddof=1) + 1e-12)\n",
    "    \n",
    "    # Bonferroni correction\n",
    "    p_bonf = min(1.0, p_val * n_comparisons)\n",
    "    \n",
    "    # Significance\n",
    "    is_significant = p_bonf < ALPHA\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Control Mean': control_scores.mean(),\n",
    "        'Other Mean': scores.mean(),\n",
    "        'Mean Difference': diff.mean(),\n",
    "        't-statistic': t_stat,\n",
    "        'p-value': p_val,\n",
    "        'p-value (Bonferroni)': p_bonf,\n",
    "        \"Cohen's d\": d,\n",
    "        'Significant (Î±=0.05)': is_significant\n",
    "    })\n",
    "\n",
    "# Create DataFrame and sort by p-value\n",
    "results_df = pd.DataFrame(results).sort_values('p-value (Bonferroni)')\n",
    "\n",
    "print(f\"{'Model':<40} {'Mean Diff':<12} {'t-stat':<10} {'p-value':<12} {'p (Bonf.)':<12} {'Sig?':<8}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    sig_marker = \"âœ“\" if row['Significant (Î±=0.05)'] else \"âœ—\"\n",
    "    print(f\"{row['Model']:<40} {row['Mean Difference']:>11.4f} {row['t-statistic']:>10.3f} \"\n",
    "          f\"{row['p-value']:>11.4f} {row['p-value (Bonferroni)']:>11.4f} {sig_marker:>8}\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.4 Summary and Interpretation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATISTICAL SIGNIFICANCE TEST SUMMARY\n",
      "================================================================================\n",
      "Control Model: SEL-NNML (TPE)\n",
      "Control Mean Accuracy: 0.8188 Â± 0.0862\n",
      "\n",
      "Total Comparisons: 12\n",
      "Significance Threshold (Bonferroni-corrected): p < 0.05\n",
      "\n",
      "Results:\n",
      "  âœ“ Significantly Better Than:  1/12 models\n",
      "  âœ— Significantly Worse Than:   0/12 models\n",
      "  â‰ˆ No Significant Difference:  11/12 models\n",
      "\n",
      "Models Significantly Outperformed:\n",
      "  â€¢ Decision Tree (Default)                       (Î” = +0.1348, p = 0.0203)\n",
      "================================================================================\n",
      "\n",
      "DETAILED RESULTS TABLE:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Control Mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Other Mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Mean Difference",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t-statistic",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value (Bonferroni)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cohen's d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Significant (Î±=0.05)",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "7fe80da7-d74e-4dd8-836f-7145c17149e3",
       "rows": [
        [
         "1",
         "Decision Tree (Default)",
         "0.8188405797101449",
         "0.6840579710144927",
         "0.1347826086956522",
         "4.411859909504677",
         "0.001691023906992164",
         "0.02029228688390597",
         "1.3951526031474712",
         "True"
        ],
        [
         "0",
         "Logistic Regression (Default)",
         "0.8188405797101449",
         "0.831340579710145",
         "-0.012499999999999989",
         "-0.8122395098083008",
         "0.437609851725992",
         "1.0",
         "-0.25685268565201264",
         "False"
        ],
        [
         "2",
         "Random Forest (Default)",
         "0.8188405797101449",
         "0.7762681159420289",
         "0.042572463768115965",
         "1.748970481285255",
         "0.11422859263872595",
         "1.0",
         "0.5530730281190449",
         "False"
        ],
        [
         "3",
         "K-Nearest Neighbors (Default)",
         "0.8188405797101449",
         "0.793659420289855",
         "0.025181159420289867",
         "1.9336040813977442",
         "0.0851788088115618",
         "1.0",
         "0.6114592990066011",
         "False"
        ],
        [
         "4",
         "Support Vector Machine (Default)",
         "0.8188405797101449",
         "0.8230072463768116",
         "-0.004166666666666663",
         "-0.42100572570796135",
         "0.6836264523224873",
         "1.0",
         "-0.13313370011667236",
         "False"
        ],
        [
         "5",
         "AdaBoost (Default)",
         "0.8188405797101449",
         "0.8148550724637682",
         "0.00398550724637683",
         "0.22010273858927626",
         "0.8307026316254139",
         "1.0",
         "0.06960259731705937",
         "False"
        ],
        [
         "6",
         "Gradient Boosting (Default)",
         "0.8188405797101449",
         "0.7644927536231884",
         "0.054347826086956555",
         "1.7813576656038983",
         "0.10854323250579227",
         "1.0",
         "0.5633147550650515",
         "False"
        ],
        [
         "7",
         "Stacking + Linear Regression",
         "0.8188405797101449",
         "0.814855072463768",
         "0.00398550724637684",
         "0.24833097095717205",
         "0.809451887129192",
         "1.0",
         "0.07852914817703147",
         "False"
        ],
        [
         "8",
         "Stacking + Default MLP",
         "0.8188405797101449",
         "0.8065217391304348",
         "0.012318840579710177",
         "0.7348024292252524",
         "0.48116649124102184",
         "1.0",
         "0.23236493065326422",
         "False"
        ],
        [
         "9",
         "SEL-NNML (GP)",
         "0.8188405797101449",
         "0.8230072463768117",
         "-0.004166666666666674",
         "-1.0",
         "0.34343639613791355",
         "1.0",
         "-0.3162277659928379",
         "False"
        ],
        [
         "10",
         "SEL-NNML (CMA-ES)",
         "0.8188405797101449",
         "0.8188405797101449",
         "1.1102230246251566e-17",
         "1.7874245903380357e-15",
         "0.9999999999999987",
         "1.0",
         "5.652332850973818e-16",
         "False"
        ],
        [
         "11",
         "SEL-NNML (QMC)",
         "0.8188405797101449",
         "0.7980072463768115",
         "0.02083333333333335",
         "1.8605210188381271",
         "0.09573390947125932",
         "1.0",
         "0.5883484053979369",
         "False"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Control Mean</th>\n",
       "      <th>Other Mean</th>\n",
       "      <th>Mean Difference</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value (Bonferroni)</th>\n",
       "      <th>Cohen's d</th>\n",
       "      <th>Significant (Î±=0.05)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree (Default)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.684058</td>\n",
       "      <td>1.347826e-01</td>\n",
       "      <td>4.411860e+00</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.020292</td>\n",
       "      <td>1.395153e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Default)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.831341</td>\n",
       "      <td>-1.250000e-02</td>\n",
       "      <td>-8.122395e-01</td>\n",
       "      <td>0.437610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.568527e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (Default)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.776268</td>\n",
       "      <td>4.257246e-02</td>\n",
       "      <td>1.748970e+00</td>\n",
       "      <td>0.114229</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.530730e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors (Default)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.793659</td>\n",
       "      <td>2.518116e-02</td>\n",
       "      <td>1.933604e+00</td>\n",
       "      <td>0.085179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.114593e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine (Default)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>-4.166667e-03</td>\n",
       "      <td>-4.210057e-01</td>\n",
       "      <td>0.683626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.331337e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost (Default)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>3.985507e-03</td>\n",
       "      <td>2.201027e-01</td>\n",
       "      <td>0.830703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.960260e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting (Default)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.764493</td>\n",
       "      <td>5.434783e-02</td>\n",
       "      <td>1.781358e+00</td>\n",
       "      <td>0.108543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.633148e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking + Linear Regression</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>3.985507e-03</td>\n",
       "      <td>2.483310e-01</td>\n",
       "      <td>0.809452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.852915e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stacking + Default MLP</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.806522</td>\n",
       "      <td>1.231884e-02</td>\n",
       "      <td>7.348024e-01</td>\n",
       "      <td>0.481166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.323649e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEL-NNML (GP)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>-4.166667e-03</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.343436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.162278e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SEL-NNML (CMA-ES)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>1.110223e-17</td>\n",
       "      <td>1.787425e-15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.652333e-16</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SEL-NNML (QMC)</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.798007</td>\n",
       "      <td>2.083333e-02</td>\n",
       "      <td>1.860521e+00</td>\n",
       "      <td>0.095734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.883484e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Control Mean  Other Mean  \\\n",
       "1            Decision Tree (Default)      0.818841    0.684058   \n",
       "0      Logistic Regression (Default)      0.818841    0.831341   \n",
       "2            Random Forest (Default)      0.818841    0.776268   \n",
       "3      K-Nearest Neighbors (Default)      0.818841    0.793659   \n",
       "4   Support Vector Machine (Default)      0.818841    0.823007   \n",
       "5                 AdaBoost (Default)      0.818841    0.814855   \n",
       "6        Gradient Boosting (Default)      0.818841    0.764493   \n",
       "7       Stacking + Linear Regression      0.818841    0.814855   \n",
       "8             Stacking + Default MLP      0.818841    0.806522   \n",
       "9                      SEL-NNML (GP)      0.818841    0.823007   \n",
       "10                 SEL-NNML (CMA-ES)      0.818841    0.818841   \n",
       "11                    SEL-NNML (QMC)      0.818841    0.798007   \n",
       "\n",
       "    Mean Difference   t-statistic   p-value  p-value (Bonferroni)  \\\n",
       "1      1.347826e-01  4.411860e+00  0.001691              0.020292   \n",
       "0     -1.250000e-02 -8.122395e-01  0.437610              1.000000   \n",
       "2      4.257246e-02  1.748970e+00  0.114229              1.000000   \n",
       "3      2.518116e-02  1.933604e+00  0.085179              1.000000   \n",
       "4     -4.166667e-03 -4.210057e-01  0.683626              1.000000   \n",
       "5      3.985507e-03  2.201027e-01  0.830703              1.000000   \n",
       "6      5.434783e-02  1.781358e+00  0.108543              1.000000   \n",
       "7      3.985507e-03  2.483310e-01  0.809452              1.000000   \n",
       "8      1.231884e-02  7.348024e-01  0.481166              1.000000   \n",
       "9     -4.166667e-03 -1.000000e+00  0.343436              1.000000   \n",
       "10     1.110223e-17  1.787425e-15  1.000000              1.000000   \n",
       "11     2.083333e-02  1.860521e+00  0.095734              1.000000   \n",
       "\n",
       "       Cohen's d  Significant (Î±=0.05)  \n",
       "1   1.395153e+00                  True  \n",
       "0  -2.568527e-01                 False  \n",
       "2   5.530730e-01                 False  \n",
       "3   6.114593e-01                 False  \n",
       "4  -1.331337e-01                 False  \n",
       "5   6.960260e-02                 False  \n",
       "6   5.633148e-01                 False  \n",
       "7   7.852915e-02                 False  \n",
       "8   2.323649e-01                 False  \n",
       "9  -3.162278e-01                 False  \n",
       "10  5.652333e-16                 False  \n",
       "11  5.883484e-01                 False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "sig_count = results_df['Significant (Î±=0.05)'].sum()\n",
    "better_count = (results_df['Mean Difference'] > 0).sum()\n",
    "worse_count = (results_df['Mean Difference'] < 0).sum()\n",
    "\n",
    "sig_better = results_df[(results_df['Significant (Î±=0.05)']) & (results_df['Mean Difference'] > 0)]\n",
    "sig_worse = results_df[(results_df['Significant (Î±=0.05)']) & (results_df['Mean Difference'] < 0)]\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL SIGNIFICANCE TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Control Model: {CONTROL_MODEL}\")\n",
    "print(f\"Control Mean Accuracy: {control_scores.mean():.4f} Â± {control_scores.std(ddof=1):.4f}\")\n",
    "print()\n",
    "print(f\"Total Comparisons: {n_comparisons}\")\n",
    "print(f\"Significance Threshold (Bonferroni-corrected): p < {ALPHA}\")\n",
    "print()\n",
    "print(\"Results:\")\n",
    "print(f\"  âœ“ Significantly Better Than:  {len(sig_better)}/{n_comparisons} models\")\n",
    "print(f\"  âœ— Significantly Worse Than:   {len(sig_worse)}/{n_comparisons} models\")\n",
    "print(f\"  â‰ˆ No Significant Difference:  {n_comparisons - sig_count}/{n_comparisons} models\")\n",
    "print()\n",
    "\n",
    "if len(sig_better) > 0:\n",
    "    print(\"Models Significantly Outperformed:\")\n",
    "    for _, row in sig_better.iterrows():\n",
    "        print(f\"  â€¢ {row['Model']:<45} (Î” = +{row['Mean Difference']:.4f}, p = {row['p-value (Bonferroni)']:.4f})\")\n",
    "\n",
    "if len(sig_worse) > 0:\n",
    "    print()\n",
    "    print(\"Models That Significantly Outperformed Control:\")\n",
    "    for _, row in sig_worse.iterrows():\n",
    "        print(f\"  â€¢ {row['Model']:<45} (Î” = {row['Mean Difference']:.4f}, p = {row['p-value (Bonferroni)']:.4f})\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Display full results table\n",
    "print(\"DETAILED RESULTS TABLE:\")\n",
    "print(\"=\"*80)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.5 Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Paired t-test results saved to: ../artifacts/ds2/models\\paired_ttest_results.csv\n",
      "âœ“ Cross-validation scores saved to: ../artifacts/ds2/models\\cv_scores_for_ttest.csv\n",
      "âœ“ Summary statistics saved to: ../artifacts/ds2/models\\ttest_summary.csv\n",
      "\n",
      "================================================================================\n",
      "âœ… STATISTICAL SIGNIFICANCE TESTING COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save paired t-test results\n",
    "output_dir = '../artifacts/ds2/models'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save main results\n",
    "results_path = os.path.join(output_dir, 'paired_ttest_results.csv')\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"âœ“ Paired t-test results saved to: {results_path}\")\n",
    "\n",
    "# Save CV scores for reproducibility\n",
    "cv_scores_data = []\n",
    "for model_name, scores in cv_scores.items():\n",
    "    for fold_idx, score in enumerate(scores, 1):\n",
    "        cv_scores_data.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': fold_idx,\n",
    "            'Accuracy': score\n",
    "        })\n",
    "\n",
    "cv_scores_df = pd.DataFrame(cv_scores_data)\n",
    "cv_scores_path = os.path.join(output_dir, 'cv_scores_for_ttest.csv')\n",
    "cv_scores_df.to_csv(cv_scores_path, index=False)\n",
    "print(f\"âœ“ Cross-validation scores saved to: {cv_scores_path}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_data = {\n",
    "    'Control_Model': CONTROL_MODEL,\n",
    "    'Control_Mean_Accuracy': control_scores.mean(),\n",
    "    'Control_Std_Accuracy': control_scores.std(ddof=1),\n",
    "    'Total_Comparisons': n_comparisons,\n",
    "    'Significantly_Better': len(sig_better),\n",
    "    'Significantly_Worse': len(sig_worse),\n",
    "    'No_Significant_Difference': n_comparisons - sig_count,\n",
    "    'Significance_Level': ALPHA,\n",
    "    'CV_Folds': N_FOLDS_TTEST,\n",
    "    'Metric': METRIC\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary_data])\n",
    "summary_path = os.path.join(output_dir, 'ttest_summary.csv')\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"âœ“ Summary statistics saved to: {summary_path}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… STATISTICAL SIGNIFICANCE TESTING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **SECTION 8: McNemar's Test**\n",
    "\n",
    "Perform McNemar's test to compare prediction disagreements between SEL-NNML (TPE) and other models on the test set. This test examines whether models make systematically different errors on specific instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.1 Generate Predictions on Test Set**\n",
    "\n",
    "Generate predictions from all 13 models on the test set for McNemar's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENERATING TEST SET PREDICTIONS FOR MCNEMAR'S TEST\n",
      "================================================================================\n",
      "Test set size: 60\n",
      "\n",
      "[1/13] Predicting with Logistic Regression (Default)... Accuracy: 0.8833\n",
      "[2/13] Predicting with Decision Tree (Default)... Accuracy: 0.8167\n",
      "[3/13] Predicting with Random Forest (Default)... Accuracy: 0.8667\n",
      "[4/13] Predicting with K-Nearest Neighbors (Default)... Accuracy: 0.8833\n",
      "[5/13] Predicting with Support Vector Machine (Default)... Accuracy: 0.9000\n",
      "[6/13] Predicting with AdaBoost (Default)... Accuracy: 0.8833\n",
      "[7/13] Predicting with Gradient Boosting (Default)... Accuracy: 0.8333\n",
      "[8/13] Predicting with Stacking + Linear Regression... Accuracy: 0.8833\n",
      "[9/13] Predicting with Stacking + Default MLP... Accuracy: 0.8833\n",
      "[10/13] Predicting with SEL-NNML (TPE)... Accuracy: 0.9167\n",
      "[11/13] Predicting with SEL-NNML (GP)... Accuracy: 0.9167\n",
      "[12/13] Predicting with SEL-NNML (CMA-ES)... Accuracy: 0.9333\n",
      "[13/13] Predicting with SEL-NNML (QMC)... Accuracy: 0.9333\n",
      "\n",
      "================================================================================\n",
      "âœ“ Generated predictions for all 13 models\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions from all 13 models on test set\n",
    "test_predictions = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENERATING TEST SET PREDICTIONS FOR MCNEMAR'S TEST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test set size: {len(y_test)}\")\n",
    "print()\n",
    "\n",
    "for idx, (name, model) in enumerate(models_for_ttest.items(), 1):\n",
    "    print(f\"[{idx}/13] Predicting with {name}...\", end=\" \", flush=True)\n",
    "    \n",
    "    # All models (baseline and optimized) were trained on the same X_train\n",
    "    # (which has both scaled numeric features and boolean features merged)\n",
    "    # So they all need X_test (not X_test_scaled which only has numeric features)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_predictions[name] = y_pred\n",
    "    accuracy = (y_pred == y_test).sum() / len(y_test)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ“ Generated predictions for all {len(test_predictions)} models\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.2 Perform McNemar's Tests**\n",
    "\n",
    "Compare SEL-NNML (TPE) against all other 12 models using McNemar's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MCNEMAR'S TEST: SEL-NNML (TPE) vs. ALL OTHER MODELS\n",
      "================================================================================\n",
      "Control Model: SEL-NNML (TPE)\n",
      "Test Set Size: 60\n",
      "Significance Level: Î± = 0.05\n",
      "================================================================================\n",
      "\n",
      "Model                                    b (Câœ“Oâœ—)     c (Câœ—Oâœ“)     Ï‡Â²         p-value      p (Bonf.)    Sig?    \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Logistic Regression (Default)                      3           1      0.250      0.6171      1.0000        âœ—\n",
      "Decision Tree (Default)                           10           4      1.786      0.1814      1.0000        âœ—\n",
      "Random Forest (Default)                            4           1      0.800      0.3711      1.0000        âœ—\n",
      "K-Nearest Neighbors (Default)                      4           2      0.167      0.6831      1.0000        âœ—\n",
      "Support Vector Machine (Default)                   2           1      0.000      1.0000      1.0000        âœ—\n",
      "AdaBoost (Default)                                 5           3      0.125      0.7237      1.0000        âœ—\n",
      "Gradient Boosting (Default)                        7           2      1.778      0.1824      1.0000        âœ—\n",
      "Stacking + Linear Regression                       3           1      0.250      0.6171      1.0000        âœ—\n",
      "Stacking + Default MLP                             3           1      0.250      0.6171      1.0000        âœ—\n",
      "SEL-NNML (GP)                                      0           0      0.000      1.0000      1.0000        âœ—\n",
      "SEL-NNML (CMA-ES)                                  1           2      0.000      1.0000      1.0000        âœ—\n",
      "SEL-NNML (QMC)                                     1           2      0.000      1.0000      1.0000        âœ—\n",
      "==============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def mcnemar_test(y_true, y_pred_a, y_pred_b):\n",
    "    \"\"\"\n",
    "    Perform McNemar's test for two classifiers.\n",
    "    \n",
    "    Returns:\n",
    "        - contingency table (2x2)\n",
    "        - chi-square statistic\n",
    "        - p-value\n",
    "    \"\"\"\n",
    "    # Create contingency table\n",
    "    # both_correct: both A and B correct\n",
    "    # a_correct_b_wrong: A correct, B wrong\n",
    "    # a_wrong_b_correct: A wrong, B correct\n",
    "    # both_wrong: both A and B wrong\n",
    "    \n",
    "    both_correct = ((y_pred_a == y_true) & (y_pred_b == y_true)).sum()\n",
    "    a_correct_b_wrong = ((y_pred_a == y_true) & (y_pred_b != y_true)).sum()\n",
    "    a_wrong_b_correct = ((y_pred_a != y_true) & (y_pred_b == y_true)).sum()\n",
    "    both_wrong = ((y_pred_a != y_true) & (y_pred_b != y_true)).sum()\n",
    "    \n",
    "    # Contingency table\n",
    "    table = np.array([[both_correct, a_correct_b_wrong],\n",
    "                      [a_wrong_b_correct, both_wrong]])\n",
    "    \n",
    "    # McNemar's test statistic with continuity correction\n",
    "    b = a_correct_b_wrong\n",
    "    c = a_wrong_b_correct\n",
    "    \n",
    "    # Chi-square test statistic (with continuity correction)\n",
    "    if b + c > 0:\n",
    "        chi2_stat = (abs(b - c) - 1)**2 / (b + c)\n",
    "    else:\n",
    "        chi2_stat = 0.0\n",
    "    \n",
    "    # p-value from chi-square distribution (df=1)\n",
    "    p_value = 1 - chi2.cdf(chi2_stat, df=1)\n",
    "    \n",
    "    return table, chi2_stat, p_value, b, c\n",
    "\n",
    "# Control model\n",
    "control_pred = test_predictions[CONTROL_MODEL]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"MCNEMAR'S TEST: {CONTROL_MODEL} vs. ALL OTHER MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Control Model: {CONTROL_MODEL}\")\n",
    "print(f\"Test Set Size: {len(y_test)}\")\n",
    "print(f\"Significance Level: Î± = {ALPHA}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "mcnemar_results = []\n",
    "\n",
    "for name, pred in test_predictions.items():\n",
    "    if name == CONTROL_MODEL:\n",
    "        continue\n",
    "    \n",
    "    table, chi2_stat, p_value, b, c = mcnemar_test(y_test.values, control_pred, pred)\n",
    "    \n",
    "    # Bonferroni correction\n",
    "    p_bonf = min(1.0, p_value * n_comparisons)\n",
    "    is_significant = p_bonf < ALPHA\n",
    "    \n",
    "    mcnemar_results.append({\n",
    "        'Model': name,\n",
    "        'Both Correct': table[0, 0],\n",
    "        'Control Right, Other Wrong': b,\n",
    "        'Control Wrong, Other Right': c,\n",
    "        'Both Wrong': table[1, 1],\n",
    "        'Chi-Square': chi2_stat,\n",
    "        'p-value': p_value,\n",
    "        'p-value (Bonferroni)': p_bonf,\n",
    "        'Significant (Î±=0.05)': is_significant\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "mcnemar_df = pd.DataFrame(mcnemar_results).sort_values('p-value (Bonferroni)')\n",
    "\n",
    "print(f\"{'Model':<40} {'b (Câœ“Oâœ—)':<12} {'c (Câœ—Oâœ“)':<12} {'Ï‡Â²':<10} {'p-value':<12} {'p (Bonf.)':<12} {'Sig?':<8}\")\n",
    "print(\"-\"*110)\n",
    "\n",
    "for _, row in mcnemar_df.iterrows():\n",
    "    sig_marker = \"âœ“\" if row['Significant (Î±=0.05)'] else \"âœ—\"\n",
    "    print(f\"{row['Model']:<40} {row['Control Right, Other Wrong']:>11} {row['Control Wrong, Other Right']:>11} \"\n",
    "          f\"{row['Chi-Square']:>10.3f} {row['p-value']:>11.4f} {row['p-value (Bonferroni)']:>11.4f} {sig_marker:>8}\")\n",
    "\n",
    "print(\"=\"*110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.3 Contingency Table Visualization**\n",
    "\n",
    "Visualize the contingency tables for significant comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš  No significant comparisons found (p < 0.05 after Bonferroni correction)\n",
      "   Contingency table visualization skipped.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get top 5 most significant comparisons (or all if fewer than 5)\n",
    "sig_comparisons = mcnemar_df[mcnemar_df['Significant (Î±=0.05)']].head(5)\n",
    "\n",
    "if len(sig_comparisons) > 0:\n",
    "    n_plots = len(sig_comparisons)\n",
    "    n_cols = min(3, n_plots)\n",
    "    n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    if n_plots == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if n_rows > 1 else axes\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sig_comparisons.iterrows()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Create contingency table\n",
    "        table_data = np.array([\n",
    "            [row['Both Correct'], row['Control Right, Other Wrong']],\n",
    "            [row['Control Wrong, Other Right'], row['Both Wrong']]\n",
    "        ])\n",
    "        \n",
    "        # Plot heatmap\n",
    "        sns.heatmap(table_data, annot=True, fmt='d', cmap='Blues', \n",
    "                    cbar=True, ax=ax, annot_kws={'size': 14, 'weight': 'bold'},\n",
    "                    xticklabels=['Other Correct', 'Other Wrong'],\n",
    "                    yticklabels=['Control Correct', 'Control Wrong'])\n",
    "        \n",
    "        ax.set_title(f\"{CONTROL_MODEL} vs. {row['Model']}\\n\"\n",
    "                     f\"Ï‡Â²={row['Chi-Square']:.3f}, p={row['p-value (Bonferroni)']:.4f}\",\n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Other Model', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('Control Model', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_plots, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nâœ“ Displayed contingency tables for {len(sig_comparisons)} significant comparison(s)\")\n",
    "else:\n",
    "    print(\"\\nâš  No significant comparisons found (p < 0.05 after Bonferroni correction)\")\n",
    "    print(\"   Contingency table visualization skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.4 Summary and Interpretation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MCNEMAR'S TEST SUMMARY\n",
      "================================================================================\n",
      "Control Model: SEL-NNML (TPE)\n",
      "Test Set Size: 60\n",
      "Total Comparisons: 12\n",
      "Significance Level: Î± = 0.05 (Bonferroni-corrected)\n",
      "\n",
      "Results:\n",
      "  âœ“ Significantly Different From:   0/12 models\n",
      "    - Control Better:                0\n",
      "    - Control Worse:                 0\n",
      "  â‰ˆ No Significant Difference:       12/12 models\n",
      "\n",
      "\n",
      "Interpretation:\n",
      "  - 'b' (Control Right, Other Wrong): Instances where control is correct but other model is wrong\n",
      "  - 'c' (Control Wrong, Other Right): Instances where control is wrong but other model is correct\n",
      "  - If b >> c: Control makes fewer errors â†’ control is better\n",
      "  - If c >> b: Other model makes fewer errors â†’ other model is better\n",
      "  - If b â‰ˆ c: Models make different but equal errors â†’ no significant difference\n",
      "================================================================================\n",
      "\n",
      "DETAILED RESULTS TABLE:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Both Correct",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Control Right, Other Wrong",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Control Wrong, Other Right",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Both Wrong",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Chi-Square",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value (Bonferroni)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Significant (Î±=0.05)",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "d67df3b9-fa79-4ace-8ccc-494cb7ca6ebb",
       "rows": [
        [
         "0",
         "Logistic Regression (Default)",
         "52",
         "3",
         "1",
         "4",
         "0.25",
         "0.6170750774519739",
         "1.0",
         "False"
        ],
        [
         "1",
         "Decision Tree (Default)",
         "45",
         "10",
         "4",
         "1",
         "1.7857142857142858",
         "0.18144920772142004",
         "1.0",
         "False"
        ],
        [
         "2",
         "Random Forest (Default)",
         "51",
         "4",
         "1",
         "4",
         "0.8",
         "0.37109336952269756",
         "1.0",
         "False"
        ],
        [
         "3",
         "K-Nearest Neighbors (Default)",
         "51",
         "4",
         "2",
         "3",
         "0.16666666666666666",
         "0.6830913983096086",
         "1.0",
         "False"
        ],
        [
         "4",
         "Support Vector Machine (Default)",
         "53",
         "2",
         "1",
         "4",
         "0.0",
         "1.0",
         "1.0",
         "False"
        ],
        [
         "5",
         "AdaBoost (Default)",
         "50",
         "5",
         "3",
         "2",
         "0.125",
         "0.7236736098317629",
         "1.0",
         "False"
        ],
        [
         "6",
         "Gradient Boosting (Default)",
         "48",
         "7",
         "2",
         "3",
         "1.7777777777777777",
         "0.18242243945173597",
         "1.0",
         "False"
        ],
        [
         "7",
         "Stacking + Linear Regression",
         "52",
         "3",
         "1",
         "4",
         "0.25",
         "0.6170750774519739",
         "1.0",
         "False"
        ],
        [
         "8",
         "Stacking + Default MLP",
         "52",
         "3",
         "1",
         "4",
         "0.25",
         "0.6170750774519739",
         "1.0",
         "False"
        ],
        [
         "9",
         "SEL-NNML (GP)",
         "55",
         "0",
         "0",
         "5",
         "0.0",
         "1.0",
         "1.0",
         "False"
        ],
        [
         "10",
         "SEL-NNML (CMA-ES)",
         "54",
         "1",
         "2",
         "3",
         "0.0",
         "1.0",
         "1.0",
         "False"
        ],
        [
         "11",
         "SEL-NNML (QMC)",
         "54",
         "1",
         "2",
         "3",
         "0.0",
         "1.0",
         "1.0",
         "False"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Both Correct</th>\n",
       "      <th>Control Right, Other Wrong</th>\n",
       "      <th>Control Wrong, Other Right</th>\n",
       "      <th>Both Wrong</th>\n",
       "      <th>Chi-Square</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value (Bonferroni)</th>\n",
       "      <th>Significant (Î±=0.05)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Default)</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree (Default)</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.181449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (Default)</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.371093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors (Default)</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.683091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine (Default)</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost (Default)</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.723674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting (Default)</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.182422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking + Linear Regression</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stacking + Default MLP</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEL-NNML (GP)</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SEL-NNML (CMA-ES)</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SEL-NNML (QMC)</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Both Correct  \\\n",
       "0      Logistic Regression (Default)            52   \n",
       "1            Decision Tree (Default)            45   \n",
       "2            Random Forest (Default)            51   \n",
       "3      K-Nearest Neighbors (Default)            51   \n",
       "4   Support Vector Machine (Default)            53   \n",
       "5                 AdaBoost (Default)            50   \n",
       "6        Gradient Boosting (Default)            48   \n",
       "7       Stacking + Linear Regression            52   \n",
       "8             Stacking + Default MLP            52   \n",
       "9                      SEL-NNML (GP)            55   \n",
       "10                 SEL-NNML (CMA-ES)            54   \n",
       "11                    SEL-NNML (QMC)            54   \n",
       "\n",
       "    Control Right, Other Wrong  Control Wrong, Other Right  Both Wrong  \\\n",
       "0                            3                           1           4   \n",
       "1                           10                           4           1   \n",
       "2                            4                           1           4   \n",
       "3                            4                           2           3   \n",
       "4                            2                           1           4   \n",
       "5                            5                           3           2   \n",
       "6                            7                           2           3   \n",
       "7                            3                           1           4   \n",
       "8                            3                           1           4   \n",
       "9                            0                           0           5   \n",
       "10                           1                           2           3   \n",
       "11                           1                           2           3   \n",
       "\n",
       "    Chi-Square   p-value  p-value (Bonferroni)  Significant (Î±=0.05)  \n",
       "0     0.250000  0.617075                   1.0                 False  \n",
       "1     1.785714  0.181449                   1.0                 False  \n",
       "2     0.800000  0.371093                   1.0                 False  \n",
       "3     0.166667  0.683091                   1.0                 False  \n",
       "4     0.000000  1.000000                   1.0                 False  \n",
       "5     0.125000  0.723674                   1.0                 False  \n",
       "6     1.777778  0.182422                   1.0                 False  \n",
       "7     0.250000  0.617075                   1.0                 False  \n",
       "8     0.250000  0.617075                   1.0                 False  \n",
       "9     0.000000  1.000000                   1.0                 False  \n",
       "10    0.000000  1.000000                   1.0                 False  \n",
       "11    0.000000  1.000000                   1.0                 False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "sig_count_mcnemar = mcnemar_df['Significant (Î±=0.05)'].sum()\n",
    "\n",
    "# Models where control is significantly better (b > c and significant)\n",
    "control_better = mcnemar_df[\n",
    "    (mcnemar_df['Significant (Î±=0.05)']) & \n",
    "    (mcnemar_df['Control Right, Other Wrong'] > mcnemar_df['Control Wrong, Other Right'])\n",
    "]\n",
    "\n",
    "# Models where other is significantly better (c > b and significant)\n",
    "control_worse = mcnemar_df[\n",
    "    (mcnemar_df['Significant (Î±=0.05)']) & \n",
    "    (mcnemar_df['Control Wrong, Other Right'] > mcnemar_df['Control Right, Other Wrong'])\n",
    "]\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"MCNEMAR'S TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Control Model: {CONTROL_MODEL}\")\n",
    "print(f\"Test Set Size: {len(y_test)}\")\n",
    "print(f\"Total Comparisons: {n_comparisons}\")\n",
    "print(f\"Significance Level: Î± = {ALPHA} (Bonferroni-corrected)\")\n",
    "print()\n",
    "print(\"Results:\")\n",
    "print(f\"  âœ“ Significantly Different From:   {sig_count_mcnemar}/{n_comparisons} models\")\n",
    "print(f\"    - Control Better:                {len(control_better)}\")\n",
    "print(f\"    - Control Worse:                 {len(control_worse)}\")\n",
    "print(f\"  â‰ˆ No Significant Difference:       {n_comparisons - sig_count_mcnemar}/{n_comparisons} models\")\n",
    "print()\n",
    "\n",
    "if len(control_better) > 0:\n",
    "    print(\"Models Significantly Outperformed by Control:\")\n",
    "    for _, row in control_better.iterrows():\n",
    "        b = row['Control Right, Other Wrong']\n",
    "        c = row['Control Wrong, Other Right']\n",
    "        print(f\"  â€¢ {row['Model']:<45} (b={b}, c={c}, Ï‡Â²={row['Chi-Square']:.3f}, p={row['p-value (Bonferroni)']:.4f})\")\n",
    "\n",
    "if len(control_worse) > 0:\n",
    "    print()\n",
    "    print(\"Models That Significantly Outperformed Control:\")\n",
    "    for _, row in control_worse.iterrows():\n",
    "        b = row['Control Right, Other Wrong']\n",
    "        c = row['Control Wrong, Other Right']\n",
    "        print(f\"  â€¢ {row['Model']:<45} (b={b}, c={c}, Ï‡Â²={row['Chi-Square']:.3f}, p={row['p-value (Bonferroni)']:.4f})\")\n",
    "\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(\"  - 'b' (Control Right, Other Wrong): Instances where control is correct but other model is wrong\")\n",
    "print(\"  - 'c' (Control Wrong, Other Right): Instances where control is wrong but other model is correct\")\n",
    "print(\"  - If b >> c: Control makes fewer errors â†’ control is better\")\n",
    "print(\"  - If c >> b: Other model makes fewer errors â†’ other model is better\")\n",
    "print(\"  - If b â‰ˆ c: Models make different but equal errors â†’ no significant difference\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Display full results table\n",
    "print(\"DETAILED RESULTS TABLE:\")\n",
    "print(\"=\"*80)\n",
    "display(mcnemar_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.5 Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ McNemar's test results saved to: ../artifacts/ds2/models\\mcnemar_test_results.csv\n",
      "âœ“ Test predictions saved to: ../artifacts/ds2/models\\test_predictions_for_mcnemar.csv\n",
      "âœ“ McNemar summary statistics saved to: ../artifacts/ds2/models\\mcnemar_summary.csv\n",
      "\n",
      "================================================================================\n",
      "âœ… MCNEMAR'S TEST COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save McNemar's test results\n",
    "mcnemar_results_path = os.path.join(output_dir, 'mcnemar_test_results.csv')\n",
    "mcnemar_df.to_csv(mcnemar_results_path, index=False)\n",
    "print(f\"âœ“ McNemar's test results saved to: {mcnemar_results_path}\")\n",
    "\n",
    "# Save test predictions for reproducibility\n",
    "test_pred_data = []\n",
    "for model_name, predictions in test_predictions.items():\n",
    "    for idx, pred in enumerate(predictions):\n",
    "        test_pred_data.append({\n",
    "            'Model': model_name,\n",
    "            'Instance_Index': idx,\n",
    "            'Prediction': pred,\n",
    "            'True_Label': y_test.iloc[idx]\n",
    "        })\n",
    "\n",
    "test_pred_df = pd.DataFrame(test_pred_data)\n",
    "test_pred_path = os.path.join(output_dir, 'test_predictions_for_mcnemar.csv')\n",
    "test_pred_df.to_csv(test_pred_path, index=False)\n",
    "print(f\"âœ“ Test predictions saved to: {test_pred_path}\")\n",
    "\n",
    "# Save McNemar summary statistics\n",
    "mcnemar_summary = {\n",
    "    'Control_Model': CONTROL_MODEL,\n",
    "    'Test_Set_Size': len(y_test),\n",
    "    'Total_Comparisons': n_comparisons,\n",
    "    'Significant_Differences': sig_count_mcnemar,\n",
    "    'Control_Better': len(control_better),\n",
    "    'Control_Worse': len(control_worse),\n",
    "    'No_Significant_Difference': n_comparisons - sig_count_mcnemar,\n",
    "    'Significance_Level': ALPHA\n",
    "}\n",
    "\n",
    "mcnemar_summary_df = pd.DataFrame([mcnemar_summary])\n",
    "mcnemar_summary_path = os.path.join(output_dir, 'mcnemar_summary.csv')\n",
    "mcnemar_summary_df.to_csv(mcnemar_summary_path, index=False)\n",
    "print(f\"âœ“ McNemar summary statistics saved to: {mcnemar_summary_path}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… MCNEMAR'S TEST COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sel_nnml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
